[
  {
    "input": "Let x=[3,0,4], y=[0,5,0]. Are they orthogonal?",
    "output": "import numpy as np\nx = np.array([3,0,4])\ny = np.array([0,5,0])\nprint(\"Orthogonal:\", np.dot(x,y) == 0)"
  },
  {
    "input": "Let f(x)=x on [0,1]. Find unit function g(x) = af(x).",
    "output": "from scipy.integrate import quad\nimport numpy as np\nnorm = np.sqrt(quad(lambda x: x**2, 0, 1)[0])\nprint(\"a:\", 1/norm)"
  },
  {
    "input": "Check if \u27e8x,x\u27e9 = 0 implies x = 0 for x=[0,0].",
    "output": "import numpy as np\nx = np.array([0,0])\nprint(\"Implication valid:\", np.dot(x,x) == 0)"
  },
  {
    "input": "Let x=[1,0,0], y=[0,1,0], z=[0,0,1]. Are they orthogonal?",
    "output": "import numpy as np\nx = np.array([1,0,0])\ny = np.array([0,1,0])\nz = np.array([0,0,1])\nprint(\"All orthogonal:\", np.dot(x,y) == 0 and np.dot(y,z) == 0 and np.dot(z,x) == 0)"
  },
  {
    "input": "Is \u27e8x,y\u27e9 = x\u2081y\u2081 + x\u2082y\u2082 \u2212 x\u2083y\u2083 an inner product on \u211d\u00b3?",
    "output": "print(\"No, because it may not be positive definite.\")"
  },
  {
    "input": "Find the projection of x=[2,1] on y=[1,0].",
    "output": "import numpy as np\nx = np.array([2,1])\ny = np.array([1,0])\nproj = (np.dot(x,y)/np.dot(y,y)) * y\nprint(\"Projection:\", proj)"
  },
  {
    "input": "Let f(x)=1, g(x)=x\u00b2 on [0,1]. Are f and g orthogonal?",
    "output": "from scipy.integrate import quad\ninner = quad(lambda x: 1 * x**2, 0, 1)[0]\nprint(\"Orthogonal:\", inner == 0)"
  },
  {
    "input": "Prove ||x\u2212y||\u00b2 = ||x||\u00b2 + ||y||\u00b2 \u2212 2\u27e8x,y\u27e9 for x=[1,2], y=[3,4].",
    "output": "import numpy as np\nx = np.array([1,2])\ny = np.array([3,4])\nprint(\"Equality holds:\", np.isclose(np.linalg.norm(x - y)**2, np.dot(x,x) + np.dot(y,y) - 2*np.dot(x,y)))"
  },
  {
    "input": "Find norm of f(x) = e^x over [0,1].",
    "output": "from scipy.integrate import quad\nimport numpy as np\nnorm = np.sqrt(quad(lambda x: np.exp(x)**2, 0, 1)[0])\nprint(\"Norm:\", norm)"
  },
  {
    "input": "Can inner product \u27e8x,y\u27e9 = x\u2081y\u2081 + x\u2082y\u2082 + 4x\u2083y\u2083 define a norm?",
    "output": "print(\"Yes, it satisfies inner product properties, so norm exists.\")"
  },
  {
    "input": "If \u27e8x,y\u27e9 = 0 and x\u22600, can y be a scalar multiple of x?",
    "output": "print(\"No, scalar multiples are not orthogonal unless zero.\")"
  },
  {
    "input": "Verify that ||x|| \u2265 0 and equality holds only if x=0 for x=[0,0,0].",
    "output": "import numpy as np\nx = np.array([0,0,0])\nprint(\"Property holds:\", np.linalg.norm(x) == 0)"
  },
  {
    "input": "Compute angle between vectors [2,0] and [1,1].",
    "output": "import numpy as np\nx = np.array([2,0])\ny = np.array([1,1])\ncos_theta = np.dot(x,y)/(np.linalg.norm(x)*np.linalg.norm(y))\nangle = np.arccos(cos_theta)\nprint(\"Angle (radians):\", angle)"
  },
  {
    "input": "If \u27e8x,y\u27e9 = \u27e8x,x\u27e9 for all y, what is x?",
    "output": "print(\"Only possible if x = 0.\")"
  },
  {
    "input": "Compute inner product in \u211d\u2074 for x=[1,2,0,3], y=[4,0,1,1].",
    "output": "import numpy as np\nx = np.array([1,2,0,3])\ny = np.array([4,0,1,1])\nprint(\"Inner product:\", np.dot(x,y))"
  },
  {
    "input": "Is norm ||x|| = |x\u2081| + |x\u2082| induced by inner product?",
    "output": "print(\"No, L1 norm is not induced by an inner product.\")"
  },
  {
    "input": "Find the L2 norm of sin(x) + cos(x) over [0,\u03c0].",
    "output": "from scipy.integrate import quad\nimport numpy as np\nnorm = np.sqrt(quad(lambda x: (np.sin(x) + np.cos(x))**2, 0, np.pi)[0])\nprint(\"Norm:\", norm)"
  },
  {
    "input": "Find value of a so that \u27e8[1,a],[a,1]\u27e9 = 0.",
    "output": "from sympy import symbols, solve\nx = symbols('x')\nsol = solve(1*x + x*1, x)\nprint(\"a:\", sol)"
  },
  {
    "input": "Check if Cauchy-Schwarz holds for x=[1,3], y=[2,2].",
    "output": "import numpy as np\nx = np.array([1,3])\ny = np.array([2,2])\ncs = abs(np.dot(x,y)) <= np.linalg.norm(x) * np.linalg.norm(y)\nprint(\"Cauchy-Schwarz holds:\", cs)"
  },
  {
    "input": "Let f(x)=x\u00b2\u22121, g(x)=x on [\u22121,1]. Compute \u27e8f,g\u27e9.",
    "output": "from scipy.integrate import quad\ninner = quad(lambda x: (x**2 - 1)*x, -1, 1)[0]\nprint(\"Inner product:\", inner)"
  },
  {
    "input": "Are [1,0,0] and [0,1,1] orthogonal?",
    "output": "import numpy as np\nx = np.array([1,0,0])\ny = np.array([0,1,1])\nprint(\"Orthogonal:\", np.dot(x,y) == 0)"
  },
  {
    "input": "If f(x)=x\u00b2, compute norm over [0,2].",
    "output": "from scipy.integrate import quad\nnorm = quad(lambda x: x**4, 0, 2)[0]**0.5\nprint(\"Norm:\", norm)"
  },
  {
    "input": "If norm of x is 5, what is norm of 2x?",
    "output": "print(\"Norm is 10.\")"
  },
  {
    "input": "Show \u27e8x,x\u27e9 = 0 implies x=0 in inner product space.",
    "output": "print(\"Follows from positive-definiteness.\")"
  },
  {
    "input": "Find scalar c minimizing ||x \u2212 cy||\u00b2 for x=[1,2], y=[3,4].",
    "output": "import numpy as np\nx = np.array([1,2])\ny = np.array([3,4])\nc = np.dot(x,y)/np.dot(y,y)\nprint(\"Optimal c:\", c)"
  },
  {
    "input": "Is \u27e8x,y\u27e9 = 2x\u2081y\u2081 + x\u2082y\u2082 + x\u2083y\u2083 a valid inner product on \u211d\u00b3?",
    "output": "print(\"Yes, as it satisfies symmetry, linearity, and positive-definiteness.\")"
  },
  {
    "input": "If ||x+y||\u00b2 = ||x||\u00b2 + ||y||\u00b2, what does that say about x and y?",
    "output": "print(\"x and y are orthogonal.\")"
  },
  {
    "input": "Check orthogonality of f(x)=x and g(x)=1\u2212x over [0,1].",
    "output": "from scipy.integrate import quad\ninner = quad(lambda x: x*(1-x), 0, 1)[0]\nprint(\"Orthogonal:\", inner == 0)"
  },
  {
    "input": "Find norm of vector [3,\u22124,1] in \u211d\u00b3.",
    "output": "import numpy as np\nx = np.array([3,-4,1])\nprint(\"Norm:\", np.linalg.norm(x))"
  },
  {
    "input": "For what a is x=[1,a] orthogonal to y=[a,\u22121]?",
    "output": "from sympy import symbols, solve, Eq\nx = symbols('x')\nexpr = 1*x + x*(-1)\nsol = solve(expr, x)\n\nif expr == 0:\n    print(\"a: All real numbers (identity)\")\nelif not sol:\n    print(\"a: No solution\")\nelse:\n    print(\"a:\", sol)"
  },
  {
    "input": "Find inner product of [1,2,3] and [4,5,6].",
    "output": "import numpy as np\nx = np.array([1,2,3])\ny = np.array([4,5,6])\nprint(\"Inner product:\", np.dot(x,y))"
  },
  {
    "input": "If x and y are orthogonal, is x+y orthogonal to x\u2212y?",
    "output": "import numpy as np\nx = np.array([1, 0])\ny = np.array([0, 1])\nprint(\"Orthogonal:\", np.dot(x + y, x - y) == 0)"
  },
  {
    "input": "Find the projection of x=[3,4] onto y=[1,1].",
    "output": "import numpy as np\nx = np.array([3,4])\ny = np.array([1,1])\nproj = (np.dot(x,y)/np.dot(y,y))*y\nprint(\"Projection:\", proj)"
  },
  {
    "input": "Can \u27e8x,y\u27e9 = x\u2081y\u2081 + x\u2082y\u2082 + 2x\u2081y\u2082 be an inner product?",
    "output": "print(\"No, it is not symmetric.\")"
  },
  {
    "input": "Find angle between [1,0] and [0,1] in degrees.",
    "output": "import numpy as np\nx = np.array([1,0])\ny = np.array([0,1])\nangle = np.degrees(np.arccos(np.dot(x,y)/(np.linalg.norm(x)*np.linalg.norm(y))))\nprint(\"Angle:\", angle)"
  },
  {
    "input": "Is the zero function orthogonal to all functions in L\u00b2[0,1]?",
    "output": "print(\"Yes, its inner product with all is zero.\")"
  },
  {
    "input": "Find norm of f(x)=x on [0,2] with inner product \u222bf(x)\u00b2 dx.",
    "output": "from scipy.integrate import quad\nnorm = quad(lambda x: x**2, 0, 2)[0]**0.5\nprint(\"Norm:\", norm)"
  },
  {
    "input": "Can \u27e8x,y\u27e9 = x\u2081y\u2082 + x\u2082y\u2081 be an inner product on \u211d\u00b2?",
    "output": "print(\"No, not positive definite.\")"
  },
  {
    "input": "Verify ||x|| = sqrt(\u27e8x,x\u27e9) for x=[5,12].",
    "output": "import numpy as np\nx = np.array([5,12])\nprint(\"Holds:\", np.linalg.norm(x) == np.sqrt(np.dot(x,x)))"
  },
  {
    "input": "Given x=[2,1], y=[3,4], find scalar c minimizing ||x\u2212cy||\u00b2.",
    "output": "import numpy as np\nx = np.array([2,1])\ny = np.array([3,4])\nc = np.dot(x,y)/np.dot(y,y)\nprint(\"c:\", c)"
  },
  {
    "input": "Find ||x+y||\u00b2 \u2212 ||x||\u00b2 \u2212 ||y||\u00b2 for x=[1,2], y=[3,4].",
    "output": "import numpy as np\nx = np.array([1,2])\ny = np.array([3,4])\ndiff = np.linalg.norm(x+y)**2 - np.linalg.norm(x)**2 - np.linalg.norm(y)**2\nprint(\"Value:\", diff)"
  },
  {
    "input": "True or False: Every norm is induced by an inner product.",
    "output": "print(\"False. Only Hilbert norms are.\")"
  },
  {
    "input": "If ||x+y|| = ||x|| + ||y||, what can you say?",
    "output": "print(\"x and y are linearly dependent and in same direction.\")"
  },
  {
    "input": "Find ||f|| where f(x)=1\u22122x on [0,1].",
    "output": "from scipy.integrate import quad\nimport numpy as np\nnorm = np.sqrt(quad(lambda x: (1-2*x)**2, 0, 1)[0])\nprint(\"Norm:\", norm)"
  },
  {
    "input": "Prove symmetry of dot product using x=[1,2], y=[3,4].",
    "output": "import numpy as np\nx = np.array([1,2])\ny = np.array([3,4])\nprint(\"Symmetric:\", np.dot(x,y) == np.dot(y,x))"
  },
  {
    "input": "What does norm of a vector represent geometrically?",
    "output": "print(\"Length or magnitude of the vector.\")"
  },
  {
    "input": "Is \u27e8f,g\u27e9 = \u222b\u2080\u00b9 f(x)g(x)dx an inner product?",
    "output": "print(\"Yes, standard inner product in L\u00b2[0,1].\")"
  },
  {
    "input": "Find the L\u00b2 norm of f(x)=cos(\u03c0x) on [0,1].",
    "output": "from scipy.integrate import quad\nimport numpy as np\nnorm = np.sqrt(quad(lambda x: np.cos(np.pi*x)**2, 0, 1)[0])\nprint(\"Norm:\", norm)"
  },
  {
    "input": "Check if triangle inequality holds for x=[1,2], y=[\u22121,3].",
    "output": "import numpy as np\nx = np.array([1,2])\ny = np.array([-1,3])\nineq = np.linalg.norm(x+y) <= np.linalg.norm(x) + np.linalg.norm(y)\nprint(\"Triangle inequality holds:\", ineq)"
  },
  {
    "input": "For x=[3,0,4], what is unit vector in same direction?",
    "output": "import numpy as np\nx = np.array([3,0,4])\nunit = x / np.linalg.norm(x)\nprint(\"Unit vector:\", unit)"
  },
  {
    "input": "Find the orthogonal complement of span{[1,2]} in \u211d\u00b2.",
    "output": "import numpy as np\nv = np.array([1,2])\northogonal = np.array([-v[1], v[0]])\nprint(\"Orthogonal complement basis:\", orthogonal)"
  },
  {
    "input": "Let V = \u211d\u00b3. Define \u27e8x,y\u27e9 = x\u2081y\u2081 + 2x\u2082y\u2082 + 3x\u2083y\u2083. Is this valid?",
    "output": "print(\"Yes, it satisfies all inner product properties.\")"
  },
  {
    "input": "Prove ||x\u2212y||\u00b2 = ||x||\u00b2 + ||y||\u00b2 \u2212 2\u27e8x,y\u27e9 for x=[1,2], y=[3,4].",
    "output": "import numpy as np\nx = np.array([1,2])\ny = np.array([3,4])\nLHS = np.linalg.norm(x - y)**2\nRHS = np.linalg.norm(x)**2 + np.linalg.norm(y)**2 - 2*np.dot(x,y)\nprint(\"Equality holds:\", np.isclose(LHS, RHS))"
  },
  {
    "input": "Find the norm of f(x)=x\u00b2 over [0,1] in L\u00b2 norm.",
    "output": "from scipy.integrate import quad\nimport numpy as np\nnorm = np.sqrt(quad(lambda x: x**4, 0, 1)[0])\nprint(\"Norm:\", norm)"
  },
  {
    "input": "Determine if \u27e8x,y\u27e9 = |x||y| is an inner product.",
    "output": "print(\"No, it is not linear and not positive definite.\")"
  },
  {
    "input": "If \u27e8x,y\u27e9 = x\u1d40Ay, find A such that it's a valid inner product.",
    "output": "print(\"A must be symmetric positive definite matrix.\")"
  },
  {
    "input": "For unit vectors x and y, what is max and min of \u27e8x,y\u27e9?",
    "output": "print(\"Maximum is 1 (same direction), minimum is -1 (opposite).\")"
  },
  {
    "input": "Check if projection of x=[4,3] on y=[1,0] lies on x-axis.",
    "output": "import numpy as np\nx = np.array([4,3])\ny = np.array([1,0])\nproj = (np.dot(x,y)/np.dot(y,y))*y\nprint(\"Projection lies on x-axis:\", proj[1] == 0)"
  },
  {
    "input": "Find an orthonormal basis from vectors [1,1,0] and [1,0,1].",
    "output": "from numpy.linalg import norm\nimport numpy as np\nv1 = np.array([1,1,0])\ne1 = v1 / norm(v1)\nv2 = np.array([1,0,1]) - np.dot(np.array([1,0,1]), e1) * e1\ne2 = v2 / norm(v2)\nprint(\"Orthonormal basis:\", e1, e2)"
  },
  {
    "input": "What is the value of inner product of vector with itself?",
    "output": "print(\"It is the square of its norm.\")"
  },
  {
    "input": "Can \u27e8x,y\u27e9 = x\u2081y\u2082 + x\u2082y\u2081 be symmetric?",
    "output": "print(\"Yes, it is symmetric but not an inner product.\")"
  },
  {
    "input": "If ||x+y||\u00b2 = ||x||\u00b2 + ||y||\u00b2 + 2\u27e8x,y\u27e9, derive inner product.",
    "output": "print(\"\u27e8x,y\u27e9 = (||x+y||\u00b2 - ||x||\u00b2 - ||y||\u00b2)/2\")"
  },
  {
    "input": "Prove \u27e8x,x\u27e9 \u2265 0 and = 0 iff x=0.",
    "output": "print(\"By positive definiteness property of inner product.\")"
  },
  {
    "input": "Given f(x)=x and g(x)=x\u00b2, find \u27e8f,g\u27e9 over [0,1].",
    "output": "from scipy.integrate import quad\nprint(\"Inner product:\", quad(lambda x: x*x**2, 0, 1)[0])"
  },
  {
    "input": "In \u211d\u207f with standard inner product, what's the induced norm?",
    "output": "print(\"Euclidean norm: sqrt(sum of squares)\")"
  },
  {
    "input": "True or False: All orthogonal vectors are linearly independent.",
    "output": "print(\"True, if none of them is zero vector.\")"
  },
  {
    "input": "Let f(x)=sin(\u03c0x) and g(x)=cos(\u03c0x), are they orthogonal?",
    "output": "from scipy.integrate import quad\nimport numpy as np\nval = quad(lambda x: np.sin(np.pi*x)*np.cos(np.pi*x), 0, 1)[0]\nprint(\"Orthogonal:\", np.isclose(val, 0))"
  },
  {
    "input": "If x\u00b7y = 0 and x \u2260 0, what can you say about y?",
    "output": "print(\"y lies in the orthogonal complement of x.\")"
  },
  {
    "input": "Determine if inner product \u27e8x,y\u27e9 = x\u2081y\u2081 \u2212 x\u2082y\u2082 is valid.",
    "output": "print(\"No, it is not positive definite.\")"
  },
  {
    "input": "Find norm of x=[1,2,2] using dot product.",
    "output": "import numpy as np\nx = np.array([1,2,2])\nprint(\"Norm:\", np.sqrt(np.dot(x,x)))"
  },
  {
    "input": "Find \u27e8x,y\u27e9 if x=[2,\u22121,0], y=[1,1,3].",
    "output": "import numpy as np\nx = np.array([2,-1,0])\ny = np.array([1,1,3])\nprint(\"Inner product:\", np.dot(x,y))"
  },
  {
    "input": "If norm is 1, what type of vector is it?",
    "output": "print(\"It is a unit vector.\")"
  },
  {
    "input": "If u,v are orthogonal unit vectors, find ||u+v||.",
    "output": "import numpy as np\nprint(\"Norm of sum:\", np.linalg.norm([1,0]) + np.linalg.norm([0,1]))"
  },
  {
    "input": "Given vectors u = [3, 4] and v = [1, 2], compute the orthogonal projection of v onto u.",
    "output": "import numpy as np\nu = np.array([3, 4])\nv = np.array([1, 2])\nprojection = (np.dot(v, u) / np.dot(u, u)) * u\nprint(projection)"
  },
  {
    "input": "Find the orthogonal projection of vector v = [2, -1, 3] onto vector u = [1, 0, 0].",
    "output": "import numpy as np\nu = np.array([1, 0, 0])\nv = np.array([2, -1, 3])\nprojection = (np.dot(v, u) / np.dot(u, u)) * u\nprint(projection)"
  },
  {
    "input": "Compute the orthogonal projection of vector v = [4, 1] onto vector u = [0, 2].",
    "output": "import numpy as np\nu = np.array([0, 2])\nv = np.array([4, 1])\nprojection = (np.dot(v, u) / np.dot(u, u)) * u\nprint(projection)"
  },
  {
    "input": "Determine the orthogonal projection of vector v = [3, 5, 2] onto vector u = [0, 0, 1].",
    "output": "import numpy as np\nu = np.array([0, 0, 1])\nv = np.array([3, 5, 2])\nprojection = (np.dot(v, u) / np.dot(u, u)) * u\nprint(projection)"
  },
  {
    "input": "Find the orthogonal projection of vector v = [1, 2, 2] onto vector u = [2, 1, 1].",
    "output": "import numpy as np\nu = np.array([2, 1, 1])\nv = np.array([1, 2, 2])\nprojection = (np.dot(v, u) / np.dot(u, u)) * u\nprint(projection)"
  },
  {
    "input": "Compute the orthogonal projection of vector v = [0, 3, 4] onto vector u = [1, 0, 0].",
    "output": "import numpy as np\nu = np.array([1, 0, 0])\nv = np.array([0, 3, 4])\nprojection = (np.dot(v, u) / np.dot(u, u)) * u\nprint(projection)"
  },
  {
    "input": "Determine the orthogonal projection of vector v = [1, 1, 1] onto vector u = [1, -1, 0].",
    "output": "import numpy as np\nu = np.array([1, -1, 0])\nv = np.array([1, 1, 1])\nprojection = (np.dot(v, u) / np.dot(u, u)) * u\nprint(projection)"
  },
  {
    "input": "Find the orthogonal projection of vector v = [2, 2, 2] onto vector u = [1, 1, 1].",
    "output": "import numpy as np\nu = np.array([1, 1, 1])\nv = np.array([2, 2, 2])\nprojection = (np.dot(v, u) / np.dot(u, u)) * u\nprint(projection)"
  },
  {
    "input": "Compute the orthogonal projection of vector v = [5, 0, 0] onto vector u = [0, 5, 0].",
    "output": "import numpy as np\nu = np.array([0, 5, 0])\nv = np.array([5, 0, 0])\nprojection = (np.dot(v, u) / np.dot(u, u)) * u\nprint(projection)"
  },
  {
    "input": "Determine the orthogonal projection of vector v = [1, 2, 3] onto vector u = [3, 2, 1].",
    "output": "import numpy as np\nu = np.array([3, 2, 1])\nv = np.array([1, 2, 3])\nprojection = (np.dot(v, u) / np.dot(u, u)) * u\nprint(projection)"
  },
  {
    "input": "Compute the projection of vector v = [6, 2] onto vector u = [1, 1].",
    "output": "import numpy as np\nu = np.array([1, 1])\nv = np.array([6, 2])\nprojection = (np.dot(v, u) / np.dot(u, u)) * u\nprint(projection)"
  },
  {
    "input": "Find the projection of v = [1, 0] onto u = [0, 1].",
    "output": "import numpy as np\nu = np.array([0, 1])\nv = np.array([1, 0])\nprojection = (np.dot(v, u) / np.dot(u, u)) * u\nprint(projection)"
  },
  {
    "input": "Determine the projection of v = [3, 4] onto u = [4, 3].",
    "output": "import numpy as np\nu = np.array([4, 3])\nv = np.array([3, 4])\nprojection = (np.dot(v, u) / np.dot(u, u)) * u\nprint(projection)"
  },
  {
    "input": "Find the projection of v = [2, 2, 1] onto u = [1, 0, 0].",
    "output": "import numpy as np\nu = np.array([1, 0, 0])\nv = np.array([2, 2, 1])\nprojection = (np.dot(v, u) / np.dot(u, u)) * u\nprint(projection)"
  },
  {
    "input": "Calculate the projection of v = [4, 4, 4] onto u = [0, 1, 0].",
    "output": "import numpy as np\nu = np.array([0, 1, 0])\nv = np.array([4, 4, 4])\nprojection = (np.dot(v, u) / np.dot(u, u)) * u\nprint(projection)"
  },
  {
    "input": "What is the projection of v = [1, -1] onto u = [1, 1]?",
    "output": "import numpy as np\nu = np.array([1, 1])\nv = np.array([1, -1])\nprojection = (np.dot(v, u) / np.dot(u, u)) * u\nprint(projection)"
  },
  {
    "input": "Project v = [0, 1, 1] onto u = [0, 1, 0].",
    "output": "import numpy as np\nu = np.array([0, 1, 0])\nv = np.array([0, 1, 1])\nprojection = (np.dot(v, u) / np.dot(u, u)) * u\nprint(projection)"
  },
  {
    "input": "Find the projection of v = [5, 5] onto u = [1, 0].",
    "output": "import numpy as np\nu = np.array([1, 0])\nv = np.array([5, 5])\nprojection = (np.dot(v, u) / np.dot(u, u)) * u\nprint(projection)"
  },
  {
    "input": "Compute the projection of v = [2, 3] onto u = [2, 0].",
    "output": "import numpy as np\nu = np.array([2, 0])\nv = np.array([2, 3])\nprojection = (np.dot(v, u) / np.dot(u, u)) * u\nprint(projection)"
  },
  {
    "input": "Project vector v = [1, 1, 0] onto vector u = [1, 0, 0].",
    "output": "import numpy as np\nu = np.array([1, 0, 0])\nv = np.array([1, 1, 0])\nprojection = (np.dot(v, u) / np.dot(u, u)) * u\nprint(projection)"
  },
  {
    "input": "Find the projection of v = [0, 0, 1] onto u = [0, 1, 1].",
    "output": "import numpy as np\nu = np.array([0, 1, 1])\nv = np.array([0, 0, 1])\nprojection = (np.dot(v, u) / np.dot(u, u)) * u\nprint(projection)"
  },
  {
    "input": "What is the projection of v = [1, 2, 1] onto u = [1, 1, 1]?",
    "output": "import numpy as np\nu = np.array([1, 1, 1])\nv = np.array([1, 2, 1])\nprojection = (np.dot(v, u) / np.dot(u, u)) * u\nprint(projection)"
  },
  {
    "input": "Compute the projection of v = [0, 1, 0] onto u = [0, 0, 1].",
    "output": "import numpy as np\nu = np.array([0, 0, 1])\nv = np.array([0, 1, 0])\nprojection = (np.dot(v, u) / np.dot(u, u)) * u\nprint(projection)"
  },
  {
    "input": "Project v = [1, 3] onto u = [3, 1].",
    "output": "import numpy as np\nu = np.array([3, 1])\nv = np.array([1, 3])\nprojection = (np.dot(v, u) / np.dot(u, u)) * u\nprint(projection)"
  },
  {
    "input": "Find the projection of v = [1, 2, 3] onto u = [0, 1, 0].",
    "output": "import numpy as np\nu = np.array([0, 1, 0])\nv = np.array([1, 2, 3])\nprojection = (np.dot(v, u) / np.dot(u, u)) * u\nprint(projection)"
  },
  {
    "input": "Q26: Compute the projection of vector v = [7, 1] onto vector u = [1, 2].",
    "output": "import numpy as np\nu = np.array([1, 2])\nv = np.array([7, 1])\nprojection = (np.dot(v, u) / np.dot(u, u)) * u\nprint(projection)"
  },
  {
    "input": "Q27: Find the projection of v = [0, -3] onto u = [2, 0].",
    "output": "import numpy as np\nu = np.array([2, 0])\nv = np.array([0, -3])\nprojection = (np.dot(v, u) / np.dot(u, u)) * u\nprint(projection)"
  },
  {
    "input": "Q28: Determine the projection of v = [2, 4] onto u = [0, 1].",
    "output": "import numpy as np\nu = np.array([0, 1])\nv = np.array([2, 4])\nprojection = (np.dot(v, u) / np.dot(u, u)) * u\nprint(projection)"
  },
  {
    "input": "Q29: Project v = [3, 3, 0] onto u = [1, -1, 0].",
    "output": "import numpy as np\nu = np.array([1, -1, 0])\nv = np.array([3, 3, 0])\nprojection = (np.dot(v, u) / np.dot(u, u)) * u\nprint(projection)"
  },
  {
    "input": "Q30: Find the projection of v = [5, 1] onto u = [1, -2].",
    "output": "import numpy as np\nu = np.array([1, -2])\nv = np.array([5, 1])\nprojection = (np.dot(v, u) / np.dot(u, u)) * u\nprint(projection)"
  },
  {
    "input": "Q31: Compute the projection of v = [-1, 2] onto u = [1, 1].",
    "output": "import numpy as np\nu = np.array([1, 1])\nv = np.array([-1, 2])\nprojection = (np.dot(v, u) / np.dot(u, u)) * u\nprint(projection)"
  },
  {
    "input": "Q32: What is the projection of vector v = [4, 0, 3] onto u = [0, 0, 1]?",
    "output": "import numpy as np\nu = np.array([0, 0, 1])\nv = np.array([4, 0, 3])\nprojection = (np.dot(v, u) / np.dot(u, u)) * u\nprint(projection)"
  },
  {
    "input": "Q33: Project v = [1, 2, 3] onto u = [2, 2, 2].",
    "output": "import numpy as np\nu = np.array([2, 2, 2])\nv = np.array([1, 2, 3])\nprojection = (np.dot(v, u) / np.dot(u, u)) * u\nprint(projection)"
  },
  {
    "input": "Q34: Find the projection of v = [2, 0, 2] onto u = [0, 1, 0].",
    "output": "import numpy as np\nu = np.array([0, 1, 0])\nv = np.array([2, 0, 2])\nprojection = (np.dot(v, u) / np.dot(u, u)) * u\nprint(projection)"
  },
  {
    "input": "Q35: Determine the projection of v = [1, 0, -1] onto u = [1, 1, 0].",
    "output": "import numpy as np\nu = np.array([1, 1, 0])\nv = np.array([1, 0, -1])\nprojection = (np.dot(v, u) / np.dot(u, u)) * u\nprint(projection)"
  },
  {
    "input": "Q36: Compute the projection of v = [-2, 4] onto u = [2, 1].",
    "output": "import numpy as np\nu = np.array([2, 1])\nv = np.array([-2, 4])\nprojection = (np.dot(v, u) / np.dot(u, u)) * u\nprint(projection)"
  },
  {
    "input": "Q37: Project vector v = [3, 3, 3] onto vector u = [0, 1, -1].",
    "output": "import numpy as np\nu = np.array([0, 1, -1])\nv = np.array([3, 3, 3])\nprojection = (np.dot(v, u) / np.dot(u, u)) * u\nprint(projection)"
  },
  {
    "input": "Q38: Find the projection of v = [1, 2] onto u = [2, 2].",
    "output": "import numpy as np\nu = np.array([2, 2])\nv = np.array([1, 2])\nprojection = (np.dot(v, u) / np.dot(u, u)) * u\nprint(projection)"
  },
  {
    "input": "Q39: Compute the projection of v = [6, -1] onto u = [1, 1].",
    "output": "import numpy as np\nu = np.array([1, 1])\nv = np.array([6, -1])\nprojection = (np.dot(v, u) / np.dot(u, u)) * u\nprint(projection)"
  },
  {
    "input": "Q40: Determine the projection of vector v = [3, 4, 0] onto vector u = [0, 0, 1].",
    "output": "import numpy as np\nu = np.array([0, 0, 1])\nv = np.array([3, 4, 0])\nprojection = (np.dot(v, u) / np.dot(u, u)) * u\nprint(projection)"
  },
  {
    "input": "Q41: Find the projection of vector v = [2, 1] onto u = [1, 0].",
    "output": "import numpy as np\nu = np.array([1, 0])\nv = np.array([2, 1])\nprojection = (np.dot(v, u) / np.dot(u, u)) * u\nprint(projection)"
  },
  {
    "input": "Q42: Compute the projection of vector v = [0, 2] onto vector u = [1, 1].",
    "output": "import numpy as np\nu = np.array([1, 1])\nv = np.array([0, 2])\nprojection = (np.dot(v, u) / np.dot(u, u)) * u\nprint(projection)"
  },
  {
    "input": "Q43: Determine the projection of v = [1, 2, 0] onto u = [0, 1, 0].",
    "output": "import numpy as np\nu = np.array([0, 1, 0])\nv = np.array([1, 2, 0])\nprojection = (np.dot(v, u) / np.dot(u, u)) * u\nprint(projection)"
  },
  {
    "input": "Q44: Project v = [3, 0, 4] onto u = [0, 0, 1].",
    "output": "import numpy as np\nu = np.array([0, 0, 1])\nv = np.array([3, 0, 4])\nprojection = (np.dot(v, u) / np.dot(u, u)) * u\nprint(projection)"
  },
  {
    "input": "Q45: Find the projection of v = [5, 5, 0] onto u = [1, -1, 0].",
    "output": "import numpy as np\nu = np.array([1, -1, 0])\nv = np.array([5, 5, 0])\nprojection = (np.dot(v, u) / np.dot(u, u)) * u\nprint(projection)"
  },
  {
    "input": "Q46: Compute the projection of v = [1, 1] onto u = [2, 2].",
    "output": "import numpy as np\nu = np.array([2, 2])\nv = np.array([1, 1])\nprojection = (np.dot(v, u) / np.dot(u, u)) * u\nprint(projection)"
  },
  {
    "input": "Q47: Project v = [0, 1, 1] onto u = [1, 0, 0].",
    "output": "import numpy as np\nu = np.array([1, 0, 0])\nv = np.array([0, 1, 1])\nprojection = (np.dot(v, u) / np.dot(u, u)) * u\nprint(projection)"
  },
  {
    "input": "Q48: Find the projection of v = [1, -1] onto u = [2, 1].",
    "output": "import numpy as np\nu = np.array([2, 1])\nv = np.array([1, -1])\nprojection = (np.dot(v, u) / np.dot(u, u)) * u\nprint(projection)"
  },
  {
    "input": "Q49: Compute the projection of vector v = [3, 2, 1] onto vector u = [1, 0, 0].",
    "output": "import numpy as np\nu = np.array([1, 0, 0])\nv = np.array([3, 2, 1])\nprojection = (np.dot(v, u) / np.dot(u, u)) * u\nprint(projection)"
  },
  {
    "input": "Q50: Project v = [0, 1, -1] onto u = [0, 1, 1].",
    "output": "import numpy as np\nu = np.array([0, 1, 1])\nv = np.array([0, 1, -1])\nprojection = (np.dot(v, u) / np.dot(u, u)) * u\nprint(projection)"
  },
  {
    "input": "Q51: Find the projection of v = [2, 2] onto u = [1, -1].",
    "output": "import numpy as np\nu = np.array([1, -1])\nv = np.array([2, 2])\nprojection = (np.dot(v, u) / np.dot(u, u)) * u\nprint(projection)"
  },
  {
    "input": "Q52: Compute the projection of v = [1, 3] onto u = [0, 1].",
    "output": "import numpy as np\nu = np.array([0, 1])\nv = np.array([1, 3])\nprojection = (np.dot(v, u) / np.dot(u, u)) * u\nprint(projection)"
  },
  {
    "input": "Q53: Project v = [5, -2] onto u = [1, 1].",
    "output": "import numpy as np\nu = np.array([1, 1])\nv = np.array([5, -2])\nprojection = (np.dot(v, u) / np.dot(u, u)) * u\nprint(projection)"
  },
  {
    "input": "Q54: Determine the projection of v = [-1, 2, 3] onto u = [0, 0, 1].",
    "output": "import numpy as np\nu = np.array([0, 0, 1])\nv = np.array([-1, 2, 3])\nprojection = (np.dot(v, u) / np.dot(u, u)) * u\nprint(projection)"
  },
  {
    "input": "Q55: Find the projection of v = [2, 1, 0] onto u = [1, 2, 0].",
    "output": "import numpy as np\nu = np.array([1, 2, 0])\nv = np.array([2, 1, 0])\nprojection = (np.dot(v, u) / np.dot(u, u)) * u\nprint(projection)"
  },
  {
    "input": "Q56: Compute the projection of v = [6, 2] onto u = [3, 1].",
    "output": "import numpy as np\nu = np.array([3, 1])\nv = np.array([6, 2])\nprojection = (np.dot(v, u) / np.dot(u, u)) * u\nprint(projection)"
  },
  {
    "input": "Q57: Find the projection of vector v = [1, 1, 1] onto u = [1, 0, 0].",
    "output": "import numpy as np\nu = np.array([1, 0, 0])\nv = np.array([1, 1, 1])\nprojection = (np.dot(v, u) / np.dot(u, u)) * u\nprint(projection)"
  },
  {
    "input": "Q58: Project vector v = [4, -2] onto u = [2, 1].",
    "output": "import numpy as np\nu = np.array([2, 1])\nv = np.array([4, -2])\nprojection = (np.dot(v, u) / np.dot(u, u)) * u\nprint(projection)"
  },
  {
    "input": "Q59: Find the projection of v = [0, 4] onto u = [1, 2].",
    "output": "import numpy as np\nu = np.array([1, 2])\nv = np.array([0, 4])\nprojection = (np.dot(v, u) / np.dot(u, u)) * u\nprint(projection)"
  },
  {
    "input": "Q60: Compute the projection of vector v = [5, 0, -5] onto u = [0, 0, 1].",
    "output": "import numpy as np\nu = np.array([0, 0, 1])\nv = np.array([5, 0, -5])\nprojection = (np.dot(v, u) / np.dot(u, u)) * u\nprint(projection)"
  },
  {
    "input": "Q61: Project v = [1, 3] onto u = [1, 0].",
    "output": "import numpy as np\nu = np.array([1, 0])\nv = np.array([1, 3])\nprojection = (np.dot(v, u) / np.dot(u, u)) * u\nprint(projection)"
  },
  {
    "input": "Q62: Find the projection of v = [3, 3] onto u = [1, 1].",
    "output": "import numpy as np\nu = np.array([1, 1])\nv = np.array([3, 3])\nprojection = (np.dot(v, u) / np.dot(u, u)) * u\nprint(projection)"
  },
  {
    "input": "Q63: Compute the projection of v = [7, 1, 2] onto u = [1, 0, 0].",
    "output": "import numpy as np\nu = np.array([1, 0, 0])\nv = np.array([7, 1, 2])\nprojection = (np.dot(v, u) / np.dot(u, u)) * u\nprint(projection)"
  },
  {
    "input": "Q64: Project v = [-2, 5] onto u = [1, 2].",
    "output": "import numpy as np\nu = np.array([1, 2])\nv = np.array([-2, 5])\nprojection = (np.dot(v, u) / np.dot(u, u)) * u\nprint(projection)"
  },
  {
    "input": "Q65: Find the projection of v = [0, 0, 6] onto u = [0, 0, 2].",
    "output": "import numpy as np\nu = np.array([0, 0, 2])\nv = np.array([0, 0, 6])\nprojection = (np.dot(v, u) / np.dot(u, u)) * u\nprint(projection)"
  },
  {
    "input": "Q66: Determine the projection of v = [2, 2] onto u = [0, 1].",
    "output": "import numpy as np\nu = np.array([0, 1])\nv = np.array([2, 2])\nprojection = (np.dot(v, u) / np.dot(u, u)) * u\nprint(projection)"
  },
  {
    "input": "Q67: Project v = [3, 6] onto u = [3, 0].",
    "output": "import numpy as np\nu = np.array([3, 0])\nv = np.array([3, 6])\nprojection = (np.dot(v, u) / np.dot(u, u)) * u\nprint(projection)"
  },
  {
    "input": "Q68: Find the projection of v = [1, 0, 2] onto u = [0, 1, 0].",
    "output": "import numpy as np\nu = np.array([0, 1, 0])\nv = np.array([1, 0, 2])\nprojection = (np.dot(v, u) / np.dot(u, u)) * u\nprint(projection)"
  },
  {
    "input": "Q69: Compute the projection of v = [5, -1] onto u = [2, 2].",
    "output": "import numpy as np\nu = np.array([2, 2])\nv = np.array([5, -1])\nprojection = (np.dot(v, u) / np.dot(u, u)) * u\nprint(projection)"
  },
  {
    "input": "Q70: Project vector v = [4, 4, 4] onto vector u = [1, 0, -1].",
    "output": "import numpy as np\nu = np.array([1, 0, -1])\nv = np.array([4, 4, 4])\nprojection = (np.dot(v, u) / np.dot(u, u)) * u\nprint(projection)"
  },
  {
    "input": "Q71: Compute the projection of v = [2, -2] onto u = [1, 1].",
    "output": "import numpy as np\nu = np.array([1, 1])\nv = np.array([2, -2])\nprojection = (np.dot(v, u) / np.dot(u, u)) * u\nprint(projection)"
  },
  {
    "input": "Q72: Project vector v = [3, 1, 0] onto u = [1, 2, 2].",
    "output": "import numpy as np\nu = np.array([1, 2, 2])\nv = np.array([3, 1, 0])\nprojection = (np.dot(v, u) / np.dot(u, u)) * u\nprint(projection)"
  },
  {
    "input": "Q73: Find the projection of v = [0, 5] onto u = [2, 0].",
    "output": "import numpy as np\nu = np.array([2, 0])\nv = np.array([0, 5])\nprojection = (np.dot(v, u) / np.dot(u, u)) * u\nprint(projection)"
  },
  {
    "input": "Q74: Compute the projection of vector v = [7, 4] onto u = [1, -1].",
    "output": "import numpy as np\nu = np.array([1, -1])\nv = np.array([7, 4])\nprojection = (np.dot(v, u) / np.dot(u, u)) * u\nprint(projection)"
  },
  {
    "input": "Q75: Project v = [1, 2, 3] onto u = [3, 2, 1].",
    "output": "import numpy as np\nu = np.array([3, 2, 1])\nv = np.array([1, 2, 3])\nprojection = (np.dot(v, u) / np.dot(u, u)) * u\nprint(projection)"
  },
  {
    "input": "Q76: Find the projection of v = [1, 4] onto u = [2, 1].",
    "output": "import numpy as np\nu = np.array([2, 1])\nv = np.array([1, 4])\nprojection = (np.dot(v, u) / np.dot(u, u)) * u\nprint(projection)"
  },
  {
    "input": "Q77: Project vector v = [0, 2, 2] onto u = [0, 1, -1].",
    "output": "import numpy as np\nu = np.array([0, 1, -1])\nv = np.array([0, 2, 2])\nprojection = (np.dot(v, u) / np.dot(u, u)) * u\nprint(projection)"
  },
  {
    "input": "Q78: Compute the projection of v = [5, 0, 0] onto u = [1, 1, 1].",
    "output": "import numpy as np\nu = np.array([1, 1, 1])\nv = np.array([5, 0, 0])\nprojection = (np.dot(v, u) / np.dot(u, u)) * u\nprint(projection)"
  },
  {
    "input": "Q79: Project v = [-1, -1] onto u = [1, -1].",
    "output": "import numpy as np\nu = np.array([1, -1])\nv = np.array([-1, -1])\nprojection = (np.dot(v, u) / np.dot(u, u)) * u\nprint(projection)"
  },
  {
    "input": "Q80: Find the projection of v = [2, 1] onto u = [0, 1].",
    "output": "import numpy as np\nu = np.array([0, 1])\nv = np.array([2, 1])\nprojection = (np.dot(v, u) / np.dot(u, u)) * u\nprint(projection)"
  },
  {
    "input": "Q81: Compute the projection of v = [3, 6, 9] onto u = [1, 1, 1].",
    "output": "import numpy as np\nu = np.array([1, 1, 1])\nv = np.array([3, 6, 9])\nprojection = (np.dot(v, u) / np.dot(u, u)) * u\nprint(projection)"
  },
  {
    "input": "Q82: Project v = [0, 0, 5] onto u = [1, 1, 0].",
    "output": "import numpy as np\nu = np.array([1, 1, 0])\nv = np.array([0, 0, 5])\nprojection = (np.dot(v, u) / np.dot(u, u)) * u\nprint(projection)"
  },
  {
    "input": "Q83: Find the projection of v = [1, 2] onto u = [2, 0].",
    "output": "import numpy as np\nu = np.array([2, 0])\nv = np.array([1, 2])\nprojection = (np.dot(v, u) / np.dot(u, u)) * u\nprint(projection)"
  },
  {
    "input": "Q84: Compute the projection of v = [4, 5, 6] onto u = [1, 0, 1].",
    "output": "import numpy as np\nu = np.array([1, 0, 1])\nv = np.array([4, 5, 6])\nprojection = (np.dot(v, u) / np.dot(u, u)) * u\nprint(projection)"
  },
  {
    "input": "Q85: Project v = [6, -3] onto u = [1, 2].",
    "output": "import numpy as np\nu = np.array([1, 2])\nv = np.array([6, -3])\nprojection = (np.dot(v, u) / np.dot(u, u)) * u\nprint(projection)"
  },
  {
    "input": "Q86: Compute the projection of v = [8, 4] onto u = [2, 1].",
    "output": "import numpy as np\nu = np.array([2, 1])\nv = np.array([8, 4])\nprojection = (np.dot(v, u) / np.dot(u, u)) * u\nprint(projection)"
  },
  {
    "input": "Q87: Project vector v = [3, 5] onto u = [1, 0].",
    "output": "import numpy as np\nu = np.array([1, 0])\nv = np.array([3, 5])\nprojection = (np.dot(v, u) / np.dot(u, u)) * u\nprint(projection)"
  },
  {
    "input": "Q88: Find the projection of v = [0, 1] onto u = [1, 1].",
    "output": "import numpy as np\nu = np.array([1, 1])\nv = np.array([0, 1])\nprojection = (np.dot(v, u) / np.dot(u, u)) * u\nprint(projection)"
  },
  {
    "input": "Q89: Compute the projection of v = [1, 2, 3] onto u = [1, 1, 0].",
    "output": "import numpy as np\nu = np.array([1, 1, 0])\nv = np.array([1, 2, 3])\nprojection = (np.dot(v, u) / np.dot(u, u)) * u\nprint(projection)"
  },
  {
    "input": "Q90: Project v = [-1, -2] onto u = [0, 1].",
    "output": "import numpy as np\nu = np.array([0, 1])\nv = np.array([-1, -2])\nprojection = (np.dot(v, u) / np.dot(u, u)) * u\nprint(projection)"
  },
  {
    "input": "Q91: Find the projection of v = [3, 3] onto u = [2, 0].",
    "output": "import numpy as np\nu = np.array([2, 0])\nv = np.array([3, 3])\nprojection = (np.dot(v, u) / np.dot(u, u)) * u\nprint(projection)"
  },
  {
    "input": "Q92: Compute the projection of v = [6, 2, 0] onto u = [0, 1, 1].",
    "output": "import numpy as np\nu = np.array([0, 1, 1])\nv = np.array([6, 2, 0])\nprojection = (np.dot(v, u) / np.dot(u, u)) * u\nprint(projection)"
  },
  {
    "input": "Q93: Project v = [1, 1, 0] onto u = [1, -1, 0].",
    "output": "import numpy as np\nu = np.array([1, -1, 0])\nv = np.array([1, 1, 0])\nprojection = (np.dot(v, u) / np.dot(u, u)) * u\nprint(projection)"
  },
  {
    "input": "Q94: Find the projection of v = [5, 2] onto u = [1, -1].",
    "output": "import numpy as np\nu = np.array([1, -1])\nv = np.array([5, 2])\nprojection = (np.dot(v, u) / np.dot(u, u)) * u\nprint(projection)"
  },
  {
    "input": "Q95: Compute the projection of v = [2, 0, 2] onto u = [1, 1, 1].",
    "output": "import numpy as np\nu = np.array([1, 1, 1])\nv = np.array([2, 0, 2])\nprojection = (np.dot(v, u) / np.dot(u, u)) * u\nprint(projection)"
  },
  {
    "input": "Q96: Project v = [3, 0, 0] onto u = [0, 1, 0].",
    "output": "import numpy as np\nu = np.array([0, 1, 0])\nv = np.array([3, 0, 0])\nprojection = (np.dot(v, u) / np.dot(u, u)) * u\nprint(projection)"
  },
  {
    "input": "Q97: Find the projection of v = [7, 8] onto u = [1, 1].",
    "output": "import numpy as np\nu = np.array([1, 1])\nv = np.array([7, 8])\nprojection = (np.dot(v, u) / np.dot(u, u)) * u\nprint(projection)"
  },
  {
    "input": "Q98: Compute the projection of v = [1, 2, 3] onto u = [0, 0, 1].",
    "output": "import numpy as np\nu = np.array([0, 0, 1])\nv = np.array([1, 2, 3])\nprojection = (np.dot(v, u) / np.dot(u, u)) * u\nprint(projection)"
  },
  {
    "input": "Q99: Project v = [1, 2] onto u = [1, 1].",
    "output": "import numpy as np\nu = np.array([1, 1])\nv = np.array([1, 2])\nprojection = (np.dot(v, u) / np.dot(u, u)) * u\nprint(projection)"
  },
  {
    "input": "Q100: Find the projection of v = [4, -4] onto u = [1, 2].",
    "output": "import numpy as np\nu = np.array([1, 2])\nv = np.array([4, -4])\nprojection = (np.dot(v, u) / np.dot(u, u)) * u\nprint(projection)"
  },
  {
    "input": "Q101: Check if vectors u = [1, 2] and v = [-2, 1] are orthogonal.",
    "output": "import numpy as np\nu = np.array([1, 2])\nv = np.array([-2, 1])\nprint(np.dot(u, v) == 0)"
  },
  {
    "input": "Q102: Check if u = [3, -3, 1] and v = [1, 1, 0] are orthogonal.",
    "output": "import numpy as np\nu = np.array([3, -3, 1])\nv = np.array([1, 1, 0])\nprint(np.dot(u, v) == 0)"
  },
  {
    "input": "Q103: Find the projection of v = [2, 3] onto u = [1, 0].",
    "output": "import numpy as np\nu = np.array([1, 0])\nv = np.array([2, 3])\nproj = (np.dot(v, u) / np.dot(u, u)) * u\nprint(proj)"
  },
  {
    "input": "Q104: Find a vector orthogonal to [1, 2] in R\u00b2.",
    "output": "import numpy as np\nv = np.array([1, 2])\northogonal = np.array([-2, 1])\nprint(orthogonal)"
  },
  {
    "input": "Q105: Compute the component of v = [4, 5] orthogonal to u = [1, 1].",
    "output": "import numpy as np\nu = np.array([1, 1])\nv = np.array([4, 5])\nproj = (np.dot(v, u) / np.dot(u, u)) * u\northogonal_component = v - proj\nprint(orthogonal_component)"
  },
  {
    "input": "Q106: Verify if vectors [1, 0, 0], [0, 1, 0], and [0, 0, 1] form an orthonormal set.",
    "output": "import numpy as np\nvectors = [np.array([1, 0, 0]), np.array([0, 1, 0]), np.array([0, 0, 1])]\northonormal = all(np.isclose(np.dot(v, v), 1) for v in vectors) and all(np.isclose(np.dot(vectors[i], vectors[j]), 0) for i in range(3) for j in range(i+1, 3))\nprint(orthonormal)"
  },
  {
    "input": "Q107: Find the orthogonal decomposition of v = [3, 4] into components parallel and orthogonal to u = [1, 0].",
    "output": "import numpy as np\nu = np.array([1, 0])\nv = np.array([3, 4])\nproj = (np.dot(v, u) / np.dot(u, u)) * u\northogonal = v - proj\nprint(\"Parallel:\", proj)\nprint(\"Orthogonal:\", orthogonal)"
  },
  {
    "input": "Q108: Start Gram-Schmidt on vectors [1, 1, 0] and [1, 0, 1]: output the first orthonormal vector.",
    "output": "import numpy as np\na = np.array([1, 1, 0])\ne1 = a / np.linalg.norm(a)\nprint(e1)"
  },
  {
    "input": "Q109: Given matrix A = [[1, 0], [1, 1]], project b = [2, 3] onto the column space of A.",
    "output": "import numpy as np\nA = np.array([[1, 0], [1, 1]])\nb = np.array([2, 3])\nproj = A @ np.linalg.inv(A.T @ A) @ A.T @ b\nprint(proj)"
  },
  {
    "input": "Q110: Find a unit vector orthogonal to [2, 1] in R\u00b2.",
    "output": "import numpy as np\nv = np.array([2, 1])\north = np.array([-1, 2])\nunit_orth = orth / np.linalg.norm(orth)\nprint(unit_orth)"
  },
  {
    "input": "Q111: Check if the projection of [1, 2] onto [1, 1] lies on the line y = x.",
    "output": "import numpy as np\nu = np.array([1, 1])\nv = np.array([1, 2])\nproj = (np.dot(v, u) / np.dot(u, u)) * u\nprint(proj[0] == proj[1])"
  },
  {
    "input": "Q112: Project [0, 3, 4] onto [0, 0, 1].",
    "output": "import numpy as np\nu = np.array([0, 0, 1])\nv = np.array([0, 3, 4])\nproj = (np.dot(v, u) / np.dot(u, u)) * u\nprint(proj)"
  },
  {
    "input": "Q113: Verify if [2, -1, 0] is orthogonal to [1, 2, 0].",
    "output": "import numpy as np\na = np.array([2, -1, 0])\nb = np.array([1, 2, 0])\nprint(np.dot(a, b) == 0)"
  },
  {
    "input": "Q114: Find the orthogonal component of v = [5, 6] relative to u = [1, 0].",
    "output": "import numpy as np\nu = np.array([1, 0])\nv = np.array([5, 6])\nproj = (np.dot(v, u) / np.dot(u, u)) * u\north = v - proj\nprint(orth)"
  },
  {
    "input": "Q115: Check if vectors [3, 4] and [-4, 3] are orthogonal.",
    "output": "import numpy as np\na = np.array([3, 4])\nb = np.array([-4, 3])\nprint(np.dot(a, b) == 0)"
  },
  {
    "input": "Q116: Find the projection of v = [5, 0] onto u = [1, 1].",
    "output": "import numpy as np\nu = np.array([1, 1])\nv = np.array([5, 0])\nproj = (np.dot(v, u) / np.dot(u, u)) * u\nprint(proj)"
  },
  {
    "input": "Q117: Check if vectors u = [2, -1] and v = [1, 2] are orthogonal.",
    "output": "import numpy as np\nu = np.array([2, -1])\nv = np.array([1, 2])\nprint(np.dot(u, v) == 0)"
  },
  {
    "input": "Q118: Project v = [2, 3, 0] onto u = [1, 0, 0].",
    "output": "import numpy as np\nu = np.array([1, 0, 0])\nv = np.array([2, 3, 0])\nproj = (np.dot(v, u) / np.dot(u, u)) * u\nprint(proj)"
  },
  {
    "input": "Q119: Find a unit vector orthogonal to [3, 4] in R\u00b2.",
    "output": "import numpy as np\nv = np.array([3, 4])\north = np.array([-4, 3])\nunit_orth = orth / np.linalg.norm(orth)\nprint(unit_orth)"
  },
  {
    "input": "Q120: Check whether [1, 0, 0], [0, 1, 0], [0, 0, -1] form an orthonormal set.",
    "output": "import numpy as np\nv1 = np.array([1, 0, 0])\nv2 = np.array([0, 1, 0])\nv3 = np.array([0, 0, -1])\northonormal = all(np.isclose(np.dot(v, v), 1) for v in [v1, v2, v3]) and all(np.isclose(np.dot(x, y), 0) for x in [v1, v2, v3] for y in [v1, v2, v3] if not np.array_equal(x, y))\nprint(orthonormal)"
  },
  {
    "input": "Q121: Compute the orthogonal component of v = [6, 2] to u = [0, 1].",
    "output": "import numpy as np\nu = np.array([0, 1])\nv = np.array([6, 2])\nproj = (np.dot(v, u) / np.dot(u, u)) * u\north = v - proj\nprint(orth)"
  },
  {
    "input": "Q122: Project [4, 5, 6] onto [1, 1, 1].",
    "output": "import numpy as np\nu = np.array([1, 1, 1])\nv = np.array([4, 5, 6])\nproj = (np.dot(v, u) / np.dot(u, u)) * u\nprint(proj)"
  },
  {
    "input": "Q123: Check if [2, 3] and [3, -2] are orthogonal.",
    "output": "import numpy as np\nv1 = np.array([2, 3])\nv2 = np.array([3, -2])\nprint(np.dot(v1, v2) == 0)"
  },
  {
    "input": "Q124: Compute the projection of v = [7, 2] onto u = [0, 1].",
    "output": "import numpy as np\nu = np.array([0, 1])\nv = np.array([7, 2])\nproj = (np.dot(v, u) / np.dot(u, u)) * u\nprint(proj)"
  },
  {
    "input": "Q125: Determine if [1/\u221a2, 1/\u221a2] is a unit vector.",
    "output": "import numpy as np\nv = np.array([1/np.sqrt(2), 1/np.sqrt(2)])\nprint(np.isclose(np.linalg.norm(v), 1))"
  },
  {
    "input": "Q126: Compute the projection of [1, 2, 2] onto the unit vector [0, 0, 1].",
    "output": "import numpy as np\nu = np.array([0, 0, 1])\nv = np.array([1, 2, 2])\nproj = (np.dot(v, u) / np.dot(u, u)) * u\nprint(proj)"
  },
  {
    "input": "Q127: Start Gram-Schmidt on vectors [1, 0] and [1, 1] \u2014 return first orthonormal vector.",
    "output": "import numpy as np\na = np.array([1, 0])\ne1 = a / np.linalg.norm(a)\nprint(e1)"
  },
  {
    "input": "Q128: Find a vector orthogonal to [1, 3] in R\u00b2.",
    "output": "import numpy as np\nv = np.array([1, 3])\north = np.array([-3, 1])\nprint(orth)"
  },
  {
    "input": "Q129: Compute the projection of [0, 4] onto [1, 1].",
    "output": "import numpy as np\nu = np.array([1, 1])\nv = np.array([0, 4])\nproj = (np.dot(v, u) / np.dot(u, u)) * u\nprint(proj)"
  },
  {
    "input": "Q130: Check if [1, -1] and [2, 2] are orthogonal.",
    "output": "import numpy as np\nv1 = np.array([1, -1])\nv2 = np.array([2, 2])\nprint(np.dot(v1, v2) == 0)"
  },
  {
    "input": "Q131: Check if u = [1, 2, 3] and v = [3, -6, 3] are orthogonal.",
    "output": "import numpy as np\nu = np.array([1, 2, 3])\nv = np.array([3, -6, 3])\nprint(np.dot(u, v) == 0)"
  },
  {
    "input": "Q132: Project vector v = [4, 0] onto u = [1, 1].",
    "output": "import numpy as np\nu = np.array([1, 1])\nv = np.array([4, 0])\nproj = (np.dot(v, u) / np.dot(u, u)) * u\nprint(proj)"
  },
  {
    "input": "Q133: Find a vector orthogonal to [5, 12] in R\u00b2.",
    "output": "import numpy as np\nv = np.array([5, 12])\north = np.array([-12, 5])\nprint(orth)"
  },
  {
    "input": "Q134: Find the component of [6, 8] orthogonal to [1, 0].",
    "output": "import numpy as np\nu = np.array([1, 0])\nv = np.array([6, 8])\nproj = (np.dot(v, u) / np.dot(u, u)) * u\north = v - proj\nprint(orth)"
  },
  {
    "input": "Q135: Check whether the set {[2, 0], [0, 0]} is orthogonal.",
    "output": "import numpy as np\nu = np.array([2, 0])\nv = np.array([0, 0])\nprint(np.dot(u, v) == 0)"
  },
  {
    "input": "Q136: Project [7, 7] onto [1, -1].",
    "output": "import numpy as np\nu = np.array([1, -1])\nv = np.array([7, 7])\nproj = (np.dot(v, u) / np.dot(u, u)) * u\nprint(proj)"
  },
  {
    "input": "Q137: Find the orthogonal decomposition of v = [4, 3] relative to u = [1, 1].",
    "output": "import numpy as np\nu = np.array([1, 1])\nv = np.array([4, 3])\nproj = (np.dot(v, u) / np.dot(u, u)) * u\north = v - proj\nprint(\"Parallel:\", proj)\nprint(\"Orthogonal:\", orth)"
  },
  {
    "input": "Q138: Determine whether [1, 2, 2] is orthogonal to [2, -1, 1].",
    "output": "import numpy as np\na = np.array([1, 2, 2])\nb = np.array([2, -1, 1])\nprint(np.dot(a, b) == 0)"
  },
  {
    "input": "Q139: Compute the projection of [1, 1, 1] onto the x-axis.",
    "output": "import numpy as np\nu = np.array([1, 0, 0])\nv = np.array([1, 1, 1])\nproj = (np.dot(v, u) / np.dot(u, u)) * u\nprint(proj)"
  },
  {
    "input": "Q140: Verify if [1, 0], [0, 2] form an orthogonal set.",
    "output": "import numpy as np\nv1 = np.array([1, 0])\nv2 = np.array([0, 2])\nprint(np.dot(v1, v2) == 0)"
  },
  {
    "input": "Q141: Compute the unit vector orthogonal to [4, 3].",
    "output": "import numpy as np\nv = np.array([4, 3])\north = np.array([-3, 4])\nunit = orth / np.linalg.norm(orth)\nprint(unit)"
  },
  {
    "input": "Q142: Project [0, 1] onto [1, 2].",
    "output": "import numpy as np\nu = np.array([1, 2])\nv = np.array([0, 1])\nproj = (np.dot(v, u) / np.dot(u, u)) * u\nprint(proj)"
  },
  {
    "input": "Q143: Check if [1, 2, 3] and [2, 4, 6] are orthogonal.",
    "output": "import numpy as np\na = np.array([1, 2, 3])\nb = np.array([2, 4, 6])\nprint(np.dot(a, b) == 0)"
  },
  {
    "input": "Q144: Find the projection of [3, 3, 0] onto [1, 1, 1].",
    "output": "import numpy as np\nu = np.array([1, 1, 1])\nv = np.array([3, 3, 0])\nproj = (np.dot(v, u) / np.dot(u, u)) * u\nprint(proj)"
  },
  {
    "input": "Q145: Project [2, -2] onto [1, 0].",
    "output": "import numpy as np\nu = np.array([1, 0])\nv = np.array([2, -2])\nproj = (np.dot(v, u) / np.dot(u, u)) * u\nprint(proj)"
  },
  {
    "input": "Q146: Find a unit vector orthogonal to [2, -1] in R\u00b2.",
    "output": "import numpy as np\nv = np.array([2, -1])\north = np.array([1, 2])\nunit = orth / np.linalg.norm(orth)\nprint(unit)"
  },
  {
    "input": "Q147: Check if [1, 2] and [2, -1] are orthogonal.",
    "output": "import numpy as np\na = np.array([1, 2])\nb = np.array([2, -1])\nprint(np.dot(a, b) == 0)"
  },
  {
    "input": "Q148: Project [1, 4] onto [0, 1].",
    "output": "import numpy as np\nu = np.array([0, 1])\nv = np.array([1, 4])\nproj = (np.dot(v, u) / np.dot(u, u)) * u\nprint(proj)"
  },
  {
    "input": "Q149: Determine if [0, 0] is orthogonal to any vector in R\u00b2.",
    "output": "import numpy as np\nv = np.array([0, 0])\nu = np.array([3, 4])\nprint(np.dot(v, u) == 0)"
  },
  {
    "input": "Q150: Compute the projection of [5, 5, 0] onto [1, 1, 1].",
    "output": "import numpy as np\nu = np.array([1, 1, 1])\nv = np.array([5, 5, 0])\nproj = (np.dot(v, u) / np.dot(u, u)) * u\nprint(proj)"
  },
  {
    "input": "Q151: Find a vector in R\u00b2 orthogonal to [7, -4].",
    "output": "import numpy as np\nv = np.array([7, -4])\north = np.array([4, 7])\nprint(orth)"
  },
  {
    "input": "Q152: Project [0, 0, 1] onto [1, 1, 1].",
    "output": "import numpy as np\nu = np.array([1, 1, 1])\nv = np.array([0, 0, 1])\nproj = (np.dot(v, u) / np.dot(u, u)) * u\nprint(proj)"
  },
  {
    "input": "Q153: Check if [1, 1, 0] and [-1, 1, 0] are orthogonal.",
    "output": "import numpy as np\na = np.array([1, 1, 0])\nb = np.array([-1, 1, 0])\nprint(np.dot(a, b) == 0)"
  },
  {
    "input": "Q154: Find the unit projection of [3, 4] onto [0, 1].",
    "output": "import numpy as np\nu = np.array([0, 1])\nv = np.array([3, 4])\nproj = (np.dot(v, u) / np.dot(u, u)) * u\nunit_proj = proj / np.linalg.norm(proj)\nprint(unit_proj)"
  },
  {
    "input": "Q155: Project [1, 2, 3] onto the y-axis.",
    "output": "import numpy as np\nu = np.array([0, 1, 0])\nv = np.array([1, 2, 3])\nproj = (np.dot(v, u) / np.dot(u, u)) * u\nprint(proj)"
  },
  {
    "input": "Q156: Determine if [2, 2, 1] and [1, -1, 0] are orthogonal.",
    "output": "import numpy as np\na = np.array([2, 2, 1])\nb = np.array([1, -1, 0])\nprint(np.dot(a, b) == 0)"
  },
  {
    "input": "Q157: Given vectors [1, 1, 0] and [1, 0, 1], apply the Gram-Schmidt process and return the orthonormal set.",
    "output": "import numpy as np\nv1 = np.array([1, 1, 0], dtype=float)\nv2 = np.array([1, 0, 1], dtype=float)\nu1 = v1 / np.linalg.norm(v1)\nproj = np.dot(v2, u1) * u1\nu2 = v2 - proj\nu2 = u2 / np.linalg.norm(u2)\nprint(u1, u2)"
  },
  {
    "input": "Q158: Compute the projection matrix that projects onto the line spanned by u = [2, 3].",
    "output": "import numpy as np\nu = np.array([2, 3])\nP = np.outer(u, u) / np.dot(u, u)\nprint(P)"
  },
  {
    "input": "Q159: Decompose v = [3, 4] into parallel and orthogonal components relative to u = [1, 2].",
    "output": "import numpy as np\nu = np.array([1, 2])\nv = np.array([3, 4])\nproj = (np.dot(v, u) / np.dot(u, u)) * u\north = v - proj\nprint(\"Parallel:\", proj)\nprint(\"Orthogonal:\", orth)"
  },
  {
    "input": "Q160: Use Gram-Schmidt to orthonormalize [1, 2, 2] and [2, 1, -1]. Return the final vectors.",
    "output": "import numpy as np\na = np.array([1, 2, 2], dtype=float)\nb = np.array([2, 1, -1], dtype=float)\nu1 = a / np.linalg.norm(a)\nproj = np.dot(b, u1) * u1\nu2 = b - proj\nu2 = u2 / np.linalg.norm(u2)\nprint(u1, u2)"
  },
  {
    "input": "Q161: Find the orthogonal projection of v = [1, 2, 3] onto the plane spanned by u1 = [1, 0, 0] and u2 = [0, 1, 0].",
    "output": "import numpy as np\nv = np.array([1, 2, 3])\nu1 = np.array([1, 0, 0])\nu2 = np.array([0, 1, 0])\nproj1 = np.dot(v, u1) / np.dot(u1, u1) * u1\nproj2 = np.dot(v, u2) / np.dot(u2, u2) * u2\nproj = proj1 + proj2\nprint(proj)"
  },
  {
    "input": "Q162: Given an orthonormal basis {[1, 0], [0, 1]}, project [4, 5] onto the space they span.",
    "output": "import numpy as np\nv = np.array([4, 5])\nbasis = [np.array([1, 0]), np.array([0, 1])]\nproj = sum(np.dot(v, b) * b for b in basis)\nprint(proj)"
  },
  {
    "input": "Q163: Find the projection matrix for projecting onto the column space of A = [[1, 1], [0, 1], [1, 0]].",
    "output": "import numpy as np\nA = np.array([[1, 1], [0, 1], [1, 0]])\nP = A @ np.linalg.inv(A.T @ A) @ A.T\nprint(P)"
  },
  {
    "input": "Q164: Orthonormalize the set {[1, 1, 1], [1, 0, 1], [1, 1, 0]} using Gram-Schmidt.",
    "output": "import numpy as np\na1 = np.array([1, 1, 1], dtype=float)\na2 = np.array([1, 0, 1], dtype=float)\na3 = np.array([1, 1, 0], dtype=float)\nu1 = a1 / np.linalg.norm(a1)\nproj2 = np.dot(a2, u1) * u1\nu2 = a2 - proj2\nu2 = u2 / np.linalg.norm(u2)\nproj3 = np.dot(a3, u1) * u1 + np.dot(a3, u2) * u2\nu3 = a3 - proj3\nu3 = u3 / np.linalg.norm(u3)\nprint(u1, u2, u3)"
  },
  {
    "input": "Q165: Given v = [3, 1, 2] and orthonormal basis {[1, 0, 0], [0, 1, 0]}, compute the projection of v.",
    "output": "import numpy as np\nv = np.array([3, 1, 2])\nb1 = np.array([1, 0, 0])\nb2 = np.array([0, 1, 0])\nproj = np.dot(v, b1) * b1 + np.dot(v, b2) * b2\nprint(proj)"
  },
  {
    "input": "Q166: Given u = [1, 2, 2], construct the matrix that projects any vector onto u.",
    "output": "import numpy as np\nu = np.array([1, 2, 2])\nP = np.outer(u, u) / np.dot(u, u)\nprint(P)"
  },
  {
    "input": "Q167: Find the projection of [3, 0, 4] onto the line spanned by [0, 1, 0].",
    "output": "import numpy as np\nv = np.array([3, 0, 4])\nu = np.array([0, 1, 0])\nproj = (np.dot(v, u) / np.dot(u, u)) * u\nprint(proj)"
  },
  {
    "input": "Q168: Compute the projection of [4, 2, 1] onto the plane x + y + z = 0.",
    "output": "import numpy as np\nv = np.array([4, 2, 1])\nn = np.array([1, 1, 1])\nproj_onto_n = (np.dot(v, n) / np.dot(n, n)) * n\nproj = v - proj_onto_n\nprint(proj)"
  },
  {
    "input": "Q169: Perform one step of Gram-Schmidt on [2, 2, 1] and [1, 0, 1]. Return orthonormal vectors.",
    "output": "import numpy as np\na = np.array([2, 2, 1], dtype=float)\nb = np.array([1, 0, 1], dtype=float)\nu1 = a / np.linalg.norm(a)\nproj = np.dot(b, u1) * u1\nu2 = b - proj\nu2 = u2 / np.linalg.norm(u2)\nprint(u1, u2)"
  },
  {
    "input": "Q170: Determine the orthogonal component of [5, 2, 3] relative to [1, 2, 2].",
    "output": "import numpy as np\nv = np.array([5, 2, 3])\nu = np.array([1, 2, 2])\nproj = (np.dot(v, u) / np.dot(u, u)) * u\north = v - proj\nprint(orth)"
  },
  {
    "input": "Q171: Given matrix A = [[1, 0], [0, 1], [1, 1]], compute the projection of b = [2, 3, 4] onto Col(A).",
    "output": "import numpy as np\nA = np.array([[1, 0], [0, 1], [1, 1]])\nb = np.array([2, 3, 4])\nP = A @ np.linalg.inv(A.T @ A) @ A.T\nproj = P @ b\nprint(proj)"
  },
  {
    "input": "Q172: Find the projection of [1, 2] onto the line y = x.",
    "output": "import numpy as np\nv = np.array([1, 2])\nu = np.array([1, 1])\nproj = (np.dot(v, u) / np.dot(u, u)) * u\nprint(proj)"
  },
  {
    "input": "Q173: Compute the orthogonal projection of [2, 3, 4] onto the vector [1, 0, -1].",
    "output": "import numpy as np\nv = np.array([2, 3, 4])\nu = np.array([1, 0, -1])\nproj = (np.dot(v, u) / np.dot(u, u)) * u\nprint(proj)"
  },
  {
    "input": "Q174: Orthonormalize [1, 1, 1], [0, 1, -1], [1, 0, -1] using Gram-Schmidt.",
    "output": "import numpy as np\nv1 = np.array([1, 1, 1], dtype=float)\nv2 = np.array([0, 1, -1], dtype=float)\nv3 = np.array([1, 0, -1], dtype=float)\nu1 = v1 / np.linalg.norm(v1)\nproj2 = np.dot(v2, u1) * u1\nu2 = v2 - proj2\nu2 = u2 / np.linalg.norm(u2)\nproj3 = np.dot(v3, u1) * u1 + np.dot(v3, u2) * u2\nu3 = v3 - proj3\nu3 = u3 / np.linalg.norm(u3)\nprint(u1, u2, u3)"
  },
  {
    "input": "Q175: Find the projection matrix that projects onto the line through [1, 2, 3].",
    "output": "import numpy as np\nu = np.array([1, 2, 3])\nP = np.outer(u, u) / np.dot(u, u)\nprint(P)"
  },
  {
    "input": "Q176: Given b = [3, 3, 3], find its projection onto the plane x + y + z = 0.",
    "output": "import numpy as np\nb = np.array([3, 3, 3])\nn = np.array([1, 1, 1])\nproj = b - (np.dot(b, n) / np.dot(n, n)) * n\nprint(proj)"
  },
  {
    "input": "Q177: Decompose [2, 2] into components along and orthogonal to [3, 1].",
    "output": "import numpy as np\nv = np.array([2, 2])\nu = np.array([3, 1])\nproj = (np.dot(v, u) / np.dot(u, u)) * u\north = v - proj\nprint(\"Parallel:\", proj)\nprint(\"Orthogonal:\", orth)"
  },
  {
    "input": "Q178: Compute the projection of [5, 5, 5] onto the subspace spanned by [1, 0, 0] and [0, 1, 0].",
    "output": "import numpy as np\nv = np.array([5, 5, 5])\nb1 = np.array([1, 0, 0])\nb2 = np.array([0, 1, 0])\nproj = np.dot(v, b1) * b1 + np.dot(v, b2) * b2\nprint(proj)"
  },
  {
    "input": "Q179: Verify if the set {[1, 0, 0], [0, 1, 0], [0, 0, 1]} is orthonormal.",
    "output": "import numpy as np\nvectors = [np.array([1, 0, 0]), np.array([0, 1, 0]), np.array([0, 0, 1])]\nresult = all(np.isclose(np.linalg.norm(v), 1) for v in vectors)\nresult &= all(np.isclose(np.dot(vectors[i], vectors[j]), 0) for i in range(3) for j in range(i+1, 3))\nprint(result)"
  },
  {
    "input": "Q180: Find the orthogonal component of [4, 5, 6] to [1, 0, 1].",
    "output": "import numpy as np\nv = np.array([4, 5, 6])\nu = np.array([1, 0, 1])\nproj = (np.dot(v, u) / np.dot(u, u)) * u\north = v - proj\nprint(orth)"
  },
  {
    "input": "Q181: Orthonormalize [2, 0], [1, 1] using Gram-Schmidt.",
    "output": "import numpy as np\nv1 = np.array([2, 0], dtype=float)\nv2 = np.array([1, 1], dtype=float)\nu1 = v1 / np.linalg.norm(v1)\nproj = np.dot(v2, u1) * u1\nu2 = v2 - proj\nu2 = u2 / np.linalg.norm(u2)\nprint(u1, u2)"
  },
  {
    "input": "Q182: Compute projection of [3, -1, 2] onto the line through [2, 0, 1].",
    "output": "import numpy as np\nv = np.array([3, -1, 2])\nu = np.array([2, 0, 1])\nproj = (np.dot(v, u) / np.dot(u, u)) * u\nprint(proj)"
  },
  {
    "input": "Q183: Find the projection matrix that projects any vector onto [0, 1, 1].",
    "output": "import numpy as np\nu = np.array([0, 1, 1])\nP = np.outer(u, u) / np.dot(u, u)\nprint(P)"
  },
  {
    "input": "Q184: Given v = [6, 2, 1], compute its orthogonal projection onto the xy-plane.",
    "output": "import numpy as np\nv = np.array([6, 2, 1])\nn = np.array([0, 0, 1])\nproj = v - (np.dot(v, n) / np.dot(n, n)) * n\nprint(proj)"
  },
  {
    "input": "Q185: Check if [1, 2, 3] is orthogonal to the plane x + y + z = 0.",
    "output": "import numpy as np\nv = np.array([1, 2, 3])\nn = np.array([1, 1, 1])\nprint(np.dot(v, n) == 0)"
  },
  {
    "input": "Q186: Project [4, 3, 0] onto the subspace spanned by [1, 0, 0] and [0, 1, 0].",
    "output": "import numpy as np\nv = np.array([4, 3, 0])\nb1 = np.array([1, 0, 0])\nb2 = np.array([0, 1, 0])\nproj = np.dot(v, b1) * b1 + np.dot(v, b2) * b2\nprint(proj)"
  },
  {
    "input": "Q187: Compute the projection of [2, 4, 6] onto the vector [1, 1, 1].",
    "output": "import numpy as np\nv = np.array([2, 4, 6])\nu = np.array([1, 1, 1])\nproj = (np.dot(v, u) / np.dot(u, u)) * u\nprint(proj)"
  },
  {
    "input": "Q188: Find the projection of [1, 2] onto the vector [2, -1].",
    "output": "import numpy as np\nv = np.array([1, 2])\nu = np.array([2, -1])\nproj = (np.dot(v, u) / np.dot(u, u)) * u\nprint(proj)"
  },
  {
    "input": "Q189: Orthonormalize the vectors [1, 2, 0], [0, 1, 1] using Gram-Schmidt.",
    "output": "import numpy as np\na = np.array([1, 2, 0], dtype=float)\nb = np.array([0, 1, 1], dtype=float)\nu1 = a / np.linalg.norm(a)\nproj = np.dot(b, u1) * u1\nu2 = b - proj\nu2 = u2 / np.linalg.norm(u2)\nprint(u1, u2)"
  },
  {
    "input": "Q190: Find the projection of b = [2, 4, 6] onto the plane orthogonal to [0, 0, 1].",
    "output": "import numpy as np\nb = np.array([2, 4, 6])\nn = np.array([0, 0, 1])\nproj = b - (np.dot(b, n) / np.dot(n, n)) * n\nprint(proj)"
  },
  {
    "input": "Q191: Determine the orthogonal projection of [2, 2, 2] onto the line spanned by [1, 0, 1].",
    "output": "import numpy as np\nv = np.array([2, 2, 2])\nu = np.array([1, 0, 1])\nproj = (np.dot(v, u) / np.dot(u, u)) * u\nprint(proj)"
  },
  {
    "input": "Q192: Construct a projection matrix for projecting onto the y-axis in R^2.",
    "output": "import numpy as np\nu = np.array([0, 1])\nP = np.outer(u, u) / np.dot(u, u)\nprint(P)"
  },
  {
    "input": "Q193: Orthonormalize [3, 1], [2, 2] using Gram-Schmidt.",
    "output": "import numpy as np\nv1 = np.array([3, 1], dtype=float)\nv2 = np.array([2, 2], dtype=float)\nu1 = v1 / np.linalg.norm(v1)\nproj = np.dot(v2, u1) * u1\nu2 = v2 - proj\nu2 = u2 / np.linalg.norm(u2)\nprint(u1, u2)"
  },
  {
    "input": "Q194: Find the orthogonal component of [5, 5, 5] to [1, -1, 0].",
    "output": "import numpy as np\nv = np.array([5, 5, 5])\nu = np.array([1, -1, 0])\nproj = (np.dot(v, u) / np.dot(u, u)) * u\north = v - proj\nprint(orth)"
  },
  {
    "input": "Q195: Verify if [1, 1] and [-1, 1] are orthogonal.",
    "output": "import numpy as np\nv1 = np.array([1, 1])\nv2 = np.array([-1, 1])\nprint(np.dot(v1, v2) == 0)"
  },
  {
    "input": "Q196: Project [2, -3] onto the line through [1, 1].",
    "output": "import numpy as np\nv = np.array([2, -3])\nu = np.array([1, 1])\nproj = (np.dot(v, u) / np.dot(u, u)) * u\nprint(proj)"
  },
  {
    "input": "Q197: Find the projection matrix for projecting onto the plane x + y + z = 0.",
    "output": "import numpy as np\nn = np.array([1, 1, 1])\nP = np.eye(3) - np.outer(n, n) / np.dot(n, n)\nprint(P)"
  },
  {
    "input": "Q198: Decompose [4, 3] into components along and orthogonal to [1, 1].",
    "output": "import numpy as np\nv = np.array([4, 3])\nu = np.array([1, 1])\nproj = (np.dot(v, u) / np.dot(u, u)) * u\north = v - proj\nprint(\"Parallel:\", proj)\nprint(\"Orthogonal:\", orth)"
  },
  {
    "input": "Q199: Determine if [0, 1, 0] is orthogonal to the vector [1, 0, 1].",
    "output": "import numpy as np\nv1 = np.array([0, 1, 0])\nv2 = np.array([1, 0, 1])\nprint(np.dot(v1, v2) == 0)"
  },
  {
    "input": "Q200: Orthonormalize [1, 2, 2], [2, 1, 2] using Gram-Schmidt.",
    "output": "import numpy as np\na = np.array([1, 2, 2], dtype=float)\nb = np.array([2, 1, 2], dtype=float)\nu1 = a / np.linalg.norm(a)\nproj = np.dot(b, u1) * u1\nu2 = b - proj\nu2 = u2 / np.linalg.norm(u2)\nprint(u1, u2)"
  },
  {
    "input": "Q201: Compute projection of [3, 1] onto [1, -1].",
    "output": "import numpy as np\nv = np.array([3, 1])\nu = np.array([1, -1])\nproj = (np.dot(v, u) / np.dot(u, u)) * u\nprint(proj)"
  },
  {
    "input": "Q202: Find the projection of [6, 2, 3] onto the vector [1, 2, 1].",
    "output": "import numpy as np\nv = np.array([6, 2, 3])\nu = np.array([1, 2, 1])\nproj = (np.dot(v, u) / np.dot(u, u)) * u\nprint(proj)"
  },
  {
    "input": "Q203: Orthonormalize [1, 1, 0], [1, 0, 1] using Gram-Schmidt process.",
    "output": "import numpy as np\nv1 = np.array([1, 1, 0], dtype=float)\nv2 = np.array([1, 0, 1], dtype=float)\nu1 = v1 / np.linalg.norm(v1)\nproj = np.dot(v2, u1) * u1\nu2 = v2 - proj\nu2 = u2 / np.linalg.norm(u2)\nprint(u1, u2)"
  },
  {
    "input": "Q204: Decompose [1, 0, -1] into components parallel and orthogonal to [1, 1, 1].",
    "output": "import numpy as np\nv = np.array([1, 0, -1])\nu = np.array([1, 1, 1])\nproj = (np.dot(v, u)/np.dot(u, u)) * u\north = v - proj\nprint(\"Parallel:\", proj)\nprint(\"Orthogonal:\", orth)"
  },
  {
    "input": "Q205: Compute the orthogonal projection of [2, -1, 0] onto the yz-plane.",
    "output": "import numpy as np\nv = np.array([2, -1, 0])\nn = np.array([1, 0, 0])\nproj = v - (np.dot(v, n) / np.dot(n, n)) * n\nprint(proj)"
  },
  {
    "input": "Q206: Project [3, 4] onto the line y = 2x.",
    "output": "import numpy as np\nv = np.array([3, 4])\nu = np.array([1, 2])\nproj = (np.dot(v, u)/np.dot(u, u)) * u\nprint(proj)"
  },
  {
    "input": "Q207: Orthonormalize the vectors [1, 2], [2, 3] using Gram-Schmidt.",
    "output": "import numpy as np\nv1 = np.array([1, 2], dtype=float)\nv2 = np.array([2, 3], dtype=float)\nu1 = v1 / np.linalg.norm(v1)\nproj = np.dot(v2, u1) * u1\nu2 = v2 - proj\nu2 = u2 / np.linalg.norm(u2)\nprint(u1, u2)"
  },
  {
    "input": "Q208: Verify whether [3, 0, 4] and [-4, 0, 3] are orthogonal.",
    "output": "import numpy as np\nv1 = np.array([3, 0, 4])\nv2 = np.array([-4, 0, 3])\nprint(np.dot(v1, v2) == 0)"
  },
  {
    "input": "Q209: Compute the projection of [7, 2, -1] onto the x-axis.",
    "output": "import numpy as np\nv = np.array([7, 2, -1])\nu = np.array([1, 0, 0])\nproj = (np.dot(v, u)/np.dot(u, u)) * u\nprint(proj)"
  },
  {
    "input": "Q210: Find projection of [0, 1, 2] onto the plane y - z = 0.",
    "output": "import numpy as np\nv = np.array([0, 1, 2])\nn = np.array([0, 1, -1])\nproj = v - (np.dot(v, n)/np.dot(n, n)) * n\nprint(proj)"
  },
  {
    "input": "Q211: Orthonormalize [1, 2, 1], [2, 0, 1] using Gram-Schmidt.",
    "output": "import numpy as np\na = np.array([1, 2, 1], dtype=float)\nb = np.array([2, 0, 1], dtype=float)\nu1 = a / np.linalg.norm(a)\nproj = np.dot(b, u1) * u1\nu2 = b - proj\nu2 = u2 / np.linalg.norm(u2)\nprint(u1, u2)"
  },
  {
    "input": "Q212: Compute the projection of [5, 1] onto the vector [4, 3].",
    "output": "import numpy as np\nv = np.array([5, 1])\nu = np.array([4, 3])\nproj = (np.dot(v, u)/np.dot(u, u)) * u\nprint(proj)"
  },
  {
    "input": "Q213: Find the projection of [2, 2, 2] onto the subspace spanned by [1, 1, 0] and [0, 1, 1].",
    "output": "import numpy as np\nv = np.array([2, 2, 2])\nb1 = np.array([1, 1, 0])\nb2 = np.array([0, 1, 1])\nproj = np.dot(v, b1) * b1 / np.dot(b1, b1) + np.dot(v, b2) * b2 / np.dot(b2, b2)\nprint(proj)"
  },
  {
    "input": "Q214: Check if [1, 2, 3] and [3, 2, 1] are orthogonal.",
    "output": "import numpy as np\nv1 = np.array([1, 2, 3])\nv2 = np.array([3, 2, 1])\nprint(np.dot(v1, v2) == 0)"
  },
  {
    "input": "Q215: Compute the projection of [1, 1, 1] onto the plane x + y + z = 3.",
    "output": "import numpy as np\nv = np.array([1, 1, 1])\nn = np.array([1, 1, 1])\nproj = v - ((np.dot(v, n) - 3) / np.dot(n, n)) * n\nprint(proj)"
  },
  {
    "input": "Q216: Find the projection of [4, 5, 6] onto the line spanned by [1, 0, 1].",
    "output": "import numpy as np\nv = np.array([4, 5, 6])\nu = np.array([1, 0, 1])\nproj = (np.dot(v, u) / np.dot(u, u)) * u\nprint(proj)"
  },
  {
    "input": "Q217: Compute the projection of [1, 3, 2] onto the vector [2, 1, 2].",
    "output": "import numpy as np\nv = np.array([1, 3, 2])\nu = np.array([2, 1, 2])\nproj = (np.dot(v, u)/np.dot(u, u)) * u\nprint(proj)"
  },
  {
    "input": "Q218: Orthonormalize [2, 2, 1] and [1, 0, 2] using the Gram-Schmidt process.",
    "output": "import numpy as np\na = np.array([2, 2, 1], dtype=float)\nb = np.array([1, 0, 2], dtype=float)\nu1 = a / np.linalg.norm(a)\nproj = np.dot(b, u1) * u1\nu2 = b - proj\nu2 = u2 / np.linalg.norm(u2)\nprint(u1, u2)"
  },
  {
    "input": "Q219: Project the vector [4, -2, 1] onto the plane with normal vector [1, -1, 1].",
    "output": "import numpy as np\nv = np.array([4, -2, 1])\nn = np.array([1, -1, 1])\nproj = v - (np.dot(v, n)/np.dot(n, n)) * n\nprint(proj)"
  },
  {
    "input": "Q220: Find the projection matrix onto the vector [1, 2].",
    "output": "import numpy as np\nu = np.array([1, 2])\nP = np.outer(u, u) / np.dot(u, u)\nprint(P)"
  },
  {
    "input": "Q221: Verify if vectors [1, 2, 3] and [-2, 1, 0] are orthogonal.",
    "output": "import numpy as np\nv1 = np.array([1, 2, 3])\nv2 = np.array([-2, 1, 0])\nprint(np.dot(v1, v2) == 0)"
  },
  {
    "input": "Q222: Project [5, 5, 5] onto the subspace orthogonal to [0, 1, 0].",
    "output": "import numpy as np\nv = np.array([5, 5, 5])\nn = np.array([0, 1, 0])\nproj = v - (np.dot(v, n)/np.dot(n, n)) * n\nprint(proj)"
  },
  {
    "input": "Q223: Find the component of [2, -1, 4] orthogonal to [1, 2, 3].",
    "output": "import numpy as np\nv = np.array([2, -1, 4])\nu = np.array([1, 2, 3])\nproj = (np.dot(v, u)/np.dot(u, u)) * u\north = v - proj\nprint(orth)"
  },
  {
    "input": "Q224: Orthonormalize the vectors [1, 3], [2, -1] using Gram-Schmidt.",
    "output": "import numpy as np\na = np.array([1, 3], dtype=float)\nb = np.array([2, -1], dtype=float)\nu1 = a / np.linalg.norm(a)\nproj = np.dot(b, u1) * u1\nu2 = b - proj\nu2 = u2 / np.linalg.norm(u2)\nprint(u1, u2)"
  },
  {
    "input": "Q225: Determine if [0, 0, 1] and [1, 0, 0] are orthogonal.",
    "output": "import numpy as np\nv1 = np.array([0, 0, 1])\nv2 = np.array([1, 0, 0])\nprint(np.dot(v1, v2) == 0)"
  },
  {
    "input": "Q226: Project [3, 2, 1] onto the line spanned by [0, 1, 0].",
    "output": "import numpy as np\nv = np.array([3, 2, 1])\nu = np.array([0, 1, 0])\nproj = (np.dot(v, u)/np.dot(u, u)) * u\nprint(proj)"
  },
  {
    "input": "Q227: Find projection of [1, 1] onto [1, 0].",
    "output": "import numpy as np\nv = np.array([1, 1])\nu = np.array([1, 0])\nproj = (np.dot(v, u)/np.dot(u, u)) * u\nprint(proj)"
  },
  {
    "input": "Q228: Compute the orthogonal projection of [0, 4] onto the y-axis.",
    "output": "import numpy as np\nv = np.array([0, 4])\nu = np.array([0, 1])\nproj = (np.dot(v, u)/np.dot(u, u)) * u\nprint(proj)"
  },
  {
    "input": "Q229: Orthonormalize [2, 0, 0], [1, 1, 0], [0, 1, 1] using Gram-Schmidt.",
    "output": "import numpy as np\nv1 = np.array([2, 0, 0], dtype=float)\nv2 = np.array([1, 1, 0], dtype=float)\nv3 = np.array([0, 1, 1], dtype=float)\nu1 = v1 / np.linalg.norm(v1)\nproj2 = np.dot(v2, u1) * u1\nu2 = v2 - proj2\nu2 = u2 / np.linalg.norm(u2)\nproj3 = np.dot(v3, u1) * u1 + np.dot(v3, u2) * u2\nu3 = v3 - proj3\nu3 = u3 / np.linalg.norm(u3)\nprint(u1, u2, u3)"
  },
  {
    "input": "Q230: Project [6, 0, 0] onto [1, 2, 2].",
    "output": "import numpy as np\nv = np.array([6, 0, 0])\nu = np.array([1, 2, 2])\nproj = (np.dot(v, u)/np.dot(u, u)) * u\nprint(proj)"
  },
  {
    "input": "Q231: Find projection of [3, -3, 3] onto the plane x - y + z = 0.",
    "output": "import numpy as np\nv = np.array([3, -3, 3])\nn = np.array([1, -1, 1])\nproj = v - (np.dot(v, n)/np.dot(n, n)) * n\nprint(proj)"
  },
  {
    "input": "Q232: Compute the projection of [2, 1, 2] onto the vector [1, 0, -1].",
    "output": "import numpy as np\nv = np.array([2, 1, 2])\nu = np.array([1, 0, -1])\nproj = (np.dot(v, u)/np.dot(u, u)) * u\nprint(proj)"
  },
  {
    "input": "Q233: Orthonormalize the vectors [3, 1], [1, 3] using Gram-Schmidt.",
    "output": "import numpy as np\na = np.array([3, 1], dtype=float)\nb = np.array([1, 3], dtype=float)\nu1 = a / np.linalg.norm(a)\nproj = np.dot(b, u1) * u1\nu2 = b - proj\nu2 = u2 / np.linalg.norm(u2)\nprint(u1, u2)"
  },
  {
    "input": "Q234: Determine if [2, -2, 1] and [1, 1, -2] are orthogonal.",
    "output": "import numpy as np\nv1 = np.array([2, -2, 1])\nv2 = np.array([1, 1, -2])\nprint(np.dot(v1, v2) == 0)"
  },
  {
    "input": "Q235: Compute the projection of [0, 1, 1] onto the plane x + y + z = 0.",
    "output": "import numpy as np\nv = np.array([0, 1, 1])\nn = np.array([1, 1, 1])\nproj = v - (np.dot(v, n)/np.dot(n, n)) * n\nprint(proj)"
  },
  {
    "input": "Q236: Project [2, 2, 2] onto the subspace spanned by [1, 1, 1] and [1, -1, 0].",
    "output": "import numpy as np\nv = np.array([2, 2, 2])\nb1 = np.array([1, 1, 1])\nb2 = np.array([1, -1, 0])\nproj = np.dot(v, b1)*b1/np.dot(b1, b1) + np.dot(v, b2)*b2/np.dot(b2, b2)\nprint(proj)"
  },
  {
    "input": "Q237: Find orthogonal projection of [5, -1] onto the x-axis.",
    "output": "import numpy as np\nv = np.array([5, -1])\nu = np.array([1, 0])\nproj = (np.dot(v, u)/np.dot(u, u)) * u\nprint(proj)"
  },
  {
    "input": "Q238: Orthonormalize vectors [0, 1, 1], [1, 0, 1] using Gram-Schmidt.",
    "output": "import numpy as np\na = np.array([0, 1, 1], dtype=float)\nb = np.array([1, 0, 1], dtype=float)\nu1 = a / np.linalg.norm(a)\nproj = np.dot(b, u1) * u1\nu2 = b - proj\nu2 = u2 / np.linalg.norm(u2)\nprint(u1, u2)"
  },
  {
    "input": "Q239: Determine the projection of [1, 1, 1] onto the yz-plane.",
    "output": "import numpy as np\nv = np.array([1, 1, 1])\nn = np.array([1, 0, 0])\nproj = v - (np.dot(v, n)/np.dot(n, n)) * n\nprint(proj)"
  },
  {
    "input": "Q240: Find the projection matrix onto the line spanned by [2, 1].",
    "output": "import numpy as np\nu = np.array([2, 1])\nP = np.outer(u, u) / np.dot(u, u)\nprint(P)"
  },
  {
    "input": "Q241: Compute orthogonal component of [3, 4, 5] to [1, 2, 1].",
    "output": "import numpy as np\nv = np.array([3, 4, 5])\nu = np.array([1, 2, 1])\nproj = (np.dot(v, u)/np.dot(u, u)) * u\north = v - proj\nprint(orth)"
  },
  {
    "input": "Q242: Verify if [1, -2] and [2, 1] are orthogonal.",
    "output": "import numpy as np\nv1 = np.array([1, -2])\nv2 = np.array([2, 1])\nprint(np.dot(v1, v2) == 0)"
  },
  {
    "input": "Q243: Orthonormalize [1, 0, 1], [1, 1, 0], [0, 1, 1] using Gram-Schmidt.",
    "output": "import numpy as np\nv1 = np.array([1, 0, 1], dtype=float)\nv2 = np.array([1, 1, 0], dtype=float)\nv3 = np.array([0, 1, 1], dtype=float)\nu1 = v1 / np.linalg.norm(v1)\nproj2 = np.dot(v2, u1) * u1\nu2 = v2 - proj2\nu2 = u2 / np.linalg.norm(u2)\nproj3 = np.dot(v3, u1) * u1 + np.dot(v3, u2) * u2\nu3 = v3 - proj3\nu3 = u3 / np.linalg.norm(u3)\nprint(u1, u2, u3)"
  },
  {
    "input": "Q244: Project [1, 2, 3] onto [0, 0, 1].",
    "output": "import numpy as np\nv = np.array([1, 2, 3])\nu = np.array([0, 0, 1])\nproj = (np.dot(v, u)/np.dot(u, u)) * u\nprint(proj)"
  },
  {
    "input": "Q245: Find projection of [4, 2] onto the vector [1, 1].",
    "output": "import numpy as np\nv = np.array([4, 2])\nu = np.array([1, 1])\nproj = (np.dot(v, u)/np.dot(u, u)) * u\nprint(proj)"
  },
  {
    "input": "Q246: Compute projection of [1, 1, -1] onto the plane with normal [0, 1, 1].",
    "output": "import numpy as np\nv = np.array([1, 1, -1])\nn = np.array([0, 1, 1])\nproj = v - (np.dot(v, n)/np.dot(n, n)) * n\nprint(proj)"
  },
  {
    "input": "Q247: Compute the projection of [4, 0, 2] onto the vector [1, 1, 0].",
    "output": "import numpy as np\nv = np.array([4, 0, 2])\nu = np.array([1, 1, 0])\nproj = (np.dot(v, u)/np.dot(u, u)) * u\nprint(proj)"
  },
  {
    "input": "Q248: Determine the orthogonal component of [1, 2] to [2, 1].",
    "output": "import numpy as np\nv = np.array([1, 2])\nu = np.array([2, 1])\nproj = (np.dot(v, u)/np.dot(u, u)) * u\north = v - proj\nprint(orth)"
  },
  {
    "input": "Q249: Orthonormalize vectors [1, 2, 2], [2, 0, -1] using Gram-Schmidt.",
    "output": "import numpy as np\na = np.array([1, 2, 2], dtype=float)\nb = np.array([2, 0, -1], dtype=float)\nu1 = a / np.linalg.norm(a)\nproj = np.dot(b, u1) * u1\nu2 = b - proj\nu2 = u2 / np.linalg.norm(u2)\nprint(u1, u2)"
  },
  {
    "input": "Q250: Find the projection matrix onto the vector [3, 4].",
    "output": "import numpy as np\nu = np.array([3, 4])\nP = np.outer(u, u) / np.dot(u, u)\nprint(P)"
  },
  {
    "input": "Q251: Project the vector [5, 1, 3] onto the xz-plane.",
    "output": "import numpy as np\nv = np.array([5, 1, 3])\nn = np.array([0, 1, 0])\nproj = v - (np.dot(v, n)/np.dot(n, n)) * n\nprint(proj)"
  },
  {
    "input": "Q252: Verify if vectors [2, 1, 0] and [-1, 2, 0] are orthogonal.",
    "output": "import numpy as np\nv1 = np.array([2, 1, 0])\nv2 = np.array([-1, 2, 0])\nprint(np.dot(v1, v2) == 0)"
  },
  {
    "input": "Q253: Orthonormalize [1, 2, 3] and [4, 5, 6] using Gram-Schmidt.",
    "output": "import numpy as np\na = np.array([1, 2, 3], dtype=float)\nb = np.array([4, 5, 6], dtype=float)\nu1 = a / np.linalg.norm(a)\nproj = np.dot(b, u1) * u1\nu2 = b - proj\nu2 = u2 / np.linalg.norm(u2)\nprint(u1, u2)"
  },
  {
    "input": "Q254: Compute projection of [1, -1, 0] onto vector [1, 1, 0].",
    "output": "import numpy as np\nv = np.array([1, -1, 0])\nu = np.array([1, 1, 0])\nproj = (np.dot(v, u)/np.dot(u, u)) * u\nprint(proj)"
  },
  {
    "input": "Q255: Project [6, 3] onto the y-axis.",
    "output": "import numpy as np\nv = np.array([6, 3])\nu = np.array([0, 1])\nproj = (np.dot(v, u)/np.dot(u, u)) * u\nprint(proj)"
  },
  {
    "input": "Q256: Find the orthogonal projection of [2, 3, 5] onto the plane y - z = 0.",
    "output": "import numpy as np\nv = np.array([2, 3, 5])\nn = np.array([0, 1, -1])\nproj = v - (np.dot(v, n)/np.dot(n, n)) * n\nprint(proj)"
  },
  {
    "input": "Q257: Determine the projection of [2, -2] onto [-1, -1].",
    "output": "import numpy as np\nv = np.array([2, -2])\nu = np.array([-1, -1])\nproj = (np.dot(v, u)/np.dot(u, u)) * u\nprint(proj)"
  },
  {
    "input": "Q258: Project [3, 4, 0] onto the yz-plane.",
    "output": "import numpy as np\nv = np.array([3, 4, 0])\nn = np.array([1, 0, 0])\nproj = v - (np.dot(v, n)/np.dot(n, n)) * n\nprint(proj)"
  },
  {
    "input": "Q259: Compute the orthogonal component of [3, 3, 1] to [1, 0, 1].",
    "output": "import numpy as np\nv = np.array([3, 3, 1])\nu = np.array([1, 0, 1])\nproj = (np.dot(v, u)/np.dot(u, u)) * u\north = v - proj\nprint(orth)"
  },
  {
    "input": "Q260: Orthonormalize [1, 0, 1], [0, 1, 0], [1, 1, 0] using Gram-Schmidt.",
    "output": "import numpy as np\nv1 = np.array([1, 0, 1], dtype=float)\nv2 = np.array([0, 1, 0], dtype=float)\nv3 = np.array([1, 1, 0], dtype=float)\nu1 = v1 / np.linalg.norm(v1)\nu2 = v2 / np.linalg.norm(v2)\nproj3 = np.dot(v3, u1) * u1 + np.dot(v3, u2) * u2\nu3 = v3 - proj3\nu3 = u3 / np.linalg.norm(u3)\nprint(u1, u2, u3)"
  },
  {
    "input": "Q261: Project [1, 0, 1] onto the plane with normal vector [0, 1, -1].",
    "output": "import numpy as np\nv = np.array([1, 0, 1])\nn = np.array([0, 1, -1])\nproj = v - (np.dot(v, n)/np.dot(n, n)) * n\nprint(proj)"
  },
  {
    "input": "Q262: Compute projection of [3, 4] onto [4, -3].",
    "output": "import numpy as np\nv = np.array([3, 4])\nu = np.array([4, -3])\nproj = (np.dot(v, u)/np.dot(u, u)) * u\nprint(proj)"
  },
  {
    "input": "Q263: Find projection of [1, 2, 2] onto the line spanned by [1, 1, 1].",
    "output": "import numpy as np\nv = np.array([1, 2, 2])\nu = np.array([1, 1, 1])\nproj = (np.dot(v, u)/np.dot(u, u)) * u\nprint(proj)"
  },
  {
    "input": "Q264: Determine if vectors [1, 0, 1] and [1, 2, -1] are orthogonal.",
    "output": "import numpy as np\nv1 = np.array([1, 0, 1])\nv2 = np.array([1, 2, -1])\nprint(np.dot(v1, v2) == 0)"
  },
  {
    "input": "Q265: Orthonormalize [2, 0, 1], [1, 1, 1] using Gram-Schmidt.",
    "output": "import numpy as np\na = np.array([2, 0, 1], dtype=float)\nb = np.array([1, 1, 1], dtype=float)\nu1 = a / np.linalg.norm(a)\nproj = np.dot(b, u1) * u1\nu2 = b - proj\nu2 = u2 / np.linalg.norm(u2)\nprint(u1, u2)"
  },
  {
    "input": "Q266: Find orthogonal projection of [0, 3] onto the x-axis.",
    "output": "import numpy as np\nv = np.array([0, 3])\nu = np.array([1, 0])\nproj = (np.dot(v, u)/np.dot(u, u)) * u\nprint(proj)"
  },
  {
    "input": "Q267: Project [2, 2, 2] onto plane x + y + z = 3.",
    "output": "import numpy as np\nv = np.array([2, 2, 2])\nn = np.array([1, 1, 1])\nproj = v - (np.dot(v, n)/np.dot(n, n)) * n\nprint(proj)"
  },
  {
    "input": "Q268: Project [3, 1, 2] onto [0, 1, 1].",
    "output": "import numpy as np\nv = np.array([3, 1, 2])\nu = np.array([0, 1, 1])\nproj = (np.dot(v, u)/np.dot(u, u)) * u\nprint(proj)"
  },
  {
    "input": "Q269: Orthonormalize [1, 1], [1, -1] using Gram-Schmidt.",
    "output": "import numpy as np\na = np.array([1, 1], dtype=float)\nb = np.array([1, -1], dtype=float)\nu1 = a / np.linalg.norm(a)\nproj = np.dot(b, u1) * u1\nu2 = b - proj\nu2 = u2 / np.linalg.norm(u2)\nprint(u1, u2)"
  },
  {
    "input": "Q270: Compute projection of [5, 6, 0] onto the yz-plane.",
    "output": "import numpy as np\nv = np.array([5, 6, 0])\nn = np.array([1, 0, 0])\nproj = v - (np.dot(v, n)/np.dot(n, n)) * n\nprint(proj)"
  },
  {
    "input": "Q271: Find the projection matrix onto the vector [1, 2, 2].",
    "output": "import numpy as np\nu = np.array([1, 2, 2])\nP = np.outer(u, u) / np.dot(u, u)\nprint(P)"
  },
  {
    "input": "Q272: Project [1, 0, 0] onto plane x + 2y + 2z = 0.",
    "output": "import numpy as np\nv = np.array([1, 0, 0])\nn = np.array([1, 2, 2])\nproj = v - (np.dot(v, n)/np.dot(n, n)) * n\nprint(proj)"
  },
  {
    "input": "Q273: Determine the projection of [3, -1] onto [-1, 2].",
    "output": "import numpy as np\nv = np.array([3, -1])\nu = np.array([-1, 2])\nproj = (np.dot(v, u)/np.dot(u, u)) * u\nprint(proj)"
  },
  {
    "input": "Q274: Orthonormalize [1, 2, 2], [2, 4, 5] using Gram-Schmidt.",
    "output": "import numpy as np\na = np.array([1, 2, 2], dtype=float)\nb = np.array([2, 4, 5], dtype=float)\nu1 = a / np.linalg.norm(a)\nproj = np.dot(b, u1) * u1\nu2 = b - proj\nu2 = u2 / np.linalg.norm(u2)\nprint(u1, u2)"
  },
  {
    "input": "Q275: Compute orthogonal component of [1, 1, 0] to [1, 1, 1].",
    "output": "import numpy as np\nv = np.array([1, 1, 0])\nu = np.array([1, 1, 1])\nproj = (np.dot(v, u)/np.dot(u, u)) * u\north = v - proj\nprint(orth)"
  },
  {
    "input": "Q276: Find projection of [0, 1, 0] onto the line spanned by [1, 2, 2].",
    "output": "import numpy as np\nv = np.array([0, 1, 0])\nu = np.array([1, 2, 2])\nproj = (np.dot(v, u)/np.dot(u, u)) * u\nprint(proj)"
  },
  {
    "input": "Q277: Project vector [4, 2, -2] onto vector [1, 0, -1].",
    "output": "import numpy as np\nv = np.array([4, 2, -2])\nu = np.array([1, 0, -1])\nproj = (np.dot(v, u)/np.dot(u, u)) * u\nprint(proj)"
  },
  {
    "input": "Q278: Find the orthogonal component of [3, 1] to [1, 2].",
    "output": "import numpy as np\nv = np.array([3, 1])\nu = np.array([1, 2])\nproj = (np.dot(v, u)/np.dot(u, u)) * u\north = v - proj\nprint(orth)"
  },
  {
    "input": "Q279: Orthonormalize the vectors [1, 0, 1], [1, 1, 0] using Gram-Schmidt.",
    "output": "import numpy as np\na = np.array([1, 0, 1], dtype=float)\nb = np.array([1, 1, 0], dtype=float)\nu1 = a / np.linalg.norm(a)\nproj = np.dot(b, u1) * u1\nu2 = b - proj\nu2 = u2 / np.linalg.norm(u2)\nprint(u1, u2)"
  },
  {
    "input": "Q280: Project [0, 2, 4] onto the xy-plane.",
    "output": "import numpy as np\nv = np.array([0, 2, 4])\nn = np.array([0, 0, 1])\nproj = v - (np.dot(v, n)/np.dot(n, n)) * n\nprint(proj)"
  },
  {
    "input": "Q281: Determine if vectors [2, -2, 0] and [1, 1, 0] are orthogonal.",
    "output": "import numpy as np\nv1 = np.array([2, -2, 0])\nv2 = np.array([1, 1, 0])\nprint(np.dot(v1, v2) == 0)"
  },
  {
    "input": "Q282: Find the projection matrix onto the line spanned by [2, -1, 2].",
    "output": "import numpy as np\nu = np.array([2, -1, 2])\nP = np.outer(u, u) / np.dot(u, u)\nprint(P)"
  },
  {
    "input": "Q283: Project [1, 1, 1] onto the plane x - y + z = 0.",
    "output": "import numpy as np\nv = np.array([1, 1, 1])\nn = np.array([1, -1, 1])\nproj = v - (np.dot(v, n)/np.dot(n, n)) * n\nprint(proj)"
  },
  {
    "input": "Q284: Project [2, 2, 1] onto [1, 2, 1].",
    "output": "import numpy as np\nv = np.array([2, 2, 1])\nu = np.array([1, 2, 1])\nproj = (np.dot(v, u)/np.dot(u, u)) * u\nprint(proj)"
  },
  {
    "input": "Q285: Orthonormalize [0, 1, 2], [1, 0, 2] using Gram-Schmidt.",
    "output": "import numpy as np\na = np.array([0, 1, 2], dtype=float)\nb = np.array([1, 0, 2], dtype=float)\nu1 = a / np.linalg.norm(a)\nproj = np.dot(b, u1) * u1\nu2 = b - proj\nu2 = u2 / np.linalg.norm(u2)\nprint(u1, u2)"
  },
  {
    "input": "Q286: Compute projection of [2, 1] onto vector [1, -1].",
    "output": "import numpy as np\nv = np.array([2, 1])\nu = np.array([1, -1])\nproj = (np.dot(v, u)/np.dot(u, u)) * u\nprint(proj)"
  },
  {
    "input": "Q287: Project vector [5, 5, 1] onto vector [1, 1, 0].",
    "output": "import numpy as np\nv = np.array([5, 5, 1])\nu = np.array([1, 1, 0])\nproj = (np.dot(v, u)/np.dot(u, u)) * u\nprint(proj)"
  },
  {
    "input": "Q288: Compute the orthogonal component of [1, 2, 3] to [0, 1, 1].",
    "output": "import numpy as np\nv = np.array([1, 2, 3])\nu = np.array([0, 1, 1])\nproj = (np.dot(v, u)/np.dot(u, u)) * u\north = v - proj\nprint(orth)"
  },
  {
    "input": "Q289: Orthonormalize [1, 2], [2, 1] using Gram-Schmidt.",
    "output": "import numpy as np\na = np.array([1, 2], dtype=float)\nb = np.array([2, 1], dtype=float)\nu1 = a / np.linalg.norm(a)\nproj = np.dot(b, u1) * u1\nu2 = b - proj\nu2 = u2 / np.linalg.norm(u2)\nprint(u1, u2)"
  },
  {
    "input": "Q290: Project [1, 1, 0] onto the plane x + y + z = 0.",
    "output": "import numpy as np\nv = np.array([1, 1, 0])\nn = np.array([1, 1, 1])\nproj = v - (np.dot(v, n)/np.dot(n, n)) * n\nprint(proj)"
  },
  {
    "input": "Q291: Project [3, 2, 1] onto [1, 0, -1].",
    "output": "import numpy as np\nv = np.array([3, 2, 1])\nu = np.array([1, 0, -1])\nproj = (np.dot(v, u)/np.dot(u, u)) * u\nprint(proj)"
  },
  {
    "input": "Q292: Compute projection of [3, 2, 1] onto vector [1, 1, 0].",
    "output": "import numpy as np\nv = np.array([3, 2, 1])\nu = np.array([1, 1, 0])\nproj = (np.dot(v, u)/np.dot(u, u)) * u\nprint(proj)"
  },
  {
    "input": "Q293: Find orthogonal component of [1, 2, 3] to vector [2, 2, 2].",
    "output": "import numpy as np\nv = np.array([1, 2, 3])\nu = np.array([2, 2, 2])\nproj = (np.dot(v, u)/np.dot(u, u)) * u\north = v - proj\nprint(orth)"
  },
  {
    "input": "Q294: Orthonormalize [3, 0, 1], [0, 2, 2] using Gram-Schmidt process.",
    "output": "import numpy as np\na = np.array([3, 0, 1], dtype=float)\nb = np.array([0, 2, 2], dtype=float)\nu1 = a / np.linalg.norm(a)\nproj = np.dot(b, u1) * u1\nu2 = b - proj\nu2 = u2 / np.linalg.norm(u2)\nprint(u1, u2)"
  },
  {
    "input": "Q295: Project [4, 1, 1] onto line spanned by [0, 1, -1].",
    "output": "import numpy as np\nv = np.array([4, 1, 1])\nu = np.array([0, 1, -1])\nproj = (np.dot(v, u)/np.dot(u, u)) * u\nprint(proj)"
  },
  {
    "input": "Q296: Find projection of [0, 0, 5] onto plane x + y + z = 0.",
    "output": "import numpy as np\nv = np.array([0, 0, 5])\nn = np.array([1, 1, 1])\nproj = v - (np.dot(v, n)/np.dot(n, n)) * n\nprint(proj)"
  },
  {
    "input": "Q297: Project [1, -1, 0] onto vector [1, 0, 1].",
    "output": "import numpy as np\nv = np.array([1, -1, 0])\nu = np.array([1, 0, 1])\nproj = (np.dot(v, u)/np.dot(u, u)) * u\nprint(proj)"
  },
  {
    "input": "Q298: Find the projection matrix onto the vector [1, -1, 1].",
    "output": "import numpy as np\nu = np.array([1, -1, 1])\nP = np.outer(u, u) / np.dot(u, u)\nprint(P)"
  },
  {
    "input": "Q299: Orthonormalize [1, 0, 0], [1, 1, 0], [1, 1, 1] using Gram-Schmidt.",
    "output": "import numpy as np\na = np.array([1, 0, 0], dtype=float)\nb = np.array([1, 1, 0], dtype=float)\nc = np.array([1, 1, 1], dtype=float)\nu1 = a / np.linalg.norm(a)\nproj_b = np.dot(b, u1) * u1\nu2 = b - proj_b\nu2 = u2 / np.linalg.norm(u2)\nproj_c = np.dot(c, u1) * u1 + np.dot(c, u2) * u2\nu3 = c - proj_c\nu3 = u3 / np.linalg.norm(u3)\nprint(u1, u2, u3)"
  },
  {
    "input": "Q300: Project [6, 0, 0] onto the yz-plane.",
    "output": "import numpy as np\nv = np.array([6, 0, 0])\nn = np.array([1, 0, 0])\nproj = v - (np.dot(v, n)/np.dot(n, n)) * n\nprint(proj)"
  },
  {
    "input": "Q301: Find projection of [1, 2, 3] onto vector [3, 2, 1].",
    "output": "import numpy as np\nv = np.array([1, 2, 3])\nu = np.array([3, 2, 1])\nproj = (np.dot(v, u)/np.dot(u, u)) * u\nprint(proj)"
  },
  {
    "input": "Q302: Determine if vectors [4, -4, 2] and [2, 2, 2] are orthogonal.",
    "output": "import numpy as np\nv1 = np.array([4, -4, 2])\nv2 = np.array([2, 2, 2])\nprint(np.dot(v1, v2) == 0)"
  },
  {
    "input": "Q303: Project vector [2, 4] onto vector [1, 1].",
    "output": "import numpy as np\nv = np.array([2, 4])\nu = np.array([1, 1])\nproj = (np.dot(v, u)/np.dot(u, u)) * u\nprint(proj)"
  },
  {
    "input": "Q304: Compute projection of [2, 0, 2] onto plane x + y + z = 1.",
    "output": "import numpy as np\nv = np.array([2, 0, 2])\nn = np.array([1, 1, 1])\nproj = v - (np.dot(v, n)/np.dot(n, n)) * n\nprint(proj)"
  },
  {
    "input": "Q305: Orthonormalize [2, 2], [1, -1] using Gram-Schmidt.",
    "output": "import numpy as np\na = np.array([2, 2], dtype=float)\nb = np.array([1, -1], dtype=float)\nu1 = a / np.linalg.norm(a)\nproj = np.dot(b, u1) * u1\nu2 = b - proj\nu2 = u2 / np.linalg.norm(u2)\nprint(u1, u2)"
  },
  {
    "input": "Q306: Project [3, -3, 6] onto vector [1, -1, 2].",
    "output": "import numpy as np\nv = np.array([3, -3, 6])\nu = np.array([1, -1, 2])\nproj = (np.dot(v, u)/np.dot(u, u)) * u\nprint(proj)"
  },
  {
    "input": "Q307: Project [4, 3, 0] onto vector [0, 1, 1].",
    "output": "import numpy as np\nv = np.array([4, 3, 0])\nu = np.array([0, 1, 1])\nproj = (np.dot(v, u)/np.dot(u, u)) * u\nprint(proj)"
  },
  {
    "input": "Q308: Orthonormalize [1, 2, 2], [2, 0, 1] using Gram-Schmidt.",
    "output": "import numpy as np\na = np.array([1, 2, 2], dtype=float)\nb = np.array([2, 0, 1], dtype=float)\nu1 = a / np.linalg.norm(a)\nproj = np.dot(b, u1) * u1\nu2 = b - proj\nu2 = u2 / np.linalg.norm(u2)\nprint(u1, u2)"
  },
  {
    "input": "Q309: Compute orthogonal component of [2, 1, 3] to [0, 0, 1].",
    "output": "import numpy as np\nv = np.array([2, 1, 3])\nu = np.array([0, 0, 1])\nproj = (np.dot(v, u)/np.dot(u, u)) * u\north = v - proj\nprint(orth)"
  },
  {
    "input": "Q310: Find projection matrix onto [1, 2].",
    "output": "import numpy as np\nu = np.array([1, 2])\nP = np.outer(u, u) / np.dot(u, u)\nprint(P)"
  },
  {
    "input": "Q311: Project [5, 1, -2] onto vector [1, 1, 1].",
    "output": "import numpy as np\nv = np.array([5, 1, -2])\nu = np.array([1, 1, 1])\nproj = (np.dot(v, u)/np.dot(u, u)) * u\nprint(proj)"
  },
  {
    "input": "Q312: Project [2, -2, 2] onto the plane x + y + z = 0.",
    "output": "import numpy as np\nv = np.array([2, -2, 2])\nn = np.array([1, 1, 1])\nproj = v - (np.dot(v, n)/np.dot(n, n)) * n\nprint(proj)"
  },
  {
    "input": "Q313: Find the orthogonal projection of vector [3, 2, 1] onto the plane defined by 2x - y + z = 0.",
    "output": "import numpy as np\nv = np.array([3, 2, 1])\nn = np.array([2, -1, 1])\nproj = v - (np.dot(v, n)/np.dot(n, n)) * n\nprint(proj)"
  },
  {
    "input": "Q314: Orthonormalize the set of vectors [[1, 1, 0], [1, 0, 1], [0, 1, 1]] using Gram-Schmidt process.",
    "output": "import numpy as np\nv1 = np.array([1, 1, 0], dtype=float)\nv2 = np.array([1, 0, 1], dtype=float)\nv3 = np.array([0, 1, 1], dtype=float)\nu1 = v1 / np.linalg.norm(v1)\nproj_v2 = np.dot(v2, u1) * u1\nu2 = v2 - proj_v2\nu2 = u2 / np.linalg.norm(u2)\nproj_v3 = np.dot(v3, u1) * u1 + np.dot(v3, u2) * u2\nu3 = v3 - proj_v3\nu3 = u3 / np.linalg.norm(u3)\nprint(u1, u2, u3)"
  },
  {
    "input": "Q315: Find the projection of vector [4, 4, 1] onto the plane with normal vector [1, -1, 1].",
    "output": "import numpy as np\nv = np.array([4, 4, 1])\nn = np.array([1, -1, 1])\nproj = v - (np.dot(v, n) / np.dot(n, n)) * n\nprint(proj)"
  },
  {
    "input": "Q316: Find projection matrix onto the subspace spanned by [[1, 0, 1], [0, 1, 1]].",
    "output": "import numpy as np\nA = np.array([[1, 0, 1], [0, 1, 1]]).T\nP = A @ np.linalg.inv(A.T @ A) @ A.T\nprint(P)"
  },
  {
    "input": "Q317: Determine if the set {[1, 1, 1], [1, 2, 3], [1, 4, 9]} is orthogonal.",
    "output": "import numpy as np\nA = np.array([[1, 1, 1], [1, 2, 3], [1, 4, 9]])\nfor i in range(3):\n    for j in range(i+1, 3):\n        print(f\"Dot product of v{i+1} and v{j+1}:\", np.dot(A[i], A[j]))"
  },
  {
    "input": "Q318: Find orthogonal projection of [5, 2, -1] onto subspace spanned by [[1, 2, 1], [2, 1, -1]].",
    "output": "import numpy as np\nv = np.array([5, 2, -1])\nA = np.array([[1, 2, 1], [2, 1, -1]]).T\nP = A @ np.linalg.inv(A.T @ A) @ A.T\nproj = P @ v\nprint(proj)"
  },
  {
    "input": "Q319: Orthonormalize [[2, 1, 0], [1, 1, 1], [0, 1, 2]] using Gram-Schmidt.",
    "output": "import numpy as np\nv1 = np.array([2, 1, 0], dtype=float)\nv2 = np.array([1, 1, 1], dtype=float)\nv3 = np.array([0, 1, 2], dtype=float)\nu1 = v1 / np.linalg.norm(v1)\nproj_v2 = np.dot(v2, u1) * u1\nu2 = v2 - proj_v2\nu2 = u2 / np.linalg.norm(u2)\nproj_v3 = np.dot(v3, u1) * u1 + np.dot(v3, u2) * u2\nu3 = v3 - proj_v3\nu3 = u3 / np.linalg.norm(u3)\nprint(u1, u2, u3)"
  },
  {
    "input": "Q320: Project [6, -2, 1] onto the plane 3x + y - z = 0.",
    "output": "import numpy as np\nv = np.array([6, -2, 1])\nn = np.array([3, 1, -1])\nproj = v - (np.dot(v, n)/np.dot(n, n)) * n\nprint(proj)"
  },
  {
    "input": "Q321: Project vector [2, 4, 6] onto the subspace orthogonal to [1, 1, 1].",
    "output": "import numpy as np\nv = np.array([2, 4, 6])\nn = np.array([1, 1, 1])\nproj = v - (np.dot(v, n)/np.dot(n, n)) * n\nprint(proj)"
  },
  {
    "input": "Q322: Project vector [2, 1, 3] onto the subspace spanned by [1, 1, 0] and [0, 1, 1].",
    "output": "import numpy as np\nv = np.array([2, 1, 3])\nA = np.array([[1, 1, 0], [0, 1, 1]]).T\nP = A @ np.linalg.inv(A.T @ A) @ A.T\nproj = P @ v\nprint(proj)"
  },
  {
    "input": "Q323: Orthonormalize vectors [[3, 1, 4], [1, 5, 9], [2, 6, 5]] using Gram-Schmidt.",
    "output": "import numpy as np\nv1 = np.array([3, 1, 4], dtype=float)\nv2 = np.array([1, 5, 9], dtype=float)\nv3 = np.array([2, 6, 5], dtype=float)\nu1 = v1 / np.linalg.norm(v1)\nproj2 = np.dot(v2, u1) * u1\nu2 = v2 - proj2\nu2 = u2 / np.linalg.norm(u2)\nproj3 = np.dot(v3, u1) * u1 + np.dot(v3, u2) * u2\nu3 = v3 - proj3\nu3 = u3 / np.linalg.norm(u3)\nprint(u1, u2, u3)"
  },
  {
    "input": "Determine if the vectors [1, 2, 2], [2, 1, 2], [2, 2, 1] form an orthogonal basis.",
    "output": "import numpy as np\nv = [np.array([1, 2, 2]), np.array([2, 1, 2]), np.array([2, 2, 1])]\nprint(np.dot(v[0], v[1]), np.dot(v[0], v[2]), np.dot(v[1], v[2]))"
  },
  {
    "input": "Find orthogonal projection of [4, 1, 2] onto the plane defined by x - 2y + z = 0.",
    "output": "import numpy as np\nv = np.array([4, 1, 2])\nn = np.array([1, -2, 1])\nproj = v - (np.dot(v, n)/np.dot(n, n)) * n\nprint(proj)"
  },
  {
    "input": "Compute projection matrix onto the column space of A = [[1, 0], [1, 1], [1, 2]].",
    "output": "import numpy as np\nA = np.array([[1, 0], [1, 1], [1, 2]])\nP = A @ np.linalg.inv(A.T @ A) @ A.T\nprint(P)"
  },
  {
    "input": "Project [1, 2, 3, 4] onto the subspace spanned by [1, 1, 0, 0], [0, 0, 1, 1].",
    "output": "import numpy as np\nv = np.array([1, 2, 3, 4])\nA = np.array([[1, 0], [1, 0], [0, 1], [0, 1]])\nP = A @ np.linalg.inv(A.T @ A) @ A.T\nproj = P @ v\nprint(proj)"
  },
  {
    "input": "Find the orthogonal projection of vector [1, 2, 2] onto the plane x + y + z = 0.",
    "output": "import numpy as np\nv = np.array([1, 2, 2])\nn = np.array([1, 1, 1])\nproj = v - (np.dot(v, n)/np.dot(n, n)) * n\nprint(proj)"
  },
  {
    "input": "Orthonormalize the set of vectors [[1, 2, 2], [2, 0, 1], [1, 1, 1]] using Gram-Schmidt.",
    "output": "import numpy as np\nv1 = np.array([1, 2, 2], dtype=float)\nv2 = np.array([2, 0, 1], dtype=float)\nv3 = np.array([1, 1, 1], dtype=float)\nu1 = v1 / np.linalg.norm(v1)\nproj2 = np.dot(v2, u1) * u1\nu2 = v2 - proj2\nu2 = u2 / np.linalg.norm(u2)\nproj3 = np.dot(v3, u1) * u1 + np.dot(v3, u2) * u2\nu3 = v3 - proj3\nu3 = u3 / np.linalg.norm(u3)\nprint(u1, u2, u3)"
  },
  {
    "input": "Project [3, -1, 4] onto the plane defined by 2x + 3y + z = 0.",
    "output": "import numpy as np\nv = np.array([3, -1, 4])\nn = np.array([2, 3, 1])\nproj = v - (np.dot(v, n)/np.dot(n, n)) * n\nprint(proj)"
  },
  {
    "input": "Find the projection matrix onto the column space of A = [[1, 2], [0, 1], [1, 0]].",
    "output": "import numpy as np\nA = np.array([[1, 2], [0, 1], [1, 0]])\nP = A @ np.linalg.inv(A.T @ A) @ A.T\nprint(P)"
  },
  {
    "input": "Determine whether the vectors [1, -1, 1], [1, 1, 0], [0, 1, 1] form an orthogonal basis.",
    "output": "import numpy as np\nv = [np.array([1, -1, 1]), np.array([1, 1, 0]), np.array([0, 1, 1])]\nprint(np.dot(v[0], v[1]), np.dot(v[0], v[2]), np.dot(v[1], v[2]))"
  },
  {
    "input": "Orthonormalize the vectors [[1, 2, 1], [2, 3, 1], [1, 1, 2]].",
    "output": "import numpy as np\nv1 = np.array([1, 2, 1], dtype=float)\nv2 = np.array([2, 3, 1], dtype=float)\nv3 = np.array([1, 1, 2], dtype=float)\nu1 = v1 / np.linalg.norm(v1)\nproj2 = np.dot(v2, u1) * u1\nu2 = v2 - proj2\nu2 = u2 / np.linalg.norm(u2)\nproj3 = np.dot(v3, u1) * u1 + np.dot(v3, u2) * u2\nu3 = v3 - proj3\nu3 = u3 / np.linalg.norm(u3)\nprint(u1, u2, u3)"
  },
  {
    "input": "Project the vector [5, 5, 5] onto the orthogonal complement of [1, 2, 3].",
    "output": "import numpy as np\nv = np.array([5, 5, 5])\nn = np.array([1, 2, 3])\nproj = v - (np.dot(v, n)/np.dot(n, n)) * n\nprint(proj)"
  },
  {
    "input": "Find the projection of [6, 2, -1] onto the subspace spanned by [[2, 1, 0], [0, 1, 2]].",
    "output": "import numpy as np\nv = np.array([6, 2, -1])\nA = np.array([[2, 1, 0], [0, 1, 2]]).T\nP = A @ np.linalg.inv(A.T @ A) @ A.T\nproj = P @ v\nprint(proj)"
  },
  {
    "input": "Project [3, 1, 2] onto the subspace orthogonal to the plane 2x + y + z = 0.",
    "output": "import numpy as np\nv = np.array([3, 1, 2])\nn = np.array([2, 1, 1])\north_comp = (np.dot(v, n) / np.dot(n, n)) * n\nprint(orth_comp)"
  },
  {
    "input": "Orthonormalize the set [[1, 0, 1], [0, 1, 1], [1, 1, 0]].",
    "output": "import numpy as np\nv1 = np.array([1, 0, 1], dtype=float)\nv2 = np.array([0, 1, 1], dtype=float)\nv3 = np.array([1, 1, 0], dtype=float)\nu1 = v1 / np.linalg.norm(v1)\nproj2 = np.dot(v2, u1) * u1\nu2 = v2 - proj2\nu2 = u2 / np.linalg.norm(u2)\nproj3 = np.dot(v3, u1) * u1 + np.dot(v3, u2) * u2\nu3 = v3 - proj3\nu3 = u3 / np.linalg.norm(u3)\nprint(u1, u2, u3)"
  },
  {
    "input": "Find the orthogonal projection of [7, -1, 3] onto the plane 4x - 2y + z = 0.",
    "output": "import numpy as np\nv = np.array([7, -1, 3])\nn = np.array([4, -2, 1])\nproj = v - (np.dot(v, n) / np.dot(n, n)) * n\nprint(proj)"
  },
  {
    "input": "Project [2, 3, 4, 5] onto the subspace spanned by [1, 1, 0, 0], [0, 0, 1, 1].",
    "output": "import numpy as np\nv = np.array([2, 3, 4, 5])\nA = np.array([[1, 0], [1, 0], [0, 1], [0, 1]])\nP = A @ np.linalg.inv(A.T @ A) @ A.T\nproj = P @ v\nprint(proj)"
  },
  {
    "input": "Determine whether [1, 2, 3, 4], [4, 3, 2, 1], [1, -1, 1, -1] are mutually orthogonal.",
    "output": "import numpy as np\nv = [np.array([1, 2, 3, 4]), np.array([4, 3, 2, 1]), np.array([1, -1, 1, -1])]\nprint(np.dot(v[0], v[1]), np.dot(v[0], v[2]), np.dot(v[1], v[2]))"
  },
  {
    "input": "Find projection matrix onto the column space of A = [[2, 0], [1, 1], [0, 2]].",
    "output": "import numpy as np\nA = np.array([[2, 0], [1, 1], [0, 2]])\nP = A @ np.linalg.inv(A.T @ A) @ A.T\nprint(P)"
  },
  {
    "input": "Project [5, 5, 5] onto the plane x - y + z = 0.",
    "output": "import numpy as np\nv = np.array([5, 5, 5])\nn = np.array([1, -1, 1])\nproj = v - (np.dot(v, n)/np.dot(n, n)) * n\nprint(proj)"
  },
  {
    "input": "Find the projection of vector [1, 2, 3] onto the subspace spanned by vectors [1, 0, 1] and [0, 1, 1].",
    "output": "import numpy as np\nv = np.array([1, 2, 3])\nA = np.array([[1, 0], [0, 1], [1, 1]])\nP = A @ np.linalg.inv(A.T @ A) @ A.T\nproj = P @ v\nprint(proj)"
  },
  {
    "input": "Check if the vectors [1, 1, 0], [-1, 1, 0], [0, 0, 1] form an orthonormal basis.",
    "output": "import numpy as np\nv1 = np.array([1, 1, 0]) / np.linalg.norm([1, 1, 0])\nv2 = np.array([-1, 1, 0]) / np.linalg.norm([-1, 1, 0])\nv3 = np.array([0, 0, 1])\nprint(np.dot(v1, v2), np.dot(v1, v3), np.dot(v2, v3))"
  },
  {
    "input": "Orthonormalize the vectors [[1, 1, 1], [1, 0, -1], [1, -2, 1]].",
    "output": "import numpy as np\nv1 = np.array([1, 1, 1], dtype=float)\nv2 = np.array([1, 0, -1], dtype=float)\nv3 = np.array([1, -2, 1], dtype=float)\nu1 = v1 / np.linalg.norm(v1)\nproj2 = np.dot(v2, u1) * u1\nu2 = v2 - proj2\nu2 = u2 / np.linalg.norm(u2)\nproj3 = np.dot(v3, u1) * u1 + np.dot(v3, u2) * u2\nu3 = v3 - proj3\nu3 = u3 / np.linalg.norm(u3)\nprint(u1, u2, u3)"
  },
  {
    "input": "Find the projection matrix onto the line spanned by [3, 4].",
    "output": "import numpy as np\nv = np.array([[3], [4]])\nP = v @ v.T / (v.T @ v)\nprint(P)"
  },
  {
    "input": "Find the projection of [2, 2, 2] onto the vector [1, 2, 3] and compute the error vector.",
    "output": "import numpy as np\nv = np.array([2, 2, 2])\nb = np.array([1, 2, 3])\nproj = (np.dot(v, b)/np.dot(b, b)) * b\nerror = v - proj\nprint(proj, error)"
  },
  {
    "input": "Compute the distance from the point [3, 4, 5] to the plane x + 2y + 2z = 10.",
    "output": "import numpy as np\npoint = np.array([3, 4, 5])\nn = np.array([1, 2, 2])\nd = abs(np.dot(point, n) - 10) / np.linalg.norm(n)\nprint(d)"
  },
  {
    "input": "Project vector [4, 4, 4] onto the null space of matrix A = [[1, 1, 1]].",
    "output": "import numpy as np\nv = np.array([4, 4, 4])\nA = np.array([[1, 1, 1]])\nP = np.eye(3) - A.T @ np.linalg.inv(A @ A.T) @ A\nproj = P @ v\nprint(proj)"
  },
  {
    "input": "Orthonormalize the columns of matrix A = [[2, 0], [1, 1], [0, 2]] using Gram-Schmidt.",
    "output": "import numpy as np\nA = np.array([[2, 0], [1, 1], [0, 2]], dtype=float)\nv1 = A[:,0]\nv2 = A[:,1]\nu1 = v1 / np.linalg.norm(v1)\nproj = np.dot(v2, u1) * u1\nu2 = v2 - proj\nu2 = u2 / np.linalg.norm(u2)\nprint(u1, u2)"
  },
  {
    "input": "Find the orthogonal complement of the subspace spanned by [1, 2, 3] in R^3.",
    "output": "import sympy as sp\nx, y, z = sp.symbols('x y z')\neq = sp.Eq(x + 2*y + 3*z, 0)\nsol = sp.solve(eq, (x, y, z))\nprint(sol)"
  },
  {
    "input": "Project vector [1, 2, 3, 4] onto the plane defined by x1 + x2 + x3 + x4 = 0.",
    "output": "import numpy as np\nv = np.array([1, 2, 3, 4])\nn = np.array([1, 1, 1, 1])\nproj = v - (np.dot(v, n)/np.dot(n, n)) * n\nprint(proj)"
  },
  {
    "input": "Find a unit vector orthogonal to both [1, 0, -1] and [1, 2, 1].",
    "output": "import numpy as np\na = np.array([1, 0, -1])\nb = np.array([1, 2, 1])\nc = np.cross(a, b)\nc = c / np.linalg.norm(c)\nprint(c)"
  },
  {
    "input": "Find the orthogonal projection of vector [6, -1] onto the line y = 2x.",
    "output": "import numpy as np\nv = np.array([6, -1])\nd = np.array([1, 2])\nproj = (np.dot(v, d)/np.dot(d, d)) * d\nprint(proj)"
  },
  {
    "input": "Find the projection matrix onto the orthogonal complement of span{[1, 1, 1]} in R^3.",
    "output": "import numpy as np\nA = np.array([[1, 1, 1]])\nP = np.eye(3) - A.T @ np.linalg.inv(A @ A.T) @ A\nprint(P)"
  },
  {
    "input": "Compute the component of [3, -2, 1] along [1, 1, 1] and perpendicular to it.",
    "output": "import numpy as np\nv = np.array([3, -2, 1])\nu = np.array([1, 1, 1])\nu = u / np.linalg.norm(u)\ncomp_along = np.dot(v, u) * u\ncomp_perp = v - comp_along\nprint(comp_along, comp_perp)"
  },
  {
    "input": "Orthonormalize the set [[2, 2, 0], [-1, 1, 0], [0, 0, 1]] using Gram-Schmidt.",
    "output": "import numpy as np\nv1 = np.array([2, 2, 0], dtype=float)\nv2 = np.array([-1, 1, 0], dtype=float)\nv3 = np.array([0, 0, 1], dtype=float)\nu1 = v1 / np.linalg.norm(v1)\nproj2 = np.dot(v2, u1) * u1\nu2 = v2 - proj2\nu2 = u2 / np.linalg.norm(u2)\nproj3 = np.dot(v3, u1) * u1 + np.dot(v3, u2) * u2\nu3 = v3 - proj3\nu3 = u3 / np.linalg.norm(u3)\nprint(u1, u2, u3)"
  },
  {
    "input": "Find the projection of vector [4, -2, 3] onto the vector [2, 1, -1], and compute the orthogonal component.",
    "output": "import numpy as np\nv = np.array([4, -2, 3])\nu = np.array([2, 1, -1])\nproj = (np.dot(v, u) / np.dot(u, u)) * u\north = v - proj\nprint(proj, orth)"
  },
  {
    "input": "Project vector [1, 3, 5] onto the column space of A = [[1, 2], [0, 1], [1, 0]].",
    "output": "import numpy as np\nA = np.array([[1, 2], [0, 1], [1, 0]])\nv = np.array([1, 3, 5])\nP = A @ np.linalg.inv(A.T @ A) @ A.T\nproj = P @ v\nprint(proj)"
  },
  {
    "input": "Find an orthonormal basis for the column space of matrix A = [[1, 0, 1], [0, 1, 1], [1, 1, 0]].",
    "output": "import numpy as np\nA = np.array([[1, 0, 1], [0, 1, 1], [1, 1, 0]], dtype=float)\nQ, _ = np.linalg.qr(A)\nprint(Q)"
  },
  {
    "input": "Find the projection matrix that projects vectors in R^3 onto the x-y plane.",
    "output": "import numpy as np\nP = np.array([[1, 0, 0], [0, 1, 0], [0, 0, 0]])\nprint(P)"
  },
  {
    "input": "Orthonormalize the vectors [[3, 1, 1], [2, 2, 2], [1, 3, 3]] using Gram-Schmidt.",
    "output": "import numpy as np\nv1 = np.array([3, 1, 1], dtype=float)\nv2 = np.array([2, 2, 2], dtype=float)\nv3 = np.array([1, 3, 3], dtype=float)\nu1 = v1 / np.linalg.norm(v1)\nproj2 = np.dot(v2, u1) * u1\nu2 = v2 - proj2\nu2 = u2 / np.linalg.norm(u2)\nproj3 = np.dot(v3, u1) * u1 + np.dot(v3, u2) * u2\nu3 = v3 - proj3\nu3 = u3 / np.linalg.norm(u3)\nprint(u1, u2, u3)"
  },
  {
    "input": "Find the projection of [4, 1, 2] onto the line passing through the origin and parallel to [2, 2, 1].",
    "output": "import numpy as np\nv = np.array([4, 1, 2])\nd = np.array([2, 2, 1])\nproj = (np.dot(v, d) / np.dot(d, d)) * d\nprint(proj)"
  },
  {
    "input": "Compute the component of [1, 0, 1] orthogonal to the space spanned by [1, 1, 0] and [0, 1, 1].",
    "output": "import numpy as np\nv = np.array([1, 0, 1])\nA = np.array([[1, 0], [1, 1], [0, 1]])\nP = A @ np.linalg.inv(A.T @ A) @ A.T\north = v - P @ v\nprint(orth)"
  },
  {
    "input": "Determine a unit vector that lies in the plane x + y + z = 0 and is orthogonal to [1, -1, 0].",
    "output": "import numpy as np\n# A vector in the plane x + y + z = 0 can be parameterized. Let's pick z = 1.\n# The plane equation becomes x + y = -1\n# The orthogonality condition with [1, -1, 0] means x - y = 0 => x = y\n# So x = y = -0.5, z = 1\nv = np.array([-0.5, -0.5, 1])\nv = v / np.linalg.norm(v)\nprint(v)"
  },
  {
    "input": "Compute the projection of [2, 2, 2, 2] onto the hyperplane x1 - x2 + x3 - x4 = 0.",
    "output": "import numpy as np\nv = np.array([2, 2, 2, 2])\nn = np.array([1, -1, 1, -1])\nproj = v - (np.dot(v, n) / np.dot(n, n)) * n\nprint(proj)"
  },
  {
    "input": "Find the orthonormal basis of the null space of matrix A = [[1, 1, 1], [0, 1, 1]].",
    "output": "import numpy as np\nfrom scipy.linalg import null_space\nA = np.array([[1, 1, 1], [0, 1, 1]])\nns = null_space(A)\nprint(ns)"
  },
  {
    "input": "Project [1, 2, 3, 4] onto the space orthogonal to [1, 1, 1, 1] and [1, -1, 1, -1].",
    "output": "import numpy as np\nv = np.array([1, 2, 3, 4])\nA = np.array([[1, 1, 1, 1], [1, -1, 1, -1]])\nP = np.eye(4) - A.T @ np.linalg.inv(A @ A.T) @ A\nproj = P @ v\nprint(proj)"
  },
  {
    "input": "Check if the set [[1, 2, 3], [2, 4, 6], [0, 0, 1]] forms an orthogonal set.",
    "output": "import numpy as np\nv1 = np.array([1, 2, 3])\nv2 = np.array([2, 4, 6])\nv3 = np.array([0, 0, 1])\nprint(np.dot(v1, v2), np.dot(v1, v3), np.dot(v2, v3))"
  },
  {
    "input": "Find the least squares projection of vector [4, 5] onto the column space of A = [[1], [2]].",
    "output": "import numpy as np\nv = np.array([4, 5])\nA = np.array([[1], [2]])\nP = A @ np.linalg.inv(A.T @ A) @ A.T\nproj = P @ v\nprint(proj)"
  },
  {
    "input": "Compute the distance from vector [1, 1, 1, 1] to the subspace spanned by [1, 0, 0, 0] and [0, 1, 0, 0].",
    "output": "import numpy as np\nv = np.array([1, 1, 1, 1])\nA = np.array([[1, 0], [0, 1], [0, 0], [0, 0]])\nP = A @ np.linalg.inv(A.T @ A) @ A.T\nproj = P @ v\ndist = np.linalg.norm(v - proj)\nprint(dist)"
  },
  {
    "input": "Find the orthogonal projection of vector [3, -1, 2] onto the plane x - y + z = 0.",
    "output": "import numpy as np\nv = np.array([3, -1, 2])\nn = np.array([1, -1, 1])\nproj = v - (np.dot(v, n)/np.dot(n, n)) * n\nprint(proj)"
  },
  {
    "input": "Find a unit vector orthogonal to the plane 2x - y + 3z = 0.",
    "output": "import numpy as np\nn = np.array([2, -1, 3])\nunit_n = n / np.linalg.norm(n)\nprint(unit_n)"
  },
  {
    "input": "Given vectors [2, 3, 1] and [4, 1, -2], compute the projection of the first onto the second.",
    "output": "import numpy as np\na = np.array([2, 3, 1])\nb = np.array([4, 1, -2])\nproj = (np.dot(a, b) / np.dot(b, b)) * b\nprint(proj)"
  },
  {
    "input": "Find the projection matrix onto the plane perpendicular to vector [1, 2, 2].",
    "output": "import numpy as np\nn = np.array([1, 2, 2])\nP = np.eye(3) - np.outer(n, n) / np.dot(n, n)\nprint(P)"
  },
  {
    "input": "Compute the projection of vector [5, 6, 7] onto the column space of A = [[1, 0], [0, 1], [1, 1]].",
    "output": "import numpy as np\nA = np.array([[1, 0], [0, 1], [1, 1]])\nv = np.array([5, 6, 7])\nP = A @ np.linalg.inv(A.T @ A) @ A.T\nproj = P @ v\nprint(proj)"
  },
  {
    "input": "Find an orthonormal basis for the space perpendicular to [1, 2, 3] in R^3.",
    "output": "import numpy as np\nfrom scipy.linalg import null_space\nn = np.array([[1, 2, 3]])\nN = null_space(n)\nprint(N)"
  },
  {
    "input": "Find the projection of [3, 2, 1, 0] onto the subspace defined by x + y + z + w = 0.",
    "output": "import numpy as np\nv = np.array([3, 2, 1, 0])\nn = np.array([1, 1, 1, 1])\nproj = v - (np.dot(v, n) / np.dot(n, n)) * n\nprint(proj)"
  },
  {
    "input": "Find the least-squares solution to Ax = b where A = [[1, 1], [1, -1], [1, 2]], b = [2, 0, 3].",
    "output": "import numpy as np\nA = np.array([[1, 1], [1, -1], [1, 2]])\nb = np.array([2, 0, 3])\nx = np.linalg.inv(A.T @ A) @ A.T @ b\nprint(x)"
  },
  {
    "input": "Project the vector [1, 4, 7] onto the span of [[2, 2, 2], [1, 0, 1]].",
    "output": "import numpy as np\nv = np.array([1, 4, 7])\nA = np.array([[2, 1], [2, 0], [2, 1]])\nP = A @ np.linalg.inv(A.T @ A) @ A.T\nproj = P @ v\nprint(proj)"
  },
  {
    "input": "Find a vector in the null space of A = [[2, 3, 1], [1, 1, 1]].",
    "output": "import numpy as np\nfrom scipy.linalg import null_space\nA = np.array([[2, 3, 1], [1, 1, 1]])\nnull = null_space(A)\nprint(null[:, 0])"
  },
  {
    "input": "Find a basis for the orthogonal complement of span{[1, 2, 3], [3, 2, 1]} in R^3.",
    "output": "import numpy as np\nfrom scipy.linalg import null_space\nA = np.array([[1, 2, 3], [3, 2, 1]])\nN = null_space(A)\nprint(N)"
  },
  {
    "input": "Given A = [[1, 2], [2, 4], [3, 6]], find the orthogonal projection of b = [1, 2, 3] onto Col(A).",
    "output": "import numpy as np\nA = np.array([[1, 2], [2, 4], [3, 6]])\nb = np.array([1, 2, 3])\nP = A @ np.linalg.pinv(A)  # Since A.T A is singular\nproj = P @ b\nprint(proj)"
  },
  {
    "input": "Find the vector component of [1, 1, 1] that lies in the null space of A = [[1, 1, 1]].",
    "output": "import numpy as np\nv = np.array([1, 1, 1])\nA = np.array([[1, 1, 1]])\nP = np.eye(3) - A.T @ np.linalg.inv(A @ A.T) @ A\ncomponent = P @ v\nprint(component)"
  },
  {
    "input": "Determine if the set {[1, 2, 3], [4, 5, 6], [7, 8, 9]} is linearly independent and orthogonal.",
    "output": "import numpy as np\nV = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\nindependent = np.linalg.matrix_rank(V) == 3\northogonal = np.allclose(V @ V.T, np.diag(np.diag(V @ V.T)))\nprint(independent, orthogonal)"
  },
  {
    "input": "Find the unit vector in the direction of projection of [5, 5, 0] onto the plane z = 0.",
    "output": "import numpy as np\nv = np.array([5, 5, 0])\nunit = v / np.linalg.norm(v)\nprint(unit)"
  },
  {
    "input": "Find a vector orthogonal to both [2, -1, 0] and [1, 1, 1] using cross product.",
    "output": "import numpy as np\na = np.array([2, -1, 0])\nb = np.array([1, 1, 1])\nc = np.cross(a, b)\nprint(c / np.linalg.norm(c))"
  },
  {
    "input": "Find the orthogonal projection of [3, -2, 5] onto the subspace spanned by [1, 1, 0] and [0, 1, 1].",
    "output": "import numpy as np\nv = np.array([3, -2, 5])\nA = np.array([[1, 0], [1, 1], [0, 1]])\nP = A @ np.linalg.inv(A.T @ A) @ A.T\nproj = P @ v\nprint(proj)"
  },
  {
    "input": "Compute the distance from vector [2, 4, 6] to the subspace defined by the span of [1, 1, 1].",
    "output": "import numpy as np\nv = np.array([2, 4, 6])\nu = np.array([1, 1, 1])\nproj = (np.dot(v, u) / np.dot(u, u)) * u\ndist = np.linalg.norm(v - proj)\nprint(dist)"
  },
  {
    "input": "Use Gram-Schmidt to orthonormalize the set [[2, 0, 0], [1, 2, 0], [1, 1, 2]].",
    "output": "import numpy as np\nV = np.array([[2, 0, 0], [1, 2, 0], [1, 1, 2]], dtype=float)\nU = []\nfor v in V:\n    for u in U:\n        v = v - np.dot(v, u) * u\n    U.append(v / np.linalg.norm(v))\nfor u in U:\n    print(u)"
  },
  {
    "input": "Find the least-squares solution to Ax = b where A = [[2, 1], [1, 2], [1, 1]], b = [1, 2, 3].",
    "output": "import numpy as np\nA = np.array([[2, 1], [1, 2], [1, 1]])\nb = np.array([1, 2, 3])\nx = np.linalg.inv(A.T @ A) @ A.T @ b\nprint(x)"
  },
  {
    "input": "Find the projection of vector [2, -1, 1] onto the plane x + y + z = 1 through origin.",
    "output": "import numpy as np\nv = np.array([2, -1, 1])\nn = np.array([1, 1, 1])\nproj = v - (np.dot(v, n)/np.dot(n, n)) * n\nprint(proj)"
  },
  {
    "input": "Find a unit vector orthogonal to the column space of matrix [[1, 2], [3, 4], [5, 6]].",
    "output": "import numpy as np\nfrom scipy.linalg import null_space\nA = np.array([[1, 2], [3, 4], [5, 6]])\nN = null_space(A.T)\nprint(N[:, 0] / np.linalg.norm(N[:, 0]))"
  },
  {
    "input": "Project vector [4, 0, 0, 1] onto the space orthogonal to [1, 1, 1, 1].",
    "output": "import numpy as np\nv = np.array([4, 0, 0, 1])\nn = np.array([1, 1, 1, 1])\nproj = v - (np.dot(v, n)/np.dot(n, n)) * n\nprint(proj)"
  },
  {
    "input": "Given the vectors [1, 1, 0] and [1, -1, 0], find an orthonormal basis for the plane they span.",
    "output": "import numpy as np\nv1 = np.array([1, 1, 0], dtype=float)\nv2 = np.array([1, -1, 0], dtype=float)\nu1 = v1 / np.linalg.norm(v1)\nv2 = v2 - np.dot(v2, u1) * u1\nu2 = v2 / np.linalg.norm(v2)\nprint(u1, u2)"
  },
  {
    "input": "Compute the projection matrix onto the space spanned by [2, -1, 1, 0].",
    "output": "import numpy as np\nu = np.array([2, -1, 1, 0])\nP = np.outer(u, u) / np.dot(u, u)\nprint(P)"
  },
  {
    "input": "Find the projection of vector [1, 2, 2, 1] onto the plane defined by x - y + z = 0 and y - z + w = 0.",
    "output": "import numpy as np\nv = np.array([1, 2, 2, 1])\nA = np.array([[1, -1, 1, 0], [0, 1, -1, 1]])\nP = np.eye(4) - A.T @ np.linalg.inv(A @ A.T) @ A\nproj = P @ v\nprint(proj)"
  },
  {
    "input": "Check whether vectors [1, 0, -1], [2, 1, 0], [0, 1, 1] are mutually orthogonal.",
    "output": "import numpy as np\nv = [np.array([1, 0, -1]), np.array([2, 1, 0]), np.array([0, 1, 1])]\nprint(np.dot(v[0], v[1]), np.dot(v[0], v[2]), np.dot(v[1], v[2]))"
  },
  {
    "input": "Find the orthogonal projection of vector [0, 2, 1] onto the span of [1, 1, 1].",
    "output": "import numpy as np\nv = np.array([0, 2, 1])\nu = np.array([1, 1, 1])\nproj = (np.dot(v, u)/np.dot(u, u)) * u\nprint(proj)"
  },
  {
    "input": "Find an orthonormal basis for the space perpendicular to both [1, 0, 1, 0] and [0, 1, 0, 1].",
    "output": "import numpy as np\nfrom scipy.linalg import null_space\nA = np.array([[1, 0, 1, 0], [0, 1, 0, 1]])\nN = null_space(A)\nprint(N)"
  },
  {
    "input": "Find the projection matrix for projecting vectors in R^2 onto the x-axis.",
    "output": "import numpy as np\nP = np.array([[1, 0], [0, 0]])\nprint(P)"
  },
  {
    "input": "Project [3, 3, 3] onto the orthogonal complement of span{[1, 0, -1], [0, 1, 1]}.",
    "output": "import numpy as np\nv = np.array([3, 3, 3])\nA = np.array([[1, 0], [0, 1], [-1, 1]])\nP = A @ np.linalg.inv(A.T @ A) @ A.T\north_proj = v - P @ v\nprint(orth_proj)"
  },
  {
    "input": "Find the projection of vector [1, 2, 3] onto the null space of matrix A = [[1, 1, 1]].",
    "output": "import numpy as np\nv = np.array([1, 2, 3])\nA = np.array([[1, 1, 1]])\nP = np.eye(3) - A.T @ np.linalg.inv(A @ A.T) @ A\nproj = P @ v\nprint(proj)"
  },
  {
    "input": "Find a vector orthogonal to both [1, 2, 2] and [2, -1, 2] using cross product.",
    "output": "import numpy as np\na = np.array([1, 2, 2])\nb = np.array([2, -1, 2])\nc = np.cross(a, b)\nprint(c / np.linalg.norm(c))"
  },
  {
    "input": "Compute the orthogonal projection of [5, 0, -3, 2] onto the subspace spanned by [1, 1, 1, 1].",
    "output": "import numpy as np\nv = np.array([5, 0, -3, 2])\nu = np.array([1, 1, 1, 1])\nproj = (np.dot(v, u) / np.dot(u, u)) * u\nprint(proj)"
  },
  {
    "input": "Use Gram-Schmidt process on [[1, 2, 2], [2, 4, 5], [3, 6, 8]].",
    "output": "import numpy as np\nV = np.array([[1, 2, 2], [2, 4, 5], [3, 6, 8]], dtype=float)\nU = []\nfor v in V:\n    for u in U:\n        v = v - np.dot(v, u) * u\n    U.append(v / np.linalg.norm(v))\nfor u in U:\n    print(u)"
  },
  {
    "input": "Find the projection matrix onto the column space of A = [[1, 2], [2, 4], [3, 6]].",
    "output": "import numpy as np\nA = np.array([[1, 2], [2, 4], [3, 6]])\nP = A @ np.linalg.pinv(A.T @ A) @ A.T\nprint(P)"
  },
  {
    "input": "Determine the orthogonal complement of the row space of matrix A = [[1, 2, 3], [4, 5, 6]].",
    "output": "import numpy as np\nfrom scipy.linalg import null_space\nA = np.array([[1, 2, 3], [4, 5, 6]])\nN = null_space(A)\nprint(N)"
  },
  {
    "input": "Project [3, 1, 4, 1] onto the space spanned by [1, 0, 0, 0] and [0, 1, 1, 0].",
    "output": "import numpy as np\nv = np.array([3, 1, 4, 1])\nA = np.array([[1, 0], [0, 1], [0, 1], [0, 0]])\nP = A @ np.linalg.inv(A.T @ A) @ A.T\nproj = P @ v\nprint(proj)"
  },
  {
    "input": "Find a unit vector perpendicular to the subspace spanned by [1, 2, 3] and [4, 5, 6].",
    "output": "import numpy as np\nfrom scipy.linalg import null_space\nA = np.array([[1, 2, 3], [4, 5, 6]])\nN = null_space(A)\nprint(N[:, 0] / np.linalg.norm(N[:, 0]))"
  },
  {
    "input": "Find a basis for the space of all vectors orthogonal to both [1, 1, 0] and [0, 1, 1].",
    "output": "import numpy as np\nfrom scipy.linalg import null_space\nA = np.array([[1, 1, 0], [0, 1, 1]])\nN = null_space(A)\nprint(N)"
  },
  {
    "input": "Find the orthogonal projection of [7, -2, 5] onto the plane 3x - y + z = 0.",
    "output": "import numpy as np\nv = np.array([7, -2, 5])\nn = np.array([3, -1, 1])\nproj = v - (np.dot(v, n)/np.dot(n, n)) * n\nprint(proj)"
  },
  {
    "input": "Find the distance from vector [1, 2, 2, 1] to the plane x + y + z + w = 0.",
    "output": "import numpy as np\nv = np.array([1, 2, 2, 1])\nn = np.array([1, 1, 1, 1])\ndistance = abs(np.dot(v, n)) / np.linalg.norm(n)\nprint(distance)"
  },
  {
    "input": "Project vector [0, 2, -1] onto the orthogonal complement of [1, 1, 1].",
    "output": "import numpy as np\nv = np.array([0, 2, -1])\nn = np.array([1, 1, 1])\nproj = v - (np.dot(v, n)/np.dot(n, n)) * n\nprint(proj)"
  },
  {
    "input": "Find an orthonormal basis for the subspace of R^3 spanned by [1, 2, 2] and [2, 0, 1].",
    "output": "import numpy as np\nV = np.array([[1, 2, 2], [2, 0, 1]], dtype=float)\nU = []\nfor v in V:\n    for u in U:\n        v -= np.dot(v, u) * u\n    U.append(v / np.linalg.norm(v))\nfor u in U:\n    print(u)"
  },
  {
    "input": "Find the projection matrix that projects onto the orthogonal complement of [2, -2, 1].",
    "output": "import numpy as np\nn = np.array([2, -2, 1])\nP = np.eye(3) - np.outer(n, n) / np.dot(n, n)\nprint(P)"
  },
  {
    "input": "Compute the projection of [1, 3, 1, 0] onto the column space of A = [[1, 0], [2, 1], [1, 0], [0, 1]].",
    "output": "import numpy as np\nv = np.array([1, 3, 1, 0])\nA = np.array([[1, 0], [2, 1], [1, 0], [0, 1]])\nP = A @ np.linalg.inv(A.T @ A) @ A.T\nproj = P @ v\nprint(proj)"
  },
  {
    "input": "Find the projection of [4, -2, 7] onto the plane defined by x + 2y - z = 0.",
    "output": "import numpy as np\nv = np.array([4, -2, 7])\nn = np.array([1, 2, -1])\nproj = v - (np.dot(v, n) / np.dot(n, n)) * n\nprint(proj)"
  },
  {
    "input": "Use Gram-Schmidt to orthonormalize [[3, 1, 4], [1, 5, 9], [2, 6, 5]].",
    "output": "import numpy as np\nV = np.array([[3, 1, 4], [1, 5, 9], [2, 6, 5]], dtype=float)\nU = []\nfor v in V:\n    for u in U:\n        v -= np.dot(v, u) * u\n    U.append(v / np.linalg.norm(v))\nfor u in U:\n    print(u)"
  },
  {
    "input": "Compute the projection matrix onto the null space of matrix A = [[1, 1, 1]].",
    "output": "import numpy as np\nA = np.array([[1, 1, 1]])\nP_null = np.eye(3) - A.T @ np.linalg.inv(A @ A.T) @ A\nprint(P_null)"
  },
  {
    "input": "Find the least squares solution to Ax = b where A = [[1, 0], [1, 1], [1, 2]], b = [1, 2, 2].",
    "output": "import numpy as np\nA = np.array([[1, 0], [1, 1], [1, 2]])\nb = np.array([1, 2, 2])\nx = np.linalg.inv(A.T @ A) @ A.T @ b\nprint(x)"
  },
  {
    "input": "Find the component of [1, 2, 3] orthogonal to [1, 0, -1].",
    "output": "import numpy as np\nv = np.array([1, 2, 3])\nu = np.array([1, 0, -1])\nproj = (np.dot(v, u) / np.dot(u, u)) * u\north = v - proj\nprint(orth)"
  },
  {
    "input": "Find a unit vector in the null space of [[1, -2, 1], [3, -6, 3]].",
    "output": "import numpy as np\nfrom scipy.linalg import null_space\nA = np.array([[1, -2, 1], [3, -6, 3]])\nN = null_space(A)\nprint(N[:, 0] / np.linalg.norm(N[:, 0]))"
  },
  {
    "input": "Find the projection of vector [1, 2, 2, 1] onto the space spanned by [1, 1, 1, 1].",
    "output": "import numpy as np\nv = np.array([1, 2, 2, 1])\nu = np.array([1, 1, 1, 1])\nproj = (np.dot(v, u) / np.dot(u, u)) * u\nprint(proj)"
  },
  {
    "input": "Find an orthonormal basis for the subspace spanned by [1, 1, 0, 0], [0, 1, 1, 0], and [0, 0, 1, 1].",
    "output": "import numpy as np\nV = np.array([[1, 1, 0, 0], [0, 1, 1, 0], [0, 0, 1, 1]], dtype=float)\nU = []\nfor v in V:\n    for u in U:\n        v -= np.dot(v, u) * u\n    U.append(v / np.linalg.norm(v))\nfor u in U:\n    print(u)"
  },
  {
    "input": "Find the distance from [3, 0, -1] to the line spanned by [1, 2, 3].",
    "output": "import numpy as np\nv = np.array([3, 0, -1])\nu = np.array([1, 2, 3])\nproj = (np.dot(v, u) / np.dot(u, u)) * u\ndist = np.linalg.norm(v - proj)\nprint(dist)"
  },
  {
    "input": "Project [4, 5] onto the subspace spanned by [1, 1].",
    "output": "import numpy as np\nv = np.array([4, 5])\nu = np.array([1, 1])\nproj = (np.dot(v, u) / np.dot(u, u)) * u\nprint(proj)"
  },
  {
    "input": "Find the projection matrix that projects vectors in R^3 onto the yz-plane.",
    "output": "import numpy as np\nP = np.array([[0, 0, 0], [0, 1, 0], [0, 0, 1]])\nprint(P)"
  },
  {
    "input": "Compute the projection of [1, 0, 0] onto the orthogonal complement of [1, 1, 1].",
    "output": "import numpy as np\nv = np.array([1, 0, 0])\nu = np.array([1, 1, 1])\nproj = v - (np.dot(v, u) / np.dot(u, u)) * u\nprint(proj)"
  },
  {
    "input": "Find an orthonormal basis for the null space of matrix [[1, 1, 1, 1]].",
    "output": "import numpy as np\nfrom scipy.linalg import null_space\nA = np.array([[1, 1, 1, 1]])\nN = null_space(A)\nprint(N)"
  },
  {
    "input": "Project [1, 2, 3] onto the plane perpendicular to vector [2, -1, 2].",
    "output": "import numpy as np\nv = np.array([1, 2, 3])\nn = np.array([2, -1, 2])\nproj = v - (np.dot(v, n) / np.dot(n, n)) * n\nprint(proj)"
  },
  {
    "input": "Given A = [[1, 1], [1, -1], [1, 0]], b = [2, 0, 1], find the least squares solution to Ax = b.",
    "output": "import numpy as np\nA = np.array([[1, 1], [1, -1], [1, 0]])\nb = np.array([2, 0, 1])\nx = np.linalg.inv(A.T @ A) @ A.T @ b\nprint(x)"
  },
  {
    "input": "Find the projection of vector [2, 1, 0] onto the space orthogonal to [1, 1, 1].",
    "output": "import numpy as np\nv = np.array([2, 1, 0])\nn = np.array([1, 1, 1])\nproj = v - (np.dot(v, n) / np.dot(n, n)) * n\nprint(proj)"
  },
  {
    "input": "Determine if vectors [1, 2, 3] and [3, -2, 1] are orthogonal.",
    "output": "import numpy as np\na = np.array([1, 2, 3])\nb = np.array([3, -2, 1])\ndot_product = np.dot(a, b)\nprint(dot_product == 0)"
  },
  {
    "input": "Find the projection matrix that projects vectors onto the line spanned by [1, -1, 2].",
    "output": "import numpy as np\nv = np.array([1, -1, 2])\nP = np.outer(v, v) / np.dot(v, v)\nprint(P)"
  },
  {
    "input": "Use Gram-Schmidt to orthonormalize the columns of [[1, 1], [1, 0], [0, 1]].",
    "output": "import numpy as np\nV = np.array([[1, 1], [1, 0], [0, 1]], dtype=float).T\nU = []\nfor v in V:\n    for u in U:\n        v -= np.dot(v, u) * u\n    U.append(v / np.linalg.norm(v))\nfor u in U:\n    print(u)"
  },
  {
    "input": "Find the orthogonal component of [5, 2, 1] with respect to [2, 2, 2].",
    "output": "import numpy as np\nv = np.array([5, 2, 1])\nu = np.array([2, 2, 2])\nproj = (np.dot(v, u) / np.dot(u, u)) * u\north = v - proj\nprint(orth)"
  },
  {
    "input": "Compute the orthogonal projection of [3, 4] onto the x-axis.",
    "output": "import numpy as np\nv = np.array([3, 4])\nu = np.array([1, 0])\nproj = (np.dot(v, u) / np.dot(u, u)) * u\nprint(proj)"
  },
  {
    "input": "Find the least squares solution for Ax = b with A = [[2, 1], [1, 3], [1, 2]], b = [5, 6, 7].",
    "output": "import numpy as np\nA = np.array([[2, 1], [1, 3], [1, 2]])\nb = np.array([5, 6, 7])\nx = np.linalg.inv(A.T @ A) @ A.T @ b\nprint(x)"
  },
  {
    "input": "Compute the projection of vector [1, 0, 2, 3] onto the space spanned by [1, 1, 1, 1].",
    "output": "import numpy as np\nv = np.array([1, 0, 2, 3])\nu = np.array([1, 1, 1, 1])\nproj = (np.dot(v, u) / np.dot(u, u)) * u\nprint(proj)"
  },
  {
    "input": "Find the orthonormal basis of the column space of A = [[1, 2], [2, 4], [3, 6]].",
    "output": "import numpy as np\nA = np.array([[1, 2], [2, 4], [3, 6]], dtype=float)\nQ, R = np.linalg.qr(A)\nprint(Q)"
  },
  {
    "input": "Check if [1, 0, -1] is orthogonal to the plane x + y + z = 0.",
    "output": "import numpy as np\nn = np.array([1, 1, 1])\nv = np.array([1, 0, -1])\nprint(np.dot(n, v) == 0)"
  },
  {
    "input": "Find the projection matrix that projects onto the column space of [[1, 0], [1, 1], [1, 2]].",
    "output": "import numpy as np\nA = np.array([[1, 0], [1, 1], [1, 2]])\nP = A @ np.linalg.inv(A.T @ A) @ A.T\nprint(P)"
  },
  {
    "input": "Find the orthogonal complement of the subspace spanned by [1, 1, 0, 0] and [0, 1, 1, 0].",
    "output": "import numpy as np\nfrom scipy.linalg import null_space\nA = np.array([[1, 1, 0, 0], [0, 1, 1, 0]])\nN = null_space(A)\nprint(N)"
  },
  {
    "input": "Project vector [2, -1, 3] onto the plane 2x + y - z = 0.",
    "output": "import numpy as np\nv = np.array([2, -1, 3])\nn = np.array([2, 1, -1])\nproj = v - (np.dot(v, n) / np.dot(n, n)) * n\nprint(proj)"
  },
  {
    "input": "Determine the distance from [1, 1, 1] to the line through the origin in direction [1, 0, -1].",
    "output": "import numpy as np\nv = np.array([1, 1, 1])\nu = np.array([1, 0, -1])\nproj = (np.dot(v, u) / np.dot(u, u)) * u\ndist = np.linalg.norm(v - proj)\nprint(dist)"
  },
  {
    "input": "Find a unit vector in the orthogonal complement of [1, 1, 1, 1] in R^4.",
    "output": "import numpy as np\nfrom scipy.linalg import null_space\nA = np.array([[1, 1, 1, 1]])\nN = null_space(A)\nunit_vector = N[:, 0] / np.linalg.norm(N[:, 0])\nprint(unit_vector)"
  },
  {
    "input": "Find the projection of [2, 2, 1] onto the plane orthogonal to [1, -1, 1].",
    "output": "import numpy as np\nv = np.array([2, 2, 1])\nn = np.array([1, -1, 1])\nproj = v - (np.dot(v, n) / np.dot(n, n)) * n\nprint(proj)"
  },
  {
    "input": "Compute the least squares solution to Ax = b where A = [[1, 2], [3, 4], [5, 6]], b = [7, 8, 9].",
    "output": "import numpy as np\nA = np.array([[1, 2], [3, 4], [5, 6]])\nb = np.array([7, 8, 9])\nx = np.linalg.inv(A.T @ A) @ A.T @ b\nprint(x)"
  },
  {
    "input": "Use Gram-Schmidt to orthonormalize the rows of [[1, 0, 1], [1, 1, 0]].",
    "output": "import numpy as np\nV = np.array([[1, 0, 1], [1, 1, 0]], dtype=float)\nU = []\nfor v in V:\n    for u in U:\n        v -= np.dot(v, u) * u\n    U.append(v / np.linalg.norm(v))\nfor u in U:\n    print(u)"
  },
  {
    "input": "Determine the projection of [6, -3] onto the subspace spanned by [2, 1].",
    "output": "import numpy as np\nv = np.array([6, -3])\nu = np.array([2, 1])\nproj = (np.dot(v, u) / np.dot(u, u)) * u\nprint(proj)"
  },
  {
    "input": "Find the orthogonal projection of [0, 1, 2] onto the column space of A = [[1, 2], [0, 1], [1, 0]].",
    "output": "import numpy as np\nA = np.array([[1, 2], [0, 1], [1, 0]])\nb = np.array([0, 1, 2])\nP = A @ np.linalg.inv(A.T @ A) @ A.T\nproj = P @ b\nprint(proj)"
  },
  {
    "input": "Compute the distance from [1, 2, 2] to the subspace spanned by [1, 0, 1] and [0, 1, 1].",
    "output": "import numpy as np\nv = np.array([1, 2, 2])\nA = np.array([[1, 0], [0, 1], [1, 1]])\nP = A @ np.linalg.inv(A.T @ A) @ A.T\nproj = P @ v\ndist = np.linalg.norm(v - proj)\nprint(dist)"
  },
  {
    "input": "Find a unit vector orthogonal to both [1, 0, 1] and [0, 1, 1].",
    "output": "import numpy as np\na = np.array([1, 0, 1])\nb = np.array([0, 1, 1])\nc = np.cross(a, b)\nunit = c / np.linalg.norm(c)\nprint(unit)"
  },
  {
    "input": "Find a nonzero vector that is orthogonal to both [1, 2, 3] and [4, 5, 6] and lies in the plane x + y + z = 0.",
    "output": "import numpy as np\nfrom scipy.linalg import null_space\nA = np.array([[1, 2, 3], [4, 5, 6], [1, 1, 1]])\nN = null_space(A)\nv = N[:, 0] / np.linalg.norm(N[:, 0])\nprint(v)"
  },
  {
    "input": "Determine the projection of [1, 2, 3, 4] onto the subspace orthogonal to the column space of A = [[1, 1], [1, 1], [1, 1], [1, 1]].",
    "output": "import numpy as np\nA = np.array([[1, 1], [1, 1], [1, 1], [1, 1]])\nb = np.array([1, 2, 3, 4])\nP = A @ np.linalg.pinv(A)  # projection matrix onto Col(A)\nproj_orth = b - P @ b  # projection onto the orthogonal complement\nprint(proj_orth)"
  },
  {
    "input": "Let u and v be orthogonal unit vectors. What is the norm of u + v?",
    "output": "import numpy as np\nu = np.array([1, 0])\nv = np.array([0, 1])\nsum_vector = u + v\nnorm = np.linalg.norm(sum_vector)\nprint(norm)"
  },
  {
    "input": "Is it possible to have three non-zero vectors in R^2 that are mutually orthogonal?",
    "output": "# In R^2, you can have at most two mutually orthogonal non-zero vectors.\nprint(False)"
  },
  {
    "input": "Find the projection matrix P such that P^2 = P and P is symmetric, for projecting onto the null space of A = [[1, 2], [3, 6]].",
    "output": "import numpy as np\nfrom scipy.linalg import null_space\nA = np.array([[1, 2], [3, 6]])\nN = null_space(A)\nP = N @ np.linalg.inv(N.T @ N) @ N.T\nprint(P)"
  },
  {
    "input": "Given A = [[1, 2], [2, 4], [3, 6]], find the orthogonal projection of b = [1, 2, 3] onto the column space of A.",
    "output": "import numpy as np\nA = np.array([[1, 2], [2, 4], [3, 6]])\nb = np.array([1, 2, 3])\nP = A @ np.linalg.pinv(A)  # Use pseudoinverse for rank-deficient A\nproj = P @ b\nprint(proj)"
  },
  {
    "input": "Given orthonormal matrix Q and vector x, show that the projection of x onto the column space of Q is Q @ Q.T @ x.",
    "output": "import numpy as np\nQ = np.array([[1, 0], [0, 1], [0, 0]])\nx = np.array([1, 2, 3])\nproj = Q @ Q.T @ x\nprint(proj)"
  },
  {
    "input": "Find a unit vector in the null space of A = [[1, 1, 1], [2, 2, 2]].",
    "output": "import numpy as np\nfrom scipy.linalg import null_space\nA = np.array([[1, 1, 1], [2, 2, 2]])\nN = null_space(A)\nv = N[:, 0] / np.linalg.norm(N[:, 0])\nprint(v)"
  },
  {
    "input": "Determine whether the set {[1, 0, 1], [0, 1, 1], [1, 1, 0]} is linearly independent and orthogonal.",
    "output": "import numpy as np\nV = np.array([[1, 0, 1], [0, 1, 1], [1, 1, 0]])\nindependent = np.linalg.matrix_rank(V) == 3\northogonal = np.allclose(V @ V.T - np.diag(np.diag(V @ V.T)), 0) == False\nprint({'independent': independent, 'orthogonal': orthogonal})"
  },
  {
    "input": "Given matrix A = [[1, 2], [3, 6]], determine a basis for the orthogonal complement of the column space.",
    "output": "import numpy as np\nfrom scipy.linalg import null_space\nA = np.array([[1, 2], [3, 6]])\nB = null_space(A.T)\nprint(B)"
  },
  {
    "input": "Find the angle between the projection of [1, 2, 2] onto [1, 1, 0] and the vector itself.",
    "output": "import numpy as np\nv = np.array([1, 2, 2])\nu = np.array([1, 1, 0])\nproj = (np.dot(v, u) / np.dot(u, u)) * u\nangle = np.arccos(np.dot(proj, v) / (np.linalg.norm(proj) * np.linalg.norm(v)))\nprint(np.degrees(angle))"
  },
  {
    "input": "Let A be an m x n matrix with orthonormal columns. Prove that A.T @ A = I.",
    "output": "import numpy as np\nA = np.array([[1/np.sqrt(2), 1/np.sqrt(2)], [-1/np.sqrt(2), 1/np.sqrt(2)]])\nresult = A.T @ A\nprint(result)"
  },
  {
    "input": "Find the vector v in R^3 such that v is orthogonal to both [1, 1, 0] and [0, 1, 1], and ||v|| = 1.",
    "output": "import numpy as np\na = np.array([1, 1, 0])\nb = np.array([0, 1, 1])\nv = np.cross(a, b)\nv = v / np.linalg.norm(v)\nprint(v)"
  },
  {
    "input": "Let v be a unit vector orthogonal to both u1 = [1, 0, 1] and u2 = [0, 1, 1]. Compute v \u00b7 (u1 + u2).",
    "output": "import numpy as np\nu1 = np.array([1, 0, 1])\nu2 = np.array([0, 1, 1])\nv = np.cross(u1, u2)\nv = v / np.linalg.norm(v)\ndot = np.dot(v, u1 + u2)\nprint(dot)"
  },
  {
    "input": "Given that a projection matrix P satisfies P^2 = P and is symmetric, check if P = [[0.5, 0.5], [0.5, 0.5]] is a valid projection matrix.",
    "output": "import numpy as np\nP = np.array([[0.5, 0.5], [0.5, 0.5]])\nprint(np.allclose(P @ P, P) and np.allclose(P, P.T))"
  },
  {
    "input": "Find the projection of [1, 2, 3, 4] onto the orthogonal complement of the column space of A = [[1, 1], [2, 2], [3, 3], [4, 4]].",
    "output": "import numpy as np\nA = np.array([[1, 1], [2, 2], [3, 3], [4, 4]])\nb = np.array([1, 2, 3, 4])\nP = A @ np.linalg.pinv(A)\nproj_orth = b - P @ b\nprint(proj_orth)"
  },
  {
    "input": "Find a vector orthogonal to the plane defined by the vectors [1, 0, 0] and [0, 1, 1], and normalize it.",
    "output": "import numpy as np\nu = np.array([1, 0, 0])\nv = np.array([0, 1, 1])\nnormal = np.cross(u, v)\nunit = normal / np.linalg.norm(normal)\nprint(unit)"
  },
  {
    "input": "Let A be a 3x2 matrix with orthonormal columns. Verify that A @ A.T is a projection matrix.",
    "output": "import numpy as np\nA = np.array([[1/np.sqrt(2), 1/np.sqrt(2)], [1/np.sqrt(2), -1/np.sqrt(2)], [0, 0]])\nP = A @ A.T\nprint(np.allclose(P @ P, P) and np.allclose(P, P.T))"
  },
  {
    "input": "Find a non-zero vector that is orthogonal to [1, 1, 1] and lies in the plane x - y + z = 0.",
    "output": "import numpy as np\nfrom scipy.linalg import null_space\nA = np.array([[1, 1, 1], [1, -1, 1]])\nv = null_space(A)[:, 0]\nv = v / np.linalg.norm(v)\nprint(v)"
  },
  {
    "input": "Check if the projection of [1, 2] onto [2, 0] is equal to the original vector.",
    "output": "import numpy as np\nv = np.array([1, 2])\nu = np.array([2, 0])\nproj = (np.dot(v, u) / np.dot(u, u)) * u\nprint(np.allclose(proj, v))"
  },
  {
    "input": "Find a vector in R^3 that is orthogonal to [1, 1, 1] and has length 3.",
    "output": "import numpy as np\nv = np.array([1, -1, 0])\nv = v / np.linalg.norm(v) * 3\nprint(v)"
  },
  {
    "input": "Find the unit vector that is orthogonal to both [1, 2, 2] and [2, 1, 2].",
    "output": "import numpy as np\na = np.array([1, 2, 2])\nb = np.array([2, 1, 2])\nc = np.cross(a, b)\nc = c / np.linalg.norm(c)\nprint(c)"
  },
  {
    "input": "Let A = [[1, 2, 3], [2, 4, 6]], find a basis for the orthogonal complement of the row space.",
    "output": "import numpy as np\nfrom scipy.linalg import null_space\nA = np.array([[1, 2, 3], [2, 4, 6]])\nB = null_space(A)\nprint(B)"
  },
  {
    "input": "Verify that the projection matrix onto a line is idempotent and symmetric.",
    "output": "import numpy as np\nu = np.array([2, 1])\nu = u / np.linalg.norm(u)\nP = np.outer(u, u)\nprint(np.allclose(P @ P, P) and np.allclose(P, P.T))"
  },
  {
    "input": "Find the projection of the vector [4, 3, 0] onto the plane x + y + z = 0.",
    "output": "import numpy as np\nv = np.array([4, 3, 0])\nn = np.array([1, 1, 1])\nproj = v - (np.dot(v, n) / np.dot(n, n)) * n\nprint(proj)"
  },
  {
    "input": "Find the distance from point [2, 3, 1] to the line passing through origin in the direction [1, 2, 2].",
    "output": "import numpy as np\np = np.array([2, 3, 1])\nd = np.array([1, 2, 2])\nproj = (np.dot(p, d) / np.dot(d, d)) * d\ndist = np.linalg.norm(p - proj)\nprint(dist)"
  },
  {
    "input": "Find the unit vector in the plane x + y + z = 0 that is closest to [1, 1, 1].",
    "output": "import numpy as np\nv = np.array([1, 1, 1])\nn = np.array([1, 1, 1])\nproj = v - (np.dot(v, n) / np.dot(n, n)) * n\nunit = proj / np.linalg.norm(proj)\nprint(unit)"
  },
  {
    "input": "Let A = [[1, 0], [0, 1], [1, 1]]. Find the projection of [2, 2, 2] onto the column space of A.",
    "output": "import numpy as np\nA = np.array([[1, 0], [0, 1], [1, 1]])\nb = np.array([2, 2, 2])\nP = A @ np.linalg.inv(A.T @ A) @ A.T\nproj = P @ b\nprint(proj)"
  },
  {
    "input": "Determine the angle between [3, 1] and its projection onto [1, 0].",
    "output": "import numpy as np\nv = np.array([3, 1])\nu = np.array([1, 0])\nproj = (np.dot(v, u) / np.dot(u, u)) * u\nangle = np.arccos(np.dot(v, proj) / (np.linalg.norm(v) * np.linalg.norm(proj)))\nprint(np.degrees(angle))"
  },
  {
    "input": "Find a vector in the subspace spanned by [1, 1, 0] and [0, 1, 1] that is orthogonal to [1, 0, 1].",
    "output": "import numpy as np\nfrom sympy import symbols, Eq, solve\nc1, c2 = symbols('c1 c2')\nv1 = np.array([1, 1, 0])\nv2 = np.array([0, 1, 1])\nw = np.array([1, 0, 1])\nv = c1 * v1 + c2 * v2\n# Dot product with w must be zero\ncondition = Eq(np.dot(v, w), 0)\n# Assume c2 = 1\nsol = solve(condition.subs(c2, 1), c1)\nc1_val = float(sol[0])\nc2_val = 1\nv_final = c1_val * v1 + c2_val * v2\nprint(v_final)"
  },
  {
    "input": "Find the unit vector that lies in the plane x + 2y + 3z = 0 and is orthogonal to [1, -1, 0].",
    "output": "import numpy as np\nfrom scipy.linalg import null_space\nA = np.array([[1, -1, 0], [1, 2, 3]])\nv = null_space(A)[:, 0]\nv = v / np.linalg.norm(v)\nprint(v)"
  },
  {
    "input": "Given two orthogonal vectors u = [1, 0, 1] and v = [0, 1, -1], compute the norm of u + v.",
    "output": "import numpy as np\nu = np.array([1, 0, 1])\nv = np.array([0, 1, -1])\nsum_vector = u + v\nnorm = np.linalg.norm(sum_vector)\nprint(norm)"
  },
  {
    "input": "Find the projection of [1, 2, 3] onto the space spanned by the orthonormal vectors [1/\u221a2, 1/\u221a2, 0] and [0, 0, 1].",
    "output": "import numpy as np\nu1 = np.array([1/np.sqrt(2), 1/np.sqrt(2), 0])\nu2 = np.array([0, 0, 1])\nv = np.array([1, 2, 3])\nproj = np.dot(v, u1) * u1 + np.dot(v, u2) * u2\nprint(proj)"
  },
  {
    "input": "Find the distance from the point [3, 1, 2] to the plane x + y + z = 0.",
    "output": "import numpy as np\np = np.array([3, 1, 2])\nn = np.array([1, 1, 1])\ndist = abs(np.dot(p, n)) / np.linalg.norm(n)\nprint(dist)"
  },
  {
    "input": "Is the projection matrix P = [[0.6, 0.4], [0.4, 0.4]] symmetric and idempotent?",
    "output": "import numpy as np\nP = np.array([[0.6, 0.4], [0.4, 0.4]])\nprint(np.allclose(P @ P, P) and np.allclose(P, P.T))"
  },
  {
    "input": "Find a unit vector orthogonal to both [1, 2, 3] and [4, 5, 6].",
    "output": "import numpy as np\nu = np.array([1, 2, 3])\nv = np.array([4, 5, 6])\nw = np.cross(u, v)\nunit = w / np.linalg.norm(w)\nprint(unit)"
  },
  {
    "input": "Find the projection matrix onto the space spanned by [2, 1, 0].",
    "output": "import numpy as np\nv = np.array([2, 1, 0])\nv = v / np.linalg.norm(v)\nP = np.outer(v, v)\nprint(P)"
  },
  {
    "input": "Find the orthogonal complement of the row space of A = [[1, 2, 3], [2, 4, 6]].",
    "output": "import numpy as np\nfrom scipy.linalg import null_space\nA = np.array([[1, 2, 3], [2, 4, 6]])\nB = null_space(A)\nprint(B)"
  },
  {
    "input": "Determine if [1, 1, 0] and [1, -1, 0] are orthogonal and form a basis for R^2 within R^3.",
    "output": "import numpy as np\nu = np.array([1, 1, 0])\nv = np.array([1, -1, 0])\northogonal = np.dot(u, v) == 0\nindependent = np.linalg.matrix_rank(np.array([u, v])) == 2\nprint({'orthogonal': orthogonal, 'basis_for_R2_in_R3': independent})"
  },
  {
    "input": "Find a vector in R^3 of magnitude 5 that is orthogonal to [1, 1, 1].",
    "output": "import numpy as np\nv = np.array([1, -1, 0])\nv = v / np.linalg.norm(v) * 5\nprint(v)"
  },
  {
    "input": "Find the projection of [1, 0, 0] onto the space spanned by [1, 2, 2] and [2, 1, 2].",
    "output": "import numpy as np\nA = np.array([[1, 2], [2, 1], [2, 2]])\nb = np.array([1, 0, 0])\nP = A @ np.linalg.pinv(A) @ b\nprint(P)"
  },
  {
    "input": "Let Q be an orthogonal matrix. Verify that Q.T @ Q = I.",
    "output": "import numpy as np\nQ = np.array([[0, -1], [1, 0]])\nidentity = Q.T @ Q\nprint(identity)"
  },
  {
    "input": "Find a unit vector in the column space of A = [[1, 0], [1, 1], [0, 1]] that is orthogonal to [1, 1, 1].",
    "output": "import numpy as np\nfrom scipy.linalg import orth\nA = np.array([[1, 0], [1, 1], [0, 1]])\nC = orth(A)\nv = C[:, 0] - (np.dot(C[:, 0], [1, 1, 1]) / 3) * np.array([1, 1, 1])\nv = v / np.linalg.norm(v)\nprint(v)"
  },
  {
    "input": "Find the projection of [3, 3, 3] onto the null space of A = [[1, 1, 1]].",
    "output": "import numpy as np\nfrom scipy.linalg import null_space\nA = np.array([[1, 1, 1]])\nN = null_space(A)\nv = np.array([3, 3, 3])\nproj = N @ (N.T @ v)\nprint(proj)"
  },
  {
    "input": "Let u = [1, 2] and v = [2, -1]. Find the projection of u onto v and compute the orthogonal component.",
    "output": "import numpy as np\nu = np.array([1, 2])\nv = np.array([2, -1])\nproj = (np.dot(u, v) / np.dot(v, v)) * v\north = u - proj\nprint({'projection': proj, 'orthogonal_component': orth})"
  },
  {
    "input": "Find the unit vector in the null space of A = [[1, 2, -1], [2, 4, -2]].",
    "output": "import numpy as np\nfrom scipy.linalg import null_space\nA = np.array([[1, 2, -1], [2, 4, -2]])\nN = null_space(A)\nv = N[:, 0] / np.linalg.norm(N[:, 0])\nprint(v)"
  },
  {
    "input": "Given v = [3, 4, 0] and u = [0, 0, 5], find the orthogonal projection of v onto u.",
    "output": "import numpy as np\nv = np.array([3, 4, 0])\nu = np.array([0, 0, 5])\nproj = (np.dot(v, u) / np.dot(u, u)) * u\nprint(proj)"
  },
  {
    "input": "Find the projection of [1, 0, 1, 0] onto the subspace spanned by [1, 1, 0, 0] and [0, 0, 1, 1].",
    "output": "import numpy as np\nA = np.array([[1, 0], [1, 0], [0, 1], [0, 1]])\nv = np.array([1, 0, 1, 0])\nP = A @ np.linalg.pinv(A) @ v\nprint(P)"
  },
  {
    "input": "Determine whether the vectors [1, 1, 1, 1], [1, -1, 1, -1], [1, 1, -1, -1] form an orthogonal set.",
    "output": "import numpy as np\nV = np.array([[1, 1, 1, 1], [1, -1, 1, -1], [1, 1, -1, -1]])\nG = V @ V.T\nis_orthogonal = np.allclose(G - np.diag(np.diag(G)), 0)\nprint(is_orthogonal)"
  },
  {
    "input": "Find the orthogonal projection of vector [1, 2, 3] onto the plane 2x + y - z = 0.",
    "output": "import numpy as np\nv = np.array([1, 2, 3])\nn = np.array([2, 1, -1])\nproj = v - (np.dot(v, n) / np.dot(n, n)) * n\nprint(proj)"
  },
  {
    "input": "Find a unit vector orthogonal to the vector [1, 2, 3] and lying in the x-y plane.",
    "output": "import numpy as np\nv = np.array([1, 2, 3])\nw = np.array([2, -1, 0])\nw = w - (np.dot(w, v) / np.dot(v, v)) * v\nunit = w / np.linalg.norm(w)\nprint(unit)"
  },
  {
    "input": "Find the component of [2, 3, 4] that is orthogonal to the space spanned by [1, 1, 0].",
    "output": "import numpy as np\nu = np.array([1, 1, 0])\nv = np.array([2, 3, 4])\nproj = (np.dot(v, u) / np.dot(u, u)) * u\north = v - proj\nprint(orth)"
  },
  {
    "input": "Let u1 = [1, 1, 0], u2 = [1, -1, 0]. Apply Gram-Schmidt to orthogonalize them.",
    "output": "import numpy as np\nu1 = np.array([1, 1, 0])\nu2 = np.array([1, -1, 0])\nv1 = u1\nv2 = u2 - (np.dot(u2, v1) / np.dot(v1, v1)) * v1\nprint(v1, v2)"
  },
  {
    "input": "Let A be a matrix with columns [1, 1], [2, 2], [3, 3]. Find the rank of the projection matrix A @ A^+.",
    "output": "import numpy as np\nA = np.array([[1, 1], [2, 2], [3, 3]])\nP = A @ np.linalg.pinv(A)\nrank = np.linalg.matrix_rank(P)\nprint(rank)"
  },
  {
    "input": "Let v = [1, 2, 2]. Find its projection onto the space orthogonal to [1, 1, 1].",
    "output": "import numpy as np\nv = np.array([1, 2, 2])\nn = np.array([1, 1, 1])\nproj = v - (np.dot(v, n) / np.dot(n, n)) * n\nprint(proj)"
  },
  {
    "input": "Let A = [[1, 0], [0, 1], [1, 1]]. Find an orthonormal basis for its column space using Gram-Schmidt.",
    "output": "import numpy as np\nfrom scipy.linalg import qr\nA = np.array([[1, 0], [0, 1], [1, 1]])\nQ, _ = qr(A, mode='economic')\nprint(Q)"
  },
  {
    "input": "Find a unit vector in the null space of A = [[1, -1, 2], [-2, 2, -4]].",
    "output": "import numpy as np\nfrom scipy.linalg import null_space\nA = np.array([[1, -1, 2], [-2, 2, -4]])\nN = null_space(A)\nunit = N[:, 0] / np.linalg.norm(N[:, 0])\nprint(unit)"
  },
  {
    "input": "Let v = [3, 2, 1]. Compute its projection onto the column space of A = [[1, 0], [1, 1], [1, 2]].",
    "output": "import numpy as np\nA = np.array([[1, 0], [1, 1], [1, 2]])\nv = np.array([3, 2, 1])\nP = A @ np.linalg.pinv(A) @ v\nprint(P)"
  },
  {
    "input": "Compute the projection of [4, 1] onto the line y = 2x.",
    "output": "import numpy as np\nv = np.array([4, 1])\nu = np.array([1, 2])\nu = u / np.linalg.norm(u)\nproj = np.dot(v, u) * u\nprint(proj)"
  },
  {
    "input": "Let v = [1, 2, 3, 4] and A = [[1, 0], [0, 1], [1, 0], [0, 1]]. Compute projection of v onto Col(A).",
    "output": "import numpy as np\nv = np.array([1, 2, 3, 4])\nA = np.array([[1, 0], [0, 1], [1, 0], [0, 1]])\nP = A @ np.linalg.pinv(A) @ v\nprint(P)"
  },
  {
    "input": "Find a unit vector in the plane x - 2y + z = 0 that is orthogonal to [2, 1, -1].",
    "output": "import numpy as np\nfrom scipy.linalg import null_space\nA = np.array([[1, -2, 1], [2, 1, -1]])\nv = null_space(A)[:, 0]\nv = v / np.linalg.norm(v)\nprint(v)"
  },
  {
    "input": "Compute the projection matrix onto the plane spanned by vectors [1, 0, 0] and [0, 1, 1].",
    "output": "import numpy as np\nA = np.array([[1, 0], [0, 1], [0, 1]])\nP = A @ np.linalg.pinv(A)\nprint(P)"
  },
  {
    "input": "Given a vector [1, 2, 3], find its orthogonal component to the subspace spanned by [1, 1, 1].",
    "output": "import numpy as np\nv = np.array([1, 2, 3])\nu = np.array([1, 1, 1])\nproj = (np.dot(v, u) / np.dot(u, u)) * u\north = v - proj\nprint(orth)"
  },
  {
    "input": "Apply the Gram-Schmidt process to vectors [1, 0, 1], [1, 1, 0], and [0, 1, 1].",
    "output": "import numpy as np\ndef gram_schmidt(V):\n    U = []\n    for v in V:\n        v = v.astype(float)\n        for u in U:\n            v -= np.dot(v, u) * u\n        U.append(v / np.linalg.norm(v))\n    return np.array(U)\nV = [np.array([1, 0, 1], dtype=float), np.array([1, 1, 0], dtype=float), np.array([0, 1, 1], dtype=float)]\nQ = gram_schmidt(V)\nprint(Q)"
  },
  {
    "input": "Find a unit vector in the orthogonal complement of the column space of A = [[1, 2], [2, 4], [3, 6]].",
    "output": "import numpy as np\nfrom scipy.linalg import null_space\nA = np.array([[1, 2], [2, 4], [3, 6]])\nN = null_space(A.T)\nunit = N[:, 0] / np.linalg.norm(N[:, 0])\nprint(unit)"
  },
  {
    "input": "Find the projection of vector [3, 3] onto the vector [1, -1], and determine if the result is orthogonal to [2, 2].",
    "output": "import numpy as np\nv = np.array([3, 3])\nu = np.array([1, -1])\nproj = (np.dot(v, u) / np.dot(u, u)) * u\nis_orthogonal = np.dot(proj, [2, 2]) == 0\nprint(proj, is_orthogonal)"
  },
  {
    "input": "Let A = [[2, 0], [0, 3]]. Is A an orthogonal matrix?",
    "output": "import numpy as np\nA = np.array([[2, 0], [0, 3]])\northogonal = np.allclose(A.T @ A, np.eye(2))\nprint(orthogonal)"
  },
  {
    "input": "Find the vector component of [4, 4, 2] parallel to [1, 1, 0] and its orthogonal component.",
    "output": "import numpy as np\nv = np.array([4, 4, 2])\nu = np.array([1, 1, 0])\nproj = (np.dot(v, u) / np.dot(u, u)) * u\north = v - proj\nprint({'parallel': proj, 'orthogonal': orth})"
  },
  {
    "input": "Find a vector perpendicular to both [1, 1, 1] and [2, 2, -1] using the cross product.",
    "output": "import numpy as np\nu = np.array([1, 1, 1])\nv = np.array([2, 2, -1])\nw = np.cross(u, v)\nprint(w / np.linalg.norm(w))"
  },
  {
    "input": "Let Q = [[1/\u221a2, -1/\u221a2], [1/\u221a2, 1/\u221a2]]. Show Q is orthogonal and compute Q.T @ Q.",
    "output": "import numpy as np\nQ = np.array([[1/np.sqrt(2), -1/np.sqrt(2)], [1/np.sqrt(2), 1/np.sqrt(2)]])\nprint(Q.T @ Q)"
  },
  {
    "input": "Given u = [1, 2, 3] and v = [4, 5, 6], compute the projection of v onto u and verify the dot product of the orthogonal component with u is zero.",
    "output": "import numpy as np\nu = np.array([1, 2, 3])\nv = np.array([4, 5, 6])\nproj = (np.dot(v, u) / np.dot(u, u)) * u\north = v - proj\nprint(np.dot(orth, u))"
  },
  {
    "input": "Find a unit vector in the plane x + 2y - z = 0, perpendicular to the vector [2, -1, 1].",
    "output": "import numpy as np\nfrom scipy.linalg import null_space\nA = np.array([[1, 2, -1], [2, -1, 1]])\nv = null_space(A)[:, 0]\nv = v / np.linalg.norm(v)\nprint(v)"
  },
  {
    "input": "Given the matrix A = [[1, 2], [3, 4], [5, 6]], find the orthogonal projection of [7, 8, 9] onto Col(A).",
    "output": "import numpy as np\nA = np.array([[1, 2], [3, 4], [5, 6]])\nv = np.array([7, 8, 9])\nproj = A @ np.linalg.pinv(A) @ v\nprint(proj)"
  },
  {
    "input": "Let A = [[1, 0], [0, 0], [0, 1]]. Find the orthogonal projection matrix onto the column space of A.",
    "output": "import numpy as np\nA = np.array([[1, 0], [0, 0], [0, 1]])\nP = A @ np.linalg.pinv(A)\nprint(P)"
  },
  {
    "input": "Use Gram-Schmidt to orthonormalize vectors [1, 2, 0], [2, 3, 4], [1, 0, 1].",
    "output": "import numpy as np\ndef gram_schmidt(V):\n    U = []\n    for v in V:\n        v = v.astype(float)\n        for u in U:\n            v -= np.dot(v, u) * u\n        U.append(v / np.linalg.norm(v))\n    return np.array(U)\nV = [np.array([1, 2, 0], dtype=float), np.array([2, 3, 4], dtype=float), np.array([1, 0, 1], dtype=float)]\nQ = gram_schmidt(V)\nprint(Q)"
  },
  {
    "input": "Find the projection of [2, 1, -1] onto the subspace defined by x - y + z = 0.",
    "output": "import numpy as np\nfrom scipy.linalg import null_space\nn = np.array([1, -1, 1])\nv = np.array([2, 1, -1])\nproj = v - (np.dot(v, n) / np.dot(n, n)) * n\nprint(proj)"
  },
  {
    "input": "Find a unit vector in the space orthogonal to both [1, 2, 3] and [4, 5, 6].",
    "output": "import numpy as np\nu = np.array([1, 2, 3])\nv = np.array([4, 5, 6])\nw = np.cross(u, v)\nw = w / np.linalg.norm(w)\nprint(w)"
  },
  {
    "input": "Given matrix A = [[1, 2], [3, 6], [5, 10]], compute the orthogonal projection matrix onto Col(A).",
    "output": "import numpy as np\nA = np.array([[1, 2], [3, 6], [5, 10]])\nP = A @ np.linalg.pinv(A)\nprint(P)"
  },
  {
    "input": "Compute the projection of v = [1, 1, 1] onto the null space of A = [[1, 2, 3]].",
    "output": "import numpy as np\nfrom scipy.linalg import null_space\nv = np.array([1, 1, 1])\nA = np.array([[1, 2, 3]])\nN = null_space(A)\nproj = N @ np.linalg.pinv(N) @ v\nprint(proj)"
  },
  {
    "input": "Let v = [3, 4, 0], find its projection onto the plane x + y + z = 0.",
    "output": "import numpy as np\nn = np.array([1, 1, 1])\nv = np.array([3, 4, 0])\nproj = v - (np.dot(v, n) / np.dot(n, n)) * n\nprint(proj)"
  },
  {
    "input": "Determine if the vectors [1, 1, 0], [0, 1, 1], and [1, 0, 1] form an orthogonal set.",
    "output": "import numpy as np\nv = [np.array([1, 1, 0]), np.array([0, 1, 1]), np.array([1, 0, 1])]\northogonal = all(np.isclose(np.dot(v[i], v[j]), 0) for i in range(3) for j in range(i+1, 3))\nprint(orthogonal)"
  },
  {
    "input": "Find the projection of [4, 5] onto the vector [1, 2], then find the orthogonal component.",
    "output": "import numpy as np\nv = np.array([4, 5])\nu = np.array([1, 2])\nproj = (np.dot(v, u) / np.dot(u, u)) * u\north = v - proj\nprint({'projection': proj, 'orthogonal': orth})"
  },
  {
    "input": "Let A = [[1, 2], [3, 4], [5, 6]]. Compute Q from QR decomposition using Gram-Schmidt.",
    "output": "import numpy as np\nfrom scipy.linalg import qr\nA = np.array([[1, 2], [3, 4], [5, 6]])\nQ, _ = qr(A, mode='economic')\nprint(Q)"
  },
  {
    "input": "Find an orthonormal basis for the null space of A = [[1, 2, 3], [4, 5, 6]].",
    "output": "import numpy as np\nfrom scipy.linalg import null_space\nN = null_space(np.array([[1, 2, 3], [4, 5, 6]]))\nprint(N)"
  },
  {
    "input": "Compute the vector component of [1, 0, -1] that is parallel to [2, 1, 0].",
    "output": "import numpy as np\nv = np.array([1, 0, -1])\nu = np.array([2, 1, 0])\nproj = (np.dot(v, u) / np.dot(u, u)) * u\nprint(proj)"
  },
  {
    "input": "Apply Gram-Schmidt to orthogonalize vectors [1, 2], [2, 1].",
    "output": "import numpy as np\ndef gram_schmidt(V):\n    U = []\n    for v in V:\n        v = v.astype(float)\n        for u in U:\n            v -= np.dot(v, u) * u\n        U.append(v / np.linalg.norm(v))\n    return np.array(U)\nV = [np.array([1, 2], dtype=float), np.array([2, 1], dtype=float)]\nQ = gram_schmidt(V)\nprint(Q)"
  },
  {
    "input": "Given v = [1, 2, 2], compute its projection onto the column space of A = [[1, 0], [0, 1], [1, 1]].",
    "output": "import numpy as np\nv = np.array([1, 2, 2])\nA = np.array([[1, 0], [0, 1], [1, 1]])\nproj = A @ np.linalg.pinv(A) @ v\nprint(proj)"
  },
  {
    "input": "Find a unit vector in the plane 2x - y + z = 0, orthogonal to [1, 0, 1].",
    "output": "import numpy as np\nfrom scipy.linalg import null_space\nA = np.array([[2, -1, 1], [1, 0, 1]])\nv = null_space(A)[:, 0]\nv = v / np.linalg.norm(v)\nprint(v)"
  },
  {
    "input": "Check if the projection matrix A = [[0.5, 0.5], [0.5, 0.5]] is idempotent.",
    "output": "import numpy as np\nA = np.array([[0.5, 0.5], [0.5, 0.5]])\nidempotent = np.allclose(A @ A, A)\nprint(idempotent)"
  },
  {
    "input": "Project the vector [1, 1, 1, 1] onto the subspace spanned by [1, 1, 0, 0] and [0, 0, 1, 1].",
    "output": "import numpy as np\nA = np.array([[1, 0], [1, 0], [0, 1], [0, 1]])\nv = np.array([1, 1, 1, 1])\nproj = A @ np.linalg.pinv(A) @ v\nprint(proj)"
  },
  {
    "input": "Given vectors u = [1, 2, -1] and v = [2, -1, 1], verify that their sum is orthogonal to their difference.",
    "output": "import numpy as np\nu = np.array([1, 2, -1])\nv = np.array([2, -1, 1])\nsum_vec = u + v\ndiff_vec = u - v\nprint(np.dot(sum_vec, diff_vec) == 0)"
  },
  {
    "input": "Find the orthogonal projection of [3, 3, 3] onto the subspace spanned by [1, 1, 0] and [0, 0, 1].",
    "output": "import numpy as np\nA = np.array([[1, 0], [1, 0], [0, 1]])\nv = np.array([3, 3, 3])\nproj = A @ np.linalg.pinv(A) @ v\nprint(proj)"
  },
  {
    "input": "Apply Gram-Schmidt to orthonormalize [2, 1, 0], [1, 1, 0], [0, 0, 1].",
    "output": "import numpy as np\ndef gram_schmidt(V):\n    U = []\n    for v in V:\n        v = v.astype(float)\n        for u in U:\n            v -= np.dot(v, u) * u\n        U.append(v / np.linalg.norm(v))\n    return np.array(U)\nV = [np.array([2, 1, 0], dtype=float), np.array([1, 1, 0], dtype=float), np.array([0, 0, 1], dtype=float)]\nQ = gram_schmidt(V)\nprint(Q)"
  },
  {
    "input": "Find a vector orthogonal to both [1, 2, 2] and [2, 3, 4] and lies in the plane x + y + z = 0.",
    "output": "from sympy import symbols, Eq, solve\nimport numpy as np\nx, y, z = symbols('x y z')\neq1 = Eq(x*1 + y*2 + z*2, 0)\neq2 = Eq(x*2 + y*3 + z*4, 0)\neq3 = Eq(x + y + z, 0)\nsol = solve((eq1, eq2, eq3), (x, y, z), dict=True)\nv = np.array([sol[0][x], sol[0][y], sol[0][z]], dtype=float)\nv = v / np.linalg.norm(v)\nprint(v)"
  },
  {
    "input": "Find the projection of [4, -2] onto the vector [3, 1] and confirm the error vector is orthogonal.",
    "output": "import numpy as np\nv = np.array([4, -2])\nu = np.array([3, 1])\nproj = (np.dot(v, u) / np.dot(u, u)) * u\nerror = v - proj\nprint(np.dot(error, u))"
  },
  {
    "input": "Given v = [1, 2, 3], find its orthogonal projection onto the plane x + 2y + 2z = 0.",
    "output": "import numpy as np\nn = np.array([1, 2, 2])\nv = np.array([1, 2, 3])\nproj = v - (np.dot(v, n) / np.dot(n, n)) * n\nprint(proj)"
  },
  {
    "input": "Given matrix A = [[1, 1], [1, -1], [1, 0]], compute the projection matrix onto Col(A).",
    "output": "import numpy as np\nA = np.array([[1, 1], [1, -1], [1, 0]])\nP = A @ np.linalg.pinv(A)\nprint(P)"
  },
  {
    "input": "Determine whether the matrix [[1, 2], [2, 1]] is orthogonal.",
    "output": "import numpy as np\nA = np.array([[1, 2], [2, 1]])\northogonal = np.allclose(A.T @ A, np.eye(2))\nprint(orthogonal)"
  },
  {
    "input": "Given vector [1, 2, 3], find its projection onto the null space of A = [[1, 1, 1]].",
    "output": "import numpy as np\nfrom scipy.linalg import null_space\nA = np.array([[1, 1, 1]])\nv = np.array([1, 2, 3])\nN = null_space(A)\nproj = N @ np.linalg.pinv(N) @ v\nprint(proj)"
  },
  {
    "input": "Let A = [[1, 0, 1], [0, 1, 1]]. Find the projection of [2, 3, 4] onto the row space of A.",
    "output": "import numpy as np\nA = np.array([[1, 0, 1], [0, 1, 1]])\nv = np.array([2, 3, 4])\nR = A.T @ np.linalg.pinv(A @ A.T) @ A\nproj = R @ v\nprint(proj)"
  },
  {
    "input": "Verify if the vector [1, 1, -2] is orthogonal to the subspace spanned by [1, -1, 0] and [2, 1, 1].",
    "output": "import numpy as np\nv = np.array([1, 1, -2])\nA = np.array([[1, -1, 0], [2, 1, 1]])\northogonal = np.allclose(A @ v, np.zeros(2))\nprint(orthogonal)"
  },
  {
    "input": "Use Gram-Schmidt to orthonormalize [1, 1, 1], [1, 0, -1], [1, -2, 1].",
    "output": "import numpy as np\ndef gram_schmidt(V):\n    U = []\n    for v in V:\n        v = v.astype(float)\n        for u in U:\n            v -= np.dot(v, u) * u\n        U.append(v / np.linalg.norm(v))\n    return np.array(U)\nV = [np.array([1, 1, 1], dtype=float), np.array([1, 0, -1], dtype=float), np.array([1, -2, 1], dtype=float)]\nQ = gram_schmidt(V)\nprint(Q)"
  },
  {
    "input": "Find a vector in the null space of A = [[1, 2, 3], [2, 4, 6], [3, 6, 9]] and make it unit length.",
    "output": "import numpy as np\nfrom scipy.linalg import null_space\nN = null_space(np.array([[1, 2, 3], [2, 4, 6], [3, 6, 9]]))\nunit = N[:, 0] / np.linalg.norm(N[:, 0])\nprint(unit)"
  },
  {
    "input": "Let A = [[1, 2], [2, 4], [3, 6]], compute projection of [1, 0, 1] onto the orthogonal complement of Col(A).",
    "output": "import numpy as np\nA = np.array([[1, 2], [2, 4], [3, 6]])\nv = np.array([1, 0, 1])\nP = A @ np.linalg.pinv(A)\north_proj = v - P @ v\nprint(orth_proj)"
  },
  {
    "input": "Given two vectors u = [1, 2] and v = [2, -1], compute the projection of v onto u and then reflect v over u.",
    "output": "import numpy as np\nu = np.array([1, 2])\nv = np.array([2, -1])\nproj = (np.dot(v, u) / np.dot(u, u)) * u\nreflected = 2 * proj - v\nprint(reflected)"
  },
  {
    "input": "Find the projection of [2, 1, -1] onto the plane defined by the normal vector [1, 1, 1].",
    "output": "import numpy as np\nn = np.array([1, 1, 1])\nv = np.array([2, 1, -1])\nproj = v - (np.dot(v, n) / np.dot(n, n)) * n\nprint(proj)"
  },
  {
    "input": "Compute the orthogonal projection of [3, 0, 1] onto the subspace spanned by [1, 1, 0] and [0, 1, 1].",
    "output": "import numpy as np\nA = np.array([[1, 0], [1, 1], [0, 1]])\nv = np.array([3, 0, 1])\nproj = A @ np.linalg.pinv(A) @ v\nprint(proj)"
  },
  {
    "input": "Let A = [[2, 1], [1, 2]]. Is the projection matrix onto Col(A) idempotent?",
    "output": "import numpy as np\nA = np.array([[2, 1], [1, 2]])\nP = A @ np.linalg.pinv(A)\nprint(np.allclose(P @ P, P))"
  },
  {
    "input": "Find a unit vector in the null space of A = [[1, 2, 1], [2, 4, 2]].",
    "output": "import numpy as np\nfrom scipy.linalg import null_space\nN = null_space(np.array([[1, 2, 1], [2, 4, 2]]))\nunit = N[:, 0] / np.linalg.norm(N[:, 0])\nprint(unit)"
  },
  {
    "input": "Orthogonally decompose [4, 2] into components parallel and orthogonal to [3, -1].",
    "output": "import numpy as np\nv = np.array([4, 2])\nu = np.array([3, -1])\nproj = (np.dot(v, u) / np.dot(u, u)) * u\north = v - proj\nprint({'parallel': proj, 'orthogonal': orth})"
  },
  {
    "input": "Apply Gram-Schmidt to orthonormalize the vectors [1, 2, 2], [2, 0, 1], [1, 1, 1].",
    "output": "import numpy as np\ndef gram_schmidt(V):\n    U = []\n    for v in V:\n        v = v.astype(float)\n        for u in U:\n            v -= np.dot(v, u) * u\n        U.append(v / np.linalg.norm(v))\n    return np.array(U)\nV = [np.array([1, 2, 2], dtype=float), np.array([2, 0, 1], dtype=float), np.array([1, 1, 1], dtype=float)]\nQ = gram_schmidt(V)\nprint(Q)"
  },
  {
    "input": "Find the orthogonal component of [1, 1, 1] relative to the vector [1, -1, 0].",
    "output": "import numpy as np\nv = np.array([1, 1, 1])\nu = np.array([1, -1, 0])\nproj = (np.dot(v, u) / np.dot(u, u)) * u\north = v - proj\nprint(orth)"
  },
  {
    "input": "Check if the vectors [1, 0, 1], [0, 1, -1], and [1, 1, 0] form an orthonormal set.",
    "output": "import numpy as np\nV = np.array([[1, 0, 1], [0, 1, -1], [1, 1, 0]])\nV = V / np.linalg.norm(V, axis=1, keepdims=True)\ndot_products = np.dot(V, V.T)\nprint(np.allclose(dot_products, np.eye(3)))"
  },
  {
    "input": "Find the projection matrix that projects any vector in R^3 onto the line spanned by [2, 2, 1].",
    "output": "import numpy as np\nu = np.array([2, 2, 1])\nu = u / np.linalg.norm(u)\nP = np.outer(u, u)\nprint(P)"
  },
  {
    "input": "Project the vector [5, -3, 2] onto the row space of A = [[1, 2, 3]].",
    "output": "import numpy as np\nA = np.array([[1, 2, 3]])\nv = np.array([5, -3, 2])\nR = A.T @ np.linalg.pinv(A @ A.T) @ A\nproj = R @ v\nprint(proj)"
  },
  {
    "input": "Determine whether the projection matrix A = [[1, 0], [0, 0]] is symmetric and idempotent.",
    "output": "import numpy as np\nA = np.array([[1, 0], [0, 0]])\nsymmetric = np.allclose(A, A.T)\nidempotent = np.allclose(A @ A, A)\nprint({'symmetric': symmetric, 'idempotent': idempotent})"
  },
  {
    "input": "Find an orthonormal basis for the column space of A = [[1, 2], [2, 4], [3, 6]].",
    "output": "import numpy as np\nfrom scipy.linalg import orth\nA = np.array([[1, 2], [2, 4], [3, 6]])\nQ = orth(A)\nprint(Q)"
  },
  {
    "input": "Decompose [3, 3, 3] into parts parallel and orthogonal to the plane x + y + z = 0.",
    "output": "import numpy as np\nv = np.array([3, 3, 3])\nn = np.array([1, 1, 1])\nproj = (np.dot(v, n) / np.dot(n, n)) * n\north = v - proj\nprint({'parallel': proj, 'orthogonal': orth})"
  },
  {
    "input": "Use QR decomposition to find an orthonormal basis for Col(A) where A = [[1, 2], [3, 4], [5, 6]].",
    "output": "import numpy as np\nfrom scipy.linalg import qr\nA = np.array([[1, 2], [3, 4], [5, 6]])\nQ, R = qr(A, mode='economic')\nprint(Q)"
  },
  {
    "input": "Find a unit vector that lies in the plane 3x + y - z = 0 and is orthogonal to [1, 2, 3].",
    "output": "import numpy as np\nfrom scipy.linalg import null_space\nA = np.array([[3, 1, -1], [1, 2, 3]])\nv = null_space(A)[:, 0]\nv = v / np.linalg.norm(v)\nprint(v)"
  },
  {
    "input": "Given v = [2, -1, 0], find its projection onto the line orthogonal to the plane x - 2y + z = 0.",
    "output": "import numpy as np\nv = np.array([2, -1, 0])\nn = np.array([1, -2, 1])\nn = n / np.linalg.norm(n)\nproj = np.dot(v, n) * n\nprint(proj)"
  },
  {
    "input": "Find a unit vector perpendicular to both [2, 1, 0] and [1, -1, 1].",
    "output": "import numpy as np\na = np.array([2, 1, 0])\nb = np.array([1, -1, 1])\nv = np.cross(a, b)\nunit = v / np.linalg.norm(v)\nprint(unit)"
  },
  {
    "input": "Compute the projection of [4, 1, -2] onto the space orthogonal to the vector [1, 0, -1].",
    "output": "import numpy as np\nv = np.array([4, 1, -2])\nn = np.array([1, 0, -1])\nproj = v - (np.dot(v, n) / np.dot(n, n)) * n\nprint(proj)"
  },
  {
    "input": "Use Gram-Schmidt to orthonormalize [3, 1, 0], [1, 1, 1], [0, 1, 2].",
    "output": "import numpy as np\ndef gram_schmidt(V):\n    U = []\n    for v in V:\n        v = v.astype(float)\n        for u in U:\n            v -= np.dot(v, u) * u\n        U.append(v / np.linalg.norm(v))\n    return np.array(U)\nV = [np.array([3, 1, 0], dtype=float), np.array([1, 1, 1], dtype=float), np.array([0, 1, 2], dtype=float)]\nQ = gram_schmidt(V)\nprint(Q)"
  },
  {
    "input": "Given a vector [1, 2, 2], compute its projection onto the span of [[1, 0, 0], [0, 1, 1]].",
    "output": "import numpy as np\nA = np.array([[1, 0], [0, 1], [0, 1]])\nv = np.array([1, 2, 2])\nproj = A @ np.linalg.pinv(A) @ v\nprint(proj)"
  },
  {
    "input": "Let A = [[2, -1], [1, 1], [0, 1]]. Find the orthogonal projection of [3, 2, 1] onto Col(A).",
    "output": "import numpy as np\nA = np.array([[2, -1], [1, 1], [0, 1]])\nv = np.array([3, 2, 1])\nproj = A @ np.linalg.pinv(A) @ v\nprint(proj)"
  },
  {
    "input": "Check whether the set {[1, 0, 1], [0, 1, 0], [1, 0, -1]} is orthogonal.",
    "output": "import numpy as np\nV = np.array([[1, 0, 1], [0, 1, 0], [1, 0, -1]])\nD = V @ V.T\nis_orthogonal = np.allclose(D - np.diag(np.diag(D)), 0)\nprint(is_orthogonal)"
  },
  {
    "input": "Find the component of [4, 4, 4] along the subspace defined by x + y + z = 0.",
    "output": "import numpy as np\nv = np.array([4, 4, 4])\nn = np.array([1, 1, 1])\ncomp_orth = (np.dot(v, n) / np.dot(n, n)) * n\nresidual = v - comp_orth\nprint(residual)"
  },
  {
    "input": "Let A = [[1, 0], [1, 1], [0, 1]]. Compute the projection matrix P = A(A^T A)^-1 A^T.",
    "output": "import numpy as np\nA = np.array([[1, 0], [1, 1], [0, 1]])\nP = A @ np.linalg.inv(A.T @ A) @ A.T\nprint(P)"
  },
  {
    "input": "Find a unit vector in the null space of A = [[1, 1, 0], [0, 1, 1]].",
    "output": "import numpy as np\nfrom scipy.linalg import null_space\nA = np.array([[1, 1, 0], [0, 1, 1]])\nv = null_space(A)[:, 0]\nv = v / np.linalg.norm(v)\nprint(v)"
  },
  {
    "input": "Given v = [2, -3], compute the projection onto u = [1, 2] and verify the residual is orthogonal.",
    "output": "import numpy as np\nv = np.array([2, -3])\nu = np.array([1, 2])\nproj = (np.dot(v, u) / np.dot(u, u)) * u\nresidual = v - proj\nprint(np.dot(residual, u))"
  },
  {
    "input": "Determine a unit vector perpendicular to both [0, 1, -1] and [1, 0, -1].",
    "output": "import numpy as np\na = np.array([0, 1, -1])\nb = np.array([1, 0, -1])\nv = np.cross(a, b)\nv = v / np.linalg.norm(v)\nprint(v)"
  },
  {
    "input": "Find the component of [2, 2, 1] perpendicular to the plane x + y + z = 6.",
    "output": "import numpy as np\nv = np.array([2, 2, 1])\nn = np.array([1, 1, 1])\ncomp = (np.dot(v, n) / np.dot(n, n)) * n\nprint(comp)"
  },
  {
    "input": "Verify if the matrix Q from QR decomposition of A = [[1, 2], [3, 4], [5, 6]] is orthonormal.",
    "output": "import numpy as np\nfrom scipy.linalg import qr\nA = np.array([[1, 2], [3, 4], [5, 6]])\nQ, R = qr(A, mode='economic')\nprint(np.allclose(Q.T @ Q, np.eye(Q.shape[1])))"
  },
  {
    "input": "Let v = [1, 2, 3], find its projection onto the subspace orthogonal to [3, 2, 1].",
    "output": "import numpy as np\nv = np.array([1, 2, 3])\nn = np.array([3, 2, 1])\nproj = v - (np.dot(v, n) / np.dot(n, n)) * n\nprint(proj)"
  },
  {
    "input": "Find a unit vector in the plane x - y + z = 0 that is orthogonal to [2, 1, 0].",
    "output": "import numpy as np\nfrom scipy.linalg import null_space\nA = np.array([[1, -1, 1], [2, 1, 0]])\nv = null_space(A)[:, 0]\nv = v / np.linalg.norm(v)\nprint(v)"
  },
  {
    "input": "Given vectors u = [1, 2, 3] and v = [4, 5, 6], find the orthogonal projection of u onto v.",
    "output": "import numpy as np\nu = np.array([1, 2, 3])\nv = np.array([4, 5, 6])\nproj = (np.dot(u, v) / np.dot(v, v)) * v\nprint(proj)"
  },
  {
    "input": "Find the orthogonal projection of [3, -1, 4] onto the plane defined by x + y + z = 0.",
    "output": "import numpy as np\nv = np.array([3, -1, 4])\nn = np.array([1, 1, 1])\nproj = v - (np.dot(v, n) / np.dot(n, n)) * n\nprint(proj)"
  },
  {
    "input": "Check whether vectors [1, 2], [2, -1] are orthogonal and normalize them if they are.",
    "output": "import numpy as np\na = np.array([1, 2])\nb = np.array([2, -1])\nif np.dot(a, b) == 0:\n    a_norm = a / np.linalg.norm(a)\n    b_norm = b / np.linalg.norm(b)\n    print(a_norm, b_norm)\nelse:\n    print(\"Not orthogonal\")"
  },
  {
    "input": "Given A = [[1, 2], [3, 4], [5, 6]], compute the projection matrix onto Col(A).",
    "output": "import numpy as np\nA = np.array([[1, 2], [3, 4], [5, 6]])\nP = A @ np.linalg.pinv(A)  # This is A(A^T A)^-1 A^T v for all v\nprint(P)"
  },
  {
    "input": "Find a vector orthogonal to both [1, 0, 1] and [0, 1, 1] and normalize it.",
    "output": "import numpy as np\na = np.array([1, 0, 1])\nb = np.array([0, 1, 1])\nv = np.cross(a, b)\nunit = v / np.linalg.norm(v)\nprint(unit)"
  },
  {
    "input": "Check if the vectors [1, 0] and [0, 1] are orthogonal.",
    "output": "import numpy as np\na = np.array([1, 0])\nb = np.array([0, 1])\nprint(np.dot(a, b) == 0)"
  },
  {
    "input": "Compute the dot product of vectors [3, 4] and [4, -3].",
    "output": "import numpy as np\na = np.array([3, 4])\nb = np.array([4, -3])\nprint(np.dot(a, b))"
  },
  {
    "input": "Normalize the vector [0, 3, 4].",
    "output": "import numpy as np\nv = np.array([0, 3, 4])\nnorm_v = v / np.linalg.norm(v)\nprint(norm_v)"
  },
  {
    "input": "Find the projection of [2, 3] onto [1, 0].",
    "output": "import numpy as np\nv = np.array([2, 3])\nu = np.array([1, 0])\nproj = (np.dot(v, u) / np.dot(u, u)) * u\nprint(proj)"
  },
  {
    "input": "Determine if [1, 1, -2] is orthogonal to [2, -1, 0].",
    "output": "import numpy as np\na = np.array([1, 1, -2])\nb = np.array([2, -1, 0])\nprint(np.dot(a, b) == 0)"
  },
  {
    "input": "Find the projection of [1, 2] onto [0, 1].",
    "output": "import numpy as np\nv = np.array([1, 2])\nu = np.array([0, 1])\nproj = (np.dot(v, u) / np.dot(u, u)) * u\nprint(proj)"
  },
  {
    "input": "Compute the norm of vector [6, 8].",
    "output": "import numpy as np\nv = np.array([6, 8])\nnorm = np.linalg.norm(v)\nprint(norm)"
  },
  {
    "input": "Check if [1, 2, 3] is orthogonal to [3, 2, 1].",
    "output": "import numpy as np\na = np.array([1, 2, 3])\nb = np.array([3, 2, 1])\nprint(np.dot(a, b) == 0)"
  },
  {
    "input": "Find the unit vector in the direction of [5, 12].",
    "output": "import numpy as np\nv = np.array([5, 12])\nunit = v / np.linalg.norm(v)\nprint(unit)"
  },
  {
    "input": "Calculate the projection of [2, 2] onto [1, 1].",
    "output": "import numpy as np\nv = np.array([2, 2])\nu = np.array([1, 1])\nproj = (np.dot(v, u) / np.dot(u, u)) * u\nprint(proj)"
  },
  {
    "input": "Determine if the vectors [1, 2, -1] and [2, -1, 1] are orthogonal. If not, find their angle.",
    "output": "import numpy as np\nv1 = np.array([1, 2, -1])\nv2 = np.array([2, -1, 1])\ndot = np.dot(v1, v2)\nif dot == 0:\n    print(\"Orthogonal\")\nelse:\n    angle = np.arccos(dot / (np.linalg.norm(v1) * np.linalg.norm(v2)))\n    print(np.degrees(angle))"
  },
  {
    "input": "Project [3, 4, 0] onto [1, 2, 0] and compute the residual vector.",
    "output": "import numpy as np\nv = np.array([3, 4, 0])\nu = np.array([1, 2, 0])\nproj = (np.dot(v, u) / np.dot(u, u)) * u\nresidual = v - proj\nprint(residual)"
  },
  {
    "input": "Use Gram-Schmidt to orthonormalize the vectors [1, 1, 0] and [1, 0, 1].",
    "output": "import numpy as np\ndef gram_schmidt(vectors):\n    u = []\n    for v in vectors:\n        for b in u:\n            v = v - np.dot(v, b) * b\n        u.append(v / np.linalg.norm(v))\n    return u\nvectors = [np.array([1, 1, 0]), np.array([1, 0, 1])]\nresult = gram_schmidt(vectors)\nprint(result)"
  },
  {
    "input": "Given A = [[1, 0], [1, 1], [0, 1]] and b = [2, 3, 4], compute the projection of b onto Col(A).",
    "output": "import numpy as np\nA = np.array([[1, 0], [1, 1], [0, 1]])\nb = np.array([2, 3, 4])\nproj = A @ np.linalg.pinv(A) @ b\nprint(proj)"
  },
  {
    "input": "Find an orthogonal basis for the subspace spanned by [1, 1, 0] and [1, -1, 2].",
    "output": "import numpy as np\ndef gram_schmidt(vectors):\n    basis = []\n    for v in vectors:\n        for b in basis:\n            v = v - np.dot(v, b) / np.dot(b, b) * b\n        basis.append(v)\n    return basis\nvectors = [np.array([1, 1, 0]), np.array([1, -1, 2])]\northogonal_basis = gram_schmidt(vectors)\nprint(orthogonal_basis)"
  },
  {
    "input": "Check if the matrix Q from QR decomposition of A = [[1, 1], [1, -1], [1, 0]] has orthonormal columns.",
    "output": "import numpy as np\nfrom scipy.linalg import qr\nA = np.array([[1, 1], [1, -1], [1, 0]])\nQ, R = qr(A, mode='economic')\nprint(np.allclose(Q.T @ Q, np.eye(Q.shape[1])))"
  },
  {
    "input": "Compute the projection of vector [2, 1, 3] onto the plane x + y + z = 0.",
    "output": "import numpy as np\nv = np.array([2, 1, 3])\nn = np.array([1, 1, 1])\nproj = v - (np.dot(v, n) / np.dot(n, n)) * n\nprint(proj)"
  },
  {
    "input": "Find the projection of [1, 0, 0] onto the subspace spanned by [1, 1, 0] and [0, 1, 1].",
    "output": "import numpy as np\nA = np.array([[1, 0], [1, 1], [0, 1]])\nv = np.array([1, 0, 0])\nproj = A @ np.linalg.pinv(A) @ v\nprint(proj)"
  },
  {
    "input": "Use Gram-Schmidt to produce an orthonormal set from [2, 0], [1, 1].",
    "output": "import numpy as np\ndef gram_schmidt(V):\n    U = []\n    for v in V:\n        v = v.astype(float)\n        for u in U:\n            v -= np.dot(v, u) * u\n        U.append(v / np.linalg.norm(v))\n    return U\nV = [np.array([2, 0], dtype=float), np.array([1, 1], dtype=float)]\nQ = gram_schmidt(V)\nprint(Q)"
  },
  {
    "input": "Find a unit vector in the null space of matrix A = [[1, 2, 3], [4, 5, 6]].",
    "output": "import numpy as np\nfrom scipy.linalg import null_space\nA = np.array([[1, 2, 3], [4, 5, 6]])\nns = null_space(A)\nunit_vector = ns[:, 0] / np.linalg.norm(ns[:, 0])\nprint(unit_vector)"
  },
  {
    "input": "Find a nonzero vector in the plane x + y + z = 0 that is orthogonal to [2, -1, 1].",
    "output": "import numpy as np\nfrom scipy.linalg import null_space\nA = np.array([[1, 1, 1], [2, -1, 1]])\nv = null_space(A)[:, 0]\nv = v / np.linalg.norm(v)\nprint(v)"
  },
  {
    "input": "Given vectors u = [3, 0, 4] and v = [1, 2, -1], find the vector component of u orthogonal to v.",
    "output": "import numpy as np\nu = np.array([3, 0, 4])\nv = np.array([1, 2, -1])\nproj = (np.dot(u, v) / np.dot(v, v)) * v\north = u - proj\nprint(orth)"
  },
  {
    "input": "Given matrix A = [[2, -1], [1, 2], [0, 1]], find the projection matrix onto Col(A).",
    "output": "import numpy as np\nA = np.array([[2, -1], [1, 2], [0, 1]])\nATA_inv = np.linalg.inv(A.T @ A)\nP = A @ ATA_inv @ A.T\nprint(P)"
  },
  {
    "input": "Use the Gram-Schmidt process to orthonormalize the vectors [1, 2, 3], [4, 5, 6], and [7, 8, 9].",
    "output": "import numpy as np\ndef gram_schmidt(V):\n    U = []\n    for v in V:\n        for u in U:\n            v = v - np.dot(v, u) * u\n        if np.linalg.norm(v) > 1e-10:\n            U.append(v / np.linalg.norm(v))\n    return U\nV = [np.array([1, 2, 3]), np.array([4, 5, 6]), np.array([7, 8, 9])]\nQ = gram_schmidt(V)\nprint(Q)"
  },
  {
    "input": "Let A = [[1, 1, 0], [0, 1, 1], [1, 0, 1]]. Find an orthonormal basis for Col(A).",
    "output": "import numpy as np\ndef gram_schmidt(V):\n    U = []\n    for v in V:\n        for u in U:\n            v = v - np.dot(v, u) * u\n        if np.linalg.norm(v) > 1e-10:\n            U.append(v / np.linalg.norm(v))\n    return U\nA = np.array([[1, 1, 0], [0, 1, 1], [1, 0, 1]])\nvectors = A.T\nbasis = gram_schmidt([v for v in vectors])\nprint(basis)"
  },
  {
    "input": "Find the projection of vector [3, 1, 4] onto the null space of matrix A = [[1, 2, 3]].",
    "output": "import numpy as np\nfrom scipy.linalg import null_space\nv = np.array([3, 1, 4])\nA = np.array([[1, 2, 3]])\nN = null_space(A)\nP = N @ np.linalg.pinv(N) @ v\nprint(P)"
  },
  {
    "input": "Given matrix A = [[1, 2], [2, 4]], find the projection matrix onto the row space of A.",
    "output": "import numpy as np\nA = np.array([[1, 2], [2, 4]])\nR = A.T @ np.linalg.pinv(A @ A.T) @ A\nprint(R)"
  },
  {
    "input": "Find the least squares solution to Ax = b where A = [[1, 2], [3, 4], [5, 6]] and b = [7, 8, 9].",
    "output": "import numpy as np\nA = np.array([[1, 2], [3, 4], [5, 6]])\nb = np.array([7, 8, 9])\nx = np.linalg.lstsq(A, b, rcond=None)[0]\nprint(x)"
  },
  {
    "input": "Let A = [[1, 1], [1, -1]]. Find the projection of [2, 0] onto the column space of A.",
    "output": "import numpy as np\nA = np.array([[1, 1], [1, -1]])\nv = np.array([2, 0])\nproj = A @ np.linalg.pinv(A) @ v\nprint(proj)"
  },
  {
    "input": "Given matrix A = [[1, 2, 3], [4, 5, 6], [7, 8, 9]] and vector b = [1, 0, 1], find the orthogonal projection of b onto the column space of A using the projection matrix.",
    "output": "import numpy as np\nA = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\nb = np.array([1, 0, 1])\nP = A @ np.linalg.pinv(A)  # Projection matrix\nproj = P @ b\nprint(proj)"
  },
  {
    "input": "Perform PCA on the dataset [[2.5, 2.4], [0.5, 0.7], [2.2, 2.9], [1.9, 2.2], [3.1, 3.0], [2.3, 2.7], [2.0, 1.6], [1.0, 1.1], [1.5, 1.6], [1.1, 0.9]] and reduce it to 1 principal component.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\n\nX = np.array([[2.5, 2.4],\n              [0.5, 0.7],\n              [2.2, 2.9],\n              [1.9, 2.2],\n              [3.1, 3.0],\n              [2.3, 2.7],\n              [2.0, 1.6],\n              [1.0, 1.1],\n              [1.5, 1.6],\n              [1.1, 0.9]])\n\npca = PCA(n_components=1)\nX_pca = pca.fit_transform(X)\n\nprint(\"Reduced Data (1D):\\n\", X_pca)\nprint(\"Explained Variance Ratio:\", pca.explained_variance_ratio_)"
  },
  {
    "input": "Perform PCA on 3D data [[1,2,3],[4,5,6],[7,8,9],[10,11,12]] and reduce it to 2 dimensions.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\n\nX = np.array([[1, 2, 3],\n              [4, 5, 6],\n              [7, 8, 9],\n              [10, 11, 12]])\n\npca = PCA(n_components=2)\nX_pca = pca.fit_transform(X)\n\nprint(\"Reduced Data (2D):\\n\", X_pca)\nprint(\"Explained Variance Ratio:\", pca.explained_variance_ratio_)"
  },
  {
    "input": "Given the dataset [[4, 2], [2, 4], [2, 3], [3, 6], [4, 4], [9, 10], [6, 8], [9, 5], [8, 7], [10, 8]], perform PCA and reduce to 2 components. Also print the principal components (eigenvectors).",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\n\nX = np.array([[4, 2], [2, 4], [2, 3], [3, 6], [4, 4],\n              [9, 10], [6, 8], [9, 5], [8, 7], [10, 8]])\n\npca = PCA(n_components=2)\nX_pca = pca.fit_transform(X)\n\nprint(\"Reduced Data (2D):\\n\", X_pca)\nprint(\"Principal Components (Eigenvectors):\\n\", pca.components_)\nprint(\"Explained Variance:\", pca.explained_variance_)"
  },
  {
    "input": "Perform PCA on the dataset [[1, 2], [3, 4], [5, 6], [7, 8]] and reduce it to 1 principal component.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\n\nX = np.array([[1, 2], [3, 4], [5, 6], [7, 8]])\n\npca = PCA(n_components=1)\nX_pca = pca.fit_transform(X)\n\nprint(\"Reduced Data (1D):\\n\", X_pca)\nprint(\"Explained Variance Ratio:\", pca.explained_variance_ratio_)"
  },
  {
    "input": "Given the dataset [[1, 2, 3], [4, 5, 6], [7, 8, 9], [10, 11, 12]], perform PCA and reduce it to 2 dimensions. Also, print the principal components.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\n\nX = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9], [10, 11, 12]])\n\npca = PCA(n_components=2)\nX_pca = pca.fit_transform(X)\n\nprint(\"Reduced Data (2D):\\n\", X_pca)\nprint(\"Principal Components:\\n\", pca.components_)\nprint(\"Explained Variance Ratio:\", pca.explained_variance_ratio_)"
  },
  {
    "input": "For the dataset [[2, 4], [3, 6], [4, 8], [5, 10]], perform PCA and determine the explained variance ratio for each principal component.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\n\nX = np.array([[2, 4], [3, 6], [4, 8], [5, 10]])\n\npca = PCA()\nX_pca = pca.fit_transform(X)\n\nprint(\"Explained Variance Ratio:\", pca.explained_variance_ratio_)"
  },
  {
    "input": "Perform PCA on the dataset [[1, 0, 0], [0, 1, 0], [0, 0, 1], [1, 1, 1]] and reduce it to 2 dimensions. Print the transformed data and the explained variance.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\n\nX = np.array([[1, 0, 0], [0, 1, 0], [0, 0, 1], [1, 1, 1]])\n\npca = PCA(n_components=2)\nX_pca = pca.fit_transform(X)\n\nprint(\"Reduced Data (2D):\\n\", X_pca)\nprint(\"Explained Variance:\", pca.explained_variance_)"
  },
  {
    "input": "Given the dataset [[1, 2], [2, 3], [3, 4], [4, 5]], perform PCA without specifying the number of components and print the cumulative explained variance ratio.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\nimport matplotlib.pyplot as plt\n\nX = np.array([[1, 2], [2, 3], [3, 4], [4, 5]])\n\npca = PCA()\nX_pca = pca.fit_transform(X)\n\ncumulative_variance = np.cumsum(pca.explained_variance_ratio_)\nprint(\"Cumulative Explained Variance Ratio:\", cumulative_variance)"
  },
  {
    "input": "For the dataset [[1, 2], [3, 4], [5, 6], [7, 8]], standardize the data, perform PCA to reduce it to 1 component, and print the transformed data.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\n\nX = np.array([[1, 2], [3, 4], [5, 6], [7, 8]])\n\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\n\npca = PCA(n_components=1)\nX_pca = pca.fit_transform(X_scaled)\n\nprint(\"Standardized Reduced Data (1D):\\n\", X_pca)"
  },
  {
    "input": "Perform PCA on the dataset [[1, 2, 3], [4, 5, 6], [7, 8, 9], [10, 11, 12]] to find the principal components. Then, reconstruct the original data from the principal components.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\n\nX = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9], [10, 11, 12]])\n\npca = PCA()\nX_pca = pca.fit_transform(X)\nX_reconstructed = pca.inverse_transform(X_pca)\n\nprint(\"Reconstructed Data:\\n\", X_reconstructed)"
  },
  {
    "input": "Given the dataset [[1, 2], [3, 4], [5, 6], [7, 8]], perform PCA and output the explained variance ratio.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\n\nX = np.array([[1, 2], [3, 4], [5, 6], [7, 8]])\n\npca = PCA()\nX_pca = pca.fit_transform(X)\n\nexplained_variance = pca.explained_variance_ratio_\nprint('Explained Variance Ratio:', explained_variance)"
  },
  {
    "input": "Given the dataset [[2, 4], [3, 6], [4, 8], [5, 10]], perform PCA and determine the explained variance ratio for each principal component.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\n\nX = np.array([[2, 4], [3, 6], [4, 8], [5, 10]])\n\npca = PCA()\nX_pca = pca.fit_transform(X)\n\nprint(\"Explained Variance Ratio:\", pca.explained_variance_ratio_)"
  },
  {
    "input": "For the dataset [[1, 2], [3, 4], [5, 6], [7, 8]], perform PCA and determine the number of components required to explain at least 95% of the variance.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\n\nX = np.array([[1, 2], [3, 4], [5, 6], [7, 8]])\n\npca = PCA()\npca.fit(X)\ncumulative_variance = np.cumsum(pca.explained_variance_ratio_)\nnum_components = np.argmax(cumulative_variance >= 0.95) + 1\n\nprint(\"Number of components to explain at least 95% variance:\", num_components)"
  },
  {
    "input": "Perform PCA on the dataset [[1, 2, 3], [4, 5, 6], [7, 8, 9], [10, 11, 12]] and project the data onto the first principal component.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\n\nX = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9], [10, 11, 12]])\n\npca = PCA(n_components=1)\nX_pca = pca.fit_transform(X)\n\nprint(\"Projected Data onto First Principal Component:\\n\", X_pca)"
  },
  {
    "input": "Perform PCA on the dataset [[2, 3, 4], [5, 6, 7], [8, 9, 10], [11, 12, 13]] and project the data onto the first two principal components.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\n\nX = np.array([[2, 3, 4], [5, 6, 7], [8, 9, 10], [11, 12, 13]])\n\npca = PCA(n_components=2)\nX_pca = pca.fit_transform(X)\n\nprint(\"Projected Data onto First Two Principal Components:\\n\", X_pca)"
  },
  {
    "input": "Given the dataset [[1, 2], [3, 4], [5, 6], [7, 8]], standardize the data and perform PCA to reduce it to 1 component. Print the transformed data and the explained variance ratio.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\n\nX = np.array([[1, 2], [3, 4], [5, 6], [7, 8]])\n\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\n\npca = PCA(n_components=1)\nX_pca = pca.fit_transform(X_scaled)\n\nprint(\"Standardized Reduced Data (1D):\\n\", X_pca)\nprint(\"Explained Variance Ratio:\", pca.explained_variance_ratio_)"
  },
  {
    "input": "Perform PCA on the dataset [[1, 2, 3], [4, 5, 6], [7, 8, 9], [10, 11, 12]] and determine the explained variance of each principal component.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\n\nX = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9], [10, 11, 12]])\n\npca = PCA()\npca.fit(X)\n\nprint(\"Explained Variance of Each Principal Component:\", pca.explained_variance_)"
  },
  {
    "input": "For the dataset [[1, 2], [3, 4], [5, 6], [7, 8]], perform PCA and reconstruct the original data from the principal components. Compare the reconstructed data with the original.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\n\nX = np.array([[1, 2], [3, 4], [5, 6], [7, 8]])\n\npca = PCA(n_components=2)\nX_pca = pca.fit_transform(X)\nX_reconstructed = pca.inverse_transform(X_pca)\n\nprint(\"Original Data:\\n\", X)\nprint(\"Reconstructed Data:\\n\", X_reconstructed)"
  },
  {
    "input": "Perform PCA on the dataset [[2, 4, 6], [3, 6, 9], [4, 8, 12], [5, 10, 15]] and determine if any principal components can be dropped without significant loss of information.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\n\nX = np.array([[2, 4, 6], [3, 6, 9], [4, 8, 12], [5, 10, 15]])\n\npca = PCA()\npca.fit(X)\nexplained_variance_ratio = pca.explained_variance_ratio_\ncumulative_variance = np.cumsum(explained_variance_ratio)\n\nprint(\"Explained Variance Ratio:\", explained_variance_ratio)\nprint(\"Cumulative Explained Variance:\", cumulative_variance)\n\n# Determine the number of components to retain 95% variance\nnum_components = np.argmax(cumulative_variance >= 0.95) + 1\nprint(\"Number of components to retain at least 95% variance:\", num_components)"
  },
  {
    "input": "Given the dataset [[2, 4], [3, 6], [4, 8], [5, 10]], perform PCA and determine the explained variance ratio for each principal component.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\n\nX = np.array([[2, 4], [3, 6], [4, 8], [5, 10]])\n\npca = PCA()\npca.fit(X)\n\nprint(\"Explained Variance Ratio:\", pca.explained_variance_ratio_)"
  },
  {
    "input": "Perform PCA on the dataset [[1, 0, 0], [0, 1, 0], [0, 0, 1], [1, 1, 1]] and reduce it to 2 dimensions. Print the transformed data and the explained variance.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\n\nX = np.array([[1, 0, 0], [0, 1, 0], [0, 0, 1], [1, 1, 1]])\n\npca = PCA(n_components=2)\nX_pca = pca.fit_transform(X)\n\nprint(\"Transformed Data:\\n\", X_pca)\nprint(\"Explained Variance:\", pca.explained_variance_)"
  },
  {
    "input": "Given the dataset [[1, 2], [2, 3], [3, 4], [4, 5]], perform PCA without specifying the number of components and print the cumulative explained variance ratio.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\n\nX = np.array([[1, 2], [2, 3], [3, 4], [4, 5]])\n\npca = PCA()\npca.fit(X)\ncumulative_variance = np.cumsum(pca.explained_variance_ratio_)\n\nprint(\"Cumulative Explained Variance Ratio:\", cumulative_variance)"
  },
  {
    "input": "For the dataset [[1, 2], [3, 4], [5, 6], [7, 8]], standardize the data, perform PCA to reduce it to 1 component, and print the transformed data.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\n\nX = np.array([[1, 2], [3, 4], [5, 6], [7, 8]])\n\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\n\npca = PCA(n_components=1)\nX_pca = pca.fit_transform(X_scaled)\n\nprint(\"Transformed Data:\\n\", X_pca)"
  },
  {
    "input": "Given the dataset [[2, 3, 4], [5, 6, 7], [8, 9, 10], [11, 12, 13]], perform PCA and determine the number of components required to explain at least 95% of the variance.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\n\nX = np.array([[2, 3, 4], [5, 6, 7], [8, 9, 10], [11, 12, 13]])\n\npca = PCA()\npca.fit(X)\ncumulative_variance = np.cumsum(pca.explained_variance_ratio_)\nnum_components = np.argmax(cumulative_variance >= 0.95) + 1\n\nprint(\"Number of components to explain at least 95% variance:\", num_components)"
  },
  {
    "input": "Perform PCA on the dataset [[1, 2, 3], [4, 5, 6], [7, 8, 9], [10, 11, 12]] and project the data onto the first principal component.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\n\nX = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9], [10, 11, 12]])\n\npca = PCA(n_components=1)\nX_pca = pca.fit_transform(X)\n\nprint(\"Projected Data:\\n\", X_pca)"
  },
  {
    "input": "Given a dataset with 5 features and 100 samples, perform PCA and determine the minimum number of principal components required to retain 90% of the variance.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\n\n# Simulating a dataset with 5 features and 100 samples\nnp.random.seed(0)\nX = np.random.rand(100, 5)\n\npca = PCA()\npca.fit(X)\ncumulative_variance = np.cumsum(pca.explained_variance_ratio_)\nnum_components = np.argmax(cumulative_variance >= 0.90) + 1\n\nprint(\"Number of components to retain 90% variance:\", num_components)"
  },
  {
    "input": "Perform PCA on the dataset [[2, 4, 6], [3, 6, 9], [4, 8, 12], [5, 10, 15]] and determine if any principal components can be dropped without significant loss of information.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\n\nX = np.array([[2, 4, 6], [3, 6, 9], [4, 8, 12], [5, 10, 15]])\n\npca = PCA()\npca.fit(X)\nexplained_variance_ratio = pca.explained_variance_ratio_\ncumulative_variance = np.cumsum(explained_variance_ratio)\n\nprint(\"Explained Variance Ratio:\", explained_variance_ratio)\nprint(\"Cumulative Variance:\", cumulative_variance)"
  },
  {
    "input": "Given a dataset with 6 features and 150 samples, perform PCA and determine the minimum number of principal components required to retain 95% of the variance.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\n\n# Simulating a dataset with 6 features and 150 samples\nnp.random.seed(0)\nX = np.random.rand(150, 6)\n\npca = PCA()\npca.fit(X)\ncumulative_variance = np.cumsum(pca.explained_variance_ratio_)\nnum_components = np.argmax(cumulative_variance >= 0.95) + 1\n\nprint(\"Number of components to retain 95% variance:\", num_components)"
  },
  {
    "input": "Perform PCA on the dataset [[3, 5, 7], [2, 4, 6], [1, 3, 5], [0, 2, 4]] and project the data onto the first two principal components.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\n\nX = np.array([[3, 5, 7], [2, 4, 6], [1, 3, 5], [0, 2, 4]])\n\npca = PCA(n_components=2)\nX_pca = pca.fit_transform(X)\n\nprint(\"Projected Data onto First Two Principal Components:\\n\", X_pca)"
  },
  {
    "input": "Given the dataset [[2, 3], [4, 6], [6, 9], [8, 12]], standardize the data and perform PCA to reduce it to 1 component. Print the transformed data and the explained variance ratio.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\n\nX = np.array([[2, 3], [4, 6], [6, 9], [8, 12]])\n\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\n\npca = PCA(n_components=1)\nX_pca = pca.fit_transform(X_scaled)\n\nprint(\"Standardized Reduced Data (1D):\\n\", X_pca)\nprint(\"Explained Variance Ratio:\", pca.explained_variance_ratio_)"
  },
  {
    "input": "Perform PCA on the dataset [[4, 7, 10], [3, 6, 9], [2, 5, 8], [1, 4, 7]] and determine the explained variance of each principal component.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\n\nX = np.array([[4, 7, 10], [3, 6, 9], [2, 5, 8], [1, 4, 7]])\n\npca = PCA()\npca.fit(X)\n\nprint(\"Explained Variance of Each Principal Component:\", pca.explained_variance_)"
  },
  {
    "input": "Given a dataset with 4 features and 120 samples, perform PCA and determine the number of components required to explain at least 85% of the variance.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\n\n# Simulating a dataset with 4 features and 120 samples\nnp.random.seed(0)\nX = np.random.rand(120, 4)\n\npca = PCA()\npca.fit(X)\ncumulative_variance = np.cumsum(pca.explained_variance_ratio_)\nnum_components = np.argmax(cumulative_variance >= 0.85) + 1\n\nprint(\"Number of components to explain at least 85% variance:\", num_components)"
  },
  {
    "input": "For the dataset [[2, 4], [3, 5], [4, 6], [5, 7]], standardize the data, perform PCA to reduce it to 1 component, and print the transformed data.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\n\nX = np.array([[2, 4], [3, 5], [4, 6], [5, 7]])\n\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\n\npca = PCA(n_components=1)\nX_pca = pca.fit_transform(X_scaled)\n\nprint(\"Transformed Data:\\n\", X_pca)"
  },
  {
    "input": "Perform PCA on the dataset [[1, 3, 5], [2, 4, 6], [3, 5, 7], [4, 6, 8]] and reconstruct the original data from the principal components. Compare the reconstructed data with the original.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\n\nX = np.array([[1, 3, 5], [2, 4, 6], [3, 5, 7], [4, 6, 8]])\n\npca = PCA(n_components=3)\nX_pca = pca.fit_transform(X)\nX_reconstructed = pca.inverse_transform(X_pca)\n\nprint(\"Original Data:\\n\", X)\nprint(\"Reconstructed Data:\\n\", X_reconstructed)"
  },
  {
    "input": "Given a dataset with 3 features and 80 samples, perform PCA and determine the explained variance ratio for each principal component.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\n\n# Simulating a dataset with 3 features and 80 samples\nnp.random.seed(0)\nX = np.random.rand(80, 3)\n\npca = PCA()\npca.fit(X)\n\nprint(\"Explained Variance Ratio:\", pca.explained_variance_ratio_)"
  },
  {
    "input": "Perform PCA on the dataset [[5, 10, 15], [4, 8, 12], [3, 6, 9], [2, 4, 6]] and project the data onto the first principal component.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\n\nX = np.array([[5, 10, 15], [4, 8, 12], [3, 6, 9], [2, 4, 6]])\n\npca = PCA(n_components=1)\nX_pca = pca.fit_transform(X)\n\nprint(\"Projected Data onto First Principal Component:\\n\", X_pca)"
  },
  {
    "input": "Perform PCA on the dataset [[2, 4], [3, 6], [4, 8], [5, 10]] and print the explained variance ratio for each principal component.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\n\nX = np.array([[2, 4], [3, 6], [4, 8], [5, 10]])\n\npca = PCA()\npca.fit(X)\n\nprint('Explained Variance Ratio:', pca.explained_variance_ratio_)\n"
  },
  {
    "input": "Perform PCA on the dataset [[1, 2, 3], [4, 5, 6], [7, 8, 9], [10, 11, 12]] and reduce it to 2 dimensions. Print the transformed data and principal components.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\n\nX = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9], [10, 11, 12]])\n\npca = PCA(n_components=2)\nX_pca = pca.fit_transform(X)\n\nprint('Transformed Data:\\n', X_pca)\nprint('Principal Components:\\n', pca.components_)\n"
  },
  {
    "input": "Given the dataset [[1, 2], [2, 3], [3, 4], [4, 5]], perform PCA without specifying n_components and print the cumulative explained variance ratio.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\n\nX = np.array([[1, 2], [2, 3], [3, 4], [4, 5]])\n\npca = PCA()\npca.fit(X)\ncum_var = np.cumsum(pca.explained_variance_ratio_)\n\nprint('Cumulative Explained Variance Ratio:', cum_var)\n"
  },
  {
    "input": "For the dataset [[1, 2], [3, 4], [5, 6], [7, 8]], standardize the data, perform PCA to reduce it to 1 component, and print the transformed data.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\n\nX = np.array([[1, 2], [3, 4], [5, 6], [7, 8]])\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\n\npca = PCA(n_components=1)\nX_pca = pca.fit_transform(X_scaled)\n\nprint('Transformed Data:', X_pca)\n"
  },
  {
    "input": "Perform PCA on the dataset [[1, 2, 3], [4, 5, 6], [7, 8, 9], [10, 11, 12]] and reconstruct the original data using the PCA components. Print the reconstructed data.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\n\nX = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9], [10, 11, 12]])\n\npca = PCA()\nX_pca = pca.fit_transform(X)\nX_reconstructed = pca.inverse_transform(X_pca)\n\nprint('Reconstructed Data:\\n', X_reconstructed)\n"
  },
  {
    "input": "For the dataset [[2, 3, 4], [5, 6, 7], [8, 9, 10], [11, 12, 13]], perform PCA and determine the number of components needed to explain at least 95% of the variance.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\n\nX = np.array([[2, 3, 4], [5, 6, 7], [8, 9, 10], [11, 12, 13]])\n\npca = PCA()\npca.fit(X)\ncum_var = np.cumsum(pca.explained_variance_ratio_)\nnum_comp = int(np.argmax(cum_var >= 0.95)) + 1\n\nprint('Number of components to explain at least 95% variance:', num_comp)\n"
  },
  {
    "input": "Perform PCA on the dataset [[1, 2, 3], [4, 5, 6], [7, 8, 9], [10, 11, 12]] and project the data onto the first principal component.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\n\nX = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9], [10, 11, 12]])\n\npca = PCA(n_components=1)\nX_pca = pca.fit_transform(X)\n\nprint('Projected Data onto First Principal Component:\\n', X_pca)\n"
  },
  {
    "input": "Given a dataset with 5 features and 100 samples (simulate using random numbers), perform PCA and determine the minimum number of components needed to retain 90% variance.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\n\nnp.random.seed(0)\nX = np.random.rand(100, 5)\n\npca = PCA()\npca.fit(X)\ncum_var = np.cumsum(pca.explained_variance_ratio_)\nnum_comp = int(np.argmax(cum_var >= 0.90)) + 1\n\nprint('Number of components to retain 90% variance:', num_comp)\n"
  },
  {
    "input": "Perform PCA on the dataset [[2, 4, 6], [3, 6, 9], [4, 8, 12], [5, 10, 15]] and project the data onto the first principal component.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\n\nX = np.array([[2, 4, 6], [3, 6, 9], [4, 8, 12], [5, 10, 15]])\n\npca = PCA(n_components=1)\nX_pca = pca.fit_transform(X)\n\nprint('Projected Data onto First Principal Component:\\n', X_pca)\n"
  },
  {
    "input": "Given the dataset [[1, 3, 5], [2, 4, 6], [3, 5, 7], [4, 6, 8]], perform PCA and print the principal components and their corresponding explained variance ratios.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\n\nX = np.array([[1, 3, 5], [2, 4, 6], [3, 5, 7], [4, 6, 8]])\n\npca = PCA()\npca.fit(X)\n\nprint('Principal Components:\\n', pca.components_)\nprint('Explained Variance Ratio:', pca.explained_variance_ratio_)\n"
  },
  {
    "input": "For a dataset with 4 features and 120 samples (simulate using random numbers), perform PCA and print the shape of the transformed data when reduced to 2 components.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\n\nnp.random.seed(0)\nX = np.random.rand(120, 4)\n\npca = PCA(n_components=2)\nX_pca = pca.fit_transform(X)\n\nprint('Shape of Transformed Data:', X_pca.shape)\n"
  },
  {
    "input": "Perform PCA on the dataset [[4, 7, 10], [3, 6, 9], [2, 5, 8], [1, 4, 7]] and print the explained variance of each principal component.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\n\nX = np.array([[4, 7, 10], [3, 6, 9], [2, 5, 8], [1, 4, 7]])\n\npca = PCA()\npca.fit(X)\n\nprint('Explained Variance:', pca.explained_variance_)\n"
  },
  {
    "input": "Given the dataset [[1, 2], [3, 4], [5, 6], [7, 8]], perform PCA and print the singular values of the decomposition.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\n\nX = np.array([[1, 2], [3, 4], [5, 6], [7, 8]])\n\npca = PCA()\npca.fit(X)\n\nprint('Singular Values:', pca.singular_values_)\n"
  },
  {
    "input": "For the dataset [[2, 4, 6], [4, 8, 12], [6, 12, 18], [8, 16, 24]], perform PCA and print the ratio of variance explained by the first principal component.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\n\nX = np.array([[2, 4, 6], [4, 8, 12], [6, 12, 18], [8, 16, 24]])\n\npca = PCA(n_components=1)\npca.fit(X)\n\nprint('Variance Ratio of First Component:', pca.explained_variance_ratio_[0])\n"
  },
  {
    "input": "Perform PCA on the dataset [[1, 3], [2, 4], [3, 5], [4, 6]] and print the PCA components matrix.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\n\nX = np.array([[1, 3], [2, 4], [3, 5], [4, 6]])\n\npca = PCA()\npca.fit(X)\n\nprint('PCA Components Matrix:\\n', pca.components_)\n"
  },
  {
    "input": "Given the dataset [[5, 10], [6, 12], [7, 14], [8, 16]], perform PCA and print the total variance explained by all components.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\n\nX = np.array([[5, 10], [6, 12], [7, 14], [8, 16]])\n\npca = PCA()\npca.fit(X)\n\ntotal_variance = np.sum(pca.explained_variance_ratio_)\n\nprint('Total Variance Explained:', total_variance)\n"
  },
  {
    "input": "Perform PCA on the dataset [[1, 2, 3], [3, 4, 5], [5, 6, 7], [7, 8, 9]] and print the transformed data when reduced to 2 components.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\n\nX = np.array([[1, 2, 3], [3, 4, 5], [5, 6, 7], [7, 8, 9]])\n\npca = PCA(n_components=2)\nX_pca = pca.fit_transform(X)\n\nprint('Transformed Data (2 components):\\n', X_pca)\n"
  },
  {
    "input": "Given a dataset with 3 features and 80 samples (simulate using random numbers), perform PCA and print the explained variance ratio for each component.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\n\nnp.random.seed(0)\nX = np.random.rand(80, 3)\n\npca = PCA()\npca.fit(X)\n\nprint('Explained Variance Ratio:', pca.explained_variance_ratio_)\n"
  },
  {
    "input": "Perform PCA on the dataset [[2, 5], [3, 6], [4, 7], [5, 8]] and print the shape of the principal components matrix.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\n\nX = np.array([[2, 5], [3, 6], [4, 7], [5, 8]])\n\npca = PCA()\npca.fit(X)\n\nprint('Shape of Principal Components Matrix:', pca.components_.shape)\n"
  },
  {
    "input": "Given the dataset [[1, 2], [3, 4], [5, 6], [7, 8]], perform PCA and print both the singular values and the explained variance.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\n\nX = np.array([[1, 2], [3, 4], [5, 6], [7, 8]])\n\npca = PCA()\npca.fit(X)\n\nprint('Singular Values:', pca.singular_values_)\nprint('Explained Variance:', pca.explained_variance_)\n"
  },
  {
    "input": "For the dataset [[2, 3], [4, 5], [6, 7], [8, 9]], perform PCA and print the PCA object's attributes: components_, explained_variance, and explained_variance_ratio_.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\n\nX = np.array([[2, 3], [4, 5], [6, 7], [8, 9]])\n\npca = PCA()\npca.fit(X)\n\nprint('Components:\\n', pca.components_)\nprint('Explained Variance:', pca.explained_variance_)\nprint('Explained Variance Ratio:', pca.explained_variance_ratio_)\n"
  },
  {
    "input": "Perform PCA on a synthetic dataset with 4 features and 200 samples (simulate using random numbers) and print the number of components needed to retain 80% of the variance.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\n\nnp.random.seed(0)\nX = np.random.rand(200, 4)\n\npca = PCA()\npca.fit(X)\ncum_var = np.cumsum(pca.explained_variance_ratio_)\nnum_components = int(np.argmax(cum_var >= 0.80)) + 1\n\nprint('Number of components to retain 80% variance:', num_components)\n"
  },
  {
    "input": "Given the dataset [[3, 6, 9], [4, 8, 12], [5, 10, 15], [6, 12, 18]], perform PCA and print the ratio of variance explained by the first principal component.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\n\nX = np.array([[3, 6, 9], [4, 8, 12], [5, 10, 15], [6, 12, 18]])\n\npca = PCA(n_components=1)\npca.fit(X)\n\nprint('Variance Ratio of First Component:', pca.explained_variance_ratio_[0])\n"
  },
  {
    "input": "Perform PCA on the dataset [[1, 2, 3], [2, 3, 4], [3, 4, 5], [4, 5, 6]] and print the transformed data when reduced to 2 components.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\n\nX = np.array([[1, 2, 3], [2, 3, 4], [3, 4, 5], [4, 5, 6]])\n\npca = PCA(n_components=2)\nX_pca = pca.fit_transform(X)\n\nprint('Transformed Data:\\n', X_pca)\n"
  },
  {
    "input": "Given the dataset [[1, 2], [3, 4], [5, 6], [7, 8]], perform PCA and compute the reconstruction error (mean squared error) between the original and reconstructed data.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\n\nX = np.array([[1, 2], [3, 4], [5, 6], [7, 8]])\n\npca = PCA(n_components=2)\nX_pca = pca.fit_transform(X)\nX_reconstructed = pca.inverse_transform(X_pca)\n\nmse = np.mean((X - X_reconstructed) ** 2)\n\nprint('Reconstruction Error (MSE):', mse)\n"
  },
  {
    "input": "Perform PCA on the dataset [[1, 3], [2, 4], [3, 5], [4, 6]] and print the total variance explained by all components.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\n\nX = np.array([[1, 3], [2, 4], [3, 5], [4, 6]])\n\npca = PCA()\npca.fit(X)\n\ntotal_variance = np.sum(pca.explained_variance_ratio_)\n\nprint('Total Variance Explained:', total_variance)\n"
  },
  {
    "input": "Given a dataset with 10 features and 200 samples, perform PCA and determine the number of components required to explain at least 90% of the variance.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\n\n# Simulating a dataset with 10 features and 200 samples\nnp.random.seed(0)\nX = np.random.rand(200, 10)\n\npca = PCA()\npca.fit(X)\ncumulative_variance = np.cumsum(pca.explained_variance_ratio_)\nnum_components = np.argmax(cumulative_variance >= 0.90) + 1\n\nprint(\"Number of components to explain at least 90% variance:\", num_components)"
  },
  {
    "input": "Perform PCA on the dataset [[1, 2, 3], [4, 5, 6], [7, 8, 9], [10, 11, 12]] and print the principal components.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\n\nX = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9], [10, 11, 12]])\n\npca = PCA()\npca.fit(X)\n\nprint(\"Principal Components:\\n\", pca.components_)"
  },
  {
    "input": "Given the dataset [[2, 4], [3, 6], [4, 8], [5, 10]], perform PCA and print the singular values.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\n\nX = np.array([[2, 4], [3, 6], [4, 8], [5, 10]])\n\npca = PCA()\npca.fit(X)\n\nprint(\"Singular Values:\", pca.singular_values_)"
  },
  {
    "input": "Perform PCA on the dataset [[1, 0], [0, 1], [-1, 0], [0, -1]] and print the mean of each feature.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\n\nX = np.array([[1, 0], [0, 1], [-1, 0], [0, -1]])\n\npca = PCA()\npca.fit(X)\n\nprint(\"Feature Means:\", pca.mean_)"
  },
  {
    "input": "Given a dataset with 5 features and 100 samples, standardize the data and perform PCA to reduce it to 3 components. Print the transformed data.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\n\n# Simulating a dataset with 5 features and 100 samples\nnp.random.seed(0)\nX = np.random.rand(100, 5)\n\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\n\npca = PCA(n_components=3)\nX_pca = pca.fit_transform(X_scaled)\n\nprint(\"Transformed Data:\\n\", X_pca)"
  },
  {
    "input": "Perform PCA on the dataset [[1, 2], [2, 3], [3, 4], [4, 5]] and print the covariance matrix of the principal components.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\n\nX = np.array([[1, 2], [2, 3], [3, 4], [4, 5]])\n\npca = PCA()\nX_pca = pca.fit_transform(X)\ncov_matrix = np.cov(X_pca.T)\n\nprint(\"Covariance Matrix:\\n\", cov_matrix)"
  },
  {
    "input": "Given the dataset [[1, 2, 3], [4, 5, 6], [7, 8, 9], [10, 11, 12]], perform PCA and print the explained variance.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\n\nX = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9], [10, 11, 12]])\n\npca = PCA()\npca.fit(X)\n\nprint(\"Explained Variance:\", pca.explained_variance_)"
  },
  {
    "input": "Perform PCA on the dataset [[2, 3], [3, 4], [4, 5], [5, 6]] and print the loadings (eigenvectors).",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\n\nX = np.array([[2, 3], [3, 4], [4, 5], [5, 6]])\n\npca = PCA()\npca.fit(X)\n\nprint(\"Loadings (Eigenvectors):\\n\", pca.components_.T)"
  },
  {
    "input": "Given a dataset with 4 features and 50 samples, perform PCA and print the proportion of variance explained by each component.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\n\n# Simulating a dataset with 4 features and 50 samples\nnp.random.seed(0)\nX = np.random.rand(50, 4)\n\npca = PCA()\npca.fit(X)\n\nprint(\"Proportion of Variance Explained:\", pca.explained_variance_ratio_)"
  },
  {
    "input": "Perform PCA on the dataset [[1, 2], [3, 4], [5, 6], [7, 8]] and print the cumulative explained variance ratio.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\n\nX = np.array([[1, 2], [3, 4], [5, 6], [7, 8]])\n\npca = PCA()\npca.fit(X)\ncumulative_variance = np.cumsum(pca.explained_variance_ratio_)\n\nprint(\"Cumulative Explained Variance Ratio:\", cumulative_variance)"
  },
  {
    "input": "Given the dataset [[2, 4, 6], [3, 6, 9], [4, 8, 12], [5, 10, 15]], perform PCA and print the principal axes in feature space.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\n\nX = np.array([[2, 4, 6], [3, 6, 9], [4, 8, 12], [5, 10, 15]])\n\npca = PCA()\npca.fit(X)\n\nprint(\"Principal axes in feature space:\")\nprint(pca.components_)"
  },
  {
    "input": "Given a dataset with 12 features and 300 samples, perform PCA and determine the number of components required to explain at least 95% of the variance.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\n\n# Simulating a dataset with 12 features and 300 samples\nnp.random.seed(0)\nX = np.random.rand(300, 12)\n\npca = PCA()\npca.fit(X)\ncumulative_variance = np.cumsum(pca.explained_variance_ratio_)\nnum_components = np.argmax(cumulative_variance >= 0.95) + 1\n\nprint(\"Number of components to explain at least 95% variance:\", num_components)"
  },
  {
    "input": "Perform PCA on the dataset [[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12], [13, 14, 15, 16]] and print the principal components.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\n\nX = np.array([[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12], [13, 14, 15, 16]])\n\npca = PCA()\npca.fit(X)\n\nprint(\"Principal Components:\\n\", pca.components_)"
  },
  {
    "input": "Given the dataset [[3, 6], [4, 8], [5, 10], [6, 12]], perform PCA and print the singular values.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\n\nX = np.array([[3, 6], [4, 8], [5, 10], [6, 12]])\n\npca = PCA()\npca.fit(X)\n\nprint(\"Singular Values:\", pca.singular_values_)"
  },
  {
    "input": "Perform PCA on the dataset [[1, 0, 0], [0, 1, 0], [0, 0, 1], [-1, -1, -1]] and print the mean of each feature.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\n\nX = np.array([[1, 0, 0], [0, 1, 0], [0, 0, 1], [-1, -1, -1]])\n\npca = PCA()\npca.fit(X)\n\nprint(\"Feature Means:\", pca.mean_)"
  },
  {
    "input": "Given a dataset with 7 features and 150 samples, standardize the data and perform PCA to reduce it to 4 components. Print the transformed data.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\n\n# Simulating a dataset with 7 features and 150 samples\nnp.random.seed(0)\nX = np.random.rand(150, 7)\n\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\n\npca = PCA(n_components=4)\nX_pca = pca.fit_transform(X_scaled)\n\nprint(\"Transformed Data:\\n\", X_pca)"
  },
  {
    "input": "Perform PCA on the dataset [[2, 4], [4, 6], [6, 8], [8, 10]] and print the covariance matrix of the principal components.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\n\nX = np.array([[2, 4], [4, 6], [6, 8], [8, 10]])\n\npca = PCA()\nX_pca = pca.fit_transform(X)\ncov_matrix = np.cov(X_pca.T)\n\nprint(\"Covariance Matrix:\\n\", cov_matrix)"
  },
  {
    "input": "Perform PCA on the dataset [[3, 5], [5, 7], [7, 9], [9, 11]] and print the loadings (eigenvectors).",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\n\nX = np.array([[3, 5], [5, 7], [7, 9], [9, 11]])\n\npca = PCA()\npca.fit(X)\n\nprint(\"Loadings (Eigenvectors):\\n\", pca.components_.T)"
  },
  {
    "input": "Given a dataset with 5 features and 60 samples, perform PCA and print the proportion of variance explained by each component.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\n\n# Simulating a dataset with 5 features and 60 samples\nnp.random.seed(0)\nX = np.random.rand(60, 5)\n\npca = PCA()\npca.fit(X)\n\nprint(\"Proportion of Variance Explained:\", pca.explained_variance_ratio_)"
  },
  {
    "input": "Perform PCA on the dataset [[2, 3], [4, 5], [6, 7], [8, 9]] and print the cumulative explained variance ratio.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\n\nX = np.array([[2, 3], [4, 5], [6, 7], [8, 9]])\n\npca = PCA()\npca.fit(X)\ncumulative_variance = np.cumsum(pca.explained_variance_ratio_)\n\nprint(\"Cumulative Explained Variance Ratio:\", cumulative_variance)"
  },
  {
    "input": "Given a dataset with 15 features and 500 samples, perform PCA and determine the number of components required to explain at least 95% of the variance.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\n\n# Simulating a dataset with 15 features and 500 samples\nnp.random.seed(0)\nX = np.random.rand(500, 15)\n\npca = PCA()\npca.fit(X)\ncumulative_variance = np.cumsum(pca.explained_variance_ratio_)\nnum_components = np.argmax(cumulative_variance >= 0.95) + 1\n\nprint(\"Number of components to explain at least 95% variance:\", num_components)"
  },
  {
    "input": "Perform PCA on the dataset [[2, 4, 6], [3, 6, 9], [4, 8, 12], [5, 10, 15]] and print the principal components.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\n\nX = np.array([[2, 4, 6], [3, 6, 9], [4, 8, 12], [5, 10, 15]])\n\npca = PCA()\npca.fit(X)\n\nprint(\"Principal Components:\\n\", pca.components_)"
  },
  {
    "input": "Given the dataset [[1, 2], [2, 3], [3, 4], [4, 5]], perform PCA and print the singular values.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\n\nX = np.array([[1, 2], [2, 3], [3, 4], [4, 5]])\n\npca = PCA()\npca.fit(X)\n\nprint(\"Singular Values:\", pca.singular_values_)"
  },
  {
    "input": "Given a dataset with 8 features and 300 samples, standardize the data and perform PCA to reduce it to 4 components. Print the transformed data.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\n\n# Simulating a dataset with 8 features and 300 samples\nnp.random.seed(0)\nX = np.random.rand(300, 8)\n\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\n\npca = PCA(n_components=4)\nX_pca = pca.fit_transform(X_scaled)\n\nprint(\"Transformed Data:\\n\", X_pca)"
  },
  {
    "input": "Perform PCA on the dataset [[3, 5], [4, 6], [5, 7], [6, 8]] and print the covariance matrix of the principal components.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\n\nX = np.array([[3, 5], [4, 6], [5, 7], [6, 8]])\n\npca = PCA()\nX_pca = pca.fit_transform(X)\ncov_matrix = np.cov(X_pca.T)\n\nprint(\"Covariance Matrix:\\n\", cov_matrix)"
  },
  {
    "input": "Given the dataset [[2, 3, 4], [5, 6, 7], [8, 9, 10], [11, 12, 13]], perform PCA and print the explained variance.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\n\nX = np.array([[2, 3, 4], [5, 6, 7], [8, 9, 10], [11, 12, 13]])\n\npca = PCA()\npca.fit(X)\n\nprint(\"Explained Variance:\", pca.explained_variance_)"
  },
  {
    "input": "Given a dataset with 6 features and 150 samples, perform PCA and print the proportion of variance explained by each component.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\n\n# Simulating a dataset with 6 features and 150 samples\nnp.random.seed(0)\nX = np.random.rand(150, 6)\n\npca = PCA()\npca.fit(X)\n\nprint(\"Proportion of Variance Explained:\", pca.explained_variance_ratio_)"
  },
  {
    "input": "Given a dataset with 20 features and 1000 samples, perform PCA and determine the number of components required to explain at least 95% of the variance.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\n\n# Simulating a dataset with 20 features and 1000 samples\nnp.random.seed(0)\nX = np.random.rand(1000, 20)\n\npca = PCA()\npca.fit(X)\ncumulative_variance = np.cumsum(pca.explained_variance_ratio_)\nnum_components = np.argmax(cumulative_variance >= 0.95) + 1\n\nprint(\"Number of components to explain at least 95% variance:\", num_components)"
  },
  {
    "input": "Perform PCA on the dataset [[3, 6, 9], [2, 4, 6], [4, 8, 12], [5, 10, 15]] and print the principal components.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\n\nX = np.array([[3, 6, 9], [2, 4, 6], [4, 8, 12], [5, 10, 15]])\n\npca = PCA()\npca.fit(X)\n\nprint(\"Principal Components:\\n\", pca.components_)"
  },
  {
    "input": "Given the dataset [[1, 3], [2, 5], [3, 7], [4, 9]], perform PCA and print the singular values.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\n\nX = np.array([[1, 3], [2, 5], [3, 7], [4, 9]])\n\npca = PCA()\npca.fit(X)\n\nprint(\"Singular Values:\", pca.singular_values_)"
  },
  {
    "input": "Perform PCA on the dataset [[0, 1], [1, 0], [-1, 0], [0, -1]] and print the mean of each feature.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\n\nX = np.array([[0, 1], [1, 0], [-1, 0], [0, -1]])\n\npca = PCA()\npca.fit(X)\n\nprint(\"Feature Means:\", pca.mean_)"
  },
  {
    "input": "Given a dataset with 10 features and 500 samples, standardize the data and perform PCA to reduce it to 5 components. Print the transformed data.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\n\n# Simulating a dataset with 10 features and 500 samples\nnp.random.seed(0)\nX = np.random.rand(500, 10)\n\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\n\npca = PCA(n_components=5)\nX_pca = pca.fit_transform(X_scaled)\n\nprint(\"Transformed Data:\\n\", X_pca)"
  },
  {
    "input": "Perform PCA on the dataset [[4, 7], [5, 8], [6, 9], [7, 10]] and print the covariance matrix of the principal components.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\n\nX = np.array([[4, 7], [5, 8], [6, 9], [7, 10]])\n\npca = PCA()\nX_pca = pca.fit_transform(X)\ncov_matrix = np.cov(X_pca.T)\n\nprint(\"Covariance Matrix:\\n\", cov_matrix)"
  },
  {
    "input": "Given the dataset [[3, 5, 7], [6, 8, 10], [9, 11, 13], [12, 14, 16]], perform PCA and print the explained variance.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\n\nX = np.array([[3, 5, 7], [6, 8, 10], [9, 11, 13], [12, 14, 16]])\n\npca = PCA()\npca.fit(X)\n\nprint(\"Explained Variance:\", pca.explained_variance_)"
  },
  {
    "input": "Perform PCA on the dataset [[3, 4], [4, 5], [5, 6], [6, 7]] and print the loadings (eigenvectors).",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\n\nX = np.array([[3, 4], [4, 5], [5, 6], [6, 7]])\n\npca = PCA()\npca.fit(X)\n\nprint(\"Loadings (Eigenvectors):\\n\", pca.components_.T)"
  },
  {
    "input": "Given a dataset with 7 features and 200 samples, perform PCA and print the proportion of variance explained by each component.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\n\n# Simulating a dataset with 7 features and 200 samples\nnp.random.seed(0)\nX = np.random.rand(200, 7)\n\npca = PCA()\npca.fit(X)\n\nprint(\"Proportion of Variance Explained:\", pca.explained_variance_ratio_)"
  },
  {
    "input": "Given the dataset [[3, 6, 9], [4, 8, 12], [5, 10, 15], [6, 12, 18]], perform PCA and print the principal axes in feature space.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\n\nX = np.array([[3, 6, 9], [4, 8, 12], [5, 10, 15], [6, 12, 18]])\n\npca = PCA()\npca.fit(X)\n\nprint(\"Principal axes in feature space:\")\nprint(pca.components_)"
  },
  {
    "input": "Given a dataset with 50 features and 1000 samples, perform PCA and determine the number of components required to explain at least 90% of the variance.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\n\n# Simulating a dataset with 50 features and 1000 samples\nnp.random.seed(0)\nX = np.random.rand(1000, 50)\n\npca = PCA()\npca.fit(X)\ncumulative_variance = np.cumsum(pca.explained_variance_ratio_)\nnum_components = np.argmax(cumulative_variance >= 0.90) + 1\n\nprint(\"Number of components to explain at least 90% variance:\", num_components)"
  },
  {
    "input": "Perform PCA on the dataset [[1, 2, 3], [2, 4, 6], [3, 6, 9], [4, 8, 12]] and print the principal components.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\n\nX = np.array([[1, 2, 3], [2, 4, 6], [3, 6, 9], [4, 8, 12]])\n\npca = PCA()\npca.fit(X)\n\nprint(\"Principal Components:\\n\", pca.components_)"
  },
  {
    "input": "Given a dataset with 30 features and 1500 samples, perform PCA and determine the number of components required to explain at least 95% of the variance.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\n\n# Simulating a dataset with 30 features and 1500 samples\nnp.random.seed(0)\nX = np.random.rand(1500, 30)\n\npca = PCA()\npca.fit(X)\ncumulative_variance = np.cumsum(pca.explained_variance_ratio_)\nnum_components = np.argmax(cumulative_variance >= 0.95) + 1\n\nprint(\"Number of components to explain at least 95% variance:\", num_components)"
  },
  {
    "input": "Given the dataset [[1, 3], [2, 4], [3, 5], [4, 6]], perform PCA and print the singular values.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\n\nX = np.array([[1, 3], [2, 4], [3, 5], [4, 6]])\n\npca = PCA()\npca.fit(X)\n\nprint(\"Singular Values:\", pca.singular_values_)"
  },
  {
    "input": "Given a dataset with 15 features and 800 samples, standardize the data and perform PCA to reduce it to 7 components. Print the transformed data.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\n\n# Simulating a dataset with 15 features and 800 samples\nnp.random.seed(0)\nX = np.random.rand(800, 15)\n\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\n\npca = PCA(n_components=7)\nX_pca = pca.fit_transform(X_scaled)\n\nprint(\"Transformed Data:\\n\", X_pca)"
  },
  {
    "input": "Perform PCA on the dataset [[5, 9], [6, 10], [7, 11], [8, 12]] and print the covariance matrix of the principal components.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\n\nX = np.array([[5, 9], [6, 10], [7, 11], [8, 12]])\n\npca = PCA()\nX_pca = pca.fit_transform(X)\ncov_matrix = np.cov(X_pca.T)\n\nprint(\"Covariance Matrix:\\n\", cov_matrix)"
  },
  {
    "input": "Given the dataset [[4, 6, 8], [7, 9, 11], [10, 12, 14], [13, 15, 17]], perform PCA and print the explained variance.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\n\nX = np.array([[4, 6, 8], [7, 9, 11], [10, 12, 14], [13, 15, 17]])\n\npca = PCA()\npca.fit(X)\n\nprint(\"Explained Variance:\", pca.explained_variance_)"
  },
  {
    "input": "Perform PCA on the dataset [[4, 5], [5, 6], [6, 7], [7, 8]] and print the loadings (eigenvectors).",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\n\nX = np.array([[4, 5], [5, 6], [6, 7], [7, 8]])\n\npca = PCA()\npca.fit(X)\n\nprint(\"Loadings (Eigenvectors):\\n\", pca.components_.T)"
  },
  {
    "input": "Given a dataset with 9 features and 300 samples, perform PCA and print the proportion of variance explained by each component.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\n\n# Simulating a dataset with 9 features and 300 samples\nnp.random.seed(0)\nX = np.random.rand(300, 9)\n\npca = PCA()\npca.fit(X)\n\nprint(\"Proportion of Variance Explained:\", pca.explained_variance_ratio_)"
  },
  {
    "input": "Perform PCA on the dataset [[3, 4], [5, 6], [7, 8], [9, 10]] and print the cumulative explained variance ratio.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\n\nX = np.array([[3, 4], [5, 6], [7, 8], [9, 10]])\n\npca = PCA()\npca.fit(X)\ncumulative_variance = np.cumsum(pca.explained_variance_ratio_)\n\nprint(\"Cumulative Explained Variance Ratio:\", cumulative_variance)"
  },
  {
    "input": "Given the dataset [[4, 8, 12], [5, 10, 15], [6, 12, 18], [7, 14, 21]], perform PCA and print the principal axes in feature space.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\n\nX = np.array([[4, 8, 12], [5, 10, 15], [6, 12, 18], [7, 14, 21]])\n\npca = PCA()\npca.fit(X)\n\nprint(\"Principal axes in feature space:\")\nprint(pca.components_)"
  },
  {
    "input": "Given a dataset with 20 features and 500 samples, perform PCA and determine the number of components required to explain at least 85% of the variance.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\n\n# Simulating a dataset with 20 features and 500 samples\nnp.random.seed(0)\nX = np.random.rand(500, 20)\n\npca = PCA()\npca.fit(X)\ncumulative_variance = np.cumsum(pca.explained_variance_ratio_)\nnum_components = np.argmax(cumulative_variance >= 0.85) + 1\n\nprint(\"Number of components to explain at least 85% variance:\", num_components)"
  },
  {
    "input": "Perform PCA on the dataset [[2, 3, 4], [5, 6, 7], [8, 9, 10], [11, 12, 13]] and print the principal components.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\n\nX = np.array([[2, 3, 4], [5, 6, 7], [8, 9, 10], [11, 12, 13]])\n\npca = PCA()\npca.fit(X)\n\nprint(\"Principal Components:\\n\", pca.components_)"
  },
  {
    "input": "Given the dataset [[1, 2], [2, 3], [3, 4], [4, 5]], perform PCA and print the explained variance ratio.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\n\nX = np.array([[1, 2], [2, 3], [3, 4], [4, 5]])\n\npca = PCA()\npca.fit(X)\n\nprint(\"Explained Variance Ratio:\", pca.explained_variance_ratio_)"
  },
  {
    "input": "Perform PCA on the dataset [[0, 1], [1, 0], [-1, 0], [0, -1]] and print the transformed data.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\n\nX = np.array([[0, 1], [1, 0], [-1, 0], [0, -1]])\n\npca = PCA()\nX_pca = pca.fit_transform(X)\n\nprint(\"Transformed Data:\\n\", X_pca)"
  },
  {
    "input": "Given a dataset with 15 features and 300 samples, standardize the data and perform PCA to reduce it to 5 components. Print the explained variance of each component.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\n\n# Simulating a dataset with 15 features and 300 samples\nnp.random.seed(0)\nX = np.random.rand(300, 15)\n\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\n\npca = PCA(n_components=5)\npca.fit(X_scaled)\n\nprint(\"Explained Variance:\", pca.explained_variance_)"
  },
  {
    "input": "Given the dataset [[2, 4, 6], [3, 5, 7], [4, 6, 8], [5, 7, 9]], perform PCA and print the singular values.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\n\nX = np.array([[2, 4, 6], [3, 5, 7], [4, 6, 8], [5, 7, 9]])\n\npca = PCA()\npca.fit(X)\n\nprint(\"Singular Values:\", pca.singular_values_)"
  },
  {
    "input": "Perform PCA on the dataset [[1, 2], [3, 4], [5, 6], [7, 8]] and print the loadings (eigenvectors).",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\n\nX = np.array([[1, 2], [3, 4], [5, 6], [7, 8]])\n\npca = PCA()\npca.fit(X)\n\nprint(\"Loadings (Eigenvectors):\\n\", pca.components_.T)"
  },
  {
    "input": "Given a dataset with 10 features and 200 samples, perform PCA and print the proportion of variance explained by each component.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\n\n# Simulating a dataset with 10 features and 200 samples\nnp.random.seed(0)\nX = np.random.rand(200, 10)\n\npca = PCA()\npca.fit(X)\n\nprint(\"Proportion of Variance Explained:\", pca.explained_variance_ratio_)"
  },
  {
    "input": "Given the dataset X = [[2, 0, -1], [3, 1, 0], [4, 2, 1]], perform PCA and return the top 2 principal components.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\n\nX = np.array([[2, 0, -1], [3, 1, 0], [4, 2, 1]])\npca = PCA(n_components=2)\nX_pca = pca.fit_transform(X)\nprint(\"Top 2 Principal Components:\\n\", X_pca)"
  },
  {
    "input": "Using the dataset X = [[1, 2], [2, 3], [3, 4], [4, 5]], perform PCA and find the variance explained by the first component.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\n\nX = np.array([[1, 2], [2, 3], [3, 4], [4, 5]])\npca = PCA()\npca.fit(X)\nprint(\"Variance Explained by First Component:\", pca.explained_variance_ratio_[0])"
  },
  {
    "input": "Given a dataset X = [[2, 4], [1, 3], [0, 2], [-1, 1]], perform PCA and return the eigenvalues of the covariance matrix.",
    "output": "import numpy as np\nfrom numpy.linalg import eig\n\nX = np.array([[2, 4], [1, 3], [0, 2], [-1, 1]])\nX_centered = X - np.mean(X, axis=0)\ncov_matrix = np.cov(X_centered.T)\neigenvalues, _ = eig(cov_matrix)\nprint(\"Eigenvalues:\", eigenvalues)"
  },
  {
    "input": "Given the dataset X = [[5, 1], [6, 2], [7, 3], [8, 4]], perform PCA and reconstruct the data using only the first principal component.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\n\nX = np.array([[5, 1], [6, 2], [7, 3], [8, 4]])\npca = PCA(n_components=1)\nX_pca = pca.fit_transform(X)\nX_reconstructed = pca.inverse_transform(X_pca)\nprint(\"Reconstructed Data:\\n\", X_reconstructed)"
  },
  {
    "input": "Perform PCA on the dataset X = [[10, 0, 3], [2, 8, 1], [5, 6, 2]] and return the principal component directions.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\n\nX = np.array([[10, 0, 3], [2, 8, 1], [5, 6, 2]])\npca = PCA()\npca.fit(X)\nprint(\"Principal Component Directions:\\n\", pca.components_)"
  },
  {
    "input": "Given dataset X = [[1, 3], [3, 7], [5, 11], [7, 15]], perform PCA and calculate the cumulative explained variance ratio.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\n\nX = np.array([[1, 3], [3, 7], [5, 11], [7, 15]])\npca = PCA()\npca.fit(X)\ncumulative_variance = np.cumsum(pca.explained_variance_ratio_)\nprint(\"Cumulative Explained Variance:\", cumulative_variance)"
  },
  {
    "input": "Apply PCA on dataset X = [[1, 0, 0], [0, 1, 0], [0, 0, 1]] and return the explained variance ratio of each component.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\n\nX = np.array([[1, 0, 0], [0, 1, 0], [0, 0, 1]])\npca = PCA()\npca.fit(X)\nprint(\"Explained Variance Ratio:\", pca.explained_variance_ratio_)"
  },
  {
    "input": "Given dataset X = [[2, 3, 4], [1, 2, 3], [0, 1, 2], [-1, 0, 1]], perform PCA and find the rank of the covariance matrix.",
    "output": "import numpy as np\n\nX = np.array([[2, 3, 4], [1, 2, 3], [0, 1, 2], [-1, 0, 1]])\nX_centered = X - np.mean(X, axis=0)\ncov_matrix = np.cov(X_centered.T)\nrank = np.linalg.matrix_rank(cov_matrix)\nprint(\"Rank of Covariance Matrix:\", rank)"
  },
  {
    "input": "Using the dataset X = [[1, 1], [2, 2], [3, 3], [4, 4]], apply PCA and identify any redundancy in features based on the eigenvalues.",
    "output": "import numpy as np\nfrom numpy.linalg import eig\n\nX = np.array([[1, 1], [2, 2], [3, 3], [4, 4]])\nX_centered = X - np.mean(X, axis=0)\ncov_matrix = np.cov(X_centered.T)\neigenvalues, _ = eig(cov_matrix)\nprint(\"Eigenvalues:\", eigenvalues)"
  },
  {
    "input": "Given X = [[10, 10], [20, 20], [30, 30]], apply PCA and return the number of non-zero principal components.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\n\nX = np.array([[10, 10], [20, 20], [30, 30]])\npca = PCA()\npca.fit(X)\nnon_zero_components = np.sum(pca.explained_variance_ > 1e-10)\nprint(\"Non-zero Principal Components:\", non_zero_components)"
  },
  {
    "input": "Perform PCA on X = [[5, 6], [6, 7], [7, 8], [8, 9]], and calculate the total variance captured by PCA.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\n\nX = np.array([[5, 6], [6, 7], [7, 8], [8, 9]])\npca = PCA()\npca.fit(X)\ntotal_variance = np.sum(pca.explained_variance_)\nprint(\"Total Variance:\", total_variance)"
  },
  {
    "input": "Given dataset X = [[1, 0], [0, 1], [1, 1], [2, 2]], apply PCA and find the loading scores (component weights).",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\n\nX = np.array([[1, 0], [0, 1], [1, 1], [2, 2]])\npca = PCA()\npca.fit(X)\nprint(\"Component Weights (Loadings):\\n\", pca.components_)"
  },
  {
    "input": "Using dataset X = [[1, 2], [2, 1], [3, 4], [4, 3]], apply PCA and project the data onto the first principal component.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\n\nX = np.array([[1, 2], [2, 1], [3, 4], [4, 3]])\npca = PCA(n_components=1)\nX_pca = pca.fit_transform(X)\nprint(\"Projected Data:\\n\", X_pca)"
  },
  {
    "input": "Given a 2D dataset X = [[1, 2], [3, 4], [5, 6], [7, 8]], calculate the covariance matrix before applying PCA.",
    "output": "import numpy as np\n\nX = np.array([[1, 2], [3, 4], [5, 6], [7, 8]])\nX_centered = X - np.mean(X, axis=0)\ncov_matrix = np.cov(X_centered.T)\nprint(\"Covariance Matrix:\\n\", cov_matrix)"
  },
  {
    "input": "Given the dataset X = [[1, 2, 3], [4, 5, 6], [7, 8, 9]], perform PCA and return the number of components with non-zero variance.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\n\nX = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\npca = PCA()\npca.fit(X)\nnon_zero = np.sum(pca.explained_variance_ > 1e-10)\nprint(\"Non-zero Components:\", non_zero)"
  },
  {
    "input": "Apply PCA on dataset X = [[5, 7], [3, 2], [8, 6], [2, 4]], and return the direction of the first principal component.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\n\nX = np.array([[5, 7], [3, 2], [8, 6], [2, 4]])\npca = PCA(n_components=1)\npca.fit(X)\nprint(\"First Principal Component Direction:\", pca.components_[0])"
  },
  {
    "input": "Given the dataset X = [[4, 2], [2, 4], [6, 6], [4, 6]], perform PCA and return the score matrix (transformed values).",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\n\nX = np.array([[4, 2], [2, 4], [6, 6], [4, 6]])\npca = PCA(n_components=2)\nX_transformed = pca.fit_transform(X)\nprint(\"PCA Transformed Matrix:\\n\", X_transformed)"
  },
  {
    "input": "Using the dataset X = [[9, 5], [4, 7], [6, 2], [3, 8]], perform PCA and calculate the explained variance of the second principal component.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\n\nX = np.array([[9, 5], [4, 7], [6, 2], [3, 8]])\npca = PCA(n_components=2)\npca.fit(X)\nprint(\"Explained Variance (2nd PC):\", pca.explained_variance_[1])"
  },
  {
    "input": "Given the dataset X = [[1, 0, 0], [0, 1, 0], [0, 0, 1], [1, 1, 1]], apply PCA and find the principal component directions.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\n\nX = np.array([[1, 0, 0], [0, 1, 0], [0, 0, 1], [1, 1, 1]])\npca = PCA()\npca.fit(X)\nprint(\"Principal Component Directions:\\n\", pca.components_)"
  },
  {
    "input": "Using dataset X = [[2, 3], [3, 4], [4, 5]], perform PCA and find how many dimensions are needed to retain 99% variance.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\n\nX = np.array([[2, 3], [3, 4], [4, 5]])\npca = PCA()\npca.fit(X)\ncumsum = np.cumsum(pca.explained_variance_ratio_)\ndims = np.searchsorted(cumsum, 0.99) + 1\nprint(\"Dimensions for 99% Variance:\", dims)"
  },
  {
    "input": "Given dataset X = [[2, 2], [4, 4], [6, 6]], perform PCA and reconstruct the data from 1D projection.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\n\nX = np.array([[2, 2], [4, 4], [6, 6]])\npca = PCA(n_components=1)\nX_pca = pca.fit_transform(X)\nX_inv = pca.inverse_transform(X_pca)\nprint(\"Reconstructed Data:\\n\", X_inv)"
  },
  {
    "input": "Apply PCA on dataset X = [[7, 8], [9, 10], [11, 12]], and return the mean of the transformed data.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\n\nX = np.array([[7, 8], [9, 10], [11, 12]])\npca = PCA(n_components=2)\nX_pca = pca.fit_transform(X)\nprint(\"Mean of Transformed Data:\", np.mean(X_pca, axis=0))"
  },
  {
    "input": "Given X = [[1, 2], [2, 4], [3, 6]], apply PCA and explain whether the features are linearly dependent or independent.",
    "output": "import numpy as np\n\nX = np.array([[1, 2], [2, 4], [3, 6]])\nX_centered = X - np.mean(X, axis=0)\ncov_matrix = np.cov(X_centered.T)\neigenvalues = np.linalg.eigvals(cov_matrix)\ndependent = np.sum(eigenvalues < 1e-10) > 0\nprint(\"Features are Linearly Dependent:\" if dependent else \"Features are Independent\")"
  },
  {
    "input": "Using dataset X = [[2, 3, 4], [3, 4, 5], [4, 5, 6], [5, 6, 7]], perform PCA and return the shape of the reduced matrix for 2 components.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\n\nX = np.array([[2, 3, 4], [3, 4, 5], [4, 5, 6], [5, 6, 7]])\npca = PCA(n_components=2)\nX_reduced = pca.fit_transform(X)\nprint(\"Shape of Reduced Matrix:\", X_reduced.shape)"
  },
  {
    "input": "Apply PCA on dataset X = [[4, 0], [0, 4], [2, 2]], and calculate the angle between the first component and x-axis.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\n\nX = np.array([[4, 0], [0, 4], [2, 2]])\npca = PCA(n_components=1)\npca.fit(X)\nimport math\nangle = math.degrees(math.atan2(pca.components_[0][1], pca.components_[0][0]))\nprint(\"Angle with X-axis:\", angle)"
  },
  {
    "input": "Given dataset X = [[0, 1], [1, 0], [2, 3], [3, 2]], perform PCA and calculate total explained variance ratio.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\n\nX = np.array([[0, 1], [1, 0], [2, 3], [3, 2]])\npca = PCA()\npca.fit(X)\ntotal_ratio = np.sum(pca.explained_variance_ratio_)\nprint(\"Total Explained Variance Ratio:\", total_ratio)"
  },
  {
    "input": "Apply PCA on dataset X = [[1, 0, 1], [0, 1, 1], [1, 1, 0]], and return the first principal axis.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\n\nX = np.array([[1, 0, 1], [0, 1, 1], [1, 1, 0]])\npca = PCA(n_components=1)\npca.fit(X)\nprint(\"First Principal Axis:\", pca.components_[0])"
  },
  {
    "input": "Using dataset X = [[10, 0], [0, 10], [10, 10]], perform PCA and determine how many components are required to retain 95% variance.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\n\nX = np.array([[10, 0], [0, 10], [10, 10]])\npca = PCA()\npca.fit(X)\ncum_var = np.cumsum(pca.explained_variance_ratio_)\ncomponents = np.searchsorted(cum_var, 0.95) + 1\nprint(\"Components for 95% Variance:\", components)"
  },
  {
    "input": "Given dataset X = [[1, 2], [2, 1], [3, 4], [4, 3]], perform PCA and calculate the variance retained after dimensionality reduction to 1D.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\n\nX = np.array([[1, 2], [2, 1], [3, 4], [4, 3]])\npca = PCA(n_components=1)\npca.fit(X)\nprint(\"Variance Retained:\", np.sum(pca.explained_variance_ratio_))"
  },
  {
    "input": "Using X = [[1, 1], [2, 2], [3, 3]], apply PCA and check whether dimensionality can be reduced.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\n\nX = np.array([[1, 1], [2, 2], [3, 3]])\npca = PCA()\npca.fit(X)\nreducible = np.sum(pca.explained_variance_ > 1e-10) < 2\nprint(\"Can Reduce Dimensionality:\", reducible)"
  },
  {
    "input": "Apply PCA on dataset X = [[5, 5], [6, 5], [7, 6], [8, 6]] and return the loading matrix.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\n\nX = np.array([[5, 5], [6, 5], [7, 6], [8, 6]])\npca = PCA()\npca.fit(X)\nprint(\"Loading Matrix (Components):\\n\", pca.components_)"
  },
  {
    "input": "Given dataset X = [[1, 2], [3, 4], [5, 6], [7, 8]], perform PCA and return eigenvalues of the covariance matrix.",
    "output": "import numpy as np\nX = np.array([[1, 2], [3, 4], [5, 6], [7, 8]])\nX_centered = X - np.mean(X, axis=0)\ncov = np.cov(X_centered.T)\neigvals = np.linalg.eigvals(cov)\nprint(\"Eigenvalues:\", eigvals)"
  },
  {
    "input": "Given the dataset [[2, 0], [0, 2], [1, 1]], perform PCA and return the principal components.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\n\nX = np.array([[2, 0], [0, 2], [1, 1]])\npca = PCA(n_components=2)\npca.fit(X)\nprint(\"Principal Components:\\n\", pca.components_)"
  },
  {
    "input": "Given the dataset [[3, 3, 3], [4, 4, 4], [5, 5, 5]], compute the variance explained by each principal component.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\n\nX = np.array([[3, 3, 3], [4, 4, 4], [5, 5, 5]])\npca = PCA()\npca.fit(X)\nprint(\"Explained Variance Ratio:\", pca.explained_variance_ratio_)"
  },
  {
    "input": "Given the dataset [[2, 4], [1, 3], [0, 2]], perform PCA and return the transformed data using 1 component.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\n\nX = np.array([[2, 4], [1, 3], [0, 2]])\npca = PCA(n_components=1)\nX_pca = pca.fit_transform(X)\nprint(\"Transformed Data:\\n\", X_pca)"
  },
  {
    "input": "Given the dataset [[6, 7, 8], [9, 10, 11], [12, 13, 14]], perform PCA and print the covariance matrix of the standardized dataset.",
    "output": "import numpy as np\nfrom sklearn.preprocessing import StandardScaler\n\nX = np.array([[6, 7, 8], [9, 10, 11], [12, 13, 14]])\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\ncov_matrix = np.cov(X_scaled.T)\nprint(\"Covariance Matrix:\\n\", cov_matrix)"
  },
  {
    "input": "Given the dataset [[1, 2], [3, 4], [5, 6]], perform PCA and output the eigenvalues of the covariance matrix.",
    "output": "import numpy as np\nfrom numpy.linalg import eig\n\nX = np.array([[1, 2], [3, 4], [5, 6]])\nX_centered = X - np.mean(X, axis=0)\ncov_matrix = np.cov(X_centered.T)\neigenvalues, _ = eig(cov_matrix)\nprint(\"Eigenvalues:\", eigenvalues)"
  },
  {
    "input": "Given the dataset [[4, 2], [2, 4], [6, 6]], compute and print the eigenvectors of its covariance matrix.",
    "output": "import numpy as np\nfrom numpy.linalg import eig\n\nX = np.array([[4, 2], [2, 4], [6, 6]])\nX_centered = X - np.mean(X, axis=0)\ncov_matrix = np.cov(X_centered.T)\n_, eigenvectors = eig(cov_matrix)\nprint(\"Eigenvectors:\\n\", eigenvectors)"
  },
  {
    "input": "Given the dataset [[1, 1], [0, 0], [-1, -1]], perform PCA and reconstruct the original data from 1 principal component.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\n\nX = np.array([[1, 1], [0, 0], [-1, -1]])\npca = PCA(n_components=1)\nX_pca = pca.fit_transform(X)\nX_reconstructed = pca.inverse_transform(X_pca)\nprint(\"Reconstructed Data:\\n\", X_reconstructed)"
  },
  {
    "input": "Given the dataset [[3, 1], [2, 3], [4, 5]], use PCA to reduce it to 1 dimension and print the result.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\n\nX = np.array([[3, 1], [2, 3], [4, 5]])\npca = PCA(n_components=1)\nX_reduced = pca.fit_transform(X)\nprint(\"Reduced Data:\\n\", X_reduced)"
  },
  {
    "input": "Given the dataset [[1, 4, 7], [2, 5, 8], [3, 6, 9]], perform PCA and display the explained variance ratio.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\n\nX = np.array([[1, 4, 7], [2, 5, 8], [3, 6, 9]])\npca = PCA()\npca.fit(X)\nprint(\"Explained Variance Ratio:\", pca.explained_variance_ratio_)"
  },
  {
    "input": "Given the dataset [[3, 3], [3, 3], [3, 3]], apply PCA and explain the number of meaningful principal components.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\n\nX = np.array([[3, 3], [3, 3], [3, 3]])\npca = PCA()\npca.fit(X)\nprint(\"Explained Variance:\", pca.explained_variance_)\nprint(\"Number of meaningful components:\", np.sum(pca.explained_variance_ > 1e-5))"
  },
  {
    "input": "Given the dataset [[1, 2, 1], [2, 1, 2], [3, 3, 3]], perform PCA and return the component with the highest variance.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\n\nX = np.array([[1, 2, 1], [2, 1, 2], [3, 3, 3]])\npca = PCA()\npca.fit(X)\nprint(\"Principal Component with Highest Variance:\\n\", pca.components_[0])"
  },
  {
    "input": "Given the dataset [[2, 0], [0, 2], [2, 2]], perform PCA and determine if the two features are correlated.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\n\nX = np.array([[2, 0], [0, 2], [2, 2]])\npca = PCA()\npca.fit(X)\nprint(\"Explained Variance Ratio:\", pca.explained_variance_ratio_)"
  },
  {
    "input": "Given the dataset [[4, 5], [5, 4], [6, 6]], calculate the percentage of variance captured by the first component.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\n\nX = np.array([[4, 5], [5, 4], [6, 6]])\npca = PCA()\npca.fit(X)\nprint(\"% Variance by 1st component:\", pca.explained_variance_ratio_[0] * 100)"
  },
  {
    "input": "Given the dataset [[1, 2, 3], [4, 5, 6], [7, 8, 9]], perform PCA and determine the number of components required to capture 95% variance.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\n\nX = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\npca = PCA(n_components=0.95)\npca.fit(X)\nprint(\"Number of Components:\", pca.n_components_)"
  },
  {
    "input": "Given the dataset [[10, 0], [0, 10], [5, 5]], perform PCA and print the mean of the dataset.",
    "output": "import numpy as np\nX = np.array([[10, 0], [0, 10], [5, 5]])\nmean = np.mean(X, axis=0)\nprint(\"Mean:\", mean)"
  },
  {
    "input": "Given the dataset [[2, 3, 4], [4, 6, 8], [6, 9, 12]], perform PCA and show that the data lies in a single direction.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\nX = np.array([[2,3,4],[4,6,8],[6,9,12]])\npca = PCA()\npca.fit(X)\nprint(\"Explained Variance:\", pca.explained_variance_ratio_)"
  },
  {
    "input": "Given the dataset [[1, 2], [2, 3], [3, 4], [4, 5]], perform PCA and print the shape of transformed data with 1 component.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\nX = np.array([[1,2],[2,3],[3,4],[4,5]])\npca = PCA(n_components=1)\nX_pca = pca.fit_transform(X)\nprint(\"Shape:\", X_pca.shape)"
  },
  {
    "input": "Given the dataset [[7, 2], [8, 3], [9, 4]], perform PCA and show that the first component captures most of the variance.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\nX = np.array([[7,2],[8,3],[9,4]])\npca = PCA()\npca.fit(X)\nprint(\"Explained Variance Ratio:\", pca.explained_variance_ratio_)"
  },
  {
    "input": "Given the dataset [[3, 4], [3, 4], [3, 4]], perform PCA and print the transformed data.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\nX = np.array([[3,4],[3,4],[3,4]])\npca = PCA(n_components=2)\nX_pca = pca.fit_transform(X)\nprint(\"Transformed Data:\\n\", X_pca)"
  },
  {
    "input": "Given the dataset [[2, 4], [4, 8], [6, 12]], perform PCA and print the loadings of the principal components.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\nX = np.array([[2,4],[4,8],[6,12]])\npca = PCA()\npca.fit(X)\nprint(\"Loadings:\\n\", pca.components_)"
  },
  {
    "input": "Given the dataset [[10, 20, 30], [20, 30, 40], [30, 40, 50]], apply PCA and determine the number of components that explain at least 90% of the variance.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\nX = np.array([[10,20,30],[20,30,40],[30,40,50]])\npca = PCA(n_components=0.9)\npca.fit(X)\nprint(\"Number of components:\", pca.n_components_)"
  },
  {
    "input": "Given the dataset [[0, 1], [1, 0], [1, 1]], apply PCA and print both eigenvalues and eigenvectors.",
    "output": "import numpy as np\nfrom numpy.linalg import eig\nX = np.array([[0,1],[1,0],[1,1]])\nX = X - np.mean(X, axis=0)\ncov = np.cov(X.T)\neigvals, eigvecs = eig(cov)\nprint(\"Eigenvalues:\", eigvals)\nprint(\"Eigenvectors:\\n\", eigvecs)"
  },
  {
    "input": "Given the dataset [[2, 2], [4, 4], [6, 6]], apply PCA and confirm that one of the components has zero variance.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\nX = np.array([[2,2],[4,4],[6,6]])\npca = PCA()\npca.fit(X)\nprint(\"Explained Variance:\", pca.explained_variance_)"
  },
  {
    "input": "Given the dataset [[1, 0], [0, 1], [1, 1]], perform PCA and print the projection matrix.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\nX = np.array([[1,0],[0,1],[1,1]])\npca = PCA(n_components=2)\npca.fit(X)\nprint(\"Projection Matrix (Components):\\n\", pca.components_)"
  },
  {
    "input": "Given the dataset [[1, 2], [2, 3], [3, 5]], use PCA to reduce to 1D and reconstruct the original data.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\nX = np.array([[1,2],[2,3],[3,5]])\npca = PCA(n_components=1)\nX_reduced = pca.fit_transform(X)\nX_reconstructed = pca.inverse_transform(X_reduced)\nprint(\"Reconstructed Data:\\n\", X_reconstructed)"
  },
  {
    "input": "Given the dataset [[4, 4, 4], [5, 5, 5], [6, 6, 6]], perform PCA and show that the second and third components have zero variance.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\nX = np.array([[4,4,4],[5,5,5],[6,6,6]])\npca = PCA()\npca.fit(X)\nprint(\"Explained Variance:\", pca.explained_variance_)"
  },
  {
    "input": "Given the dataset [[5, 0], [10, 5], [15, 10]], apply PCA and display the variance captured by each component as a percentage.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\nX = np.array([[5,0],[10,5],[15,10]])\npca = PCA()\npca.fit(X)\nprint(\"% Variance:\", pca.explained_variance_ratio_ * 100)"
  },
  {
    "input": "Given the dataset [[1, 2, 3], [4, 5, 6], [7, 8, 9]], calculate the eigen decomposition of the covariance matrix.",
    "output": "import numpy as np\nfrom numpy.linalg import eig\nX = np.array([[1,2,3],[4,5,6],[7,8,9]])\nX = X - np.mean(X, axis=0)\ncov = np.cov(X.T)\neigvals, eigvecs = eig(cov)\nprint(\"Eigenvalues:\", eigvals)\nprint(\"Eigenvectors:\\n\", eigvecs)"
  },
  {
    "input": "Given the dataset [[1, 3], [2, 6], [3, 9]], perform PCA and explain why the data lies in 1 dimension.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\nX = np.array([[1,3],[2,6],[3,9]])\npca = PCA()\npca.fit(X)\nprint(\"Explained Variance Ratio:\", pca.explained_variance_ratio_)"
  },
  {
    "input": "Given the dataset [[1, 0], [0, 1], [-1, 0], [0, -1]], apply PCA and print the projected 2D data using 2 components.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\nX = np.array([[1,0],[0,1],[-1,0],[0,-1]])\npca = PCA(n_components=2)\nX_pca = pca.fit_transform(X)\nprint(\"Projected Data:\\n\", X_pca)"
  },
  {
    "input": "Given the dataset [[3, 3], [6, 6], [9, 9]], perform PCA and verify that both components point in the same direction.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\nX = np.array([[3,3],[6,6],[9,9]])\npca = PCA()\npca.fit(X)\nprint(\"Principal Components:\\n\", pca.components_)"
  },
  {
    "input": "Given the dataset [[2, 3], [4, 6], [6, 9]], apply PCA and print the transformed coordinates using the first component.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\nX = np.array([[2,3],[4,6],[6,9]])\npca = PCA(n_components=1)\nX_pca = pca.fit_transform(X)\nprint(\"Transformed Coordinates:\\n\", X_pca)"
  },
  {
    "input": "Given the dataset [[2, 4, 6], [4, 8, 12], [6, 12, 18]], perform PCA and show that the data lies along a single axis.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\nX = np.array([[2,4,6],[4,8,12],[6,12,18]])\npca = PCA()\npca.fit(X)\nprint(\"Explained Variance Ratio:\", pca.explained_variance_ratio_)"
  },
  {
    "input": "Given the dataset [[5, 5, 5], [5, 5, 5], [5, 5, 5]], perform PCA and explain the output of transformed data.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\nX = np.array([[5,5,5],[5,5,5],[5,5,5]])\npca = PCA()\nX_pca = pca.fit_transform(X)\nprint(\"Transformed Data:\\n\", X_pca)"
  },
  {
    "input": "Given the dataset [[1, 2], [2, 4], [3, 6]], apply PCA and print the direction of the first component.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\nX = np.array([[1,2],[2,4],[3,6]])\npca = PCA(n_components=1)\npca.fit(X)\nprint(\"First Principal Component:\", pca.components_[0])"
  },
  {
    "input": "Given the dataset [[1, 3], [3, 7], [5, 11]], perform PCA and reduce to 1D then inverse transform.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\nX = np.array([[1,3],[3,7],[5,11]])\npca = PCA(n_components=1)\nX_pca = pca.fit_transform(X)\nX_orig = pca.inverse_transform(X_pca)\nprint(\"Reconstructed Data:\\n\", X_orig)"
  },
  {
    "input": "Given the dataset [[10, 2], [9, 3], [8, 4], [7, 5]], perform PCA and print the principal components.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\nX = np.array([[10,2],[9,3],[8,4],[7,5]])\npca = PCA()\npca.fit(X)\nprint(\"Principal Components:\\n\", pca.components_)"
  },
  {
    "input": "Given the dataset [[5, 1], [10, 2], [15, 3]], perform PCA and print the explained variance.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\nX = np.array([[5,1],[10,2],[15,3]])\npca = PCA()\npca.fit(X)\nprint(\"Explained Variance:\", pca.explained_variance_)"
  },
  {
    "input": "Given the dataset [[1, 1], [2, 2], [3, 3]], apply PCA and verify the components and variance ratios.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\nX = np.array([[1,1],[2,2],[3,3]])\npca = PCA()\npca.fit(X)\nprint(\"Components:\\n\", pca.components_)\nprint(\"Variance Ratios:\", pca.explained_variance_ratio_)"
  },
  {
    "input": "Given the dataset [[1, 3], [2, 2], [3, 1]], apply PCA and reduce to 1 component. Print the transformed data.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\nX = np.array([[1,3],[2,2],[3,1]])\npca = PCA(n_components=1)\nX_reduced = pca.fit_transform(X)\nprint(\"Reduced Data:\\n\", X_reduced)"
  },
  {
    "input": "Given the dataset [[1, 2, 3], [3, 2, 1], [2, 2, 2]], perform PCA and print the variance ratio of each component.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\nX = np.array([[1,2,3],[3,2,1],[2,2,2]])\npca = PCA()\npca.fit(X)\nprint(\"Explained Variance Ratio:\", pca.explained_variance_ratio_)"
  },
  {
    "input": "Given the dataset [[4, 0], [0, 4], [-4, 0], [0, -4]], use PCA to reduce to 1D.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\n\nX = np.array([[4, 0], [0, 4], [-4, 0], [0, -4]])\npca = PCA(n_components=1)\nX_pca = pca.fit_transform(X)\nprint(\"1D PCA Projection:\", X_pca)"
  },
  {
    "input": "Given the dataset [[2, 3, 4], [6, 7, 8], [10, 11, 12]], apply PCA and print the singular values.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\nX = np.array([[2,3,4],[6,7,8],[10,11,12]])\npca = PCA()\npca.fit(X)\nprint(\"Singular Values:\", pca.singular_values_)"
  },
  {
    "input": "Given the dataset [[1, 0], [0, 1], [-1, 0], [0, -1]], perform PCA and plot the transformed data.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\n\nX = np.array([[1, 0], [0, 1], [-1, 0], [0, -1]])\npca = PCA(n_components=2)\nX_pca = pca.fit_transform(X)\nprint(\"PCA Transformed Data:\\n\", X_pca)"
  },
  {
    "input": "Given the dataset [[3, 3], [6, 6], [9, 9]], verify using PCA that the second principal component has near zero variance.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\nX = np.array([[3,3],[6,6],[9,9]])\npca = PCA()\npca.fit(X)\nprint(\"Explained Variance:\", pca.explained_variance_)"
  },
  {
    "input": "Given the dataset [[4, 2], [2, 4], [4, 4], [2, 2]], apply PCA and print both the mean and components.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\nX = np.array([[4,2],[2,4],[4,4],[2,2]])\npca = PCA()\npca.fit(X)\nprint(\"Mean:\", pca.mean_)\nprint(\"Components:\\n\", pca.components_)"
  },
  {
    "input": "Given the dataset [[1, 1], [2, 2], [3, 3]], apply PCA and reconstruct the data after dimensionality reduction to 1D.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\nX = np.array([[1,1],[2,2],[3,3]])\npca = PCA(n_components=1)\nX_reduced = pca.fit_transform(X)\nX_reconstructed = pca.inverse_transform(X_reduced)\nprint(\"Reconstructed Data:\\n\", X_reconstructed)"
  },
  {
    "input": "Given the dataset [[2, 1], [1, 2], [3, 3]], apply PCA and print the cumulative explained variance ratio.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\nX = np.array([[2,1],[1,2],[3,3]])\npca = PCA()\npca.fit(X)\ncumulative = np.cumsum(pca.explained_variance_ratio_)\nprint(\"Cumulative Explained Variance:\", cumulative)"
  },
  {
    "input": "Given the dataset [[10, 15], [20, 25], [30, 35]], apply PCA and verify if 1D representation retains most of the variance.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\nX = np.array([[10,15],[20,25],[30,35]])\npca = PCA(n_components=1)\npca.fit(X)\nprint(\"Explained Variance Ratio:\", pca.explained_variance_ratio_)"
  },
  {
    "input": "Given the dataset [[3, 3], [3, 3], [3, 3]], apply PCA and explain why all components have zero variance.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\nX = np.array([[3,3],[3,3],[3,3]])\npca = PCA()\npca.fit(X)\nprint(\"Explained Variance:\", pca.explained_variance_)"
  },
  {
    "input": "Given the dataset [[2, 2], [4, 4], [6, 6]], perform PCA and verify both components and explained variance.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\nX = np.array([[2,2],[4,4],[6,6]])\npca = PCA()\npca.fit(X)\nprint(\"Components:\\n\", pca.components_)\nprint(\"Explained Variance:\", pca.explained_variance_)"
  },
  {
    "input": "Given the dataset [[1, 4, 7], [2, 5, 8], [3, 6, 9]], perform PCA and check how many components explain 95% of the variance.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\nX = np.array([[1,4,7],[2,5,8],[3,6,9]])\npca = PCA(n_components=0.95)\npca.fit(X)\nprint(\"Number of Components:\", pca.n_components_)"
  },
  {
    "input": "Given the dataset [[4, 4], [4, 4], [4, 4]], perform PCA and explain the output components.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\nX = np.array([[4,4],[4,4],[4,4]])\npca = PCA()\npca.fit(X)\nprint(\"Components:\\n\", pca.components_)\nprint(\"Explained Variance:\", pca.explained_variance_)"
  },
  {
    "input": "Given the dataset [[2, 3], [5, 6], [8, 9]], apply PCA and print the explained variance ratio and singular values.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\nX = np.array([[2,3],[5,6],[8,9]])\npca = PCA()\npca.fit(X)\nprint(\"Explained Variance Ratio:\", pca.explained_variance_ratio_)\nprint(\"Singular Values:\", pca.singular_values_)"
  },
  {
    "input": "Given the dataset [[3, 6], [6, 3], [4, 4]], perform PCA and visualize the reduced 1D data.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\n\nX = np.array([[3, 6], [6, 3], [4, 4]])\npca = PCA(n_components=1)\nX_reduced = pca.fit_transform(X)\nprint(\"PCA Reduced 1D Data:\\n\", X_reduced)"
  },
  {
    "input": "Given the dataset [[1, 2], [2, 4], [3, 6]], perform PCA and print the direction vector of the principal component.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\nX = np.array([[1,2],[2,4],[3,6]])\npca = PCA()\npca.fit(X)\nprint(\"Principal Component Vector:\", pca.components_[0])"
  },
  {
    "input": "Apply PCA on dataset [[1, 2], [3, 4], [5, 6], [7, 8]] and print the explained variance ratio.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\nX = np.array([[1,2],[3,4],[5,6],[7,8]])\npca = PCA()\npca.fit(X)\nprint(\"Explained Variance Ratio:\", pca.explained_variance_ratio_)"
  },
  {
    "input": "Use PCA to reduce dataset [[10, 1], [20, 2], [30, 3]] to 1D and show the projected values.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\nX = np.array([[10,1],[20,2],[30,3]])\npca = PCA(n_components=1)\nX_pca = pca.fit_transform(X)\nprint(\"1D Projection:\\n\", X_pca)"
  },
  {
    "input": "Perform PCA on [[3, 5], [5, 3], [6, 6], [2, 8]] and print the principal axes.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\nX = np.array([[3,5],[5,3],[6,6],[2,8]])\npca = PCA()\npca.fit(X)\nprint(\"Principal Axes:\\n\", pca.components_)"
  },
  {
    "input": "Perform PCA on [[5, 5], [6, 6], [7, 7]] and print the transformed data and inverse transformed data.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\nX = np.array([[5,5],[6,6],[7,7]])\npca = PCA(n_components=1)\nX_transformed = pca.fit_transform(X)\nX_inverse = pca.inverse_transform(X_transformed)\nprint(\"Transformed:\\n\", X_transformed)\nprint(\"Reconstructed:\\n\", X_inverse)"
  },
  {
    "input": "Given dataset [[2, 0], [0, 2], [-2, 0], [0, -2]], apply PCA and plot the principal axes on top of the original points.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\n\nX = np.array([[2, 0], [0, 2], [-2, 0], [0, -2]])\npca = PCA()\npca.fit(X)\nprint(\"Principal components:\\n\", pca.components_)\nprint(\"Explained variance:\\n\", pca.explained_variance_)\nprint(\"Mean of the data:\\n\", pca.mean_)"
  },
  {
    "input": "Apply PCA to [[9, 10], [4, 7], [2, 5], [3, 1]] and display the explained variance for each component.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\nX = np.array([[9,10],[4,7],[2,5],[3,1]])\npca = PCA()\npca.fit(X)\nprint(\"Explained Variance:\", pca.explained_variance_)"
  },
  {
    "input": "Perform PCA on [[5, 7], [7, 5], [9, 9]] and reduce it to 1D. Print the reduced and original shape.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\nX = np.array([[5,7],[7,5],[9,9]])\npca = PCA(n_components=1)\nX_new = pca.fit_transform(X)\nprint(\"Reduced Shape:\", X_new.shape)\nprint(\"Original Shape:\", X.shape)"
  },
  {
    "input": "Given [[1, 2, 3], [4, 5, 6], [7, 8, 9]], use PCA to find the minimum number of components that explain at least 95% variance.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\nX = np.array([[1,2,3],[4,5,6],[7,8,9]])\npca = PCA(n_components=0.95)\npca.fit(X)\nprint(\"Number of Components:\", pca.n_components_)"
  },
  {
    "input": "Perform PCA on [[10, 20], [20, 30], [30, 40]] and print the mean and singular values.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\nX = np.array([[10,20],[20,30],[30,40]])\npca = PCA()\npca.fit(X)\nprint(\"Mean:\", pca.mean_)\nprint(\"Singular Values:\", pca.singular_values_)"
  },
  {
    "input": "Use PCA to reduce [[3, 3], [6, 6], [9, 9], [12, 12]] to 1D and inverse transform it. Print all.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\nX = np.array([[3,3],[6,6],[9,9],[12,12]])\npca = PCA(n_components=1)\nX_reduced = pca.fit_transform(X)\nX_reconstructed = pca.inverse_transform(X_reduced)\nprint(\"Reduced:\\n\", X_reduced)\nprint(\"Reconstructed:\\n\", X_reconstructed)"
  },
  {
    "input": "Given [[5, 0], [0, 5]], perform PCA and verify that the components are orthogonal.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\nX = np.array([[5,0],[0,5]])\npca = PCA()\npca.fit(X)\nprint(\"Components (Orthogonal):\\n\", pca.components_)\nprint(\"Dot Product:\", np.dot(pca.components_[0], pca.components_[1]))"
  },
  {
    "input": "Apply PCA on [[6, 3], [8, 6], [9, 9], [10, 12]] and print the explained variance ratio and the principal axes.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\nX = np.array([[6,3],[8,6],[9,9],[10,12]])\npca = PCA()\npca.fit(X)\nprint(\"Explained Variance Ratio:\", pca.explained_variance_ratio_)\nprint(\"Principal Axes:\\n\", pca.components_)"
  },
  {
    "input": "Perform PCA on [[1, 0], [0, 1], [-1, 0], [0, -1]] and verify if the data lies on a circle or line.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\nX = np.array([[1,0],[0,1],[-1,0],[0,-1]])\npca = PCA()\npca.fit(X)\nprint(\"Explained Variance Ratio:\", pca.explained_variance_ratio_)"
  },
  {
    "input": "Use PCA on [[3, 3, 3], [6, 6, 6], [9, 9, 9]] and show that only one component is needed.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\nX = np.array([[3,3,3],[6,6,6],[9,9,9]])\npca = PCA()\npca.fit(X)\nprint(\"Explained Variance Ratio:\", pca.explained_variance_ratio_)"
  },
  {
    "input": "Apply PCA on dataset [[2, 4], [4, 2], [6, 6]] and print the covariance matrix of the transformed data.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\nX = np.array([[2,4],[4,2],[6,6]])\npca = PCA()\nX_pca = pca.fit_transform(X)\nprint(\"Covariance Matrix:\\n\", np.cov(X_pca.T))"
  },
  {
    "input": "Perform PCA on [[4, 8], [8, 4], [12, 12]] and visualize the original and reduced dimensions.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\n\nX = np.array([[4, 8], [8, 4], [12, 12]])\npca = PCA(n_components=1)\nX_pca = pca.fit_transform(X)\nX_inv = pca.inverse_transform(X_pca)\n\nprint(\"Reduced data (1D):\\n\", X_pca)\nprint(\"Reconstructed data (approximation in 2D):\\n\", X_inv)"
  },
  {
    "input": "Given [[3, 2], [2, 3], [3, 3]], use PCA to reduce to 1D and explain retained variance.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\nX = np.array([[3,2],[2,3],[3,3]])\npca = PCA(n_components=1)\npca.fit(X)\nprint(\"Variance Ratio:\", pca.explained_variance_ratio_)"
  },
  {
    "input": "Apply PCA to reduce [[1, 3], [2, 4], [3, 5]] to 1D and print the transformed output.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\nX = np.array([[1,3],[2,4],[3,5]])\npca = PCA(n_components=1)\nX_new = pca.fit_transform(X)\nprint(\"Transformed:\", X_new)"
  },
  {
    "input": "Find explained variance and components using PCA on [[4, 6], [6, 8], [8, 10]]",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\nX = np.array([[4,6],[6,8],[8,10]])\npca = PCA()\npca.fit(X)\nprint(\"Explained Variance:\", pca.explained_variance_)\nprint(\"Components:\", pca.components_)"
  },
  {
    "input": "Use PCA to reduce [[1, 2], [3, 6], [5, 10]] and check the shape before and after transformation.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\nX = np.array([[1,2],[3,6],[5,10]])\npca = PCA(n_components=1)\nX_new = pca.fit_transform(X)\nprint(\"Original Shape:\", X.shape)\nprint(\"Reduced Shape:\", X_new.shape)"
  },
  {
    "input": "Fit PCA on [[3, 4], [6, 8], [9, 12]] and print the mean used for centering the data.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\nX = np.array([[3,4],[6,8],[9,12]])\npca = PCA()\npca.fit(X)\nprint(\"Mean:\", pca.mean_)"
  },
  {
    "input": "Perform PCA on [[1, 2], [2, 3], [3, 4]] and print singular values.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\nX = np.array([[1,2],[2,3],[3,4]])\npca = PCA()\npca.fit(X)\nprint(\"Singular Values:\", pca.singular_values_)"
  },
  {
    "input": "Use PCA with n_components=2 on [[2, 4], [4, 6], [6, 8]] and print the transformed result.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\nX = np.array([[2,4],[4,6],[6,8]])\npca = PCA(n_components=2)\nX_new = pca.fit_transform(X)\nprint(\"Transformed:\", X_new)"
  },
  {
    "input": "Apply PCA to [[7, 14], [8, 16], [9, 18]] and print the ratio of variance explained.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\nX = np.array([[7,14],[8,16],[9,18]])\npca = PCA()\npca.fit(X)\nprint(\"Explained Variance Ratio:\", pca.explained_variance_ratio_)"
  },
  {
    "input": "Check how many components are needed to retain 100% variance in [[10, 20], [15, 30], [20, 40]]",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\n\nX = np.array([[10, 20], [15, 30], [20, 40]])\npca = PCA(n_components=None)\npca.fit(X)\n\nexplained_variance_ratio = np.cumsum(pca.explained_variance_ratio_)\nnum_components = np.argmax(explained_variance_ratio >= 1.0) + 1\nprint(\"Number of Components to retain 100% variance:\", num_components)"
  },
  {
    "input": "Perform PCA on [[3, 5], [4, 6], [5, 7]] and print components and transformed data.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\nX = np.array([[3,5],[4,6],[5,7]])\npca = PCA()\nX_transformed = pca.fit_transform(X)\nprint(\"Components:\", pca.components_)\nprint(\"Transformed:\", X_transformed)"
  },
  {
    "input": "Reduce dimensions of [[11, 22], [13, 26], [15, 30]] to 1D using PCA and reconstruct the data.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\nX = np.array([[11,22],[13,26],[15,30]])\npca = PCA(n_components=1)\nX_reduced = pca.fit_transform(X)\nX_reconstructed = pca.inverse_transform(X_reduced)\nprint(\"Reconstructed:\\n\", X_reconstructed)"
  },
  {
    "input": "Perform PCA on [[2, 1], [4, 2], [6, 3]] and verify if only one component explains all variance.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\nX = np.array([[2,1],[4,2],[6,3]])\npca = PCA()\npca.fit(X)\nprint(\"Explained Variance Ratio:\", pca.explained_variance_ratio_)"
  },
  {
    "input": "Use PCA to transform [[2, 2], [3, 3], [4, 4]] and show the result of inverse_transform.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\nX = np.array([[2,2],[3,3],[4,4]])\npca = PCA(n_components=1)\nX_new = pca.fit_transform(X)\nX_inv = pca.inverse_transform(X_new)\nprint(\"Inverse Transformed:\", X_inv)"
  },
  {
    "input": "Use PCA to transform and inverse [[10, 5], [20, 10], [30, 15]] and show loss if any.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\nX = np.array([[10,5],[20,10],[30,15]])\npca = PCA(n_components=1)\nX_transformed = pca.fit_transform(X)\nX_inv = pca.inverse_transform(X_transformed)\nprint(\"Loss:\", np.abs(X - X_inv))"
  },
  {
    "input": "Fit PCA on [[1, 5], [2, 10], [3, 15]] and print number of components when variance threshold is 0.9.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\nX = np.array([[1,5],[2,10],[3,15]])\npca = PCA(n_components=0.9)\npca.fit(X)\nprint(\"Components Needed:\", pca.n_components_)"
  },
  {
    "input": "Use PCA to reduce [[5, 10], [10, 20], [15, 30]] and check if any component has near zero variance.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\nX = np.array([[5,10],[10,20],[15,30]])\npca = PCA()\npca.fit(X)\nprint(\"Variance of Each Component:\", pca.explained_variance_)"
  },
  {
    "input": "Apply PCA on [[0, 1], [0, 2], [0, 3]] and print the transformed values and components.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\nX = np.array([[0,1],[0,2],[0,3]])\npca = PCA()\nX_new = pca.fit_transform(X)\nprint(\"Components:\", pca.components_)\nprint(\"Transformed:\", X_new)"
  },
  {
    "input": "Perform PCA on [[10, 10], [10, 10], [10, 10]] and observe explained variance.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\nX = np.array([[10,10],[10,10],[10,10]])\npca = PCA()\npca.fit(X)\nprint(\"Explained Variance:\", pca.explained_variance_)"
  },
  {
    "input": "Use PCA on [[5, 0], [10, 0], [15, 0]] and confirm if PCA finds variance only along x-axis.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\nX = np.array([[5,0],[10,0],[15,0]])\npca = PCA()\npca.fit(X)\nprint(\"Components:\", pca.components_)\nprint(\"Explained Variance Ratio:\", pca.explained_variance_ratio_)"
  },
  {
    "input": "Use PCA with n_components=1 on [[1, 1], [2, 2], [3, 3]] and print all results.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\nX = np.array([[1,1],[2,2],[3,3]])\npca = PCA(n_components=1)\nX_new = pca.fit_transform(X)\nprint(\"Components:\", pca.components_)\nprint(\"Transformed:\", X_new)"
  },
  {
    "input": "Fit PCA on [[4, 4], [4, 4], [4, 4]] and check the shape of components and explained variance.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\nX = np.array([[4,4],[4,4],[4,4]])\npca = PCA()\npca.fit(X)\nprint(\"Components Shape:\", pca.components_.shape)\nprint(\"Explained Variance:\", pca.explained_variance_)"
  },
  {
    "input": "Check how PCA handles identical rows: [[1, 2], [1, 2], [1, 2]]",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\nX = np.array([[1,2],[1,2],[1,2]])\npca = PCA()\npca.fit(X)\nprint(\"Explained Variance:\", pca.explained_variance_)"
  },
  {
    "input": "Transform and inverse [[9, 3], [18, 6], [27, 9]] using PCA and confirm if reconstruction is lossless.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\nX = np.array([[9,3],[18,6],[27,9]])\npca = PCA(n_components=1)\nX_pca = pca.fit_transform(X)\nX_inv = pca.inverse_transform(X_pca)\nprint(\"Difference:\\n\", X - X_inv)"
  },
  {
    "input": "Perform PCA on [[1, 0], [0, 1]] and print dot product of components to confirm orthogonality.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\nX = np.array([[1,0],[0,1]])\npca = PCA()\npca.fit(X)\nprint(\"Dot Product:\", np.dot(pca.components_[0], pca.components_[1]))"
  },
  {
    "input": "Apply PCA on [[8, 0], [0, 8]] and print explained variance and components.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\nX = np.array([[8,0],[0,8]])\npca = PCA()\npca.fit(X)\nprint(\"Explained Variance:\", pca.explained_variance_)\nprint(\"Components:\", pca.components_)"
  },
  {
    "input": "Use PCA with n_components=1 on [[1, 1], [2, 2], [3, 3]] and print all results.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\nX = np.array([[1,1],[2,2],[3,3]])\npca = PCA(n_components=1)\nX_new = pca.fit_transform(X)\nprint(\"Transformed:\", X_new)\nprint(\"Components:\", pca.components_)\nprint(\"Mean:\", pca.mean_)\nprint(\"Explained Variance:\", pca.explained_variance_)"
  },
  {
    "input": "Apply PCA to a dataset [[1, 2], [2, 3], [3, 4]] and print cumulative explained variance ratio.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\nX = np.array([[1,2],[2,3],[3,4]])\npca = PCA()\npca.fit(X)\ncumsum = np.cumsum(pca.explained_variance_ratio_)\nprint(\"Cumulative Explained Variance Ratio:\", cumsum)"
  },
  {
    "input": "Transform and inverse a dataset using PCA and calculate reconstruction error for [[1, 1], [2, 2], [3, 3]]",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\nX = np.array([[1,1],[2,2],[3,3]])\npca = PCA(n_components=1)\nX_transformed = pca.fit_transform(X)\nX_inv = pca.inverse_transform(X_transformed)\nerror = np.mean((X - X_inv)**2)\nprint(\"Reconstruction Error:\", error)"
  },
  {
    "input": "Find the number of PCA components that retain at least 95% variance for [[1, 2], [2, 4], [3, 6], [4, 8]]",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\nX = np.array([[1,2],[2,4],[3,6],[4,8]])\npca = PCA(n_components=0.95)\npca.fit(X)\nprint(\"Components to retain 95%:\", pca.n_components_)"
  },
  {
    "input": "Fit PCA to [[1, 0], [0, 1], [1, 1]] and verify the direction of the principal components.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\nX = np.array([[1,0],[0,1],[1,1]])\npca = PCA()\npca.fit(X)\nprint(\"Principal Components:\", pca.components_)"
  },
  {
    "input": "Verify if PCA on [[1, 2], [2, 4], [3, 6]] results in one dominant component.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\nX = np.array([[1,2],[2,4],[3,6]])\npca = PCA()\npca.fit(X)\nprint(\"Explained Variance Ratio:\", pca.explained_variance_ratio_)"
  },
  {
    "input": "Run PCA on [[0, 0], [1, 1], [2, 2], [3, 3]] and print all explained variances and components.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\nX = np.array([[0,0],[1,1],[2,2],[3,3]])\npca = PCA()\npca.fit(X)\nprint(\"Explained Variance:\", pca.explained_variance_)\nprint(\"Components:\", pca.components_)"
  },
  {
    "input": "Use PCA on [[1, 10], [2, 20], [3, 30], [4, 40]] and check if there's only one informative direction.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\nX = np.array([[1,10],[2,20],[3,30],[4,40]])\npca = PCA()\npca.fit(X)\nprint(\"Explained Variance Ratio:\", pca.explained_variance_ratio_)"
  },
  {
    "input": "Transform data [[2, 0], [4, 0], [6, 0]] using PCA and compare transformed and inverse values.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\nX = np.array([[2,0],[4,0],[6,0]])\npca = PCA(n_components=1)\nX_trans = pca.fit_transform(X)\nX_inv = pca.inverse_transform(X_trans)\nprint(\"Inverse Transformed:\", X_inv)"
  },
  {
    "input": "Fit PCA with 2D input [[0, 1], [1, 0], [1, 1]] and show mean and singular values.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\nX = np.array([[0,1],[1,0],[1,1]])\npca = PCA()\npca.fit(X)\nprint(\"Mean:\", pca.mean_)\nprint(\"Singular Values:\", pca.singular_values_)"
  },
  {
    "input": "Fit PCA to [[1, 2], [2, 1], [3, 3]] and get the projection onto principal component.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\nX = np.array([[1,2],[2,1],[3,3]])\npca = PCA(n_components=1)\nX_proj = pca.fit_transform(X)\nprint(\"Projected Data:\", X_proj)"
  },
  {
    "input": "Check if PCA detects direction in data [[1, 0], [2, 1], [3, 2]] and print first component.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\nX = np.array([[1,0],[2,1],[3,2]])\npca = PCA()\npca.fit(X)\nprint(\"First Component:\", pca.components_[0])"
  },
  {
    "input": "Use PCA on [[1, 3], [2, 6], [3, 9]] and print all PCA attributes.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\nX = np.array([[1,3],[2,6],[3,9]])\npca = PCA()\npca.fit(X)\nprint(\"Mean:\", pca.mean_)\nprint(\"Components:\", pca.components_)\nprint(\"Explained Variance:\", pca.explained_variance_)\nprint(\"Explained Variance Ratio:\", pca.explained_variance_ratio_)"
  },
  {
    "input": "Verify PCA behavior on a dataset with same values [[1, 1], [1, 1], [1, 1]]",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\nX = np.array([[1,1],[1,1],[1,1]])\npca = PCA()\npca.fit(X)\nprint(\"Explained Variance:\", pca.explained_variance_)"
  },
  {
    "input": "Run PCA on [[5, 10], [6, 12], [7, 14]] and print the shape of reduced and reconstructed data.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\nX = np.array([[5,10],[6,12],[7,14]])\npca = PCA(n_components=1)\nX_red = pca.fit_transform(X)\nX_rec = pca.inverse_transform(X_red)\nprint(\"Reduced Shape:\", X_red.shape)\nprint(\"Reconstructed Shape:\", X_rec.shape)"
  },
  {
    "input": "Use PCA to reduce and reconstruct [[1, 4], [2, 8], [3, 12]] and check reconstruction accuracy.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\nX = np.array([[1,4],[2,8],[3,12]])\npca = PCA(n_components=1)\nX_reduced = pca.fit_transform(X)\nX_reconstructed = pca.inverse_transform(X_reduced)\nprint(\"Reconstruction Accuracy:\", np.allclose(X, X_reconstructed, atol=1e-10))"
  },
  {
    "input": "Perform PCA on [[10, 1], [20, 2], [30, 3]] and print all singular values and means.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\nX = np.array([[10,1],[20,2],[30,3]])\npca = PCA()\npca.fit(X)\nprint(\"Singular Values:\", pca.singular_values_)\nprint(\"Means:\", pca.mean_)"
  },
  {
    "input": "Check principal directions using PCA on [[2, 2], [4, 0], [0, 4]]",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\nX = np.array([[2,2],[4,0],[0,4]])\npca = PCA()\npca.fit(X)\nprint(\"Principal Components:\", pca.components_)"
  },
  {
    "input": "Use PCA with n_components=0.99 on [[1, 1], [2, 2], [3, 3], [4, 4]] and get required components.",
    "output": "import numpy as np\nfrom sklearn.decomposition import PCA\nX = np.array([[1,1],[2,2],[3,3],[4,4]])\npca = PCA(n_components=0.99)\npca.fit(X)\nprint(\"Required Components:\", pca.n_components_)"
  },
  {
    "input": "Given a vector v = [3, 4] in the standard basis, and a new basis B = [[1, 0], [0, 1]], find the coordinates of v in basis B.",
    "output": "import numpy as np\n\nv = np.array([3, 4])\nB = np.array([[1, 0], [0, 1]])\n\nB_inv = np.linalg.inv(B)\nv_coords = B_inv @ v\nprint(\"Coordinates of v in basis B:\", v_coords)"
  },
  {
    "input": "Convert the vector v = [2, -1] to coordinates in the new basis B = [[1, 1], [1, -1]].",
    "output": "import numpy as np\n\nv = np.array([2, -1])\nB = np.array([[1, 1], [1, -1]])\n\nB_inv = np.linalg.inv(B)\nv_coords = B_inv @ v\nprint(\"Coordinates of v in basis B:\", v_coords)"
  },
  {
    "input": "Find the standard coordinates of a vector whose coordinates in basis B = [[2, 0], [0, 3]] are [1, 2].",
    "output": "import numpy as np\n\nB = np.array([[2, 0], [0, 3]])\nv_coords = np.array([1, 2])\nv_standard = B @ v_coords\nprint(\"Vector in standard coordinates:\", v_standard)"
  },
  {
    "input": "Given basis B = [[1, 2], [0, 1]], find the matrix that changes coordinates from B to standard basis.",
    "output": "import numpy as np\n\nB = np.array([[1, 2], [0, 1]])\nchange_matrix = B\nprint(\"Change of basis matrix (B to standard):\\n\", change_matrix)"
  },
  {
    "input": "Given basis B = [[1, 2], [0, 1]], find the matrix that changes coordinates from standard basis to B.",
    "output": "import numpy as np\n\nB = np.array([[1, 2], [0, 1]])\nchange_matrix = np.linalg.inv(B)\nprint(\"Change of basis matrix (standard to B):\\n\", change_matrix)"
  },
  {
    "input": "If a vector is [5, 6] in the basis B = [[2, 1], [1, 2]], find its coordinates in the standard basis.",
    "output": "import numpy as np\n\nB = np.array([[2, 1], [1, 2]])\nv_B = np.array([5, 6])\nv_standard = B @ v_B\nprint(\"Vector in standard basis:\", v_standard)"
  },
  {
    "input": "If v = [7, 3] and basis B = [[3, 0], [0, 1]], what are the coordinates of v in B?",
    "output": "import numpy as np\n\nv = np.array([7, 3])\nB = np.array([[3, 0], [0, 1]])\nB_inv = np.linalg.inv(B)\nv_coords = B_inv @ v\nprint(\"Coordinates of v in B:\", v_coords)"
  },
  {
    "input": "Change the coordinates of v = [1, 1] from standard basis to B = [[1, 1], [1, -1]].",
    "output": "import numpy as np\n\nv = np.array([1, 1])\nB = np.array([[1, 1], [1, -1]])\nB_inv = np.linalg.inv(B)\nv_B = B_inv @ v\nprint(\"Coordinates of v in basis B:\", v_B)"
  },
  {
    "input": "Given a vector in B-coordinates [2, 0], and B = [[4, 1], [0, 2]], find its coordinates in standard basis.",
    "output": "import numpy as np\n\nB = np.array([[4, 1], [0, 2]])\nv_B = np.array([2, 0])\nv_std = B @ v_B\nprint(\"Vector in standard coordinates:\", v_std)"
  },
  {
    "input": "Find the matrix to convert coordinates from basis A = [[1, 0], [1, 1]] to basis B = [[1, 1], [0, 1]].",
    "output": "import numpy as np\n\nA = np.array([[1, 0], [1, 1]])\nB = np.array([[1, 1], [0, 1]])\nA_to_B = np.linalg.inv(B) @ A\nprint(\"Change of basis matrix from A to B:\\n\", A_to_B)"
  },
  {
    "input": "A vector has coordinates [3, 2] in basis B = [[2, 0], [1, 1]]. Convert it to standard basis.",
    "output": "import numpy as np\n\nB = np.array([[2, 0], [1, 1]])\nv_B = np.array([3, 2])\nv_std = B @ v_B\nprint(\"Vector in standard basis:\", v_std)"
  },
  {
    "input": "Find coordinates of v = [4, 4] in basis B = [[2, 2], [0, 1]].",
    "output": "import numpy as np\n\nv = np.array([4, 4])\nB = np.array([[2, 2], [0, 1]])\nB_inv = np.linalg.inv(B)\nv_B = B_inv @ v\nprint(\"Coordinates of v in basis B:\", v_B)"
  },
  {
    "input": "Change of basis matrix from standard basis to B = [[1, 2], [3, 4]]?",
    "output": "import numpy as np\n\nB = np.array([[1, 2], [3, 4]])\nchange_matrix = np.linalg.inv(B)\nprint(\"Change of basis matrix (standard to B):\\n\", change_matrix)"
  },
  {
    "input": "What is the vector in standard basis if its coordinates in B = [[1, 0], [2, 3]] are [1, 1]?",
    "output": "import numpy as np\n\nB = np.array([[1, 0], [2, 3]])\nv_B = np.array([1, 1])\nv_std = B @ v_B\nprint(\"Vector in standard basis:\", v_std)"
  },
  {
    "input": "A basis transformation matrix is [[1, 2], [3, 4]]. Find its inverse.",
    "output": "import numpy as np\n\nB = np.array([[1, 2], [3, 4]])\nB_inv = np.linalg.inv(B)\nprint(\"Inverse of the basis matrix:\\n\", B_inv)"
  },
  {
    "input": "If v = [5, -3] in standard basis and B = [[1, -1], [1, 1]], find its coordinates in B.",
    "output": "import numpy as np\n\nv = np.array([5, -3])\nB = np.array([[1, -1], [1, 1]])\nB_inv = np.linalg.inv(B)\nv_B = B_inv @ v\nprint(\"Coordinates in basis B:\", v_B)"
  },
  {
    "input": "Given two bases A = [[1, 0], [0, 1]] and B = [[0, 1], [-1, 0]], find matrix to convert from A to B.",
    "output": "import numpy as np\n\nA = np.array([[1, 0], [0, 1]])\nB = np.array([[0, 1], [-1, 0]])\nchange_matrix = np.linalg.inv(B) @ A\nprint(\"Change of basis from A to B:\\n\", change_matrix)"
  },
  {
    "input": "Convert v = [1, 0] from standard basis to basis B = [[2, 1], [0, 1]].",
    "output": "import numpy as np\n\nv = np.array([1, 0])\nB = np.array([[2, 1], [0, 1]])\nB_inv = np.linalg.inv(B)\nv_B = B_inv @ v\nprint(\"Coordinates of v in B:\", v_B)"
  },
  {
    "input": "Find vector in basis B = [[1, 1], [1, -1]] that corresponds to standard vector [3, 1].",
    "output": "import numpy as np\n\nv = np.array([3, 1])\nB = np.array([[1, 1], [1, -1]])\nB_inv = np.linalg.inv(B)\nv_B = B_inv @ v\nprint(\"Coordinates in basis B:\", v_B)"
  },
  {
    "input": "A vector in B-coordinates is [0, 3] and B = [[2, 2], [1, 0]]. What is its standard form?",
    "output": "import numpy as np\n\nB = np.array([[2, 2], [1, 0]])\nv_B = np.array([0, 3])\nv_std = B @ v_B\nprint(\"Vector in standard basis:\", v_std)"
  },
  {
    "input": "Find change of basis matrix from basis B to basis A, where B = [[1, 2], [3, 4]], A = [[2, 0], [0, 2]].",
    "output": "import numpy as np\n\nB = np.array([[1, 2], [3, 4]])\nA = np.array([[2, 0], [0, 2]])\nB_to_A = np.linalg.inv(A) @ B\nprint(\"Change of basis matrix from B to A:\\n\", B_to_A)"
  },
  {
    "input": "Vector in A = [[1, 2], [0, 1]] is [2, 1]. Convert to standard coordinates.",
    "output": "import numpy as np\n\nA = np.array([[1, 2], [0, 1]])\nv_A = np.array([2, 1])\nv_std = A @ v_A\nprint(\"Vector in standard coordinates:\", v_std)"
  },
  {
    "input": "What are the coordinates of [0, 2] in basis B = [[1, 0], [1, 1]]?",
    "output": "import numpy as np\n\nv = np.array([0, 2])\nB = np.array([[1, 0], [1, 1]])\nB_inv = np.linalg.inv(B)\nv_B = B_inv @ v\nprint(\"Coordinates in basis B:\", v_B)"
  },
  {
    "input": "Given v = [1, -1] in standard basis, and B = [[2, 2], [0, 1]], find v in B-coordinates.",
    "output": "import numpy as np\n\nv = np.array([1, -1])\nB = np.array([[2, 2], [0, 1]])\nB_inv = np.linalg.inv(B)\nv_B = B_inv @ v\nprint(\"Coordinates of v in B:\", v_B)"
  },
  {
    "input": "Convert the 3D vector v = [3, 2, 1] into coordinates with respect to the basis B = [[1, 0, 1], [0, 1, 1], [1, 1, 0]].",
    "output": "import numpy as np\n\nv = np.array([3, 2, 1])\nB = np.array([[1, 0, 1], [0, 1, 1], [1, 1, 0]])\nB_inv = np.linalg.inv(B)\nv_B = B_inv @ v\nprint(\"Coordinates of v in basis B:\", v_B)"
  },
  {
    "input": "A vector v has coordinates [1, 0, 2] in basis B = [[1, 1, 0], [0, 1, 1], [1, 0, 1]]. Find v in the standard basis.",
    "output": "import numpy as np\n\nB = np.array([[1, 1, 0], [0, 1, 1], [1, 0, 1]])\nv_B = np.array([1, 0, 2])\nv_std = B @ v_B\nprint(\"Vector in standard coordinates:\", v_std)"
  },
  {
    "input": "Find the change of basis matrix from basis A = [[1, 1], [0, 2]] to B = [[2, 0], [1, 1]].",
    "output": "import numpy as np\n\nA = np.array([[1, 1], [0, 2]])\nB = np.array([[2, 0], [1, 1]])\nchange_matrix = np.linalg.inv(B) @ A\nprint(\"Change of basis matrix from A to B:\\n\", change_matrix)"
  },
  {
    "input": "A vector is given in basis A = [[1, 2], [3, 4]] as [4, -1]. Convert it to coordinates in basis B = [[2, 0], [0, 2]].",
    "output": "import numpy as np\n\nA = np.array([[1, 2], [3, 4]])\nB = np.array([[2, 0], [0, 2]])\nv_A = np.array([4, -1])\nstandard = A @ v_A\nv_B = np.linalg.inv(B) @ standard\nprint(\"Coordinates in basis B:\", v_B)"
  },
  {
    "input": "Transform v = [1, 2, 3] from standard basis to basis B = [[1, 2, 3], [0, 1, 1], [0, 0, 1]].",
    "output": "import numpy as np\n\nv = np.array([1, 2, 3])\nB = np.array([[1, 2, 3], [0, 1, 1], [0, 0, 1]])\nB_inv = np.linalg.inv(B)\nv_B = B_inv @ v\nprint(\"v in basis B:\", v_B)"
  },
  {
    "input": "Let A and B be bases in R^2. A = [[1, 1], [0, 2]], B = [[2, 3], [1, 4]]. Find the matrix that converts from B to A.",
    "output": "import numpy as np\n\nA = np.array([[1, 1], [0, 2]])\nB = np.array([[2, 3], [1, 4]])\nB_to_A = np.linalg.inv(A) @ B\nprint(\"Change of basis matrix from B to A:\\n\", B_to_A)"
  },
  {
    "input": "Convert v = [2, 2] from basis A = [[1, 0], [0, 2]] to basis B = [[1, 1], [0, 1]].",
    "output": "import numpy as np\n\nA = np.array([[1, 0], [0, 2]])\nB = np.array([[1, 1], [0, 1]])\nv_A = np.array([2, 2])\nstandard = A @ v_A\nv_B = np.linalg.inv(B) @ standard\nprint(\"Coordinates in basis B:\", v_B)"
  },
  {
    "input": "Given v in B-coordinates as [1, 2, 3], and B = [[1, 0, 1], [0, 1, 1], [1, 1, 0]], find v in standard basis.",
    "output": "import numpy as np\n\nB = np.array([[1, 0, 1], [0, 1, 1], [1, 1, 0]])\nv_B = np.array([1, 2, 3])\nv_std = B @ v_B\nprint(\"Vector in standard coordinates:\", v_std)"
  },
  {
    "input": "Compute the transformation matrix T that changes coordinates from B = [[1, 1], [1, -1]] to standard basis.",
    "output": "import numpy as np\n\nB = np.array([[1, 1], [1, -1]])\nT = B\nprint(\"Transformation matrix T (B to standard):\\n\", T)"
  },
  {
    "input": "Find the inverse transformation matrix for B = [[3, 1], [2, 4]].",
    "output": "import numpy as np\n\nB = np.array([[3, 1], [2, 4]])\nB_inv = np.linalg.inv(B)\nprint(\"Inverse transformation matrix for B:\\n\", B_inv)"
  },
  {
    "input": "Convert coordinates [1, 2] in basis B = [[1, 2], [3, 4]] to standard basis, then to C = [[0, 1], [1, 0]].",
    "output": "import numpy as np\n\nB = np.array([[1, 2], [3, 4]])\nC = np.array([[0, 1], [1, 0]])\nv_B = np.array([1, 2])\nstandard = B @ v_B\nv_C = np.linalg.inv(C) @ standard\nprint(\"Coordinates in C:\", v_C)"
  },
  {
    "input": "Let A = [[2, 1], [1, 2]], and a vector has standard coordinates [5, 5]. Find coordinates in basis A.",
    "output": "import numpy as np\n\nA = np.array([[2, 1], [1, 2]])\nv = np.array([5, 5])\nv_A = np.linalg.inv(A) @ v\nprint(\"Coordinates in basis A:\", v_A)"
  },
  {
    "input": "Given 3D vector v = [4, 2, 0] and basis B = [[1, 1, 0], [0, 1, 1], [1, 0, 1]], express v in B-coordinates.",
    "output": "import numpy as np\n\nv = np.array([4, 2, 0])\nB = np.array([[1, 1, 0], [0, 1, 1], [1, 0, 1]])\nB_inv = np.linalg.inv(B)\nv_B = B_inv @ v\nprint(\"v in basis B:\", v_B)"
  },
  {
    "input": "What matrix transforms coordinates from B = [[1, 2], [0, 1]] to C = [[2, 0], [1, 1]]?",
    "output": "import numpy as np\n\nB = np.array([[1, 2], [0, 1]])\nC = np.array([[2, 0], [1, 1]])\nB_to_C = np.linalg.inv(C) @ B\nprint(\"Change of basis matrix from B to C:\\n\", B_to_C)"
  },
  {
    "input": "Vector has coordinates [1, 1] in B = [[1, 1], [1, -1]]. Convert to basis C = [[2, 0], [0, 2]].",
    "output": "import numpy as np\n\nB = np.array([[1, 1], [1, -1]])\nC = np.array([[2, 0], [0, 2]])\nv_B = np.array([1, 1])\nstandard = B @ v_B\nv_C = np.linalg.inv(C) @ standard\nprint(\"Coordinates in basis C:\", v_C)"
  },
  {
    "input": "Change of basis matrix from orthogonal basis B = [[1, 0], [0, 2]] to C = [[1, 1], [-1, 1]]?",
    "output": "import numpy as np\n\nB = np.array([[1, 0], [0, 2]])\nC = np.array([[1, 1], [-1, 1]])\nB_to_C = np.linalg.inv(C) @ B\nprint(\"Change of basis from B to C:\\n\", B_to_C)"
  },
  {
    "input": "Find matrix that maps coordinates from standard basis to orthogonal basis B = [[0, 1], [-1, 0]].",
    "output": "import numpy as np\n\nB = np.array([[0, 1], [-1, 0]])\nchange_matrix = np.linalg.inv(B)\nprint(\"Standard to B transformation matrix:\\n\", change_matrix)"
  },
  {
    "input": "Given B = [[1, 2], [3, 4]] and C = [[0, 1], [1, 1]], find the matrix to go from B to C.",
    "output": "import numpy as np\n\nB = np.array([[1, 2], [3, 4]])\nC = np.array([[0, 1], [1, 1]])\nB_to_C = np.linalg.inv(C) @ B\nprint(\"Change of basis from B to C:\\n\", B_to_C)"
  },
  {
    "input": "A vector v = [6, 2] is in basis A = [[1, 0], [1, 2]]. Convert it to basis B = [[2, 1], [0, 1]].",
    "output": "import numpy as np\n\nA = np.array([[1, 0], [1, 2]])\nB = np.array([[2, 1], [0, 1]])\nv_A = np.array([6, 2])\nstandard = A @ v_A\nv_B = np.linalg.inv(B) @ standard\nprint(\"Coordinates in basis B:\", v_B)"
  },
  {
    "input": "Convert vector [1, 0, -1] from basis A = [[1, 1, 0], [0, 1, 1], [1, 0, 1]] to standard basis.",
    "output": "import numpy as np\n\nA = np.array([[1, 1, 0], [0, 1, 1], [1, 0, 1]])\nv_A = np.array([1, 0, -1])\nv_std = A @ v_A\nprint(\"Vector in standard basis:\", v_std)"
  },
  {
    "input": "Find the basis matrix B such that standard vector [3, 3] has coordinates [1, 1] in B.",
    "output": "import numpy as np\n\nv = np.array([3, 3])\ncoords = np.array([1, 1])\n# Bx = v => B = v @ coords.T (outer product of v and inverse of coords)\nB = np.column_stack((v / coords[0], v / coords[1])) / 2\nprint(\"Basis B:\\n\", B)"
  },
  {
    "input": "Vector v = [2, 1] in standard basis. Find its coordinates in rotated basis B = [[cos(pi/4), -sin(pi/4)], [sin(pi/4), cos(pi/4)]].",
    "output": "import numpy as np\nfrom math import pi, cos, sin\n\nv = np.array([2, 1])\nB = np.array([[cos(pi/4), -sin(pi/4)], [sin(pi/4), cos(pi/4)]])\nB_inv = np.linalg.inv(B)\nv_B = B_inv @ v\nprint(\"Coordinates in rotated basis B:\", v_B)"
  },
  {
    "input": "Given a matrix A = [[2, 0], [0, 3]] and a basis B = [[1, 1], [1, -1]], find the matrix of A in basis B.",
    "output": "import numpy as np\n\nA = np.array([[2, 0], [0, 3]])\nB = np.array([[1, 1], [1, -1]])\nP = B\nP_inv = np.linalg.inv(P)\nA_B = P_inv @ A @ P\nprint(\"Matrix A in basis B:\\n\", A_B)"
  },
  {
    "input": "Find the change of basis matrix from basis B = [[1, 0], [2, 1]] to C = [[2, 1], [1, 1]], and then apply it to vector [3, 4].",
    "output": "import numpy as np\n\nB = np.array([[1, 0], [2, 1]])\nC = np.array([[2, 1], [1, 1]])\nv_B = np.array([3, 4])\nP = np.linalg.inv(C) @ B\nv_C = P @ v_B\nprint(\"Coordinates in basis C:\", v_C)"
  },
  {
    "input": "A transformation T rotates vectors 90 degrees counterclockwise. What is the matrix representation of T in standard basis and in basis B = [[1, 1], [-1, 1]]?",
    "output": "import numpy as np\n\nT_std = np.array([[0, -1], [1, 0]])\nB = np.array([[1, 1], [-1, 1]])\nP = B\nP_inv = np.linalg.inv(P)\nT_B = P_inv @ T_std @ P\nprint(\"Matrix in standard basis:\\n\", T_std)\nprint(\"Matrix in basis B:\\n\", T_B)"
  },
  {
    "input": "Find the matrix representation of reflection over the x-axis in the basis B = [[1, 1], [1, -1]].",
    "output": "import numpy as np\n\nT_std = np.array([[1, 0], [0, -1]])\nB = np.array([[1, 1], [1, -1]])\nP = B\nP_inv = np.linalg.inv(P)\nT_B = P_inv @ T_std @ P\nprint(\"Reflection matrix in basis B:\\n\", T_B)"
  },
  {
    "input": "Let A = [[4, 1], [2, 3]]. Find its representation in the eigenbasis.",
    "output": "import numpy as np\n\nA = np.array([[4, 1], [2, 3]])\nevals, evecs = np.linalg.eig(A)\nP = evecs\nP_inv = np.linalg.inv(P)\nA_diag = P_inv @ A @ P\nprint(\"Diagonal representation of A:\\n\", A_diag)"
  },
  {
    "input": "Convert the vector v = [1, 2, 3] from standard basis to orthonormal basis B = [[1/\u00e2\u02c6\u01613, 1/\u00e2\u02c6\u01613, 1/\u00e2\u02c6\u01613], [1/\u00e2\u02c6\u01612, -1/\u00e2\u02c6\u01612, 0], [1/\u00e2\u02c6\u01616, 1/\u00e2\u02c6\u01616, -2/\u00e2\u02c6\u01616]].",
    "output": "import numpy as np\n\nv = np.array([1, 2, 3])\nB = np.array([\n    [1/np.sqrt(3), 1/np.sqrt(3), 1/np.sqrt(3)],\n    [1/np.sqrt(2), -1/np.sqrt(2), 0],\n    [1/np.sqrt(6), 1/np.sqrt(6), -2/np.sqrt(6)]\n])\nv_B = B @ v\nprint(\"Coordinates in orthonormal basis B:\", v_B)"
  },
  {
    "input": "Let T be a linear transformation that scales by 2 in x-direction and rotates 90 degrees. Find T in basis B = [[1, 0], [1, 1]].",
    "output": "import numpy as np\n\nS = np.array([[2, 0], [0, 1]])\nR = np.array([[0, -1], [1, 0]])\nT = R @ S\nB = np.array([[1, 0], [1, 1]])\nP = B\nP_inv = np.linalg.inv(P)\nT_B = P_inv @ T @ P\nprint(\"T in basis B:\\n\", T_B)"
  },
  {
    "input": "Let matrix A = [[0, -1], [1, 0]] represent 90-degree rotation. Find its representation in basis B = [[2, 1], [1, 2]].",
    "output": "import numpy as np\n\nA = np.array([[0, -1], [1, 0]])\nB = np.array([[2, 1], [1, 2]])\nP = B\nP_inv = np.linalg.inv(P)\nA_B = P_inv @ A @ P\nprint(\"Matrix A in basis B:\\n\", A_B)"
  },
  {
    "input": "Find the coordinates of v = [5, -3] in the basis formed by the eigenvectors of A = [[2, 1], [1, 2]].",
    "output": "import numpy as np\n\nv = np.array([5, -3])\nA = np.array([[2, 1], [1, 2]])\n_, evecs = np.linalg.eig(A)\nv_new = np.linalg.inv(evecs) @ v\nprint(\"Coordinates of v in the eigenbasis:\", v_new)"
  },
  {
    "input": "Given a 3x3 rotation matrix R for 45 degrees around z-axis, express vector [1, 0, 0] in the rotated frame.",
    "output": "import numpy as np\n\nangle = np.pi / 4\nR = np.array([\n    [np.cos(angle), -np.sin(angle), 0],\n    [np.sin(angle), np.cos(angle), 0],\n    [0, 0, 1]\n])\nv = np.array([1, 0, 0])\nv_rot = np.linalg.inv(R) @ v\nprint(\"Vector in rotated frame:\", v_rot)"
  },
  {
    "input": "Convert the matrix A = [[3, 0], [0, 1]] to the basis B = [[1, 1], [1, -1]] and verify it is diagonal in B.",
    "output": "import numpy as np\n\nA = np.array([[3, 0], [0, 1]])\nB = np.array([[1, 1], [1, -1]])\nP = B\nP_inv = np.linalg.inv(P)\nA_B = P_inv @ A @ P\nprint(\"A in basis B:\\n\", A_B)"
  },
  {
    "input": "Compute the matrix representation of the derivative operator d/dx on the space spanned by {1, x, x^2} using finite difference.",
    "output": "import numpy as np\n\n# Approximate using forward difference on three sample points\nX = np.array([[1, 0, 0], [1, 1, 1], [1, 2, 4]])\ndX = np.array([[0, 1, 0], [0, 1, 2], [0, 1, 4]])\nD = np.linalg.lstsq(X, dX, rcond=None)[0]\nprint(\"Derivative matrix in basis {1, x, x^2} (approx.):\\n\", D)"
  },
  {
    "input": "Find the transition matrix from standard basis to eigenbasis of A = [[5, 2], [2, 5]].",
    "output": "import numpy as np\n\nA = np.array([[5, 2], [2, 5]])\n_, evecs = np.linalg.eig(A)\nP = evecs\nprint(\"Transition matrix to eigenbasis:\\n\", P)"
  },
  {
    "input": "Express v = [2, -1] in terms of the basis vectors [3, 1] and [1, -1].",
    "output": "import numpy as np\n\nB = np.array([[3, 1], [1, -1]])\nv = np.array([2, -1])\nv_B = np.linalg.inv(B) @ v\nprint(\"Coordinates in new basis:\", v_B)"
  },
  {
    "input": "Compute the inverse of a change of basis matrix from B = [[1, 2], [2, 3]] to standard basis.",
    "output": "import numpy as np\n\nB = np.array([[1, 2], [2, 3]])\nP = B\nP_inv = np.linalg.inv(P)\nprint(\"Inverse of change of basis matrix:\\n\", P_inv)"
  },
  {
    "input": "A linear operator T has matrix [[1, 2], [3, 4]] in basis B = [[1, 0], [1, 1]]. Find its matrix in standard basis.",
    "output": "import numpy as np\n\nT_B = np.array([[1, 2], [3, 4]])\nB = np.array([[1, 0], [1, 1]])\nP = B\nT_std = P @ T_B @ np.linalg.inv(P)\nprint(\"Matrix in standard basis:\\n\", T_std)"
  },
  {
    "input": "Let A be the reflection over line y = x. What is the matrix representation of A in basis B = [[1, 1], [1, -1]]?",
    "output": "import numpy as np\n\nA = np.array([[0, 1], [1, 0]])\nB = np.array([[1, 1], [1, -1]])\nP = B\nA_B = np.linalg.inv(P) @ A @ P\nprint(\"Reflection over y = x in basis B:\\n\", A_B)"
  },
  {
    "input": "Given a symmetric matrix A = [[4, 2], [2, 3]], find the orthogonal matrix that diagonalizes it.",
    "output": "import numpy as np\n\nA = np.array([[4, 2], [2, 3]])\nevals, evecs = np.linalg.eigh(A)\nprint(\"Orthogonal matrix (eigenvectors):\\n\", evecs)"
  },
  {
    "input": "Let v = [1, 1, 0]. Find its coordinates in the basis B = [[1, 0, 1], [0, 1, 1], [1, 1, 0]].",
    "output": "import numpy as np\n\nv = np.array([1, 1, 0])\nB = np.array([[1, 0, 1], [0, 1, 1], [1, 1, 0]])\nB_inv = np.linalg.inv(B)\nv_B = B_inv @ v\nprint(\"Coordinates in basis B:\", v_B)"
  },
  {
    "input": "If a matrix T acts as a reflection about the line y = -x, express T in the eigenbasis of T.",
    "output": "import numpy as np\n\nT = np.array([[0, -1], [-1, 0]])\nevals, evecs = np.linalg.eig(T)\nT_diag = np.linalg.inv(evecs) @ T @ evecs\nprint(\"Matrix T in eigenbasis:\\n\", T_diag)"
  },
  {
    "input": "A linear transformation T doubles x and subtracts y. What is the matrix representation of T in the standard basis, and then in basis B = [[1, 1], [1, -1]]?",
    "output": "import numpy as np\n\nA = np.array([[2, 0], [-1, 0]])\nB = np.array([[1, 1], [1, -1]])\nP = B\nP_inv = np.linalg.inv(P)\nA_B = P_inv @ A @ P\nprint(\"Matrix in standard basis:\\n\", A)\nprint(\"Matrix in basis B:\\n\", A_B)"
  },
  {
    "input": "Given the basis B = [[1, 2], [2, 3]], express vector v = [4, 5] in coordinates relative to B.",
    "output": "import numpy as np\n\nB = np.array([[1, 2], [2, 3]])\nv = np.array([4, 5])\nv_B = np.linalg.inv(B) @ v\nprint(\"v in basis B:\", v_B)"
  },
  {
    "input": "Let A = [[1, 1], [0, 2]] and B = [[1, 0], [1, 1]]. Compute the matrix A in the basis B.",
    "output": "import numpy as np\n\nA = np.array([[1, 1], [0, 2]])\nB = np.array([[1, 0], [1, 1]])\nP = B\nP_inv = np.linalg.inv(P)\nA_B = P_inv @ A @ P\nprint(\"Matrix A in basis B:\\n\", A_B)"
  },
  {
    "input": "Express the function f(x) = x + 2x^2 in the basis {1, x, x^2}.",
    "output": "import numpy as np\n\n# Basis is standard: {1, x, x^2}\nf_coeffs = np.array([0, 1, 2])\nprint(\"Coordinates of f(x) in standard polynomial basis:\", f_coeffs)"
  },
  {
    "input": "Let T be the derivative operator d/dx on the basis {1, x, x^2}. Find its matrix representation.",
    "output": "import numpy as np\n\nD = np.array([\n    [0, 1, 0],\n    [0, 0, 2],\n    [0, 0, 0]\n])\nprint(\"Matrix of d/dx in {1, x, x^2} basis:\\n\", D)"
  },
  {
    "input": "A 3x3 matrix A = [[1,2,0],[0,1,0],[0,0,3]] acts on \u211d\u00b3. Find its representation in basis B = [[1,0,0],[1,1,0],[0,0,1]].",
    "output": "import numpy as np\n\nA = np.array([[1,2,0],[0,1,0],[0,0,3]])\nB = np.array([[1,0,0],[1,1,0],[0,0,1]])\nP = B\nP_inv = np.linalg.inv(P)\nA_B = P_inv @ A @ P\nprint(\"A in basis B:\\n\", A_B)"
  },
  {
    "input": "Given A = [[3, 1], [0, 2]], find the basis that diagonalizes it and write A in that basis.",
    "output": "import numpy as np\n\nA = np.array([[3, 1], [0, 2]])\nevals, evecs = np.linalg.eig(A)\nA_diag = np.linalg.inv(evecs) @ A @ evecs\nprint(\"Diagonal form of A:\\n\", A_diag)"
  },
  {
    "input": "Given the vector v = [2, -2, 1], express it in the basis B = [[1, 0, 1], [0, 1, 0], [1, 0, -1]].",
    "output": "import numpy as np\n\nv = np.array([2, -2, 1])\nB = np.array([[1, 0, 1], [0, 1, 0], [1, 0, -1]])\nv_B = np.linalg.inv(B) @ v\nprint(\"v in basis B:\", v_B)"
  },
  {
    "input": "Let T rotate vectors by 180 degrees. Find the matrix representation in standard basis and in B = [[1, 1], [1, -1]].",
    "output": "import numpy as np\n\nT_std = -np.eye(2)\nB = np.array([[1, 1], [1, -1]])\nT_B = np.linalg.inv(B) @ T_std @ B\nprint(\"T in standard basis:\\n\", T_std)\nprint(\"T in basis B:\\n\", T_B)"
  },
  {
    "input": "Given A = [[1, 4], [2, 3]], find its matrix in the eigenbasis of A.",
    "output": "import numpy as np\n\nA = np.array([[1, 4], [2, 3]])\nevals, evecs = np.linalg.eig(A)\nA_diag = np.linalg.inv(evecs) @ A @ evecs\nprint(\"A in its eigenbasis:\\n\", A_diag)"
  },
  {
    "input": "Let B and C be two bases for \u211d\u00b2: B = [[2, 1], [1, 1]], C = [[1, 0], [0, 2]]. Find the transition matrix from B to C.",
    "output": "import numpy as np\n\nB = np.array([[2, 1], [1, 1]])\nC = np.array([[1, 0], [0, 2]])\nT = np.linalg.inv(C) @ B\nprint(\"Transition matrix from B to C:\\n\", T)"
  },
  {
    "input": "Given a transformation T: \u211d\u00b2 \u2192 \u211d\u00b2 defined by T(x, y) = (x + y, x - y), find its matrix in the standard basis.",
    "output": "import numpy as np\n\nT = np.array([[1, 1], [1, -1]])\nprint(\"Matrix of T in standard basis:\\n\", T)"
  },
  {
    "input": "Convert the coordinates [1, 0, -1] from basis B = [[1, 1, 0], [0, 1, 1], [1, 0, 1]] to standard basis.",
    "output": "import numpy as np\n\nB = np.array([[1, 1, 0], [0, 1, 1], [1, 0, 1]])\nv_B = np.array([1, 0, -1])\nv_std = B @ v_B\nprint(\"Vector in standard basis:\", v_std)"
  },
  {
    "input": "The matrix A = [[0, 1], [-1, 0]] represents rotation. Find a basis in which it becomes diagonal (if possible).",
    "output": "import numpy as np\n\nA = np.array([[0, 1], [-1, 0]])\nevals, evecs = np.linalg.eig(A)\nprint(\"Eigenvalues:\", evals)\nprint(\"Eigenvectors (possibly complex):\\n\", evecs)"
  },
  {
    "input": "Find the coordinates of vector [3, 3] in the orthonormal basis B = [[1/\u221a2, 1/\u221a2], [-1/\u221a2, 1/\u221a2]].",
    "output": "import numpy as np\n\nv = np.array([3, 3])\nB = np.array([[1/np.sqrt(2), 1/np.sqrt(2)], [-1/np.sqrt(2), 1/np.sqrt(2)]])\nv_B = B @ v\nprint(\"Coordinates in basis B:\", v_B)"
  },
  {
    "input": "Let v = [4, -1], and B = [[2, 3], [1, 4]]. Find v in coordinates of B and then reconstruct v from those coordinates.",
    "output": "import numpy as np\n\nB = np.array([[2, 3], [1, 4]])\nv = np.array([4, -1])\nv_B = np.linalg.inv(B) @ v\nv_reconstructed = B @ v_B\nprint(\"v in basis B:\", v_B)\nprint(\"Reconstructed v:\", v_reconstructed)"
  },
  {
    "input": "Find the matrix representation of projection onto x-axis in basis B = [[1, 0], [1, 1]].",
    "output": "import numpy as np\n\nP_std = np.array([[1, 0], [0, 0]])\nB = np.array([[1, 0], [1, 1]])\nP_B = np.linalg.inv(B) @ P_std @ B\nprint(\"Projection in basis B:\\n\", P_B)"
  },
  {
    "input": "Given a 3D transformation T represented by A = [[1,0,0],[0,2,0],[0,0,3]], find A in basis B = [[1,1,0],[0,1,1],[1,0,1]].",
    "output": "import numpy as np\n\nA = np.diag([1,2,3])\nB = np.array([[1,1,0],[0,1,1],[1,0,1]])\nA_B = np.linalg.inv(B) @ A @ B\nprint(\"A in basis B:\\n\", A_B)"
  },
  {
    "input": "Let T(x, y) = (2x + y, x - y). Find the matrix of T in basis B = [[1, 1], [0, 1]].",
    "output": "import numpy as np\n\nA = np.array([[2, 1], [1, -1]])\nB = np.array([[1, 1], [0, 1]])\nT_B = np.linalg.inv(B) @ A @ B\nprint(\"T in basis B:\\n\", T_B)"
  },
  {
    "input": "Diagonalize the matrix A = [[6, 2], [2, 3]].",
    "output": "import numpy as np\n\nA = np.array([[6, 2], [2, 3]])\nevals, evecs = np.linalg.eig(A)\nD = np.linalg.inv(evecs) @ A @ evecs\nprint(\"Diagonal matrix:\\n\", D)"
  },
  {
    "input": "Let vector v = [1, 2] be in coordinates of basis B = [[3, 1], [1, 2]]. Convert it to standard basis.",
    "output": "import numpy as np\n\nB = np.array([[3, 1], [1, 2]])\nv_B = np.array([1, 2])\nv_std = B @ v_B\nprint(\"v in standard basis:\", v_std)"
  },
  {
    "input": "Let T: \u211d\u00b2 \u2192 \u211d\u00b2 be reflection over y-axis. Express T in basis B = [[1, 0], [1, 1]].",
    "output": "import numpy as np\n\nT_std = np.array([[-1, 0], [0, 1]])\nB = np.array([[1, 0], [1, 1]])\nT_B = np.linalg.inv(B) @ T_std @ B\nprint(\"T in basis B:\\n\", T_B)"
  },
  {
    "input": "Let T: \u211d\u00b2 \u2192 \u211d\u00b2 be defined as T(x, y) = (3x - y, x + 4y). Diagonalize T, if possible. If not, compute its Jordan form.",
    "output": "import sympy as sp\n\nx, y = sp.symbols('x y')\nA = sp.Matrix([[3, -1], [1, 4]])\nP, J = A.jordan_form()\nprint(\"Jordan Form J:\")\nsp.pprint(J)\nprint(\"Transformation Matrix P:\")\nsp.pprint(P)"
  },
  {
    "input": "Let f(x) = 3 + 2x - x^2 in basis B = {1 - x, x, x^2}. Express f in coordinates of B.",
    "output": "import numpy as np\n\nB = np.array([[1, -1, 0], [0, 1, 0], [0, 0, 1]]).T\nf = np.array([3, 2, -1])\nf_B = np.linalg.inv(B) @ f\nprint(\"f(x) in basis B:\", f_B)"
  },
  {
    "input": "Given A = [[1, 1], [0, 1]], find a basis where A is not diagonal but is upper triangular, and compute A in that basis.",
    "output": "import numpy as np\n\nA = np.array([[1, 1], [0, 1]])\nevals, evecs = np.linalg.eig(A)\nA_jordan = np.linalg.inv(evecs) @ A @ evecs\nprint(\"Jordan form of A:\\n\", A_jordan)"
  },
  {
    "input": "Let B be the basis {1, x, x^2} and T: f(x) \u21a6 f''(x). Find the matrix of T in basis B.",
    "output": "import numpy as np\n\nT = np.array([[0, 0, 2], [0, 0, 0], [0, 0, 0]])\nprint(\"Matrix of f'' in basis {1, x, x^2}:\", T)"
  },
  {
    "input": "Let v = [1, 2, 3] and B = [[1, 1, 0], [0, 1, 1], [1, 0, 1]]. Verify B is a basis and express v in basis B.",
    "output": "import numpy as np\n\nv = np.array([1, 2, 3])\nB = np.array([[1, 1, 0], [0, 1, 1], [1, 0, 1]])\nif np.linalg.matrix_rank(B) == 3:\n    v_B = np.linalg.inv(B) @ v\n    print(\"v in basis B:\", v_B)\nelse:\n    print(\"B is not a valid basis.\")"
  },
  {
    "input": "Let M be the space of 2x2 symmetric matrices. Find a basis for M and represent A = [[1, 2], [2, 3]] in this basis.",
    "output": "import numpy as np\n\n# Basis: E1 = [[1,0],[0,0]], E2 = [[0,1],[1,0]], E3 = [[0,0],[0,1]]\nA = np.array([[1, 2], [2, 3]])\ncoords = [A[0,0], A[0,1], A[1,1]]\nprint(\"Coordinates of A in symmetric matrix basis:\", coords)"
  },
  {
    "input": "Let T: \u211d\u00b3 \u2192 \u211d\u00b3 be defined by T(x, y, z) = (x + y, y + z, x + z). Find its matrix and diagonalize it if possible.",
    "output": "import numpy as np\n\nA = np.array([[1, 1, 0], [0, 1, 1], [1, 0, 1]])\nevals, evecs = np.linalg.eig(A)\nprint(\"Eigenvalues:\", evals)\nprint(\"Eigenvectors:\\n\", evecs)"
  },
  {
    "input": "Let B = [[1, 2], [2, 4]]. Is B a valid basis for \u211d\u00b2? Justify with rank.",
    "output": "import numpy as np\n\nB = np.array([[1, 2], [2, 4]])\nrank = np.linalg.matrix_rank(B)\nprint(\"Rank of B:\", rank)\nprint(\"Valid basis:\" if rank == 2 else \"B is linearly dependent\")"
  },
  {
    "input": "Find the matrix of the Laplace operator (\u2202\u00b2/\u2202x\u00b2) on basis {1, x, x\u00b2, x\u00b3}.",
    "output": "import numpy as np\n\nL = np.array([[0, 0, 2, 0], [0, 0, 0, 6], [0, 0, 0, 0], [0, 0, 0, 0]])\nprint(\"Laplace operator matrix on {1, x, x\u00b2, x\u00b3}:\", L)"
  },
  {
    "input": "Let A = [[2, 0], [0, 3]], B = [[1, 2], [0, 1]]. Compute A in basis B and its inverse in that basis.",
    "output": "import numpy as np\n\nA = np.array([[2, 0], [0, 3]])\nB = np.array([[1, 2], [0, 1]])\nP = B\nP_inv = np.linalg.inv(P)\nA_B = P_inv @ A @ P\nA_inv_B = np.linalg.inv(A_B)\nprint(\"A in basis B:\\n\", A_B)\nprint(\"Inverse of A in basis B:\\n\", A_inv_B)"
  },
  {
    "input": "Let v = 3x + 4x\u00b2. Express in B = {x - 1, x\u00b2 + x}.",
    "output": "import numpy as np\n\n# Solve for a,b such that 3x + 4x\u00b2 = a(x - 1) + b(x\u00b2 + x)\n# => a*x - a + b*x\u00b2 + b*x = (a + b)x + b*x\u00b2 - a = 3x + 4x\u00b2\n# Match coefficients: a + b = 3, b = 4 => a = -1\nv_B = np.array([-1, 4])\nprint(\"Coordinates in basis B:\", v_B)"
  },
  {
    "input": "Let A = [[1, 1], [0, 1]]. Is A diagonalizable? If not, find its Jordan form.",
    "output": "import numpy as np\n\nA = np.array([[1, 1], [0, 1]])\nevals, evecs = np.linalg.eig(A)\nprint(\"Eigenvalues:\", evals)\nprint(\"A is diagonalizable:\" if np.linalg.matrix_rank(evecs) == 2 else \"No, Jordan form needed\")"
  },
  {
    "input": "Let v = [1, 0, -1] in standard basis. Convert to basis B = [[1, 1, 0], [1, -1, 0], [0, 0, 1]].",
    "output": "import numpy as np\n\nv = np.array([1, 0, -1])\nB = np.array([[1, 1, 0], [1, -1, 0], [0, 0, 1]])\nv_B = np.linalg.inv(B) @ v\nprint(\"v in basis B:\", v_B)"
  },
  {
    "input": "Find the matrix representing T(f) = f' in the basis {1, x, x\u00b2, x\u00b3}.",
    "output": "import numpy as np\n\nT = np.array([[0, 1, 0, 0], [0, 0, 2, 0], [0, 0, 0, 3], [0, 0, 0, 0]])\nprint(\"Matrix of derivative operator:\", T)"
  },
  {
    "input": "Let v = [3, -1] in basis B = [[2, 1], [1, 3]]. Find v in standard basis and then verify it satisfies the transformation matrix A = [[1,2],[3,4]] in that basis.",
    "output": "import numpy as np\n\nB = np.array([[2, 1], [1, 3]])\nv_B = np.array([3, -1])\nv_std = B @ v_B\nA = np.array([[1,2],[3,4]])\nAv = A @ v_std\nprint(\"v in standard basis:\", v_std)\nprint(\"A*v:\", Av)"
  },
  {
    "input": "Given T(x,y) = (x + 2y, 3x + 4y), find matrix of T in eigenbasis.",
    "output": "import numpy as np\n\nA = np.array([[1,2],[3,4]])\nevals, evecs = np.linalg.eig(A)\nT_diag = np.linalg.inv(evecs) @ A @ evecs\nprint(\"T in eigenbasis:\\n\", T_diag)"
  },
  {
    "input": "Is the set {[1, 1, 1], [1, 0, -1], [0, 1, 1]} a basis? Justify using determinant.",
    "output": "import numpy as np\n\nB = np.array([[1, 1, 1], [1, 0, -1], [0, 1, 1]])\ndet = np.linalg.det(B)\nprint(\"Determinant:\", det)\nprint(\"Valid basis:\" if abs(det) > 1e-6 else \"Linearly dependent\")"
  },
  {
    "input": "Let T be the integral operator: T(f) = \u222bf from 0 to x. Represent T on {1, x, x\u00b2}.",
    "output": "import numpy as np\n\n# T(1) = x, T(x) = x\u00b2/2, T(x\u00b2) = x\u00b3/3\n# Coefficients in {1, x, x\u00b2, x\u00b3}\nT = np.array([[0, 0, 0], [1, 0, 0], [0, 0.5, 0]])\nprint(\"Integral operator matrix:\", T)"
  },
  {
    "input": "Let v = [1, 2, 3] and B is an orthonormal basis via Gram-Schmidt from [[1, 0, 1], [1, 1, 0], [0, 1, 1]]. Express v in B.",
    "output": "import numpy as np\nfrom scipy.linalg import orth\n\nraw = np.array([[1, 0, 1], [1, 1, 0], [0, 1, 1]]).T\nB = orth(raw)\nv = np.array([1, 2, 3])\nv_B = B.T @ v\nprint(\"v in orthonormal basis:\", v_B)"
  },
  {
    "input": "Let A be a matrix whose columns are eigenvectors of T. Show that the matrix of T in this basis is diagonal.",
    "output": "import numpy as np\n\nT = np.array([[5, 4], [1, 2]])\nevals, evecs = np.linalg.eig(T)\nD = np.linalg.inv(evecs) @ T @ evecs\nprint(\"Matrix of T in its eigenbasis:\\n\", D)"
  },
  {
    "input": "Let B = [[1, 2], [3, 6]]. Show this is not a valid basis for \u211d\u00b2 using rank and determinant.",
    "output": "import numpy as np\n\nB = np.array([[1, 2], [3, 6]])\ndet = np.linalg.det(B)\nrank = np.linalg.matrix_rank(B)\nprint(\"Determinant:\", det)\nprint(\"Rank:\", rank)\nprint(\"Valid basis:\" if rank == 2 else \"Invalid basis\")"
  },
  {
    "input": "Let f(x) = 5 + 3x - x\u00b2 + x\u00b3. Express it in basis {1+x, x\u00b2 - 1, x\u00b3}.",
    "output": "import sympy as sp\n\nx = sp.Symbol('x')\na, b, c = sp.symbols('a b c')\nf = 5 + 3*x - x**2 + x**3\nb1 = 1 + x\nb2 = x**2 - 1\nb3 = x**3\nexpr = f - (a*b1 + b*b2 + c*b3)\ncoeffs = sp.linsolve([sp.expand(expr)], (a, b, c))\nprint(\"Coordinates in custom basis:\", list(coeffs)[0])"
  },
  {
    "input": "Let T: \u211d\u00b3 \u2192 \u211d\u00b3 be a linear map with matrix A = [[0, 1, 0], [0, 0, 1], [0, 0, 0]]. Show that A is not diagonalizable, and find its Jordan canonical form.",
    "output": "import numpy as np\nfrom scipy.linalg import eig\n\nA = np.array([[0, 1, 0], [0, 0, 1], [0, 0, 0]])\nevals, evecs = eig(A)\nprint(\"Eigenvalues:\", evals)\nprint(\"Rank of eigenvectors:\", np.linalg.matrix_rank(evecs))\n# Not diagonalizable if rank < n"
  },
  {
    "input": "Let f(x) = x\u00b3 + 2x\u00b2 - x + 5. Find its coordinate vector relative to B = {x\u00b3 + x, x\u00b2 - 1, x - 2, 1}.",
    "output": "import sympy as sp\n\nx = sp.Symbol('x')\nf = x**3 + 2*x**2 - x + 5\nB = [x**3 + x, x**2 - 1, x - 2, 1]\na, b, c, d = sp.symbols('a b c d')\neq = sp.Eq(f, a*B[0] + b*B[1] + c*B[2] + d*B[3])\ncoeffs = sp.solve(eq, (a, b, c, d))\nprint(\"Coordinates in B:\", coeffs)"
  },
  {
    "input": "Let T be defined on \u211d\u2074 by projecting any vector onto the subspace W spanned by [1,1,1,1]. Find the matrix of T.",
    "output": "import numpy as np\n\nw = np.array([[1], [1], [1], [1]])\nP = (w @ w.T) / (w.T @ w)\nprint(\"Projection matrix T onto W:\", P)"
  },
  {
    "input": "In inner product space V with basis B = {[1,0], [1,1]}, find the Gram matrix of B.",
    "output": "import numpy as np\n\nB = np.array([[1, 1], [0, 1]])\nG = B.T @ B\nprint(\"Gram matrix of B:\", G)"
  },
  {
    "input": "Let A be a 3x3 matrix with eigenvalues 2 (multiplicity 3). If A is not diagonalizable, find its Jordan form and generalized eigenspaces.",
    "output": "import numpy as np\n\nA = np.array([[2,1,0],[0,2,1],[0,0,2]])\nevals, evecs = np.linalg.eig(A)\nprint(\"Eigenvalues:\", evals)\nprint(\"Jordan form structure for repeated root with chain length 3\")"
  },
  {
    "input": "Given the space of polynomials P\u2084, define the differential operator D\u00b2. Find the matrix of D\u00b2 relative to the basis {1, x, x\u00b2, x\u00b3, x\u2074}.",
    "output": "import numpy as np\n\nD2 = np.zeros((5, 5))\nD2[0][2] = 2\nD2[1][3] = 6\nD2[2][4] = 12\nprint(\"Matrix of second derivative D\u00b2:\", D2)"
  },
  {
    "input": "Find the change-of-basis matrix from B = {1, x, x\u00b2} to B' = {x\u00b2, x, 1}.",
    "output": "import numpy as np\n\nP = np.array([[0, 0, 1], [0, 1, 0], [1, 0, 0]])\nprint(\"Change of basis matrix B to B':\", P)"
  },
  {
    "input": "Let V = M\u2082\u00d7\u2082, the space of 2x2 matrices. Define B = {[1,0;0,0], [0,1;0,0], [0,0;1,0], [0,0;0,1]}. Find coordinates of A = [[2,3],[4,5]] in B.",
    "output": "import numpy as np\n\nA = np.array([[2,3],[4,5]])\ncoords = A.flatten()\nprint(\"Coordinates of A in standard matrix basis:\", coords)"
  },
  {
    "input": "Given a symmetric bilinear form B on \u211d\u00b2 defined by B(x,y) = x\u2081y\u2081 + 2x\u2081y\u2082 + 2x\u2082y\u2081 + 4x\u2082y\u2082, find its matrix and diagonalize it.",
    "output": "import numpy as np\n\nA = np.array([[1, 2], [2, 4]])\nevals, evecs = np.linalg.eigh(A)\nprint(\"Diagonal form (eigenvalues):\", evals)"
  },
  {
    "input": "Let A be a 4x4 real matrix such that A = PDP\u207b\u00b9, where D is diagonal. Construct an example where P is not orthogonal.",
    "output": "import numpy as np\n\nD = np.diag([1, 2, 3, 4])\nP = np.array([[1, 1, 1, 1],\n              [0, 1, 1, 1],\n              [0, 0, 1, 1],\n              [0, 0, 0, 1]])  # Upper triangular, non-orthogonal but invertible\nA = P @ D @ np.linalg.inv(P)\nprint(\"Matrix A:\")\nprint(A)"
  },
  {
    "input": "Let f(x) = x\u00b3 + 1. Express f in basis B = {1 + x, x + x\u00b2, x\u00b2 + x\u00b3, x\u00b3}.",
    "output": "import sympy as sp\n\nx = sp.Symbol('x')\nf = x**3 + 1\nB = [1 + x, x + x**2, x**2 + x**3, x**3]\na,b,c,d = sp.symbols('a b c d')\neq = sp.Eq(f, a*B[0] + b*B[1] + c*B[2] + d*B[3])\ncoeffs = sp.solve(eq, (a,b,c,d))\nprint(\"Coordinates in B:\", coeffs)"
  },
  {
    "input": "Let V be \u211d\u00b3 with the inner product \u27e8x,y\u27e9 = x\u1d40Wy, where W = [[2,0,0],[0,3,0],[0,0,4]]. Find an orthonormal basis under this product.",
    "output": "import numpy as np\nfrom scipy.linalg import sqrtm\n\nW = np.diag([2,3,4])\nB = np.eye(3)\nS = np.linalg.inv(sqrtm(W))\northo = S @ B\nprint(\"Orthonormal basis under W:\", ortho)"
  },
  {
    "input": "Let f be a linear functional on P\u2082 defined by f(p) = p(1) + p'(2). Find its coordinate in dual basis to {1, x, x\u00b2}.",
    "output": "import sympy as sp\n\nx = sp.Symbol('x')\nbasis = [1, x, x**2]\nfunctionals = [sp.lambdify(x, b, 'numpy') for b in basis]\np = sp.Symbol('p')\ncoords = [1 + 0, 0 + 1, 0 + 4]  # f(1) + derivative(2)\nprint(\"Coordinate in dual basis:\", coords)"
  },
  {
    "input": "Let A = [[0,1],[-2,-3]]. Find a basis of generalized eigenvectors and the Jordan form of A.",
    "output": "import numpy as np\n\nA = np.array([[0,1],[-2,-3]])\nevals, evecs = np.linalg.eig(A)\nprint(\"Eigenvalues:\", evals)\n# Check for defective eigenvalues by computing nullity of (A - \u03bbI)^k"
  },
  {
    "input": "Let T: \u211d\u00b2 \u2192 \u211d\u00b2 be rotation by \u03b8 = \u03c0/4. Find the matrix in standard basis and find a basis in which T becomes a scalar multiple of identity.",
    "output": "import numpy as np\n\n\u03b8 = np.pi/4\nA = np.array([[np.cos(\u03b8), -np.sin(\u03b8)], [np.sin(\u03b8), np.cos(\u03b8)]])\nprint(\"Rotation matrix:\", A)\n# Eigenbasis does not exist in \u211d; diagonalizable over \u2102 only"
  },
  {
    "input": "Find a basis B of \u211d\u00b2 such that the linear transformation T(x, y) = (5x + y, x + 5y) has matrix [[6, 0], [0, 4]] in B.",
    "output": "import numpy as np\n\nA = np.array([[5,1],[1,5]])\nevals, evecs = np.linalg.eig(A)\nprint(\"Eigenvectors give the required basis B:\\n\", evecs)"
  },
  {
    "input": "Let A = [[1, 1], [0, 1]]. Compute the minimal polynomial and explain why it affects diagonalizability.",
    "output": "import numpy as np\n\nA = np.array([[1,1],[0,1]])\n# Characteristic: (\u03bb-1)^2\n# Minimal: (\u03bb-1)^2 (not (\u03bb-1)) \u2192 not diagonalizable\nprint(\"Minimal polynomial: (x-1)^2\")"
  },
  {
    "input": "Given v = x + 2x\u00b2 and basis B = {x\u00b2, x\u00b2 + x, x + 1}, express v in B.",
    "output": "import sympy as sp\n\nx = sp.Symbol('x')\nv = x + 2*x**2\nB = [x**2, x**2 + x, x + 1]\na, b, c = sp.symbols('a b c')\neq = sp.Eq(v, a*B[0] + b*B[1] + c*B[2])\ncoeffs = sp.solve(eq, (a,b,c))\nprint(\"v in basis B:\", coeffs)"
  },
  {
    "input": "Let A be a symmetric matrix. Prove there exists an orthonormal basis in which A is diagonal.",
    "output": "print(\"By the spectral theorem, any real symmetric matrix is orthogonally diagonalizable. Thus there exists an orthonormal basis of eigenvectors.\")"
  },
  {
    "input": "Let A = [[1,2],[3,4]]. Find a matrix P such that P\u207b\u00b9AP is diagonal if possible.",
    "output": "import numpy as np\n\nA = np.array([[1,2],[3,4]])\nevals, evecs = np.linalg.eig(A)\nif np.linalg.matrix_rank(evecs) == 2:\n    D = np.diag(evals)\n    print(\"Diagonal matrix:\", D)\nelse:\n    print(\"Not diagonalizable\")"
  },
  {
    "input": "Let T: V \u2192 V be a linear transformation with known basis B. Given [T]_B = [[1,1],[0,1]], find generalized eigenvector of rank 2.",
    "output": "import numpy as np\n\nA = np.array([[1,1],[0,1]])\n# Solve (A - I)^2 v = 0 but (A - I) v \u2260 0\nv = np.array([1,0])\nprint(\"Generalized eigenvector:\", v)"
  },
  {
    "input": "Let B be an orthogonal matrix. Show that change of basis with B preserves dot products.",
    "output": "print(\"If B is orthogonal, then B\u1d40B = I. So \u27e8Bx, By\u27e9 = x\u1d40B\u1d40By = x\u1d40y. Hence dot products are preserved.\")"
  },
  {
    "input": "Let A = [[2,0,0],[0,3,4],[0,0,3]]. Find the Jordan form and basis for each generalized eigenspace.",
    "output": "import numpy as np\n\nA = np.array([[2,0,0],[0,3,4],[0,0,3]])\nevals, evecs = np.linalg.eig(A)\nprint(\"Jordan form has 1 block for 2 and a 2x2 Jordan block for 3\")"
  },
  {
    "input": "In robotics, a robot arm has local coordinates [2, 3] in its own frame. The base frame is rotated 90 degrees counter-clockwise. Find the coordinates in the base frame.",
    "output": "import numpy as np\n\nv_local = np.array([2, 3])\nR = np.array([[0, -1], [1, 0]])  # 90 degree CCW rotation\nv_base = R @ v_local\nprint(\"Coordinates in base frame:\", v_base)"
  },
  {
    "input": "In computer graphics, a point is in a rotated frame B with basis vectors b1 = [1, 1], b2 = [-1, 1]. Find the coordinates of v = [2, 3] in B.",
    "output": "import numpy as np\n\nB = np.array([[1, -1], [1, 1]])\nv = np.array([2, 3])\nv_B = np.linalg.inv(B) @ v\nprint(\"Coordinates in basis B:\", v_B)"
  },
  {
    "input": "In GPS systems, the Earth-centered coordinate system is being rotated 45 degrees for local computation. Given vector [1,0], find its new coordinates.",
    "output": "import numpy as np\n\n\u03b8 = np.deg2rad(45)\nR = np.array([[np.cos(\u03b8), -np.sin(\u03b8)], [np.sin(\u03b8), np.cos(\u03b8)]])\nv = np.array([1, 0])\nv_rot = R @ v\nprint(\"Rotated coordinates:\", v_rot)"
  },
  {
    "input": "In physics, a force vector F = [10, 5] N is applied in a rotated frame. Convert it to the standard frame if the rotated frame is 30 degrees clockwise.",
    "output": "import numpy as np\n\nF_rotated = np.array([10, 5])\n\u03b8 = -np.pi/6  # 30 degrees clockwise\nR = np.array([[np.cos(\u03b8), -np.sin(\u03b8)], [np.sin(\u03b8), np.cos(\u03b8)]])\nF_standard = R @ F_rotated\nprint(\"Force in standard frame:\", F_standard)"
  },
  {
    "input": "In computer vision, a camera's coordinate system is aligned with vectors [0.866, 0.5], [-0.5, 0.866]. Transform point [1,0] into this frame.",
    "output": "import numpy as np\n\nB = np.array([[0.866, -0.5], [0.5, 0.866]])\nv = np.array([1, 0])\nv_cam = np.linalg.inv(B) @ v\nprint(\"Point in camera frame:\", v_cam)"
  },
  {
    "input": "A wind vector [5, 2] m/s is measured in a rotated sensor frame. Convert it to the Earth frame with a 60-degree rotation.",
    "output": "import numpy as np\n\nv_sensor = np.array([5, 2])\n\u03b8 = np.deg2rad(60)\nR = np.array([[np.cos(\u03b8), -np.sin(\u03b8)], [np.sin(\u03b8), np.cos(\u03b8)]])\nv_earth = R @ v_sensor\nprint(\"Wind in Earth frame:\", v_earth)"
  },
  {
    "input": "In aerospace, convert velocity vector [300, 0] m/s from body frame to inertial frame with a yaw of 15 degrees.",
    "output": "import numpy as np\n\nv_body = np.array([300, 0])\nyaw = np.deg2rad(15)\nR = np.array([[np.cos(yaw), -np.sin(yaw)], [np.sin(yaw), np.cos(yaw)]])\nv_inertial = R @ v_body\nprint(\"Velocity in inertial frame:\", v_inertial)"
  },
  {
    "input": "A 3D model is defined in a local coordinate frame. Convert point [1, 2, 3] to global coordinates using rotation matrix R and translation t.",
    "output": "import numpy as np\n\nR = np.eye(3)  # Identity rotation for simplicity\nt = np.array([5, -2, 1])\nv_local = np.array([1, 2, 3])\nv_global = R @ v_local + t\nprint(\"Global coordinates:\", v_global)"
  },
  {
    "input": "In robotics, joint axis is defined in a different frame. Convert unit vector [0, 1, 0] using rotation matrix for pitch 45 degrees.",
    "output": "import numpy as np\n\n\u03b8 = np.deg2rad(45)\nR_pitch = np.array([[1,0,0],[0,np.cos(\u03b8),-np.sin(\u03b8)],[0,np.sin(\u03b8),np.cos(\u03b8)]])\naxis_local = np.array([0,1,0])\naxis_global = R_pitch @ axis_local\nprint(\"Axis in global frame:\", axis_global)"
  },
  {
    "input": "In augmented reality, project a point in world coordinates to camera coordinates using given transformation matrix T.",
    "output": "import numpy as np\n\nT = np.array([[0.9, 0, 0, 1], [0, 0.9, 0, 2], [0, 0, 0.9, 3], [0, 0, 0, 1]])\np_world = np.array([2, 3, 4, 1])\np_camera = T @ p_world\nprint(\"Point in camera coordinates:\", p_camera[:3])"
  },
  {
    "input": "A particle moves in a rotated reference frame. Given position [3, 4] in new frame rotated 60 degrees, convert to original frame.",
    "output": "import numpy as np\n\n\u03b8 = np.deg2rad(60)\nR = np.array([[np.cos(\u03b8), -np.sin(\u03b8)], [np.sin(\u03b8), np.cos(\u03b8)]])\nv_new = np.array([3, 4])\nv_original = R @ v_new\nprint(\"Position in original frame:\", v_original)"
  },
  {
    "input": "A car is moving in a 2D plane. The local velocity vector is [10, 0]. Find its global velocity after a 90 degree yaw.",
    "output": "import numpy as np\n\nv_local = np.array([10, 0])\n\u03b8 = np.pi/2\nR = np.array([[np.cos(\u03b8), -np.sin(\u03b8)], [np.sin(\u03b8), np.cos(\u03b8)]])\nv_global = R @ v_local\nprint(\"Velocity in global frame:\", v_global)"
  },
  {
    "input": "A satellite's orientation is described by rotation matrix R. Compute global vector of onboard sensor pointing along [0, 0, 1].",
    "output": "import numpy as np\n\nR = np.array([[0, -1, 0], [1, 0, 0], [0, 0, 1]])\nsensor_local = np.array([0, 0, 1])\nsensor_global = R @ sensor_local\nprint(\"Sensor in global frame:\", sensor_global)"
  },
  {
    "input": "In data science, reduce 3D vector to 2D using basis vectors e1 = [1,0,1], e2 = [0,1,1]. Express [2,3,5] in this basis.",
    "output": "import numpy as np\n\nB = np.array([[1,0],[0,1],[1,1]])\nv = np.array([2,3,5])\nv_B = np.linalg.lstsq(B, v, rcond=None)[0]\nprint(\"Coordinates in new basis:\", v_B)"
  },
  {
    "input": "In animation, convert a point from model space [1,2,1] to world space using rotation and translation.",
    "output": "import numpy as np\n\nR = np.eye(3)\nt = np.array([5, 5, 0])\np_model = np.array([1, 2, 1])\np_world = R @ p_model + t\nprint(\"World space coordinates:\", p_world)"
  },
  {
    "input": "In medical imaging, a 2D scan is rotated by 135 degrees. Convert the pixel vector [10, 0] to original coordinates.",
    "output": "import numpy as np\n\n\u03b8 = np.deg2rad(135)\nR = np.array([[np.cos(\u03b8), -np.sin(\u03b8)], [np.sin(\u03b8), np.cos(\u03b8)]])\nv_scan = np.array([10, 0])\nv_orig = R @ v_scan\nprint(\"Original pixel vector:\", v_orig)"
  },
  {
    "input": "In mechanical design, a vector [4,4,0] is aligned with a rotated part. Rotate it -45 degrees about z-axis to original orientation.",
    "output": "import numpy as np\n\n\u03b8 = -np.pi/4\nRz = np.array([[np.cos(\u03b8), -np.sin(\u03b8), 0], [np.sin(\u03b8), np.cos(\u03b8), 0], [0, 0, 1]])\nv = np.array([4, 4, 0])\nv_orig = Rz @ v\nprint(\"Original vector:\", v_orig)"
  },
  {
    "input": "In 3D printing, a part is designed in rotated frame. Convert vector [0, 5, 0] to printer base frame rotated 180\u00b0 about x-axis.",
    "output": "import numpy as np\n\n\u03b8 = np.pi\nRx = np.array([[1,0,0],[0,np.cos(\u03b8), -np.sin(\u03b8)],[0,np.sin(\u03b8), np.cos(\u03b8)]])\nv = np.array([0,5,0])\nv_base = Rx @ v\nprint(\"Vector in base frame:\", v_base)"
  },
  {
    "input": "A drone's local frame is rotated 60 degrees about z. Convert local position [2, 0, 0] to global frame.",
    "output": "import numpy as np\n\n\u03b8 = np.deg2rad(60)\nR = np.array([[np.cos(\u03b8), -np.sin(\u03b8), 0], [np.sin(\u03b8), np.cos(\u03b8), 0], [0, 0, 1]])\nv_local = np.array([2, 0, 0])\nv_global = R @ v_local\nprint(\"Global position:\", v_global)"
  },
  {
    "input": "In a wind tunnel simulation, a flow vector [1, -1] is rotated 45 degrees. Find the new vector.",
    "output": "import numpy as np\n\n\u03b8 = np.pi/4\nR = np.array([[np.cos(\u03b8), -np.sin(\u03b8)], [np.sin(\u03b8), np.cos(\u03b8)]])\nflow = np.array([1, -1])\nflow_rot = R @ flow\nprint(\"Rotated flow vector:\", flow_rot)"
  },
  {
    "input": "A weather balloon sends data in local frame. Convert acceleration vector [0.5, 0.5, 0.1] using 30\u00b0 pitch rotation.",
    "output": "import numpy as np\n\n\u03b8 = np.deg2rad(30)\nR_pitch = np.array([[1,0,0],[0,np.cos(\u03b8),-np.sin(\u03b8)],[0,np.sin(\u03b8),np.cos(\u03b8)]])\na_local = np.array([0.5, 0.5, 0.1])\na_global = R_pitch @ a_local\nprint(\"Acceleration in global frame:\", a_global)"
  },
  {
    "input": "In biomechanics, convert leg motion vector [3,0,0] from hip frame to world frame with 90\u00b0 yaw.",
    "output": "import numpy as np\n\n\u03b8 = np.deg2rad(90)\nR = np.array([[np.cos(\u03b8), -np.sin(\u03b8), 0],[np.sin(\u03b8), np.cos(\u03b8), 0],[0, 0, 1]])\nv_hip = np.array([3, 0, 0])\nv_world = R @ v_hip\nprint(\"Leg motion in world frame:\", v_world)"
  },
  {
    "input": "In 2D design, convert a point [6, 2] from rotated grid (45\u00b0) to Cartesian frame.",
    "output": "import numpy as np\n\n\u03b8 = np.deg2rad(45)\nR = np.array([[np.cos(\u03b8), -np.sin(\u03b8)],[np.sin(\u03b8), np.cos(\u03b8)]])\np_rot = np.array([6, 2])\np_cartesian = R @ p_rot\nprint(\"Point in Cartesian frame:\", p_cartesian)"
  },
  {
    "input": "In 3D modeling, rotate point [1,2,3] by 30\u00b0 about y-axis.",
    "output": "import numpy as np\n\n\u03b8 = np.deg2rad(30)\nRy = np.array([[np.cos(\u03b8), 0, np.sin(\u03b8)], [0,1,0], [-np.sin(\u03b8), 0, np.cos(\u03b8)]])\np = np.array([1,2,3])\np_rot = Ry @ p\nprint(\"Rotated point:\", p_rot)"
  },
  {
    "input": "In game development, a character moves along direction [1, 1] in a 2D rotated camera view (30\u00b0). Convert to world coordinates.",
    "output": "import numpy as np\n\nv_cam = np.array([1, 1])\n\u03b8 = np.deg2rad(30)\nR = np.array([[np.cos(\u03b8), -np.sin(\u03b8)], [np.sin(\u03b8), np.cos(\u03b8)]])\nv_world = R @ v_cam\nprint(\"Movement in world coordinates:\", v_world)"
  },
  {
    "input": "In aerospace engineering, a sensor frame is rotated 120\u00b0 about the z-axis. Convert vector [0, 1, 0] to inertial frame.",
    "output": "import numpy as np\n\n\u03b8 = np.deg2rad(120)\nRz = np.array([[np.cos(\u03b8), -np.sin(\u03b8), 0],[np.sin(\u03b8), np.cos(\u03b8), 0],[0, 0, 1]])\nv_sensor = np.array([0, 1, 0])\nv_inertial = Rz @ v_sensor\nprint(\"Vector in inertial frame:\", v_inertial)"
  },
  {
    "input": "In medical imaging, an MRI slice is rotated 90\u00b0. Convert coordinates [4, 5] in the rotated frame to standard orientation.",
    "output": "import numpy as np\n\nv_rotated = np.array([4, 5])\n\u03b8 = np.pi/2\nR = np.array([[np.cos(-\u03b8), -np.sin(-\u03b8)], [np.sin(-\u03b8), np.cos(-\u03b8)]])\nv_standard = R @ v_rotated\nprint(\"MRI coordinates in standard orientation:\", v_standard)"
  },
  {
    "input": "In space exploration, convert thrust vector [100, 0, 0] from spacecraft body frame to world frame (30\u00b0 pitch, 45\u00b0 yaw).",
    "output": "import numpy as np\n\npitch = np.deg2rad(30)\nyaw = np.deg2rad(45)\nRy = np.array([[np.cos(pitch), 0, np.sin(pitch)], [0,1,0], [-np.sin(pitch), 0, np.cos(pitch)]])\nRz = np.array([[np.cos(yaw), -np.sin(yaw), 0], [np.sin(yaw), np.cos(yaw), 0], [0,0,1]])\nR = Rz @ Ry\nv_body = np.array([100, 0, 0])\nv_world = R @ v_body\nprint(\"Thrust in world frame:\", v_world)"
  },
  {
    "input": "In 2D graphics, a sprite is drawn at [5, 2] in a rotated local frame. The frame is rotated 135\u00b0. Get global coordinates.",
    "output": "import numpy as np\n\nv_local = np.array([5, 2])\n\u03b8 = np.deg2rad(135)\nR = np.array([[np.cos(\u03b8), -np.sin(\u03b8)],[np.sin(\u03b8), np.cos(\u03b8)]])\nv_global = R @ v_local\nprint(\"Sprite global coordinates:\", v_global)"
  },
  {
    "input": "In control systems, convert state vector [1, 0] to new coordinates using transformation matrix [[0.6, 0.8], [-0.8, 0.6]].",
    "output": "import numpy as np\n\nT = np.array([[0.6, -0.8], [0.8, 0.6]])\nv = np.array([1, 0])\nv_new = T @ v\nprint(\"State in new coordinates:\", v_new)"
  },
  {
    "input": "A quadcopter has orientation with roll=30\u00b0, pitch=45\u00b0, yaw=60\u00b0. Convert [1,0,0] to global frame.",
    "output": "import numpy as np\n\nroll = np.deg2rad(30)\npitch = np.deg2rad(45)\nyaw = np.deg2rad(60)\nRx = np.array([[1,0,0], [0,np.cos(roll),-np.sin(roll)], [0,np.sin(roll),np.cos(roll)]])\nRy = np.array([[np.cos(pitch),0,np.sin(pitch)], [0,1,0], [-np.sin(pitch),0,np.cos(pitch)]])\nRz = np.array([[np.cos(yaw), -np.sin(yaw), 0], [np.sin(yaw), np.cos(yaw), 0], [0,0,1]])\nR = Rz @ Ry @ Rx\nv = np.array([1,0,0])\nv_global = R @ v\nprint(\"Vector in global frame:\", v_global)"
  },
  {
    "input": "In 3D animation, an object has local coordinates [1,2,3]. The world transformation matrix includes rotation and translation. Apply it.",
    "output": "import numpy as np\n\nR = np.eye(3)\nt = np.array([4, 5, 6])\np_local = np.array([1, 2, 3])\np_world = R @ p_local + t\nprint(\"Object in world coordinates:\", p_world)"
  },
  {
    "input": "In LIDAR mapping, a scan point [0,10] is in sensor frame. Rotate 270\u00b0 to map frame.",
    "output": "import numpy as np\n\n\u03b8 = np.deg2rad(270)\nR = np.array([[np.cos(\u03b8), -np.sin(\u03b8)], [np.sin(\u03b8), np.cos(\u03b8)]])\npoint_sensor = np.array([0,10])\npoint_map = R @ point_sensor\nprint(\"LIDAR point in map frame:\", point_map)"
  },
  {
    "input": "In a CAD system, express vector [4, 4, 4] in a new orthonormal basis with b1 = [1,0,0], b2 = [0,1,1]/\u221a2, b3 = [0,1,-1]/\u221a2.",
    "output": "import numpy as np\n\nb1 = np.array([1,0,0])\nb2 = np.array([0,1,1])/np.sqrt(2)\nb3 = np.array([0,1,-1])/np.sqrt(2)\nB = np.column_stack((b1, b2, b3))\nv = np.array([4, 4, 4])\nv_new = np.linalg.inv(B) @ v\nprint(\"Vector in new basis:\", v_new)"
  },
  {
    "input": "A satellite sends a vector [5,5,0] in rotated orbital frame (90\u00b0 about y). Convert to Earth-centered frame.",
    "output": "import numpy as np\n\n\u03b8 = np.pi/2\nRy = np.array([[np.cos(\u03b8),0,np.sin(\u03b8)], [0,1,0], [-np.sin(\u03b8),0,np.cos(\u03b8)]])\nv_orbital = np.array([5, 5, 0])\nv_earth = Ry @ v_orbital\nprint(\"Vector in Earth-centered frame:\", v_earth)"
  },
  {
    "input": "In navigation, rotate position vector [1, 1, 0] by -30\u00b0 around z-axis.",
    "output": "import numpy as np\n\n\u03b8 = -np.deg2rad(30)\nRz = np.array([[np.cos(\u03b8), -np.sin(\u03b8), 0],[np.sin(\u03b8), np.cos(\u03b8), 0],[0, 0, 1]])\nv = np.array([1, 1, 0])\nv_rotated = Rz @ v\nprint(\"Position after rotation:\", v_rotated)"
  },
  {
    "input": "In a drone sim, convert local velocity [1, 2] m/s to inertial frame with 135\u00b0 yaw.",
    "output": "import numpy as np\n\n\u03b8 = np.deg2rad(135)\nR = np.array([[np.cos(\u03b8), -np.sin(\u03b8)], [np.sin(\u03b8), np.cos(\u03b8)]])\nv_local = np.array([1, 2])\nv_inertial = R @ v_local\nprint(\"Velocity in inertial frame:\", v_inertial)"
  },
  {
    "input": "In control theory, change coordinates of x = [3, 2] using basis [[1, 1], [1, -1]].",
    "output": "import numpy as np\n\nB = np.array([[1, 1], [1, -1]])\nx = np.array([3, 2])\nx_new = np.linalg.inv(B) @ x\nprint(\"State in new coordinates:\", x_new)"
  },
  {
    "input": "In physics, a vector is [0, 9.8] in Earth frame. Find components in frame rotated 45\u00b0 clockwise.",
    "output": "import numpy as np\n\n\u03b8 = -np.pi/4\nR = np.array([[np.cos(\u03b8), -np.sin(\u03b8)], [np.sin(\u03b8), np.cos(\u03b8)]])\ng = np.array([0, 9.8])\ng_rotated = R @ g\nprint(\"Gravity in rotated frame:\", g_rotated)"
  },
  {
    "input": "In AR, a virtual object moves [2, 0] in user frame. Convert to global frame (60\u00b0 rotation).",
    "output": "import numpy as np\n\nv_user = np.array([2, 0])\n\u03b8 = np.deg2rad(60)\nR = np.array([[np.cos(\u03b8), -np.sin(\u03b8)], [np.sin(\u03b8), np.cos(\u03b8)]])\nv_global = R @ v_user\nprint(\"Movement in global frame:\", v_global)"
  },
  {
    "input": "In data compression, project [4, 4] onto basis [1, 1], [-1, 1].",
    "output": "import numpy as np\n\nB = np.array([[1, -1], [1, 1]])\nv = np.array([4, 4])\nv_new = np.linalg.inv(B) @ v\nprint(\"Vector in compressed basis:\", v_new)"
  },
  {
    "input": "In aerospace dynamics, express [1,1,0] in a new frame defined by orthogonal axes u=[1,0,0], v=[0,1,0], w=[0,0,1].",
    "output": "import numpy as np\n\nB = np.eye(3)\nv = np.array([1,1,0])\nv_new = np.linalg.inv(B) @ v\nprint(\"Vector in new frame:\", v_new)"
  },
  {
    "input": "A robot base rotates 180\u00b0 around z-axis. Convert local point [1, 2, 0] to world frame.",
    "output": "import numpy as np\n\n\u03b8 = np.pi\nRz = np.array([[np.cos(\u03b8), -np.sin(\u03b8), 0],[np.sin(\u03b8), np.cos(\u03b8), 0],[0, 0, 1]])\np_local = np.array([1,2,0])\np_world = Rz @ p_local\nprint(\"Point in world frame:\", p_world)"
  },
  {
    "input": "In VR, head position vector [0, 1, 0] is rotated 90\u00b0 left. Find its new orientation.",
    "output": "import numpy as np\n\n\u03b8 = np.pi/2\nR = np.array([[np.cos(\u03b8), 0, np.sin(\u03b8)],[0,1,0],[-np.sin(\u03b8), 0, np.cos(\u03b8)]])\nv = np.array([0, 1, 0])\nv_new = R @ v\nprint(\"Head position after rotation:\", v_new)"
  },
  {
    "input": "In computer graphics, rotate vector [1, 0, 0] 120\u00b0 around axis [0, 0, 1].",
    "output": "import numpy as np\n\n\u03b8 = np.deg2rad(120)\nRz = np.array([[np.cos(\u03b8), -np.sin(\u03b8), 0],[np.sin(\u03b8), np.cos(\u03b8), 0],[0, 0, 1]])\nv = np.array([1, 0, 0])\nv_rotated = Rz @ v\nprint(\"Rotated vector:\", v_rotated)"
  },
  {
    "input": "A matrix A is expressed in basis B = [[2,0],[0,3]]. Change basis to standard basis.",
    "output": "import numpy as np\n\nA_B = np.array([[1,2],[3,4]])\nB = np.array([[2,0],[0,3]])\nA_std = B @ A_B @ np.linalg.inv(B)\nprint(\"Matrix in standard basis:\", A_std)"
  },
  {
    "input": "In signal processing, change vector [3, 3] to frequency basis [[1,1], [1,-1]].",
    "output": "import numpy as np\n\nF = np.array([[1,1], [1,-1]])\nv = np.array([3,3])\nv_freq = np.linalg.inv(F) @ v\nprint(\"Vector in frequency basis:\", v_freq)"
  },
  {
    "input": "A robotic arm has a local coordinate [2, -1, 3] in the wrist frame. The arm is rotated 45\u00b0 about the x-axis, then 60\u00b0 about the y-axis. Find the position in the base frame.",
    "output": "import numpy as np\n\nx = np.deg2rad(45)\ny = np.deg2rad(60)\nRx = np.array([[1, 0, 0], [0, np.cos(x), -np.sin(x)], [0, np.sin(x), np.cos(x)]])\nRy = np.array([[np.cos(y), 0, np.sin(y)], [0, 1, 0], [-np.sin(y), 0, np.cos(y)]])\nR = Ry @ Rx\nv_local = np.array([2, -1, 3])\nv_base = R @ v_local\nprint(\"Position in base frame:\", v_base)"
  },
  {
    "input": "In satellite telemetry, a vector is given in a basis rotated 30\u00b0 about z, then 45\u00b0 about y, then 60\u00b0 about x. Transform [0, 1, 0] into Earth frame.",
    "output": "import numpy as np\n\nz = np.deg2rad(30)\ny = np.deg2rad(45)\nx = np.deg2rad(60)\nRz = np.array([[np.cos(z), -np.sin(z), 0], [np.sin(z), np.cos(z), 0], [0, 0, 1]])\nRy = np.array([[np.cos(y), 0, np.sin(y)], [0, 1, 0], [-np.sin(y), 0, np.cos(y)]])\nRx = np.array([[1, 0, 0], [0, np.cos(x), -np.sin(x)], [0, np.sin(x), np.cos(x)]])\nR = Rx @ Ry @ Rz\nv = np.array([0, 1, 0])\nv_earth = R @ v\nprint(\"Vector in Earth frame:\", v_earth)"
  },
  {
    "input": "A transformation matrix T is applied to a basis B = [[1,1,0],[0,1,1],[1,0,1]]. Find the matrix representation of T in the B basis.",
    "output": "import numpy as np\n\nT = np.array([[2, 0, 1], [1, 3, 0], [0, 0, 1]])\nB = np.array([[1,1,0],[0,1,1],[1,0,1]])\nT_B = np.linalg.inv(B) @ T @ B\nprint(\"Matrix in new basis B:\", T_B)"
  },
  {
    "input": "In computer vision, a 3D point is in camera frame as [1, 2, 3]. The rotation matrix R and translation t convert to world frame. Apply the transformation.",
    "output": "import numpy as np\n\nR = np.array([[0.866, -0.5, 0], [0.5, 0.866, 0], [0, 0, 1]])\nt = np.array([2, -1, 3])\np_cam = np.array([1, 2, 3])\np_world = R @ p_cam + t\nprint(\"Point in world frame:\", p_world)"
  },
  {
    "input": "In aerospace, the body-to-inertial rotation matrix is known. Compute its inverse and verify it is equal to the transpose (orthogonal matrix property).",
    "output": "import numpy as np\n\nR = np.array([[0.36, -0.48, 0.8], [0.8, 0.6, 0], [-0.48, 0.64, 0.6]])\nR_inv = np.linalg.inv(R)\nR_T = R.T\nprint(\"Inverse of R:\", R_inv)\nprint(\"Transpose of R:\", R_T)\nprint(\"Are they equal?\", np.allclose(R_inv, R_T))"
  },
  {
    "input": "Given basis B = [[2, 1], [1, 2]] and vector x = [3, 4], compute coordinates of x in B and reconstruct x from those coordinates.",
    "output": "import numpy as np\n\nB = np.array([[2, 1], [1, 2]])\nx = np.array([3, 4])\nx_B = np.linalg.inv(B) @ x\nx_reconstructed = B @ x_B\nprint(\"Coordinates in basis B:\", x_B)\nprint(\"Reconstructed vector:\", x_reconstructed)"
  },
  {
    "input": "In 3D modeling, a point in local frame is [1, 2, 3]. It's transformed using a 4x4 homogeneous transformation matrix. Apply it.",
    "output": "import numpy as np\n\nH = np.array([[1,0,0,2], [0,1,0,3], [0,0,1,4], [0,0,0,1]])\np_local = np.array([1,2,3,1])\np_world = H @ p_local\nprint(\"Transformed point:\", p_world[:3])"
  },
  {
    "input": "Transform a 3D vector [3,1,2] using eigenbasis B where eigenvectors are columns of B. B = [[1,0,1],[1,1,0],[0,1,1]].",
    "output": "import numpy as np\n\nB = np.array([[1,0,1], [1,1,0], [0,1,1]])\nv = np.array([3,1,2])\nv_B = np.linalg.inv(B) @ v\nprint(\"Vector in eigenbasis:\", v_B)"
  },
  {
    "input": "You have a symmetric matrix A = [[4,1],[1,3]]. Diagonalize it using eigen-decomposition and verify that the diagonalized form matches the expected result.",
    "output": "import numpy as np\n\nA = np.array([[4,1],[1,3]])\nD, P = np.linalg.eigh(A)\nA_diag = P.T @ A @ P\nprint(\"Diagonal matrix:\", np.diag(D))\nprint(\"Computed A in eigenbasis:\", A_diag)"
  },
  {
    "input": "Rotate a vector [5, 0, 0] around axis [1,1,1] by 120\u00b0. Use Rodrigues\u2019 formula.",
    "output": "import numpy as np\n\nv = np.array([5, 0, 0])\nk = np.array([1,1,1])\nk = k / np.linalg.norm(k)\ntheta = np.deg2rad(120)\nK = np.array([[0, -k[2], k[1]], [k[2], 0, -k[0]], [-k[1], k[0], 0]])\nR = np.eye(3) + np.sin(theta)*K + (1 - np.cos(theta))*(K @ K)\nv_rot = R @ v\nprint(\"Rotated vector:\", v_rot)"
  },
  {
    "input": "In robotics, a transformation matrix includes rotation and translation. Decompose matrix T into R and t components.",
    "output": "import numpy as np\n\nT = np.array([[1,0,0,4], [0,0,-1,3], [0,1,0,2], [0,0,0,1]])\nR = T[:3,:3]\nt = T[:3,3]\nprint(\"Rotation matrix R:\", R)\nprint(\"Translation vector t:\", t)"
  },
  {
    "input": "You are given a matrix expressed in basis A = [[2,1],[1,2]]. Transform it to basis B = [[1,0],[0,1]].",
    "output": "import numpy as np\n\nA_basis = np.array([[2,1],[1,2]])\nM = np.array([[4, 2],[2, 4]])\nM_std = np.linalg.inv(A_basis) @ M @ A_basis\nprint(\"Matrix in standard basis:\", M_std)"
  },
  {
    "input": "Given two orthonormal bases B1 and B2, construct the change-of-basis matrix from B1 to B2. Then convert vector x = [1,2].",
    "output": "import numpy as np\n\nB1 = np.array([[1,0],[0,1]])\nB2 = np.array([[0,1],[-1,0]])\nP = B2.T @ B1\nx = np.array([1,2])\nx_new = P @ x\nprint(\"Change of basis matrix:\", P)\nprint(\"x in B2 basis:\", x_new)"
  },
  {
    "input": "Apply a shear transformation to a vector [1,2] using matrix [[1,1],[0,1]] and then express the result in basis [[1,0],[0,2]].",
    "output": "import numpy as np\n\nshear = np.array([[1,1],[0,1]])\nB = np.array([[1,0],[0,2]])\nv = np.array([1,2])\nv_sheared = shear @ v\nv_B = np.linalg.inv(B) @ v_sheared\nprint(\"Sheared vector:\", v_sheared)\nprint(\"In new basis:\", v_B)"
  },
  {
    "input": "Find the rotation matrix that aligns vector [1,0,0] to [0,1,0] and verify it's orthogonal.",
    "output": "import numpy as np\n\nv1 = np.array([1,0,0])\nv2 = np.array([0,1,0])\nv = np.cross(v1, v2)\ns = np.linalg.norm(v)\nc = np.dot(v1, v2)\nVx = np.array([[0, -v[2], v[1]], [v[2], 0, -v[0]], [-v[1], v[0], 0]])\nR = np.eye(3) + Vx + Vx @ Vx * ((1 - c)/(s**2))\nprint(\"Rotation matrix:\", R)\nprint(\"Is orthogonal:\", np.allclose(R.T @ R, np.eye(3)))"
  },
  {
    "input": "In linear algebra, given basis B and coordinates x_B, reconstruct the original vector x = B @ x_B.",
    "output": "import numpy as np\n\nB = np.array([[3,1],[2,2]])\nx_B = np.array([1,1])\nx = B @ x_B\nprint(\"Original vector:\", x)"
  },
  {
    "input": "A spacecraft rotates 30\u00b0 around z and then 45\u00b0 around y. Derive the total rotation matrix and apply to vector [0,0,1].",
    "output": "import numpy as np\n\nz = np.deg2rad(30)\ny = np.deg2rad(45)\nRz = np.array([[np.cos(z), -np.sin(z), 0],[np.sin(z), np.cos(z), 0],[0,0,1]])\nRy = np.array([[np.cos(y),0,np.sin(y)],[0,1,0],[-np.sin(y),0,np.cos(y)]])\nR = Ry @ Rz\nv = np.array([0,0,1])\nv_rot = R @ v\nprint(\"Rotated vector:\", v_rot)"
  },
  {
    "input": "Apply an affine transformation to a point [2, 1] using matrix A = [[2,0],[0,3]] and translation [4,5].",
    "output": "import numpy as np\n\nA = np.array([[2,0],[0,3]])\nt = np.array([4,5])\np = np.array([2,1])\np_transformed = A @ p + t\nprint(\"Affine transformed point:\", p_transformed)"
  },
  {
    "input": "Compute the inverse transformation for a matrix that rotates 90\u00b0 and translates [1,2]. Apply it to point [4,5].",
    "output": "import numpy as np\n\n\u03b8 = np.deg2rad(90)\nR = np.array([[np.cos(\u03b8), -np.sin(\u03b8)], [np.sin(\u03b8), np.cos(\u03b8)]])\nt = np.array([1,2])\nR_inv = R.T\nt_inv = -R_inv @ t\np = np.array([4,5])\np_local = R_inv @ (p - t)\nprint(\"Point in original frame:\", p_local)"
  },
  {
    "input": "Transform a covariance matrix under a change of basis B = [[2,0],[0,0.5]]. C = [[4,1],[1,3]].",
    "output": "import numpy as np\n\nB = np.array([[2,0],[0,0.5]])\nC = np.array([[4,1],[1,3]])\nC_new = B.T @ C @ B\nprint(\"Transformed covariance matrix:\", C_new)"
  },
  {
    "input": "In signal analysis, express signal vector [3, 4] in DFT basis (unnormalized for N=2).",
    "output": "import numpy as np\n\nF = np.array([[1, 1], [1, -1]])\nv = np.array([3,4])\nv_freq = np.linalg.inv(F) @ v\nprint(\"Signal in frequency basis:\", v_freq)"
  },
  {
    "input": "In 3D transformations, prove the determinant of a pure rotation matrix is 1 using an example.",
    "output": "import numpy as np\n\n\u03b8 = np.deg2rad(90)\nRz = np.array([[np.cos(\u03b8), -np.sin(\u03b8), 0],[np.sin(\u03b8), np.cos(\u03b8), 0],[0,0,1]])\ndet = np.linalg.det(Rz)\nprint(\"Determinant:\", det)"
  },
  {
    "input": "A drone's local coordinate [3, -2, 5] needs to be transformed to the global frame. The drone's orientation is given by Euler angles: roll = 30\u00b0, pitch = 45\u00b0, yaw = 60\u00b0. Compute the global coordinates.",
    "output": "import numpy as np\nfrom scipy.spatial.transform import Rotation as R\n\neuler_angles = [60, 45, 30]  # yaw, pitch, roll in degrees\nr = R.from_euler('zyx', euler_angles, degrees=True)\nv_local = np.array([3, -2, 5])\nv_global = r.apply(v_local)\nprint(\"Global coordinates:\", v_global)"
  },
  {
    "input": "In computer graphics, a model's vertex at [1, 0, 0] is rotated 90\u00b0 around the z-axis and then scaled by a factor of 2 along the x-axis. Determine the transformed vertex.",
    "output": "import numpy as np\n\nRz = np.array([[0, -1, 0], [1, 0, 0], [0, 0, 1]])\nS = np.array([[2, 0, 0], [0, 1, 0], [0, 0, 1]])\nT = S @ Rz\nv = np.array([1, 0, 0])\nv_transformed = T @ v\nprint(\"Transformed vertex:\", v_transformed)"
  },
  {
    "input": "A satellite's orientation is represented by the quaternion [0.707, 0, 0.707, 0]. Transform the inertial frame vector [0, 1, 0] to the satellite's body frame.",
    "output": "import numpy as np\nfrom scipy.spatial.transform import Rotation as R\n\nq = [0.707, 0, 0.707, 0]\nr = R.from_quat(q)\nv_inertial = np.array([0, 1, 0])\nv_body = r.apply(v_inertial)\nprint(\"Vector in body frame:\", v_body)"
  },
  {
    "input": "In a 2D plane, a point [4, 3] is rotated 45\u00b0 counterclockwise about the origin and then translated by [2, -1]. Find the final coordinates.",
    "output": "import numpy as np\n\n\u03b8 = np.deg2rad(45)\nR = np.array([[np.cos(\u03b8), -np.sin(\u03b8)], [np.sin(\u03b8), np.cos(\u03b8)]])\nt = np.array([2, -1])\np_initial = np.array([4, 3])\np_rotated = R @ p_initial\np_final = p_rotated + t\nprint(\"Final coordinates:\", p_final)"
  },
  {
    "input": "A 3D point cloud needs to be aligned to a new coordinate system defined by orthonormal vectors u, v, w. Given a point [1, 2, 3], compute its coordinates in the new system.",
    "output": "import numpy as np\n\nu = np.array([0.707, 0.707, 0])\nv = np.array([-0.707, 0.707, 0])\nw = np.array([0, 0, 1])\nR = np.column_stack((u, v, w))\np_original = np.array([1, 2, 3])\np_new = np.linalg.inv(R) @ p_original\nprint(\"Coordinates in new system:\", p_new)"
  },
  {
    "input": "In machine learning, a dataset is projected onto its first two principal components. Given the projection matrix P and a data point [5, 3, 2], find its coordinates in the principal component space.",
    "output": "import numpy as np\n\nP = np.array([[0.5, 0.5, 0.707], [0.5, 0.5, -0.707]])\ndata_point = np.array([5, 3, 2])\nprojected = P @ data_point\nprint(\"Coordinates in principal component space:\", projected)"
  },
  {
    "input": "A 2D image undergoes a shear transformation defined by the matrix [[1, 0.5], [0, 1]]. Determine the new coordinates of a pixel originally at [10, 15].",
    "output": "import numpy as np\n\nshear_matrix = np.array([[1, 0.5], [0, 1]])\npixel = np.array([10, 15])\nnew_pixel = shear_matrix @ pixel\nprint(\"New pixel coordinates:\", new_pixel)"
  },
  {
    "input": "In quantum mechanics, a state vector is represented in basis B. Given the change of basis matrix from B to the standard basis and the state vector in B as [1, 0, 0], find its representation in the standard basis.",
    "output": "import numpy as np\n\nP = np.array([[0.707, 0.707, 0], [-0.707, 0.707, 0], [0, 0, 1]])\nstate_B = np.array([1, 0, 0])\nstate_standard = P @ state_B\nprint(\"State vector in standard basis:\", state_standard)"
  },
  {
    "input": "A car's local coordinate system has a point at [2, 3]. The car rotates 30\u00b0 counterclockwise. Compute the point's coordinates in the global frame.",
    "output": "import numpy as np\n\n\u03b8 = np.deg2rad(30)\nR = np.array([[np.cos(\u03b8), -np.sin(\u03b8)], [np.sin(\u03b8), np.cos(\u03b8)]])\npoint_local = np.array([2, 3])\npoint_global = R @ point_local\nprint(\"Point in global frame:\", point_global)"
  },
  {
    "input": "In structural engineering, a force vector [100, 50] N is applied at an angle of 60\u00b0 to the horizontal. Resolve this force into its horizontal and vertical components.",
    "output": "import numpy as np\n\nF = np.array([100, 50])\n\u03b8 = np.deg2rad(60)\nR = np.array([[np.cos(\u03b8), -np.sin(\u03b8)], [np.sin(\u03b8), np.cos(\u03b8)]])\nF_components = R @ F\nprint(\"Horizontal and vertical components:\", F_components)"
  },
  {
    "input": "A spacecraft's orientation is updated by a rotation matrix R. Given an initial velocity vector [0, 0, 1] km/s in the inertial frame, compute the velocity in the spacecraft's body frame.",
    "output": "import numpy as np\n\nR = np.array([[0.866, -0.5, 0], [0.5, 0.866, 0], [0, 0, 1]])\nv_inertial = np.array([0, 0, 1])\nv_body = R.T @ v_inertial\nprint(\"Velocity in body frame:\", v_body)"
  },
  {
    "input": "In a graphics application, a texture is mapped onto a 3D model. The texture coordinates [0.5, 0.5] are in the texture space. Given the transformation matrix from texture space to model space, find the corresponding point on the model.",
    "output": "import numpy as np\n\nT = np.array([[1.2, 0.2, 0], [0.3, 0.8, 0], [0, 0, 1]])\ntex_coords = np.array([0.5, 0.5, 1])\nmodel_coords = T @ tex_coords\nprint(\"Point on model:\", model_coords[:2])"
  },
  {
    "input": "A robot arm's end effector is at position [0.5, -0.2, 0.3] in the base frame. The joint connecting the end effector to the arm rotates 45\u00b0 about the z-axis. Determine the new position of the end effector.",
    "output": "import numpy as np\n\n\u03b8 = np.deg2rad(45)\nR = np.array([[np.cos(\u03b8), -np.sin(\u03b8), 0], [np.sin(\u03b8), np.cos(\u03b8), 0], [0, 0, 1]])\nend_effector_pos = np.array([0.5, -0.2, 0.3])\nnew_pos = R @ end_effector_pos\nprint(\"New position of end effector:\", new_pos)"
  },
  {
    "input": "In a physics simulation, a particle's velocity vector [2, -1, 0] m/s is given in a rotated coordinate system. The system is rotated 30\u00b0 around the x-axis relative to the standard basis. Transform the velocity vector to the standard basis.",
    "output": "import numpy as np\n\n\u03b8 = np.deg2rad(-30)\nRx = np.array([[1, 0, 0], [0, np.cos(\u03b8), -np.sin(\u03b8)], [0, np.sin(\u03b8), np.cos(\u03b8)]])\nv_rotated = np.array([2, -1, 0])\nv_standard = Rx @ v_rotated\nprint(\"Velocity in standard basis:\", v_standard)"
  },
  {
    "input": "A 3D model is scaled non-uniformly by factors of 2, 1.5, and 0.5 along the x, y, and z axes, respectively. Given a vertex at [1, 1, 1], compute its new position after scaling.",
    "output": "import numpy as np\n\nS = np.diag([2, 1.5, 0.5])\nvertex = np.array([1, 1, 1])\nnew_vertex = S @ vertex\nprint(\"New vertex position:\", new_vertex)"
  },
  {
    "input": "In a navigation system, a vehicle's position is represented in a local coordinate system as [100, 200]. The local system's origin is at [1000, 500] in the global system, and it's rotated 45\u00b0 relative to the global system. Determine the vehicle's position in the global coordinate system.",
    "output": "import numpy as np\n\n\u03b8 = np.deg2rad(45)\nR = np.array([[np.cos(\u03b8), -np.sin(\u03b8)], [np.sin(\u03b8), np.cos(\u03b8)]])\norigin_global = np.array([1000, 500])\nposition_local = np.array([100, 200])\nposition_global = R @ position_local + origin_global\nprint(\"Position in global coordinates:\", position_global)"
  },
  {
    "input": "A camera captures an image of a planar object. The homography matrix H relates the image coordinates to the world coordinates. Given H and a point [150, 200] in the image, find the corresponding point in the world.",
    "output": "import numpy as np\n\nH = np.array([[1.2, 0.1, 100], [0.2, 1.1, 150], [0.001, 0.002, 1]])\npoint_image = np.array([150, 200, 1])\npoint_world = H @ point_image\npoint_world /= point_world[2]\nprint(\"Point in world coordinates:\", point_world[:2])"
  },
  {
    "input": "In a physics simulation, a rigid body's orientation is represented by a quaternion [0.92388, 0.38268, 0, 0]. Transform the body's local vector [1, 0, 0] to the world frame.",
    "output": "import numpy as np\nfrom scipy.spatial.transform import Rotation as R\n\nq = [0.92388, 0.38268, 0, 0]\nr = R.from_quat(q)\nv_local = np.array([1, 0, 0])\nv_world = r.apply(v_local)\nprint(\"Vector in world frame:\", v_world)"
  },
  {
    "input": "A 2D shape undergoes a reflection across the line y = x. Given a point [3, 4], find its coordinates after the reflection.",
    "output": "import numpy as np\n\nR = np.array([[0, 1], [1, 0]])\npoint = np.array([3, 4])\nreflected_point = R @ point\nprint(\"Reflected point:\", reflected_point)"
  },
  {
    "input": "Given a vector v = [3, -2] in the standard basis, and a new basis B = {[1, 1], [1, -1]}, find the coordinates of v in the basis B.",
    "output": "import numpy as np\n\nv = np.array([3, -2])\nB = np.array([[1, 1], [1, -1]])\nv_B = np.linalg.inv(B) @ v\nprint(\"Coordinates of v in basis B:\", v_B)"
  },
  {
    "input": "Let B = {[1, 2], [3, 4]} and C = {[2, 0], [0, 2]} be two bases. Find the change of basis matrix from B to C.",
    "output": "import numpy as np\n\nB = np.array([[1, 3], [2, 4]])\nC = np.array([[2, 0], [0, 2]])\nP_BC = np.linalg.inv(C) @ B\nprint(\"Change of basis matrix from B to C:\", P_BC)"
  },
  {
    "input": "A linear transformation T has a matrix representation A = [[2, 1], [0, 3]] in the standard basis. Find its representation in the basis B = {[1, 1], [1, -1]}.",
    "output": "import numpy as np\n\nA = np.array([[2, 1], [0, 3]])\nB = np.array([[1, 1], [1, -1]])\nA_B = np.linalg.inv(B) @ A @ B\nprint(\"Matrix of T in basis B:\", A_B)"
  },
  {
    "input": "Given a vector v = [1, 2, 3] in the standard basis, and an orthogonal basis B = {[1, 0, 0], [0, 1, 0], [0, 0, 1]}, find the coordinates of v in the basis B.",
    "output": "import numpy as np\n\nv = np.array([1, 2, 3])\nB = np.array([[1, 0, 0], [0, 1, 0], [0, 0, 1]])\nv_B = B.T @ v\nprint(\"Coordinates of v in basis B:\", v_B)"
  },
  {
    "input": "Let B = {[1, 0], [0, 1]} and C = {[1, 1], [1, -1]} be two bases. Find the change of basis matrix from B to C.",
    "output": "import numpy as np\n\nB = np.array([[1, 0], [0, 1]])\nC = np.array([[1, 1], [1, -1]])\nP_BC = np.linalg.inv(C) @ B\nprint(\"Change of basis matrix from B to C:\", P_BC)"
  },
  {
    "input": "A linear transformation T has a matrix representation A = [[0, -1], [1, 0]] in the standard basis. Find its representation in the basis B = {[1, 1], [1, -1]}.",
    "output": "import numpy as np\n\nA = np.array([[0, -1], [1, 0]])\nB = np.array([[1, 1], [1, -1]])\nA_B = np.linalg.inv(B) @ A @ B\nprint(\"Matrix of T in basis B:\", A_B)"
  },
  {
    "input": "Given a vector v = [4, -3] in the standard basis, and a new basis B = {[2, 1], [1, 2]}, find the coordinates of v in the basis B.",
    "output": "import numpy as np\n\nv = np.array([4, -3])\nB = np.array([[2, 1], [1, 2]])\nv_B = np.linalg.inv(B) @ v\nprint(\"Coordinates of v in basis B:\", v_B)"
  },
  {
    "input": "Let B = {[2, 0], [0, 2]} and C = {[1, 1], [1, -1]} be two bases. Find the change of basis matrix from B to C.",
    "output": "import numpy as np\n\nB = np.array([[2, 0], [0, 2]])\nC = np.array([[1, 1], [1, -1]])\nP_BC = np.linalg.inv(C) @ B\nprint(\"Change of basis matrix from B to C:\", P_BC)"
  },
  {
    "input": "A linear transformation T has a matrix representation A = [[3, 0], [0, 2]] in the standard basis. Find its representation in the basis B = {[1, 2], [2, 1]}.",
    "output": "import numpy as np\n\nA = np.array([[3, 0], [0, 2]])\nB = np.array([[1, 2], [2, 1]])\nA_B = np.linalg.inv(B) @ A @ B\nprint(\"Matrix of T in basis B:\", A_B)"
  },
  {
    "input": "Given a vector v = [5, 5] in the standard basis, and a new basis B = {[1, 0], [0, 1]}, find the coordinates of v in the basis B.",
    "output": "import numpy as np\n\nv = np.array([5, 5])\nB = np.array([[1, 0], [0, 1]])\nv_B = np.linalg.inv(B) @ v\nprint(\"Coordinates of v in basis B:\", v_B)"
  },
  {
    "input": "Let B = {[1, 1], [1, -1]} and C = {[2, 0], [0, 2]} be two bases. Find the change of basis matrix from B to C.",
    "output": "import numpy as np\n\nB = np.array([[1, 1], [1, -1]])\nC = np.array([[2, 0], [0, 2]])\nP_BC = np.linalg.inv(C) @ B\nprint(\"Change of basis matrix from B to C:\", P_BC)"
  },
  {
    "input": "A linear transformation T has a matrix representation A = [[1, 2], [3, 4]] in the standard basis. Find its representation in the basis B = {[2, 1], [1, 2]}.",
    "output": "import numpy as np\n\nA = np.array([[1, 2], [3, 4]])\nB = np.array([[2, 1], [1, 2]])\nA_B = np.linalg.inv(B) @ A @ B\nprint(\"Matrix of T in basis B:\", A_B)"
  },
  {
    "input": "Given basis B = {[1, 0, 1], [0, 1, 1], [1, 1, 0]}, express the standard basis vector e1 = [1, 0, 0] in terms of B.",
    "output": "import numpy as np\n\nB = np.array([[1, 0, 1], [0, 1, 1], [1, 1, 0]]).T\ne1 = np.array([1, 0, 0])\ne1_B = np.linalg.inv(B) @ e1\nprint(\"e1 in basis B:\", e1_B)"
  },
  {
    "input": "Find the transition matrix from basis B = {[1, 2], [2, -1]} to the standard basis.",
    "output": "import numpy as np\n\nB = np.array([[1, 2], [2, -1]])\nP = B\nprint(\"Transition matrix from B to standard basis:\", P)"
  },
  {
    "input": "Let v = [6, -2] be a vector in the standard basis. Express v in basis B = {[2, 1], [1, -1]}.",
    "output": "import numpy as np\n\nv = np.array([6, -2])\nB = np.array([[2, 1], [1, -1]])\nv_B = np.linalg.inv(B) @ v\nprint(\"Coordinates of v in basis B:\", v_B)"
  },
  {
    "input": "A transformation T has matrix A = [[4, 1], [2, 3]]. Compute the similarity transformation under B = {[1, 1], [1, -1]}.",
    "output": "import numpy as np\n\nA = np.array([[4, 1], [2, 3]])\nB = np.array([[1, 1], [1, -1]])\nA_B = np.linalg.inv(B) @ A @ B\nprint(\"T in basis B:\", A_B)"
  },
  {
    "input": "Let v = [2, 3] in the basis B = {[1, 1], [1, -1]}. Convert v to standard basis coordinates.",
    "output": "import numpy as np\n\nB = np.array([[1, 1], [1, -1]])\nv_B = np.array([2, 3])\nv_std = B @ v_B\nprint(\"v in standard basis:\", v_std)"
  },
  {
    "input": "Find the matrix representation of the identity map in basis B = {[1, 1], [1, -1]}.",
    "output": "import numpy as np\n\nB = np.array([[1, 1], [1, -1]])\nI_B = np.linalg.inv(B) @ np.identity(2) @ B\nprint(\"Identity map in basis B:\", I_B)"
  },
  {
    "input": "Let A = [[0, 1], [1, 0]] represent a transformation in standard basis. Find its matrix in basis B = {[1, 0], [1, 1]}.",
    "output": "import numpy as np\n\nA = np.array([[0, 1], [1, 0]])\nB = np.array([[1, 1], [0, 1]])\nA_B = np.linalg.inv(B) @ A @ B\nprint(\"Matrix of T in basis B:\", A_B)"
  },
  {
    "input": "Convert vector [1, 2] from basis B = {[2, 3], [1, -1]} to standard coordinates.",
    "output": "import numpy as np\n\nB = np.array([[2, 1], [3, -1]])\nv_B = np.array([1, 2])\nv_std = B @ v_B\nprint(\"v in standard basis:\", v_std)"
  },
  {
    "input": "Given T is a linear transformation with matrix A = [[1, 2], [2, 1]] in standard basis, find T in basis B = {[1, 1], [1, -1]}.",
    "output": "import numpy as np\n\nA = np.array([[1, 2], [2, 1]])\nB = np.array([[1, 1], [1, -1]])\nA_B = np.linalg.inv(B) @ A @ B\nprint(\"Matrix of T in basis B:\", A_B)"
  },
  {
    "input": "Let a vector v = [3, 2] be expressed in B = {[1, 0], [0, 1]}. Convert to standard coordinates.",
    "output": "import numpy as np\n\nB = np.identity(2)\nv_B = np.array([3, 2])\nv_std = B @ v_B\nprint(\"v in standard basis:\", v_std)"
  },
  {
    "input": "Given transformation matrix A = [[0, -1], [1, 0]], determine its matrix in orthonormal basis B = {[1/sqrt(2), 1/sqrt(2)], [1/sqrt(2), -1/sqrt(2)]}.",
    "output": "import numpy as np\n\nB = np.array([[1/np.sqrt(2), 1/np.sqrt(2)], [1/np.sqrt(2), -1/np.sqrt(2)]])\nA = np.array([[0, -1], [1, 0]])\nA_B = np.linalg.inv(B) @ A @ B\nprint(\"A in basis B:\", A_B)"
  },
  {
    "input": "Compute the change of basis matrix from standard basis to B = {[3, 1], [2, 2]}.",
    "output": "import numpy as np\n\nB = np.array([[3, 2], [1, 2]])\nP = np.linalg.inv(B)\nprint(\"Change of basis from standard to B:\", P)"
  },
  {
    "input": "Let a vector v = [7, 1] in the standard basis. Find coordinates in basis B = {[2, 2], [0, 1]}.",
    "output": "import numpy as np\n\nv = np.array([7, 1])\nB = np.array([[2, 0], [2, 1]])\nv_B = np.linalg.inv(B) @ v\nprint(\"Coordinates of v in basis B:\", v_B)"
  },
  {
    "input": "Find the matrix representation of the rotation transformation by 90 degrees in basis B = {[1, 1], [-1, 1]}.",
    "output": "import numpy as np\n\nA = np.array([[0, -1], [1, 0]])  # 90 degree rotation\nB = np.array([[1, -1], [1, 1]])\nA_B = np.linalg.inv(B) @ A @ B\nprint(\"Rotation matrix in basis B:\", A_B)"
  },
  {
    "input": "Given two bases B = {[1, 0], [1, 1]} and C = {[2, 1], [0, 1]}, find the matrix to convert B-coordinates to C-coordinates.",
    "output": "import numpy as np\n\nB = np.array([[1, 1], [0, 1]])\nC = np.array([[2, 0], [1, 1]])\nP = np.linalg.inv(C) @ B\nprint(\"B to C basis conversion matrix:\", P)"
  },
  {
    "input": "Convert the vector [1, 1] from basis B = {[3, 1], [1, 2]} to standard coordinates.",
    "output": "import numpy as np\n\nB = np.array([[3, 1], [1, 2]])\nv_B = np.array([1, 1])\nv_std = B @ v_B\nprint(\"Vector in standard basis:\", v_std)"
  },
  {
    "input": "Determine if the basis B = {[1, 1, 1], [0, 1, 1], [0, 0, 1]} is orthogonal.",
    "output": "import numpy as np\n\nB = np.array([[1, 0, 0], [1, 1, 0], [1, 1, 1]])\nG = B.T @ B\nprint(\"Gram matrix (should be diagonal if orthogonal):\\n\", G)"
  },
  {
    "input": "Let B = {[1, 2], [2, 4]}. Is B a valid basis?",
    "output": "import numpy as np\n\nB = np.array([[1, 2], [2, 4]])\ndet = np.linalg.det(B)\nprint(\"Determinant of B:\", det)\nprint(\"Is B a valid basis?\", det != 0)"
  },
  {
    "input": "Find the inverse of the change of basis matrix from B = {[1, 2], [3, 4]} to standard basis.",
    "output": "import numpy as np\n\nB = np.array([[1, 3], [2, 4]])\nP = B\nP_inv = np.linalg.inv(P)\nprint(\"Inverse of change of basis matrix:\", P_inv)"
  },
  {
    "input": "Given a transformation matrix A = [[2, 0], [0, 3]] in standard basis, and B = {[1, 1], [1, -1]}, compute its matrix in B.",
    "output": "import numpy as np\n\nA = np.array([[2, 0], [0, 3]])\nB = np.array([[1, 1], [1, -1]])\nA_B = np.linalg.inv(B) @ A @ B\nprint(\"Matrix in basis B:\", A_B)"
  },
  {
    "input": "Express the vector [5, -3] in the coordinate system of the basis B = {[1, 1], [0, 1]}.",
    "output": "import numpy as np\n\nv = np.array([5, -3])\nB = np.array([[1, 0], [1, 1]])\nv_B = np.linalg.inv(B) @ v\nprint(\"Coordinates in basis B:\", v_B)"
  },
  {
    "input": "Check if the vectors {[1, 0, 0], [1, 1, 0], [1, 1, 1]} form a basis of R^3.",
    "output": "import numpy as np\n\nB = np.array([[1, 1, 1], [0, 1, 1], [0, 0, 1]])\ndet = np.linalg.det(B)\nprint(\"Determinant:\", det)\nprint(\"Forms a basis?\", not np.isclose(det, 0))"
  },
  {
    "input": "Convert v = [3, 5] from basis B = {[2, 1], [1, 3]} to standard coordinates.",
    "output": "import numpy as np\n\nB = np.array([[2, 1], [1, 3]])\nv_B = np.array([3, 5])\nv_std = B @ v_B\nprint(\"v in standard basis:\", v_std)"
  },
  {
    "input": "Let T be a transformation with matrix [[1, 0], [0, -1]] in standard basis. Represent it in B = {[1, 1], [1, -1]}.",
    "output": "import numpy as np\n\nA = np.array([[1, 0], [0, -1]])\nB = np.array([[1, 1], [1, -1]])\nA_B = np.linalg.inv(B) @ A @ B\nprint(\"Matrix in basis B:\", A_B)"
  },
  {
    "input": "Let B = {[1, 2, 0], [0, 1, 1], [1, 0, 1]}. Find the matrix that transforms from B to standard coordinates.",
    "output": "import numpy as np\n\nB = np.array([[1, 0, 1], [2, 1, 0], [0, 1, 1]]).T\nP = B\nprint(\"B to standard coordinates matrix:\", P)"
  },
  {
    "input": "Given A = [[1, 0, 0], [0, 2, 0], [0, 0, 3]] and basis B = identity, find its matrix in B.",
    "output": "import numpy as np\n\nA = np.diag([1, 2, 3])\nB = np.eye(3)\nA_B = np.linalg.inv(B) @ A @ B\nprint(\"Matrix in basis B:\", A_B)"
  },
  {
    "input": "Convert vector v = [4, 1] to basis B = {[1, 1], [1, -1]}.",
    "output": "import numpy as np\n\nv = np.array([4, 1])\nB = np.array([[1, 1], [1, -1]])\nv_B = np.linalg.inv(B) @ v\nprint(\"v in basis B:\", v_B)"
  },
  {
    "input": "Given a vector v = [4, 2] in the standard basis, and a new basis B = {[2, 1], [1, 1]}, find the coordinates of v in the basis B.",
    "output": "import numpy as np\n\nv = np.array([4, 2])\nB = np.array([[2, 1], [1, 1]])\nv_B = np.linalg.inv(B) @ v\nprint(\"Coordinates of v in basis B:\", v_B)"
  },
  {
    "input": "A linear transformation T has a matrix representation A = [[1, 2], [3, 4]] in the standard basis. Find its representation in the basis B = {[1, 1], [0, 1]}.",
    "output": "import numpy as np\n\nA = np.array([[1, 2], [3, 4]])\nB = np.array([[1, 0], [1, 1]])\nA_B = np.linalg.inv(B) @ A @ B\nprint(\"Matrix of T in basis B:\", A_B)"
  },
  {
    "input": "Convert vector [7, -2] from basis B = {[1, 1], [1, -1]} to standard coordinates.",
    "output": "import numpy as np\n\nv_B = np.array([7, -2])\nB = np.array([[1, 1], [1, -1]])\nv_std = B @ v_B\nprint(\"Vector in standard basis:\", v_std)"
  },
  {
    "input": "Given a vector v = [2, 3] in standard coordinates, and basis B = {[3, 1], [1, 2]}, express v in B coordinates.",
    "output": "import numpy as np\n\nv = np.array([2, 3])\nB = np.array([[3, 1], [1, 2]])\nv_B = np.linalg.inv(B) @ v\nprint(\"v in basis B:\", v_B)"
  },
  {
    "input": "Let B = {[1, 2, 3], [0, 1, 4], [0, 0, 1]}. Find the matrix to convert from B coordinates to standard coordinates.",
    "output": "import numpy as np\n\nB = np.array([[1, 0, 0], [2, 1, 0], [3, 4, 1]])\nprint(\"Matrix to convert from B to standard:\", B)"
  },
  {
    "input": "Let B = {[2, -1], [1, 3]}. Check if it forms a basis of R^2.",
    "output": "import numpy as np\n\nB = np.array([[2, 1], [-1, 3]])\ndet = np.linalg.det(B)\nprint(\"Determinant of B:\", det)\nprint(\"Forms a basis?\", not np.isclose(det, 0))"
  },
  {
    "input": "Given T: R^2 \u2192 R^2 with matrix A = [[0, 1], [1, 0]], find its representation in the basis B = {[1, 2], [3, 4]}.",
    "output": "import numpy as np\n\nA = np.array([[0, 1], [1, 0]])\nB = np.array([[1, 3], [2, 4]])\nA_B = np.linalg.inv(B) @ A @ B\nprint(\"Matrix in basis B:\", A_B)"
  },
  {
    "input": "Convert the standard basis vector [1, 0, 0] to coordinates in basis B = {[1, 1, 0], [0, 1, 1], [1, 0, 1]}.",
    "output": "import numpy as np\n\nv = np.array([1, 0, 0])\nB = np.array([[1, 0, 1], [1, 1, 0], [0, 1, 1]]).T\nv_B = np.linalg.inv(B) @ v\nprint(\"v in basis B:\", v_B)"
  },
  {
    "input": "Given basis B = {[1, 0], [0, 2]}, what is the matrix representation of identity transformation in this basis?",
    "output": "import numpy as np\n\nB = np.array([[1, 0], [0, 2]])\nI = np.eye(2)\nA_B = np.linalg.inv(B) @ I @ B\nprint(\"Identity in basis B:\", A_B)"
  },
  {
    "input": "Check if the basis {[1, 0, 0], [1, 1, 0], [1, 1, 1]} is orthonormal.",
    "output": "import numpy as np\n\nB = np.array([[1, 1, 1], [0, 1, 1], [0, 0, 1]])\nG = B.T @ B\nprint(\"Gram matrix:\", G)\nprint(\"Is orthonormal?\", np.allclose(G, np.eye(3)))"
  },
  {
    "input": "Find the matrix of the reflection transformation over the x-axis in basis B = {[1, 1], [1, -1]}.",
    "output": "import numpy as np\n\nA = np.array([[1, 0], [0, -1]])\nB = np.array([[1, 1], [1, -1]])\nA_B = np.linalg.inv(B) @ A @ B\nprint(\"Reflection matrix in basis B:\", A_B)"
  },
  {
    "input": "Let A = [[2, 0], [0, 3]], and B = {[1, 0], [1, 1]}. Compute A in the basis B.",
    "output": "import numpy as np\n\nA = np.array([[2, 0], [0, 3]])\nB = np.array([[1, 1], [0, 1]])\nA_B = np.linalg.inv(B) @ A @ B\nprint(\"Matrix of A in basis B:\", A_B)"
  },
  {
    "input": "Find coordinates of vector v = [6, 2, 3] in the basis B = {[1, 1, 0], [0, 1, 1], [1, 0, 1]}.",
    "output": "import numpy as np\n\nv = np.array([6, 2, 3])\nB = np.array([[1, 0, 1], [1, 1, 0], [0, 1, 1]]).T\nv_B = np.linalg.inv(B) @ v\nprint(\"v in basis B:\", v_B)"
  },
  {
    "input": "Given vector v = [3, 4] and basis B = {[1, 2], [2, 1]}, find v in basis B.",
    "output": "import numpy as np\n\nv = np.array([3, 4])\nB = np.array([[1, 2], [2, 1]])\nv_B = np.linalg.inv(B) @ v\nprint(\"Coordinates of v in basis B:\", v_B)"
  },
  {
    "input": "Is the set {[2, 3], [4, 6]} a basis for R^2?",
    "output": "import numpy as np\n\nB = np.array([[2, 4], [3, 6]])\ndet = np.linalg.det(B)\nprint(\"Determinant:\", det)\nprint(\"Is it a basis?\", not np.isclose(det, 0))"
  },
  {
    "input": "Transform A = [[1, 2], [0, 1]] from standard basis to B = {[1, 1], [1, -1]}.",
    "output": "import numpy as np\n\nA = np.array([[1, 2], [0, 1]])\nB = np.array([[1, 1], [1, -1]])\nA_B = np.linalg.inv(B) @ A @ B\nprint(\"A in basis B:\", A_B)"
  },
  {
    "input": "Given a vector v = [1, 1] and B = {[1, 0], [1, 1]}, find coordinates of v in B.",
    "output": "import numpy as np\n\nv = np.array([1, 1])\nB = np.array([[1, 1], [0, 1]])\nv_B = np.linalg.inv(B) @ v\nprint(\"v in basis B:\", v_B)"
  },
  {
    "input": "Given basis B = {[2, 3], [1, 4]}, convert vector v = [10, 17] into B-coordinates.",
    "output": "import numpy as np\n\nv = np.array([10, 17])\nB = np.array([[2, 1], [3, 4]])\nv_B = np.linalg.inv(B) @ v\nprint(\"Coordinates of v in basis B:\", v_B)"
  },
  {
    "input": "If T is a transformation with matrix A = [[5, -1], [2, 3]] in standard basis, find its representation in basis B = {[1, 0], [1, 1]}.",
    "output": "import numpy as np\n\nA = np.array([[5, -1], [2, 3]])\nB = np.array([[1, 1], [0, 1]])\nA_B = np.linalg.inv(B) @ A @ B\nprint(\"Matrix of T in basis B:\", A_B)"
  },
  {
    "input": "Given v = [4, 1] and orthogonal basis B = {[1, 1]/\u221a2, [1, -1]/\u221a2}, find v's coordinates in B.",
    "output": "import numpy as np\n\nv = np.array([4, 1])\nb1 = np.array([1, 1]) / np.sqrt(2)\nb2 = np.array([1, -1]) / np.sqrt(2)\nv_B = np.array([np.dot(v, b1), np.dot(v, b2)])\nprint(\"v in orthogonal basis B:\", v_B)"
  },
  {
    "input": "Let A = [[0, -1], [1, 0]] (rotation). Compute A in basis B = {[1, 2], [3, 4]}.",
    "output": "import numpy as np\n\nA = np.array([[0, -1], [1, 0]])\nB = np.array([[1, 3], [2, 4]])\nA_B = np.linalg.inv(B) @ A @ B\nprint(\"Rotation matrix in basis B:\", A_B)"
  },
  {
    "input": "Is the set {[1, 1], [2, 2]} a valid basis for R^2? Justify using Python.",
    "output": "import numpy as np\n\nB = np.array([[1, 2], [1, 2]])\ndet = np.linalg.det(B)\nprint(\"Determinant:\", det)\nprint(\"Is basis?\", not np.isclose(det, 0))"
  },
  {
    "input": "Find the inverse transformation matrix of A = [[3, 2], [1, 2]] in basis B = {[1, 1], [0, 1]}.",
    "output": "import numpy as np\n\nA = np.array([[3, 2], [1, 2]])\nB = np.array([[1, 0], [1, 1]])\nA_B = np.linalg.inv(B) @ A @ B\nA_B_inv = np.linalg.inv(A_B)\nprint(\"Inverse in basis B:\", A_B_inv)"
  },
  {
    "input": "Convert the vector [1, -2, 3] into coordinates under the basis B = {[1, 0, 0], [0, 2, 0], [0, 0, 0.5]}.",
    "output": "import numpy as np\n\nv = np.array([1, -2, 3])\nB = np.array([[1, 0, 0], [0, 2, 0], [0, 0, 0.5]])\nv_B = np.linalg.inv(B) @ v\nprint(\"v in basis B:\", v_B)"
  },
  {
    "input": "Let B = {[1, -1], [1, 1]}. Compute change of basis matrix from B to standard.",
    "output": "import numpy as np\n\nB = np.array([[1, 1], [-1, 1]])\nP = B\nprint(\"Change of basis matrix (B to standard):\", P)"
  },
  {
    "input": "Let v = [5, 5] be in basis B = {[1, 2], [3, 4]}. Find its standard coordinates.",
    "output": "import numpy as np\n\nv_B = np.array([5, 5])\nB = np.array([[1, 3], [2, 4]])\nv_std = B @ v_B\nprint(\"Vector in standard coordinates:\", v_std)"
  },
  {
    "input": "Given transformation T with standard matrix [[2, 0], [0, 3]], find the matrix in basis B = {[2, 1], [1, 2]}.",
    "output": "import numpy as np\n\nA = np.array([[2, 0], [0, 3]])\nB = np.array([[2, 1], [1, 2]])\nA_B = np.linalg.inv(B) @ A @ B\nprint(\"Matrix in basis B:\", A_B)"
  },
  {
    "input": "Determine whether the transformation T(v) = 2v is basis-invariant.",
    "output": "print(\"Since T(v) = 2v scales all vectors, it's linear and commutes with basis changes. So it is basis-invariant.\")"
  },
  {
    "input": "Convert [6, 2] from standard basis to B = {[3, 1], [1, 2]} coordinates.",
    "output": "import numpy as np\n\nv = np.array([6, 2])\nB = np.array([[3, 1], [1, 2]])\nv_B = np.linalg.inv(B) @ v\nprint(\"v in basis B:\", v_B)"
  },
  {
    "input": "Let A = [[1, 2], [3, 4]] be a transformation matrix. Compute its similarity transform under B = {[1, 0], [0, 2]}.",
    "output": "import numpy as np\n\nA = np.array([[1, 2], [3, 4]])\nB = np.array([[1, 0], [0, 2]])\nA_B = np.linalg.inv(B) @ A @ B\nprint(\"Similarity transform of A:\", A_B)"
  },
  {
    "input": "Find coordinates of [0, 1] in orthonormal basis {[1, 0], [0, 1]}.",
    "output": "import numpy as np\n\nv = np.array([0, 1])\nB = np.eye(2)\nv_B = np.linalg.inv(B) @ v\nprint(\"Coordinates in B:\", v_B)"
  },
  {
    "input": "Let v = [1, 2] and B = {[1, 1], [0, 1]}. Compute v\u2019s coordinates in B and verify the result.",
    "output": "import numpy as np\n\nv = np.array([1, 2])\nB = np.array([[1, 0], [1, 1]])\nv_B = np.linalg.inv(B) @ v\nprint(\"v in basis B:\", v_B)\nprint(\"Reconstructed v:\", B @ v_B)"
  },
  {
    "input": "Find matrix representation of projection onto x-axis in basis B = {[1, 1], [1, -1]}.",
    "output": "import numpy as np\n\nP = np.array([[1, 0], [0, 0]])\nB = np.array([[1, 1], [1, -1]])\nP_B = np.linalg.inv(B) @ P @ B\nprint(\"Projection matrix in basis B:\", P_B)"
  },
  {
    "input": "Let T be a rotation by 90 degrees counterclockwise. Find its matrix in standard basis.",
    "output": "import numpy as np\n\nT = np.array([[0, -1], [1, 0]])\nprint(\"Rotation matrix:\", T)"
  },
  {
    "input": "Determine the coordinates of [3, 3, 3] in B = {[1, 0, 1], [1, 1, 0], [0, 1, 1]}.",
    "output": "import numpy as np\n\nv = np.array([3, 3, 3])\nB = np.array([[1, 1, 0], [0, 1, 1], [1, 0, 1]]).T\nv_B = np.linalg.inv(B) @ v\nprint(\"v in B:\", v_B)"
  },
  {
    "input": "Let A = [[2, -1], [1, 3]]. Find its inverse in B = {[1, 2], [3, 4]}.",
    "output": "import numpy as np\n\nA = np.array([[2, -1], [1, 3]])\nB = np.array([[1, 3], [2, 4]])\nA_B = np.linalg.inv(B) @ A @ B\nA_B_inv = np.linalg.inv(A_B)\nprint(\"Inverse in B:\", A_B_inv)"
  },
  {
    "input": "Does the matrix [[0, 1], [1, 0]] preserve orthogonality of any basis?",
    "output": "print(\"Yes, it reflects over the line y = x, which preserves orthogonality of any orthonormal basis.\")"
  },
  {
    "input": "Let B = {[1, 1], [2, -1]}. Find the matrix to convert from standard to B coordinates.",
    "output": "import numpy as np\n\nB = np.array([[1, 2], [1, -1]])\nP = np.linalg.inv(B)\nprint(\"Change of basis matrix (standard to B):\", P)"
  },
  {
    "input": "Given matrix A = [[4, 1], [2, 3]], find its action on v = [1, 0] in basis B = {[1, 2], [0, 1]}.",
    "output": "import numpy as np\n\nA = np.array([[4, 1], [2, 3]])\nv = np.array([1, 0])\nB = np.array([[1, 0], [2, 1]])\nA_B = np.linalg.inv(B) @ A @ B\nv_B = np.linalg.inv(B) @ v\nresult_B = A_B @ v_B\nprint(\"T(v) in basis B:\", result_B)"
  },
  {
    "input": "Compute the determinant of the transformation matrix [[1, 2], [3, 4]] in the basis {[1, 0], [1, 1]} and compare with standard basis.",
    "output": "import numpy as np\n\nA = np.array([[1, 2], [3, 4]])\nB = np.array([[1, 1], [0, 1]])\nA_B = np.linalg.inv(B) @ A @ B\nprint(\"Det in standard:\", np.linalg.det(A))\nprint(\"Det in basis B:\", np.linalg.det(A_B))"
  },
  {
    "input": "Let v = [2, -1, 4] and B = identity matrix. What are the coordinates of v in B?",
    "output": "import numpy as np\n\nv = np.array([2, -1, 4])\nB = np.eye(3)\nv_B = np.linalg.inv(B) @ v\nprint(\"v in identity basis:\", v_B)"
  },
  {
    "input": "Given basis B = {[1, 2, 3], [0, 1, 0], [1, 0, 1]}, express vector v = [4, 3, 7] in basis B.",
    "output": "import numpy as np\n\nB = np.array([[1, 0, 1], [2, 1, 0], [3, 0, 1]])\nv = np.array([4, 3, 7])\nv_B = np.linalg.inv(B) @ v\nprint(\"Coordinates of v in basis B:\", v_B)"
  },
  {
    "input": "Find the matrix representation of T(v) = [[1, 2], [0, 1]]v in the basis B = {[1, 1], [1, -1]}.",
    "output": "import numpy as np\n\nA = np.array([[1, 2], [0, 1]])\nB = np.array([[1, 1], [1, -1]])\nA_B = np.linalg.inv(B) @ A @ B\nprint(\"Matrix of T in basis B:\", A_B)"
  },
  {
    "input": "A linear transformation rotates vectors 90\u00b0 clockwise. Express its matrix in the basis B = {[1, 0], [1, 1]}.",
    "output": "import numpy as np\n\nA = np.array([[0, 1], [-1, 0]])  # 90\u00b0 clockwise\nB = np.array([[1, 1], [0, 1]])\nA_B = np.linalg.inv(B) @ A @ B\nprint(\"Rotation matrix in basis B:\", A_B)"
  },
  {
    "input": "Let B = {[1, 1, 0], [0, 1, 1], [1, 0, 1]}. Is B a valid basis for \u211d^3?",
    "output": "import numpy as np\n\nB = np.array([[1, 0, 1], [1, 1, 0], [0, 1, 1]])\ndet = np.linalg.det(B)\nprint(\"Determinant:\", det)\nprint(\"Valid basis?\", not np.isclose(det, 0))"
  },
  {
    "input": "Transform v = [6, -1] from standard to basis B = {[2, 1], [1, 3]} and back to standard.",
    "output": "import numpy as np\n\nv = np.array([6, -1])\nB = np.array([[2, 1], [1, 3]])\nv_B = np.linalg.inv(B) @ v\nv_std = B @ v_B\nprint(\"v in B:\", v_B)\nprint(\"Back in standard:\", v_std)"
  },
  {
    "input": "Find the change of basis matrix from basis B = {[1, 2], [3, 5]} to C = {[2, 0], [0, 2]}.",
    "output": "import numpy as np\n\nB = np.array([[1, 3], [2, 5]])\nC = np.array([[2, 0], [0, 2]])\nP = np.linalg.inv(C) @ B\nprint(\"Change of basis matrix B \u2192 C:\", P)"
  },
  {
    "input": "Let v = [1, 2, 3] and B = standard basis. What is the coordinate vector of v in B?",
    "output": "import numpy as np\n\nv = np.array([1, 2, 3])\nprint(\"v in standard basis is itself:\", v)"
  },
  {
    "input": "Determine the coordinates of [2, 3] in the basis B = {[4, 1], [-1, 2]}.",
    "output": "import numpy as np\n\nv = np.array([2, 3])\nB = np.array([[4, -1], [1, 2]])\nv_B = np.linalg.inv(B) @ v\nprint(\"v in basis B:\", v_B)"
  },
  {
    "input": "Let A = [[1, 1], [0, 1]]. Find its representation in the eigenbasis of A.",
    "output": "import numpy as np\n\nA = np.array([[1, 1], [0, 1]])\nvals, vecs = np.linalg.eig(A)\nP = vecs\nA_diag = np.linalg.inv(P) @ A @ P\nprint(\"A in its eigenbasis:\", A_diag)"
  },
  {
    "input": "Verify that converting to a basis and back gives the original vector. Use v = [7, 3] and B = {[1, 2], [3, 4]}.",
    "output": "import numpy as np\n\nv = np.array([7, 3])\nB = np.array([[1, 3], [2, 4]])\nv_B = np.linalg.inv(B) @ v\nv_recovered = B @ v_B\nprint(\"v in B:\", v_B)\nprint(\"Recovered v:\", v_recovered)"
  },
  {
    "input": "Find coordinates of the zero vector in any basis.",
    "output": "import numpy as np\n\nB = np.random.rand(3, 3)\nv = np.zeros(3)\nv_B = np.linalg.inv(B) @ v\nprint(\"Zero vector in any basis:\", v_B)"
  },
  {
    "input": "Let transformation A = [[0, 2], [-2, 0]]. Find its matrix in the basis B = {[1, 1], [1, -1]}.",
    "output": "import numpy as np\n\nA = np.array([[0, 2], [-2, 0]])\nB = np.array([[1, 1], [1, -1]])\nA_B = np.linalg.inv(B) @ A @ B\nprint(\"Matrix of A in basis B:\", A_B)"
  },
  {
    "input": "Given matrix [[2, 0], [0, -2]], explain what this transformation does geometrically.",
    "output": "print(\"It stretches the x-axis by 2 and reflects y-axis with stretch factor 2. A scaling + reflection.\")"
  },
  {
    "input": "If a matrix A is diagonal in some basis, what does that imply about its eigenvectors?",
    "output": "print(\"It means the basis vectors are eigenvectors of A, and the diagonal entries are the corresponding eigenvalues.\")"
  },
  {
    "input": "Convert vector [1, 0, 1] into coordinates under B = {[1, 1, 0], [0, 1, 1], [1, 0, 1]}.",
    "output": "import numpy as np\n\nB = np.array([[1, 0, 1], [1, 1, 0], [0, 1, 1]])\nv = np.array([1, 0, 1])\nv_B = np.linalg.inv(B) @ v\nprint(\"v in basis B:\", v_B)"
  },
  {
    "input": "Let transformation T = reflection over y = x. Find its matrix in standard basis.",
    "output": "import numpy as np\n\nT = np.array([[0, 1], [1, 0]])\nprint(\"Reflection matrix over y = x:\", T)"
  },
  {
    "input": "A transformation matrix is symmetric. Does this affect its behavior under basis change?",
    "output": "print(\"A symmetric matrix remains symmetric in any orthonormal basis, preserving diagonalizability if real.\")"
  },
  {
    "input": "Let v = [3, -2] in basis B = {[2, 0], [0, 5]}. Find its coordinates in the standard basis.",
    "output": "import numpy as np\n\nv_B = np.array([3, -2])\nB = np.array([[2, 0], [0, 5]])\nv_std = B @ v_B\nprint(\"v in standard basis:\", v_std)"
  },
  {
    "input": "Find the inverse of the change-of-basis matrix from B = {[1, 1], [0, 1]} to standard.",
    "output": "import numpy as np\n\nB = np.array([[1, 0], [1, 1]])\nP = B\nP_inv = np.linalg.inv(P)\nprint(\"Inverse change-of-basis matrix:\", P_inv)"
  },
  {
    "input": "Is every invertible 2x2 matrix a change-of-basis matrix? Why or why not?",
    "output": "print(\"Yes, any invertible 2x2 matrix can be a change-of-basis matrix, since it maps a basis to another.\")"
  },
  {
    "input": "Convert [2, 1] from standard to orthonormal basis B = {[1/\u221a2, 1/\u221a2], [1/\u221a2, -1/\u221a2]}.",
    "output": "import numpy as np\n\nv = np.array([2, 1])\nb1 = np.array([1, 1]) / np.sqrt(2)\nb2 = np.array([1, -1]) / np.sqrt(2)\nv_B = np.array([np.dot(v, b1), np.dot(v, b2)])\nprint(\"v in orthonormal basis B:\", v_B)"
  },
  {
    "input": "Let A = [[2, 1], [0, 2]]. Is it diagonalizable? Show its matrix in its eigenbasis.",
    "output": "import numpy as np\n\nA = np.array([[2, 1], [0, 2]])\nvals, vecs = np.linalg.eig(A)\nA_diag = np.linalg.inv(vecs) @ A @ vecs\nprint(\"Eigenvalues:\", vals)\nprint(\"A in eigenbasis:\", A_diag)"
  },
  {
    "input": "Determine if the basis B = {[1, 2, 3], [2, 4, 6], [0, 1, 0]} is valid.",
    "output": "import numpy as np\n\nB = np.array([[1, 2, 0], [2, 4, 1], [3, 6, 0]]).T\nrank = np.linalg.matrix_rank(B)\nprint(\"Rank:\", rank)\nprint(\"Is valid basis?\", rank == 3)"
  },
  {
    "input": "Find the standard representation of vector [2, 4] originally in B = {[1, 1], [2, 1]}.",
    "output": "import numpy as np\n\nv_B = np.array([2, 4])\nB = np.array([[1, 2], [1, 1]])\nv_std = B @ v_B\nprint(\"Standard coordinates:\", v_std)"
  },
  {
    "input": "Let B = {[1, 0], [0, 0]}. Determine whether B is a valid basis for \u211d\u00b2 and explain.",
    "output": "import numpy as np\n\nB = np.array([[1, 0], [0, 0]])\ndet = np.linalg.det(B)\nprint(\"Determinant:\", det)\nprint(\"Valid basis?\", not np.isclose(det, 0))  # Should return False"
  },
  {
    "input": "Let A = [[1, 2], [3, 4]]. Find a basis B such that A becomes diagonal in B.",
    "output": "import numpy as np\n\nA = np.array([[1, 2], [3, 4]])\nvals, vecs = np.linalg.eig(A)\nA_diag = np.diag(vals)\nprint(\"Eigenbasis B (columns):\\n\", vecs)\nprint(\"Diagonalized A:\", A_diag)"
  },
  {
    "input": "Let v = [3, 2] and B = {[1, 1], [2, 2]}. Find v in basis B and explain any issue.",
    "output": "import numpy as np\n\nB = np.array([[1, 2], [1, 2]])\nrank = np.linalg.matrix_rank(B)\nprint(\"Rank of B:\", rank)\nif rank < 2:\n    print(\"B is not a basis \u2014 the vectors are linearly dependent.\")\nelse:\n    v = np.array([3, 2])\n    v_B = np.linalg.inv(B) @ v\n    print(\"v in basis B:\", v_B)"
  },
  {
    "input": "Given two different bases B and C for \u211d\u00b2, show that the change of basis matrix from B to C is invertible.",
    "output": "import numpy as np\n\nB = np.array([[1, 2], [3, 4]])\nC = np.array([[2, 0], [0, 1]])\nP = np.linalg.inv(C) @ B\nprint(\"Change-of-basis matrix from B to C:\\n\", P)\nprint(\"Is invertible?\", np.linalg.matrix_rank(P) == 2)"
  },
  {
    "input": "Why does converting a vector to a basis with linearly dependent vectors fail?",
    "output": "print(\"Linearly dependent vectors do not span the space, so the basis matrix is singular and not invertible.\")"
  },
  {
    "input": "Let A = identity matrix. Show that it looks the same in every orthonormal basis.",
    "output": "import numpy as np\n\nA = np.eye(3)\nQ, _ = np.linalg.qr(np.random.rand(3,3))  # Random orthonormal basis\nA_prime = np.linalg.inv(Q) @ A @ Q\nprint(\"A in orthonormal basis:\", A_prime)"
  },
  {
    "input": "Use Gram-Schmidt to create an orthonormal basis from B = [[3, 1], [2, 2]].",
    "output": "import numpy as np\n\nB = np.array([[3, 2], [1, 2]], dtype=float)  # Ensure float type for safe division and subtraction\n\ndef gram_schmidt(vectors):\n    ortho = []\n    for v in vectors.T:\n        v = v.copy()\n        for b in ortho:\n            v -= np.dot(v, b) * b\n        v = v / np.linalg.norm(v)\n        ortho.append(v)\n    return np.stack(ortho, axis=1)\n\nB_ortho = gram_schmidt(B)\nprint(\"Orthonormal basis:\\n\", B_ortho)"
  },
  {
    "input": "Let A = [[1, 1], [0, 1]]. Why can\u2019t it be diagonalized?",
    "output": "import numpy as np\n\nA = np.array([[1, 1], [0, 1]])\nvals, vecs = np.linalg.eig(A)\nprint(\"Eigenvalues:\", vals)\nprint(\"Eigenvectors:\\n\", vecs)\nrank = np.linalg.matrix_rank(vecs)\nprint(\"Is diagonalizable?\", rank == A.shape[0])"
  },
  {
    "input": "Find coordinates of [0, 0, 0] in basis B = {[1, 0, 0], [0, 1, 0], [1, 1, 1]} and interpret.",
    "output": "import numpy as np\n\nB = np.array([[1, 0, 1], [0, 1, 1], [0, 0, 1]])\nv = np.array([0, 0, 0])\nv_B = np.linalg.inv(B) @ v\nprint(\"Zero vector in B:\", v_B)"
  },
  {
    "input": "Let B = {[1, 0], [1, 0]}. Why does changing to this basis fail?",
    "output": "import numpy as np\n\nB = np.array([[1, 1], [0, 0]])\ndet = np.linalg.det(B)\nprint(\"Determinant:\", det)\nprint(\"Valid basis?\", not np.isclose(det, 0))"
  },
  {
    "input": "Show that a change of basis matrix is always invertible if both bases are valid.",
    "output": "import numpy as np\n\nB = np.array([[1, 2], [0, 1]])\nC = np.array([[2, 1], [1, 2]])\nP = np.linalg.inv(C) @ B\nprint(\"Change-of-basis matrix:\\n\", P)\nprint(\"Determinant:\", np.linalg.det(P))"
  },
  {
    "input": "Find the coordinates of vector [1, 1] in rotated basis by 45 degrees.",
    "output": "import numpy as np\n\nv = np.array([1, 1])\ntheta = np.pi / 4\nQ = np.array([[np.cos(theta), -np.sin(theta)], [np.sin(theta), np.cos(theta)]])\nv_B = Q.T @ v\nprint(\"Coordinates in rotated basis:\", v_B)"
  },
  {
    "input": "Prove that transforming to a basis and back yields the identity matrix compositionally.",
    "output": "import numpy as np\n\nB = np.array([[2, 1], [1, 2]])\nP = B\nP_inv = np.linalg.inv(P)\nI = P @ P_inv\nprint(\"P * P_inv = Identity:\", np.allclose(I, np.eye(2)))"
  },
  {
    "input": "Let B = {[1, 0], [0, 2]}. What kind of transformation does this basis encode?",
    "output": "print(\"This basis scales y-axis vectors by a factor of 2 while leaving x-axis unchanged.\")"
  },
  {
    "input": "Show that coordinate transformation is linear: T(av + bw) = aT(v) + bT(w).",
    "output": "import numpy as np\n\nB = np.array([[2, 1], [0, 1]])\nv = np.array([1, 2])\nw = np.array([3, 4])\na, b = 2, -1\nlhs = np.linalg.inv(B) @ (a*v + b*w)\nrhs = a * (np.linalg.inv(B) @ v) + b * (np.linalg.inv(B) @ w)\nprint(\"Linear transformation preserved?\", np.allclose(lhs, rhs))"
  },
  {
    "input": "Let B = {[1, 2], [2, 4]}. Attempt to transform vector and show what happens.",
    "output": "import numpy as np\n\nB = np.array([[1, 2], [2, 4]])\nv = np.array([5, 6])\ntry:\n    v_B = np.linalg.inv(B) @ v\n    print(\"v in B:\", v_B)\nexcept np.linalg.LinAlgError:\n    print(\"B is not invertible \u2014 linearly dependent vectors.\")"
  },
  {
    "input": "Let A = [[3, 1], [0, 3]]. Transform to Jordan form.",
    "output": "import sympy as sp\n\nA = sp.Matrix([[3, 1], [0, 3]])\nP, J = A.jordan_form()\nprint(\"Jordan form J:\")\nsp.pprint(J)\nprint(\"Transformation matrix P:\")\nsp.pprint(P)"
  },
  {
    "input": "Given orthonormal basis Q, show that Q.T == Q\u207b\u00b9 and verify numerically.",
    "output": "import numpy as np\n\nQ, _ = np.linalg.qr(np.random.rand(3,3))\nprint(\"Q.T == Q\u207b\u00b9?\", np.allclose(Q.T, np.linalg.inv(Q)))"
  },
  {
    "input": "Let A be a projection matrix onto x-axis. Show its matrix in basis B = {[1, 1], [1, -1]}.",
    "output": "import numpy as np\n\nA = np.array([[1, 0], [0, 0]])\nB = np.array([[1, 1], [1, -1]])\nA_B = np.linalg.inv(B) @ A @ B\nprint(\"Projection in new basis:\", A_B)"
  },
  {
    "input": "Can a matrix be diagonal in more than one basis? Justify with example.",
    "output": "print(\"Yes \u2014 for example, identity matrix is diagonal in every basis.\")"
  },
  {
    "input": "Construct a matrix that is not diagonalizable, and explain why.",
    "output": "import numpy as np\n\nA = np.array([[0, 1], [0, 0]])\nvals, vecs = np.linalg.eig(A)\nprint(\"Eigenvalues:\", vals)\nprint(\"Rank of eigenvector matrix:\", np.linalg.matrix_rank(vecs))"
  },
  {
    "input": "Show that coordinate change preserves vector magnitude in orthonormal bases only.",
    "output": "import numpy as np\n\nv = np.array([1, 1])\nB = np.array([[2, 0], [0, 1]])\nv_B = np.linalg.inv(B) @ v\nprint(\"Original magnitude:\", np.linalg.norm(v))\nprint(\"Transformed magnitude:\", np.linalg.norm(v_B))"
  },
  {
    "input": "Let B = {[1, 2, 3], [4, 5, 6], [7, 8, 9]}. Show that it\u2019s not a basis for \u211d\u00b3.",
    "output": "import numpy as np\n\nB = np.array([[1, 4, 7], [2, 5, 8], [3, 6, 9]])\nprint(\"Determinant:\", np.linalg.det(B))\nprint(\"Is valid basis?\", not np.isclose(np.linalg.det(B), 0))"
  },
  {
    "input": "Can two different vectors have the same coordinates in different bases?",
    "output": "print(\"Yes \u2014 if the bases are different, the same coordinates can represent different vectors in standard form.\")"
  },
  {
    "input": "Let B = {[1, 0], [0, 1]}. Express vector [4, 5] in basis B.",
    "output": "import numpy as np\n\nB = np.array([[1, 0], [0, 1]])\nv = np.array([4, 5])\nv_B = np.linalg.inv(B) @ v\nprint(\"Coordinates of v in basis B:\", v_B)"
  },
  {
    "input": "Let B = {[2, 1], [1, 1]}. Express vector [5, 3] in basis B.",
    "output": "import numpy as np\n\nB = np.array([[2, 1], [1, 1]])\nv = np.array([5, 3])\nv_B = np.linalg.inv(B) @ v\nprint(\"Coordinates of v in basis B:\", v_B)"
  },
  {
    "input": "Convert vector [3, 4] from basis B = {[1, 1], [1, -1]} to standard basis.",
    "output": "import numpy as np\n\nB = np.array([[1, 1], [1, -1]])\nv_B = np.array([3, 4])\nv = B @ v_B\nprint(\"Vector in standard basis:\", v)"
  },
  {
    "input": "Let B = {[1, 2], [3, 4]}, and v = [7, 10]. Find v in basis B and convert back.",
    "output": "import numpy as np\n\nB = np.array([[1, 3], [2, 4]])\nv = np.array([7, 10])\nv_B = np.linalg.inv(B) @ v\nv_recovered = B @ v_B\nprint(\"v in B:\", v_B)\nprint(\"Back to standard basis:\", v_recovered)"
  },
  {
    "input": "Prove that the change-of-basis matrix from B to C is invertible.",
    "output": "import numpy as np\n\nB = np.array([[1, 2], [0, 1]])\nC = np.array([[2, 0], [1, 3]])\nP = np.linalg.inv(C) @ B\nprint(\"Change of basis matrix:\\n\", P)\nprint(\"Is invertible?\", np.linalg.matrix_rank(P) == 2)"
  },
  {
    "input": "Let B = {[1, 2], [2, 4]}. Show why this is not a valid basis.",
    "output": "import numpy as np\n\nB = np.array([[1, 2], [2, 4]])\ndet = np.linalg.det(B)\nprint(\"Determinant of B:\", det)\nprint(\"Valid basis?\", not np.isclose(det, 0))"
  },
  {
    "input": "Diagonalize matrix A = [[2, 1], [1, 2]] using its eigenbasis.",
    "output": "import numpy as np\n\nA = np.array([[2, 1], [1, 2]])\nevals, evecs = np.linalg.eig(A)\nD = np.diag(evals)\nprint(\"Eigenvalues:\", evals)\nprint(\"Eigenvectors (columns):\\n\", evecs)\nprint(\"Diagonalized A (in eigenbasis):\\n\", D)"
  },
  {
    "input": "Let v = [6, 2] and B = {[2, 0], [0, 1]}. Convert v to basis B.",
    "output": "import numpy as np\n\nB = np.array([[2, 0], [0, 1]])\nv = np.array([6, 2])\nv_B = np.linalg.inv(B) @ v\nprint(\"Coordinates of v in B:\", v_B)"
  },
  {
    "input": "Given vector [1, 2, 3] and standard basis, express in another orthonormal basis.",
    "output": "import numpy as np\n\nv = np.array([1, 2, 3])\nQ, _ = np.linalg.qr(np.random.randn(3,3))  # random orthonormal basis\nv_Q = Q.T @ v\nprint(\"Coordinates in orthonormal basis:\", v_Q)"
  },
  {
    "input": "Let B = [[1, 1], [0, 1]]. Compute inverse and verify B\u207b\u00b9B = I.",
    "output": "import numpy as np\n\nB = np.array([[1, 1], [0, 1]])\nB_inv = np.linalg.inv(B)\nI = B_inv @ B\nprint(\"Inverse of B:\\n\", B_inv)\nprint(\"Product B\u207b\u00b9 * B:\\n\", I)"
  },
  {
    "input": "Let v = [1, 1] and B = [[0, 1], [1, 0]]. Convert v to B and back.",
    "output": "import numpy as np\n\nB = np.array([[0, 1], [1, 0]])\nv = np.array([1, 1])\nv_B = np.linalg.inv(B) @ v\nv_recovered = B @ v_B\nprint(\"v in B:\", v_B)\nprint(\"Back in standard basis:\", v_recovered)"
  },
  {
    "input": "Demonstrate that changing basis using orthogonal matrix preserves norms.",
    "output": "import numpy as np\n\nv = np.random.rand(3)\nQ, _ = np.linalg.qr(np.random.rand(3, 3))\nv_Q = Q.T @ v\nprint(\"Original norm:\", np.linalg.norm(v))\nprint(\"Norm in new basis:\", np.linalg.norm(v_Q))"
  },
  {
    "input": "Let v = [1, 1, 1] and B = identity matrix. Confirm v_B = v.",
    "output": "import numpy as np\n\nB = np.eye(3)\nv = np.array([1, 1, 1])\nv_B = np.linalg.inv(B) @ v\nprint(\"v in B:\", v_B)"
  },
  {
    "input": "Given matrix A = [[2, 0], [0, 3]], express A in basis B = [[1, 1], [1, -1]].",
    "output": "import numpy as np\n\nA = np.array([[2, 0], [0, 3]])\nB = np.array([[1, 1], [1, -1]])\nA_B = np.linalg.inv(B) @ A @ B\nprint(\"Matrix A in basis B:\\n\", A_B)"
  },
  {
    "input": "Let B = [[3, 1], [1, 2]]. Diagonalize B if possible.",
    "output": "import numpy as np\n\nB = np.array([[3, 1], [1, 2]])\nevals, evecs = np.linalg.eig(B)\nD = np.diag(evals)\nprint(\"Diagonal form:\\n\", D)\nprint(\"Eigenvectors:\\n\", evecs)"
  },
  {
    "input": "Show that identity matrix is the same in any basis.",
    "output": "import numpy as np\n\nI = np.eye(2)\nB = np.array([[1, 2], [3, 4]])\nI_B = np.linalg.inv(B) @ I @ B\nprint(\"Identity in new basis:\\n\", I_B)"
  },
  {
    "input": "Find matrix that reflects across line y = x, and show it in standard basis.",
    "output": "import numpy as np\n\nR = np.array([[0, 1], [1, 0]])\nprint(\"Reflection across y = x:\\n\", R)"
  },
  {
    "input": "Convert coordinates [2, -1] from basis B = [[2, 1], [1, -1]] to standard basis.",
    "output": "import numpy as np\n\nB = np.array([[2, 1], [1, -1]])\nv_B = np.array([2, -1])\nv = B @ v_B\nprint(\"Vector in standard basis:\", v)"
  },
  {
    "input": "Use symbolic computation to express a vector in a symbolic basis.",
    "output": "from sympy import symbols, Matrix\n\na, b = symbols('a b')\nv = Matrix([a + b, 2*a - b])\nB = Matrix([[1, 2], [1, -1]])\nv_B = B.inv() * v\nprint(\"v in B:\", v_B)"
  },
  {
    "input": "Let B = [[1, 1], [0, 1]]. Compute its determinant and invertibility.",
    "output": "import numpy as np\n\nB = np.array([[1, 1], [0, 1]])\ndet = np.linalg.det(B)\nprint(\"Determinant:\", det)\nprint(\"Invertible?\", not np.isclose(det, 0))"
  },
  {
    "input": "Let B be a random orthogonal matrix. Confirm B^T = B\u207b\u00b9.",
    "output": "import numpy as np\n\nQ, _ = np.linalg.qr(np.random.rand(3,3))\nprint(\"Q^T == Q\u207b\u00b9?\", np.allclose(Q.T, np.linalg.inv(Q)))"
  },
  {
    "input": "Let A = [[0, -1], [1, 0]]. Show it represents a 90\u00b0 rotation in \u211d\u00b2.",
    "output": "import numpy as np\n\nA = np.array([[0, -1], [1, 0]])\nv = np.array([1, 0])\nv_rot = A @ v\nprint(\"Rotated vector:\", v_rot)"
  },
  {
    "input": "Transform matrix A = [[1, 0], [0, 2]] to new basis B = [[1, 1], [-1, 1]].",
    "output": "import numpy as np\n\nA = np.array([[1, 0], [0, 2]])\nB = np.array([[1, -1], [1, 1]])\nA_B = np.linalg.inv(B) @ A @ B\nprint(\"A in basis B:\\n\", A_B)"
  },
  {
    "input": "Let B = [[1, 0], [0, -1]]. Show it reflects across x-axis.",
    "output": "import numpy as np\n\nB = np.array([[1, 0], [0, -1]])\nv = np.array([3, 4])\nv_reflected = B @ v\nprint(\"Reflected vector:\", v_reflected)"
  },
  {
    "input": "Let A = [[1, 2], [3, 4]] and B = [[1, 0], [0, 2]]. Find A in basis B.",
    "output": "import numpy as np\n\nA = np.array([[1, 2], [3, 4]])\nB = np.array([[1, 0], [0, 2]])\nA_B = np.linalg.inv(B) @ A @ B\nprint(\"A in basis B:\\n\", A_B)"
  },
  {
    "input": "Let A = [[0, 1], [-1, 0]], a 90-degree rotation. Find its representation in basis B = [[1, 1], [-1, 1]].",
    "output": "import numpy as np\n\nA = np.array([[0, 1], [-1, 0]])\nB = np.array([[1, -1], [1, 1]])\nA_B = np.linalg.inv(B) @ A @ B\nprint(\"A in basis B:\\n\", A_B)"
  },
  {
    "input": "Given A = [[3, 1], [0, 2]] and basis B = [[1, 2], [1, -1]], compute matrix representation in B.",
    "output": "import numpy as np\n\nA = np.array([[3, 1], [0, 2]])\nB = np.array([[1, 1], [2, -1]])\nA_B = np.linalg.inv(B) @ A @ B\nprint(\"A in basis B:\\n\", A_B)"
  },
  {
    "input": "Let A = [[2, 0], [0, 3]]. Use orthogonal basis B = [[1/\u221a2, 1/\u221a2], [-1/\u221a2, 1/\u221a2]]. Find A in B.",
    "output": "import numpy as np\n\nA = np.array([[2, 0], [0, 3]])\nB = np.array([[1/np.sqrt(2), -1/np.sqrt(2)], [1/np.sqrt(2), 1/np.sqrt(2)]])\nA_B = np.linalg.inv(B) @ A @ B\nprint(\"A in basis B:\\n\", A_B)"
  },
  {
    "input": "Let A = [[5, 2], [2, 5]]. Diagonalize A using its eigenbasis.",
    "output": "import numpy as np\n\nA = np.array([[5, 2], [2, 5]])\nevals, evecs = np.linalg.eig(A)\nD = np.diag(evals)\nprint(\"Eigenvalues:\", evals)\nprint(\"Diagonal matrix D:\\n\", D)\nprint(\"Change of basis matrix P (eigenvectors):\\n\", evecs)"
  },
  {
    "input": "Let A = [[1, 0], [0, 2]]. Find its representation in basis B = [[2, 1], [1, 1]].",
    "output": "import numpy as np\n\nA = np.array([[1, 0], [0, 2]])\nB = np.array([[2, 1], [1, 1]])\nA_B = np.linalg.inv(B) @ A @ B\nprint(\"Matrix A in basis B:\\n\", A_B)"
  },
  {
    "input": "Let A = [[1, 2], [3, 4]] and basis C = [[1, 1], [0, 1]]. Compute A in C.",
    "output": "import numpy as np\n\nA = np.array([[1, 2], [3, 4]])\nC = np.array([[1, 0], [1, 1]])\nA_C = np.linalg.inv(C) @ A @ C\nprint(\"A in basis C:\\n\", A_C)"
  },
  {
    "input": "Let A = [[0, -1], [1, 0]]. Diagonalize A if possible.",
    "output": "import numpy as np\n\nA = np.array([[0, -1], [1, 0]])\nevals, evecs = np.linalg.eig(A)\nprint(\"Eigenvalues:\", evals)\nprint(\"Diagonalizable?\", np.linalg.matrix_rank(evecs) == 2)"
  },
  {
    "input": "Given linear transformation matrix A = [[4, 1], [2, 3]], find A in new basis B = [[1, 0], [1, 1]].",
    "output": "import numpy as np\n\nA = np.array([[4, 1], [2, 3]])\nB = np.array([[1, 1], [0, 1]])\nA_B = np.linalg.inv(B) @ A @ B\nprint(\"Matrix A in new basis B:\\n\", A_B)"
  },
  {
    "input": "Show that trace of A = [[1,2],[3,4]] is invariant under basis change.",
    "output": "import numpy as np\n\nA = np.array([[1, 2], [3, 4]])\nB = np.array([[1, 1], [0, 1]])\nA_B = np.linalg.inv(B) @ A @ B\nprint(\"Trace A:\", np.trace(A))\nprint(\"Trace A in basis B:\", np.trace(A_B))"
  },
  {
    "input": "Confirm that similar matrices A and A' = P\u207b\u00b9AP have same determinant.",
    "output": "import numpy as np\n\nA = np.array([[1, 2], [3, 4]])\nP = np.array([[1, 1], [0, 1]])\nA_prime = np.linalg.inv(P) @ A @ P\nprint(\"det(A):\", np.linalg.det(A))\nprint(\"det(P\u207b\u00b9AP):\", np.linalg.det(A_prime))"
  },
  {
    "input": "Let A = [[3, -1], [1, 1]]. Find a basis that diagonalizes A.",
    "output": "import numpy as np\n\nA = np.array([[3, -1], [1, 1]])\nevals, evecs = np.linalg.eig(A)\nprint(\"Eigenvalues:\", evals)\nprint(\"Eigenbasis:\\n\", evecs)"
  },
  {
    "input": "If A has complex eigenvalues, can it be diagonalized over \u211d?",
    "output": "print(\"No, a real matrix with complex eigenvalues cannot be diagonalized over \u211d. It requires \u2102.\")"
  },
  {
    "input": "Given basis B = [[1, 1], [1, -1]] and linear map A = [[2, 0], [0, 3]], compute A_B.",
    "output": "import numpy as np\n\nA = np.array([[2, 0], [0, 3]])\nB = np.array([[1, 1], [1, -1]])\nA_B = np.linalg.inv(B) @ A @ B\nprint(\"Matrix in new basis:\\n\", A_B)"
  },
  {
    "input": "Prove similarity of A and A' = P\u207b\u00b9AP implies they share eigenvalues.",
    "output": "import numpy as np\n\nA = np.array([[4, 2], [1, 3]])\nP = np.array([[1, 1], [0, 1]])\nA_prime = np.linalg.inv(P) @ A @ P\nevals1 = np.linalg.eigvals(A)\nevals2 = np.linalg.eigvals(A_prime)\nprint(\"Eigenvalues of A:\", evals1)\nprint(\"Eigenvalues of A':\", evals2)"
  },
  {
    "input": "Show that if A is diagonal, then it's already in its eigenbasis.",
    "output": "import numpy as np\n\nA = np.diag([5, 7])\nevals, evecs = np.linalg.eig(A)\nprint(\"A is already diagonal. Eigenbasis:\\n\", evecs)"
  },
  {
    "input": "Let A = [[0, 1], [-2, -3]]. Find its representation in its eigenbasis.",
    "output": "import numpy as np\n\nA = np.array([[0, 1], [-2, -3]])\nevals, evecs = np.linalg.eig(A)\nA_diag = np.linalg.inv(evecs) @ A @ evecs\nprint(\"Diagonal matrix in eigenbasis:\\n\", A_diag)"
  },
  {
    "input": "Construct a matrix A, then show that P\u207b\u00b9AP transforms it to a simpler form.",
    "output": "import numpy as np\n\nA = np.array([[1, 2], [0, 1]])\nP = np.array([[1, 1], [0, 1]])\nA_new = np.linalg.inv(P) @ A @ P\nprint(\"Transformed matrix:\\n\", A_new)"
  },
  {
    "input": "Let A = [[2, 3], [0, 2]]. Is A diagonalizable?",
    "output": "import numpy as np\n\nA = np.array([[2, 3], [0, 2]])\nevals, evecs = np.linalg.eig(A)\nprint(\"Eigenvalues:\", evals)\nprint(\"Diagonalizable?\", np.linalg.matrix_rank(evecs) == 2)"
  },
  {
    "input": "Let A = [[1, 1], [0, 1]] be non-diagonalizable. Find Jordan form.",
    "output": "import sympy as sp\n\nA = sp.Matrix([[1, 1], [0, 1]])\nJ, P = A.jordan_form()\nprint(\"Jordan Form:\\n\", J)"
  },
  {
    "input": "Let A = [[0, 1], [-1, 0]]. Rotate a vector and express in rotated basis.",
    "output": "import numpy as np\n\nA = np.array([[0, 1], [-1, 0]])\nv = np.array([1, 0])\nrotated_v = A @ v\nB = A  # new basis is rotation matrix\nv_in_B = np.linalg.inv(B) @ rotated_v\nprint(\"Vector in rotated basis:\", v_in_B)"
  },
  {
    "input": "Let A = [[2, 1], [1, 2]]. Confirm it's diagonalizable with real eigenvalues.",
    "output": "import numpy as np\n\nA = np.array([[2, 1], [1, 2]])\nevals, evecs = np.linalg.eig(A)\nprint(\"Eigenvalues:\", evals)\nprint(\"Diagonalizable?\", np.linalg.matrix_rank(evecs) == 2)"
  },
  {
    "input": "Let A = identity matrix. Prove that change of basis has no effect.",
    "output": "import numpy as np\n\nA = np.eye(2)\nB = np.array([[1, 2], [3, 4]])\nA_B = np.linalg.inv(B) @ A @ B\nprint(\"A in new basis:\\n\", A_B)"
  },
  {
    "input": "Let A = [[1, 4], [2, 3]], and B = [[1, 0], [2, 1]]. Find matrix in B basis.",
    "output": "import numpy as np\n\nA = np.array([[1, 4], [2, 3]])\nB = np.array([[1, 2], [0, 1]])\nA_B = np.linalg.inv(B) @ A @ B\nprint(\"A in basis B:\\n\", A_B)"
  },
  {
    "input": "Express vector v = [3, 2] in basis B = [[1, 1], [1, -1]].",
    "output": "import numpy as np\n\nv = np.array([3, 2])\nB = np.array([[1, 1], [1, -1]])\nv_new = np.linalg.inv(B) @ v\nprint(\"Coordinates of v in basis B:\", v_new)"
  },
  {
    "input": "Convert v = [1, 2] from basis B = [[2, 1], [1, 1]] to standard basis.",
    "output": "import numpy as np\n\nv_B = np.array([1, 2])\nB = np.array([[2, 1], [1, 1]])\nv_standard = B @ v_B\nprint(\"v in standard basis:\", v_standard)"
  },
  {
    "input": "Given basis B = [[1, 2], [0, 1]] and v = [5, 3], find coordinates of v in B.",
    "output": "import numpy as np\n\nv = np.array([5, 3])\nB = np.array([[1, 0], [2, 1]])\nv_B = np.linalg.inv(B) @ v\nprint(\"v in basis B:\", v_B)"
  },
  {
    "input": "Find vector in standard basis given v_B = [1, -1] and B = [[1, 1], [0, 2]].",
    "output": "import numpy as np\n\nv_B = np.array([1, -1])\nB = np.array([[1, 0], [1, 2]])\nv_standard = B @ v_B\nprint(\"v in standard basis:\", v_standard)"
  },
  {
    "input": "Let v = [2, -1]. Find its coordinates in basis B = [[1, 0], [1, 1]].",
    "output": "import numpy as np\n\nv = np.array([2, -1])\nB = np.array([[1, 1], [0, 1]])\nv_B = np.linalg.inv(B) @ v\nprint(\"v in basis B:\", v_B)"
  },
  {
    "input": "Let B = [[2, 1], [-1, 1]] and v_B = [0, 3]. Find v in standard basis.",
    "output": "import numpy as np\n\nv_B = np.array([0, 3])\nB = np.array([[2, -1], [1, 1]])\nv_std = B @ v_B\nprint(\"v in standard basis:\", v_std)"
  },
  {
    "input": "Show change of basis and back again gives same vector: v = [4, 5], B = [[1, 1], [0, 2]].",
    "output": "import numpy as np\n\nv = np.array([4, 5])\nB = np.array([[1, 0], [1, 2]])\nv_B = np.linalg.inv(B) @ v\nv_back = B @ v_B\nprint(\"Back to standard:\", v_back)"
  },
  {
    "input": "Transform v = [6, -2] to coordinates in B = [[1, 2], [1, -1]].",
    "output": "import numpy as np\n\nv = np.array([6, -2])\nB = np.array([[1, 1], [2, -1]])\nv_B = np.linalg.inv(B) @ v\nprint(\"v in B:\", v_B)"
  },
  {
    "input": "Let v = [1, 3] and basis B = [[2, 1], [1, -1]]. Find v_B and verify back-transform.",
    "output": "import numpy as np\n\nv = np.array([1, 3])\nB = np.array([[2, 1], [1, -1]])\nv_B = np.linalg.inv(B) @ v\nv_std = B @ v_B\nprint(\"v_B:\", v_B)\nprint(\"Back to standard:\", v_std)"
  },
  {
    "input": "Express vector [7, 4] in basis B = [[1, 3], [2, 1]].",
    "output": "import numpy as np\n\nv = np.array([7, 4])\nB = np.array([[1, 2], [3, 1]])\nv_B = np.linalg.inv(B) @ v\nprint(\"v in basis B:\", v_B)"
  },
  {
    "input": "Check if B = [[1, 1], [1, 1]] is a valid basis.",
    "output": "import numpy as np\n\nB = np.array([[1, 1], [1, 1]])\ndet_B = np.linalg.det(B)\nprint(\"Is B a valid basis?\", det_B != 0)"
  },
  {
    "input": "Convert vector [2, 0] from B = [[1, 0], [1, 1]] to standard basis.",
    "output": "import numpy as np\n\nv_B = np.array([2, 0])\nB = np.array([[1, 1], [0, 1]])\nv_std = B @ v_B\nprint(\"Standard basis vector:\", v_std)"
  },
  {
    "input": "Convert v = [5, 1] to basis B = [[1, -1], [1, 1]] and back to standard.",
    "output": "import numpy as np\n\nv = np.array([5, 1])\nB = np.array([[1, 1], [-1, 1]])\nv_B = np.linalg.inv(B) @ v\nv_std = B @ v_B\nprint(\"v_B:\", v_B)\nprint(\"v back in standard:\", v_std)"
  },
  {
    "input": "Let B = [[3, 1], [1, 2]]. Convert v = [4, 5] into B basis.",
    "output": "import numpy as np\n\nv = np.array([4, 5])\nB = np.array([[3, 1], [1, 2]])\nv_B = np.linalg.inv(B) @ v\nprint(\"v in B basis:\", v_B)"
  },
  {
    "input": "Convert [0, 1] to basis B = [[1, 0], [2, 1]].",
    "output": "import numpy as np\n\nv = np.array([0, 1])\nB = np.array([[1, 2], [0, 1]])\nv_B = np.linalg.inv(B) @ v\nprint(\"v in B basis:\", v_B)"
  },
  {
    "input": "Express v = [6, 2] in rotated basis B = [[cos(pi/4), -sin(pi/4)], [sin(pi/4), cos(pi/4)]].",
    "output": "import numpy as np\n\nv = np.array([6, 2])\ntheta = np.pi / 4\nB = np.array([[np.cos(theta), np.sin(theta)], [-np.sin(theta), np.cos(theta)]])\nv_B = np.linalg.inv(B) @ v\nprint(\"v in rotated basis:\", v_B)"
  },
  {
    "input": "Check if B = [[0, 1], [0, 2]] is valid basis.",
    "output": "import numpy as np\n\nB = np.array([[0, 0], [1, 2]])\ndet_B = np.linalg.det(B)\nprint(\"Valid basis?\", det_B != 0)"
  },
  {
    "input": "Convert v = [1, 2] to basis B = [[2, 2], [1, -1]].",
    "output": "import numpy as np\n\nv = np.array([1, 2])\nB = np.array([[2, 1], [2, -1]])\nv_B = np.linalg.inv(B) @ v\nprint(\"v in B:\", v_B)"
  },
  {
    "input": "Let v_B = [3, -1] and B = [[4, 1], [2, 1]]. Get standard coordinates.",
    "output": "import numpy as np\n\nv_B = np.array([3, -1])\nB = np.array([[4, 2], [1, 1]])\nv_std = B @ v_B\nprint(\"v in standard basis:\", v_std)"
  },
  {
    "input": "Given basis B = [[1, 2], [1, -1]], find inverse transformation matrix.",
    "output": "import numpy as np\n\nB = np.array([[1, 1], [2, -1]])\nB_inv = np.linalg.inv(B)\nprint(\"Inverse change of basis matrix:\\n\", B_inv)"
  },
  {
    "input": "Let B = [[1, 0], [1, 1]]. Convert v = [3, 3] to B and back.",
    "output": "import numpy as np\n\nv = np.array([3, 3])\nB = np.array([[1, 1], [0, 1]])\nv_B = np.linalg.inv(B) @ v\nv_back = B @ v_B\nprint(\"v_B:\", v_B)\nprint(\"Back to standard:\", v_back)"
  },
  {
    "input": "Let v = [2, -3] and B = [[1, 1], [2, 1]]. Find v_B and check correctness.",
    "output": "import numpy as np\n\nv = np.array([2, -3])\nB = np.array([[1, 2], [1, 1]])\nv_B = np.linalg.inv(B) @ v\nprint(\"v in B:\", v_B)\nprint(\"Back to standard:\", B @ v_B)"
  },
  {
    "input": "Convert vector [7, 5] to B = [[1, 2], [3, 1]] and return to standard.",
    "output": "import numpy as np\n\nv = np.array([7, 5])\nB = np.array([[1, 3], [2, 1]])\nv_B = np.linalg.inv(B) @ v\nv_std = B @ v_B\nprint(\"v_B:\", v_B)\nprint(\"Back to standard:\", v_std)"
  },
  {
    "input": "Express v = [5, 6] in orthonormal basis B = [[1/\u221a2, -1/\u221a2], [1/\u221a2, 1/\u221a2]].",
    "output": "import numpy as np\n\nv = np.array([5, 6])\nB = np.array([[1/np.sqrt(2), 1/np.sqrt(2)], [-1/np.sqrt(2), 1/np.sqrt(2)]])\nv_B = np.linalg.inv(B) @ v\nprint(\"v in orthonormal basis:\", v_B)"
  },
  {
    "input": "Given linear transformation matrix A = [[2, 1], [0, 3]] and basis B = [[1, 1], [0, 1]], compute [T]_B.",
    "output": "import numpy as np\n\nA = np.array([[2, 1], [0, 3]])\nB = np.array([[1, 0], [1, 1]])\nP = B\nP_inv = np.linalg.inv(P)\nT_B = P_inv @ A @ P\nprint(\"Matrix representation [T]_B:\", T_B)"
  },
  {
    "input": "Let A = [[0, 1], [-2, -3]] and B = [[1, 1], [1, -1]]. Find representation of A in basis B.",
    "output": "import numpy as np\n\nA = np.array([[0, 1], [-2, -3]])\nB = np.array([[1, 1], [1, -1]])\nP = B\nP_inv = np.linalg.inv(P)\nA_B = P_inv @ A @ P\nprint(\"Matrix A in basis B:\", A_B)"
  },
  {
    "input": "Given matrix A = [[1, 2], [3, 4]] and B = [[1, 0], [1, 1]], find its form in B basis and back to standard.",
    "output": "import numpy as np\n\nA = np.array([[1, 2], [3, 4]])\nB = np.array([[1, 1], [0, 1]])\nP = B\nP_inv = np.linalg.inv(P)\nA_B = P_inv @ A @ P\nA_std_back = P @ A_B @ P_inv\nprint(\"A in basis B:\", A_B)\nprint(\"Back to standard:\", A_std_back)"
  },
  {
    "input": "Show that matrices A = [[5, 4], [1, 2]] and B = [[3, 2], [2, 1]] are not similar by computing their change of basis.",
    "output": "import numpy as np\n\nA = np.array([[5, 4], [1, 2]])\nB = np.array([[3, 2], [2, 1]])\n# Try to find P such that B = P\u207b\u00b9 A P is not generally possible\n# Here we simply compare eigenvalues\nwA, _ = np.linalg.eig(A)\nwB, _ = np.linalg.eig(B)\nprint(\"Eigenvalues of A:\", wA)\nprint(\"Eigenvalues of B:\", wB)"
  },
  {
    "input": "Given transformation A = [[4, 0], [1, 3]], and B = [[1, 2], [0, 1]], find [A]_B.",
    "output": "import numpy as np\n\nA = np.array([[4, 0], [1, 3]])\nB = np.array([[1, 0], [2, 1]])\nP = B\nP_inv = np.linalg.inv(P)\nA_B = P_inv @ A @ P\nprint(\"[A]_B:\", A_B)"
  },
  {
    "input": "Let T: R^2 \u2192 R^2 be represented by A = [[0, 1], [1, 0]]. Find T in basis B = [[1, 1], [1, -1]].",
    "output": "import numpy as np\n\nA = np.array([[0, 1], [1, 0]])\nB = np.array([[1, 1], [1, -1]])\nP = B\nP_inv = np.linalg.inv(P)\nT_B = P_inv @ A @ P\nprint(\"T in basis B:\", T_B)"
  },
  {
    "input": "Check if A = [[1, 2], [0, 3]] and A_B = [[1, 0], [0, 3]] can be related by a change of basis.",
    "output": "import numpy as np\n\nA = np.array([[1, 2], [0, 3]])\nA_B = np.array([[1, 0], [0, 3]])\n# Same eigenvalues => maybe similar\nwA, _ = np.linalg.eig(A)\nwB, _ = np.linalg.eig(A_B)\nprint(\"Eigenvalues A:\", wA)\nprint(\"Eigenvalues A_B:\", wB)"
  },
  {
    "input": "Given A = [[2, 3], [0, 1]], and B = [[1, 2], [2, 3]], compute [A]_B.",
    "output": "import numpy as np\n\nA = np.array([[2, 3], [0, 1]])\nB = np.array([[1, 2], [2, 3]])\nP = B\nP_inv = np.linalg.inv(P)\nA_B = P_inv @ A @ P\nprint(\"A in basis B:\", A_B)"
  },
  {
    "input": "Given transformation T(v) = Av with A = [[1, 1], [0, 1]], find its matrix under basis B = [[1, 0], [1, 1]].",
    "output": "import numpy as np\n\nA = np.array([[1, 1], [0, 1]])\nB = np.array([[1, 1], [0, 1]])\nP = B\nP_inv = np.linalg.inv(P)\nA_B = P_inv @ A @ P\nprint(\"Matrix A in new basis:\", A_B)"
  },
  {
    "input": "Find matrix representation of reflection across x-axis in basis B = [[1, 1], [1, -1]].",
    "output": "import numpy as np\n\nA = np.array([[1, 0], [0, -1]])\nB = np.array([[1, 1], [1, -1]])\nP = B\nP_inv = np.linalg.inv(P)\nA_B = P_inv @ A @ P\nprint(\"Reflection matrix in B:\", A_B)"
  },
  {
    "input": "Diagonalize matrix A = [[4, 1], [0, 4]] and find similarity transformation.",
    "output": "import numpy as np\n\nA = np.array([[4, 1], [0, 4]])\nw, P = np.linalg.eig(A)\nD = np.diag(w)\nP_inv = np.linalg.inv(P)\nA_diag = P @ D @ P_inv\nprint(\"Eigenvalues:\", w)\nprint(\"Diagonal matrix:\", D)\nprint(\"Reconstructed A:\", A_diag)"
  },
  {
    "input": "Given A = [[1, 2], [3, 4]] and eigenvectors [[-0.85, 0.52], [0.52, 0.85]], construct diagonal form.",
    "output": "import numpy as np\n\nA = np.array([[1, 2], [3, 4]])\n_, P = np.linalg.eig(A)\nD = np.diag(np.linalg.eigvals(A))\nP_inv = np.linalg.inv(P)\nA_diag = P @ D @ P_inv\nprint(\"Diagonalized A:\", A_diag)"
  },
  {
    "input": "Given A = [[3, 0], [0, 2]], verify A is already diagonal in standard basis.",
    "output": "import numpy as np\n\nA = np.array([[3, 0], [0, 2]])\nis_diag = np.allclose(A, np.diag(np.diag(A)))\nprint(\"Is A diagonal in standard basis?\", is_diag)"
  },
  {
    "input": "Let A = [[0, 1], [-1, 0]] (rotation by 90 degrees). Is A diagonalizable?",
    "output": "import numpy as np\n\nA = np.array([[0, 1], [-1, 0]])\nevals, _ = np.linalg.eig(A)\nprint(\"Eigenvalues:\", evals)"
  },
  {
    "input": "Find basis in which A = [[5, 4], [1, 2]] becomes diagonal.",
    "output": "import numpy as np\n\nA = np.array([[5, 4], [1, 2]])\nevals, evecs = np.linalg.eig(A)\nprint(\"Diagonal form:\", np.diag(evals))\nprint(\"Basis of eigenvectors:\", evecs)"
  },
  {
    "input": "Given A = [[2, 1], [0, 2]], check whether it's diagonalizable.",
    "output": "import numpy as np\n\nA = np.array([[2, 1], [0, 2]])\nevals, evecs = np.linalg.eig(A)\nrank = np.linalg.matrix_rank(evecs)\nprint(\"Eigenvalues:\", evals)\nprint(\"Rank of eigenvector matrix:\", rank)"
  },
  {
    "input": "Verify that A = [[1, 1], [0, 1]] is not diagonalizable.",
    "output": "import numpy as np\n\nA = np.array([[1, 1], [0, 1]])\nevals, evecs = np.linalg.eig(A)\nprint(\"Eigenvalues:\", evals)\nprint(\"Eigenvectors:\", evecs)"
  },
  {
    "input": "Construct similarity transformation for A = [[0, 1], [-1, 0]].",
    "output": "import numpy as np\n\nA = np.array([[0, 1], [-1, 0]])\nevals, evecs = np.linalg.eig(A)\nprint(\"Eigenvalues:\", evals)\nprint(\"Eigenvectors:\", evecs)"
  },
  {
    "input": "Use Jordan form to represent A = [[1, 1], [0, 1]].",
    "output": "import numpy as np\n\nA = np.array([[1, 1], [0, 1]])\n# Jordan form is A itself since it's not diagonalizable\nprint(\"Jordan form of A:\", A)"
  },
  {
    "input": "Compute transformation matrix to diagonalize A = [[3, 1], [0, 3]].",
    "output": "import numpy as np\n\nA = np.array([[3, 1], [0, 3]])\nevals, evecs = np.linalg.eig(A)\nprint(\"Eigenvalues:\", evals)\nprint(\"Eigenvectors:\", evecs)"
  },
  {
    "input": "Given A = [[4, 2], [1, 3]], compute similarity matrix P and diagonal D.",
    "output": "import numpy as np\n\nA = np.array([[4, 2], [1, 3]])\nevals, evecs = np.linalg.eig(A)\nP = evecs\nD = np.diag(evals)\nprint(\"P:\", P)\nprint(\"D:\", D)"
  },
  {
    "input": "Show that determinant is preserved under similarity: det(A) = det(P\u207b\u00b9AP).",
    "output": "import numpy as np\n\nA = np.array([[1, 2], [3, 4]])\nevals, evecs = np.linalg.eig(A)\nP = evecs\nP_inv = np.linalg.inv(P)\nA_sim = P_inv @ A @ P\nprint(\"det(A):\", np.linalg.det(A))\nprint(\"det(P\u207b\u00b9 A P):\", np.linalg.det(A_sim))"
  },
  {
    "input": "Show that trace is preserved under change of basis.",
    "output": "import numpy as np\n\nA = np.array([[5, 4], [1, 2]])\nevals, evecs = np.linalg.eig(A)\nP = evecs\nP_inv = np.linalg.inv(P)\nA_sim = P_inv @ A @ P\nprint(\"trace(A):\", np.trace(A))\nprint(\"trace(similar A):\", np.trace(A_sim))"
  },
  {
    "input": "Given matrix A = [[2, 1, 0], [0, 3, 1], [0, 0, 4]] and basis B = [[1,0,0], [1,1,0], [1,1,1]], compute [A]_B.",
    "output": "import numpy as np\n\nA = np.array([[2,1,0], [0,3,1], [0,0,4]])\nB = np.array([[1,0,0], [1,1,0], [1,1,1]])\nP = B\nP_inv = np.linalg.inv(P)\nA_B = P_inv @ A @ P\nprint(\"[A]_B:\", A_B)"
  },
  {
    "input": "Diagonalize the matrix A = [[6, 2, 1], [0, 3, 0], [0, 0, 3]] and verify A = P D P\u207b\u00b9.",
    "output": "import numpy as np\n\nA = np.array([[6, 2, 1], [0, 3, 0], [0, 0, 3]])\nw, P = np.linalg.eig(A)\nD = np.diag(w)\nP_inv = np.linalg.inv(P)\nA_diag = P @ D @ P_inv\nprint(\"Eigenvalues:\", w)\nprint(\"Diagonalized A:\", A_diag)"
  },
  {
    "input": "Given A = [[1,2,0], [0,1,2], [0,0,1]], find its Jordan form and check if it's diagonalizable.",
    "output": "import numpy as np\n\nA = np.array([[1,2,0], [0,1,2], [0,0,1]])\nevals, evecs = np.linalg.eig(A)\nprint(\"Eigenvalues:\", evals)\nprint(\"Diagonalizable:\", np.linalg.matrix_rank(evecs) == 3)"
  },
  {
    "input": "Let A = [[4,0,1], [0,2,0], [0,0,3]]. Transform A using B = [[1,1,0], [0,1,1], [1,0,1]].",
    "output": "import numpy as np\n\nA = np.array([[4,0,1], [0,2,0], [0,0,3]])\nB = np.array([[1,1,0], [0,1,1], [1,0,1]])\nP = B\nP_inv = np.linalg.inv(P)\nA_B = P_inv @ A @ P\nprint(\"A in basis B:\", A_B)"
  },
  {
    "input": "Given A = [[1,0,0], [0,2,0], [0,0,3]], apply a basis change with B = [[2,0,0], [0,2,0], [0,0,2]].",
    "output": "import numpy as np\n\nA = np.diag([1,2,3])\nB = np.diag([2,2,2])\nP = B\nP_inv = np.linalg.inv(P)\nA_B = P_inv @ A @ P\nprint(\"Transformed A:\", A_B)"
  },
  {
    "input": "Given 3D transformation matrix A = [[0,1,0], [0,0,1], [1,0,0]], find its form in basis B = I.",
    "output": "import numpy as np\n\nA = np.array([[0,1,0], [0,0,1], [1,0,0]])\nI = np.identity(3)\nP_inv = np.linalg.inv(I)\nA_B = P_inv @ A @ I\nprint(\"A in identity basis:\", A_B)"
  },
  {
    "input": "Verify that A = [[1,1,1], [0,1,1], [0,0,1]] has a single eigenvalue and is not diagonalizable.",
    "output": "import numpy as np\n\nA = np.array([[1,1,1], [0,1,1], [0,0,1]])\nevals, evecs = np.linalg.eig(A)\nprint(\"Eigenvalues:\", evals)\nprint(\"Diagonalizable:\", np.linalg.matrix_rank(evecs) == 3)"
  },
  {
    "input": "For A = [[3,0,0], [0,3,0], [0,0,3]], verify that any basis transforms it into itself.",
    "output": "import numpy as np\n\nA = 3 * np.eye(3)\n# Choose an invertible (non-singular) basis matrix\nB = np.array([[1, 0, 0], [1, 1, 0], [0, 1, 1]], dtype=float)\nP = B\nP_inv = np.linalg.inv(P)\nA_B = P_inv @ A @ P\nprint(\"Transformed A in new basis:\")\nprint(A_B)"
  },
  {
    "input": "Given A = [[5,1,0], [0,5,1], [0,0,5]], check if it's diagonalizable and compute Jordan form.",
    "output": "import numpy as np\n\nA = np.array([[5,1,0], [0,5,1], [0,0,5]])\nevals, evecs = np.linalg.eig(A)\nprint(\"Eigenvalues:\", evals)\nprint(\"Diagonalizable:\", np.linalg.matrix_rank(evecs) == 3)"
  },
  {
    "input": "Compute similarity transform for A = [[2,1,0], [0,2,1], [0,0,2]] using random invertible matrix.",
    "output": "import numpy as np\n\nA = np.array([[2,1,0], [0,2,1], [0,0,2]])\nP = np.array([[1,1,0], [0,1,1], [1,0,1]])\nP_inv = np.linalg.inv(P)\nA_sim = P_inv @ A @ P\nprint(\"Similarity transformed A:\", A_sim)"
  },
  {
    "input": "Let A = np.eye(4). Apply change of basis with B = [[1,0,0,0],[1,1,0,0],[1,1,1,0],[1,1,1,1]].",
    "output": "import numpy as np\n\nA = np.eye(4)\nB = np.array([[1,0,0,0],[1,1,0,0],[1,1,1,0],[1,1,1,1]])\nP_inv = np.linalg.inv(B)\nA_B = P_inv @ A @ B\nprint(\"Transformed A:\", A_B)"
  },
  {
    "input": "Given a 4x4 diagonal matrix A = diag([1,2,3,4]), confirm trace and determinant are basis-invariant.",
    "output": "import numpy as np\n\nA = np.diag([1,2,3,4])\nB = np.array([[1,0,0,0],[1,1,0,0],[1,1,1,0],[1,1,1,1]])\nP_inv = np.linalg.inv(B)\nA_B = P_inv @ A @ B\nprint(\"Trace original:\", np.trace(A))\nprint(\"Trace transformed:\", np.trace(A_B))\nprint(\"Det original:\", np.linalg.det(A))\nprint(\"Det transformed:\", np.linalg.det(A_B))"
  },
  {
    "input": "Use eigendecomposition to diagonalize A = [[1,0,0],[0,2,0],[0,0,3]].",
    "output": "import numpy as np\n\nA = np.diag([1,2,3])\nw, v = np.linalg.eig(A)\nP = v\nD = np.diag(w)\nP_inv = np.linalg.inv(P)\nprint(\"Diagonal matrix:\", D)"
  },
  {
    "input": "Compute the change of basis matrix from standard basis to B = [[1,2,3], [0,1,1], [1,0,1]].",
    "output": "import numpy as np\n\n# Corrected B matrix (linearly independent)\nB = np.array([[1, 0, 2], [0, 1, 1], [1, 1, 0]], dtype=float)\nP = B\nP_inv = np.linalg.inv(P)\nprint(\"Change of basis matrix P (from standard to B):\")\nprint(P)\nprint(\"Inverse P\u207b\u00b9 (from B to standard):\")\nprint(P_inv)"
  },
  {
    "input": "For transformation T: R^3 \u2192 R^3 with A = [[0,1,0],[0,0,1],[1,0,0]], compute A^3.",
    "output": "import numpy as np\n\nA = np.array([[0,1,0],[0,0,1],[1,0,0]])\nA3 = A @ A @ A\nprint(\"A\u00b3:\", A3)"
  },
  {
    "input": "Given A = [[2,1,0],[0,2,1],[0,0,2]], compute its minimal polynomial.",
    "output": "import numpy as np\n\nA = np.array([[2,1,0],[0,2,1],[0,0,2]])\nA2 = A @ A\nA3 = A2 @ A\nI = np.eye(3)\nprint(\"Try minimal polynomial (A-2I)^3 = 0:\", A3 - 6*A2 + 12*A - 8*I)"
  },
  {
    "input": "Let A be a rotation matrix in 3D around z-axis. Compute its form in a new orthogonal basis.",
    "output": "import numpy as np\n\nfrom scipy.spatial.transform import Rotation as R\nA = R.from_euler('z', 90, degrees=True).as_matrix()\nB = np.eye(3)\nP_inv = np.linalg.inv(B)\nA_B = P_inv @ A @ B\nprint(\"Rotation matrix in new basis:\", A_B)"
  },
  {
    "input": "Construct a transformation matrix that reflects over the yz-plane in 3D.",
    "output": "import numpy as np\n\nA = np.diag([-1,1,1])\nprint(\"Reflection over yz-plane:\", A)"
  },
  {
    "input": "Construct matrix for projection onto xy-plane in R^3.",
    "output": "import numpy as np\n\nA = np.array([[1,0,0],[0,1,0],[0,0,0]])\nprint(\"Projection onto xy-plane:\", A)"
  },
  {
    "input": "Rotate vector [1,0,0] by 120\u00b0 around axis [1,1,1] using rotation matrix.",
    "output": "import numpy as np\n\nfrom scipy.spatial.transform import Rotation as R\nrot = R.from_rotvec((2*np.pi/3)*np.array([1,1,1])/np.sqrt(3))\nv = np.array([1,0,0])\nresult = rot.apply(v)\nprint(\"Rotated vector:\", result)"
  },
  {
    "input": "Find if A = [[1,1,0],[0,1,1],[0,0,1]] is diagonalizable. If not, explain why.",
    "output": "import numpy as np\n\nA = np.array([[1,1,0],[0,1,1],[0,0,1]])\nevals, evecs = np.linalg.eig(A)\nrank = np.linalg.matrix_rank(evecs)\nprint(\"Eigenvalues:\", evals)\nprint(\"Rank of eigenspace:\", rank)\nprint(\"Diagonalizable:\", rank == 3)"
  },
  {
    "input": "Diagonalize matrix A = [[2,1,0],[0,2,1],[0,0,2]].",
    "output": "import numpy as np\n\nA = np.array([[2,1,0],[0,2,1],[0,0,2]])\nevals, evecs = np.linalg.eig(A)\nprint(\"Eigenvalues:\", evals)\nprint(\"Eigenvectors:\", evecs)"
  },
  {
    "input": "Given a 4x4 matrix A = diag([1,2,3,4]), verify similarity transformation with identity matrix.",
    "output": "import numpy as np\n\nA = np.diag([1,2,3,4])\nP = np.eye(4)\nP_inv = np.linalg.inv(P)\nA_B = P_inv @ A @ P\nprint(\"Transformed A:\", A_B)"
  },
  {
    "input": "Let A = [[4,1,0],[0,4,1],[0,0,4]]. Find its minimal polynomial and verify it's not diagonalizable.",
    "output": "import numpy as np\n\nA = np.array([[4,1,0],[0,4,1],[0,0,4]])\nI = np.eye(3)\nA_ = A - 4 * I\nA2 = A_ @ A_\nA3 = A2 @ A_\nprint(\"(A - 4I)^3:\", A3)\nprint(\"Diagonalizable:\", np.linalg.matrix_rank(np.linalg.eig(A)[1]) == 3)"
  },
  {
    "input": "Compute the matrix of T(x) = Ax where A = [[0,1],[1,0]] under basis B = [[1,1],[1,-1]].",
    "output": "import numpy as np\n\nA = np.array([[0,1],[1,0]])\nB = np.array([[1,1],[1,-1]])\nP = B\nP_inv = np.linalg.inv(P)\nA_B = P_inv @ A @ P\nprint(\"Matrix of T under B:\", A_B)"
  },
  {
    "input": "Given a matrix A = [[0,1,0], [0,0,1], [0,0,0]], compute its nilpotency index.",
    "output": "import numpy as np\n\nA = np.array([[0,1,0], [0,0,1], [0,0,0]])\nA2 = A @ A\nA3 = A2 @ A\nprint(\"A^3:\", A3)"
  },
  {
    "input": "Given matrix A = [[1,2],[3,4]], verify that trace and determinant remain unchanged under similarity.",
    "output": "import numpy as np\n\nA = np.array([[1,2],[3,4]])\nP = np.array([[1,1],[0,1]])\nP_inv = np.linalg.inv(P)\nA_sim = P_inv @ A @ P\nprint(\"Trace A:\", np.trace(A))\nprint(\"Trace A':\", np.trace(A_sim))\nprint(\"Det A:\", np.linalg.det(A))\nprint(\"Det A':\", np.linalg.det(A_sim))"
  },
  {
    "input": "Let A = [[2,1],[0,2]]. Find its Jordan canonical form.",
    "output": "import numpy as np\n\nA = np.array([[2,1],[0,2]])\nprint(\"This matrix is already in Jordan form:\", A)"
  },
  {
    "input": "Transform matrix A = [[0,-1],[1,0]] (90\u00b0 rotation) into new basis B = [[1,1],[1,-1]].",
    "output": "import numpy as np\n\nA = np.array([[0,-1],[1,0]])\nB = np.array([[1,1],[1,-1]])\nP = B\nP_inv = np.linalg.inv(P)\nA_B = P_inv @ A @ P\nprint(\"A in basis B:\", A_B)"
  },
  {
    "input": "Verify that the transformation matrix for reflection across y=x in R\u00b2 is its own inverse.",
    "output": "import numpy as np\n\nA = np.array([[0,1],[1,0]])\nA_inv = np.linalg.inv(A)\nprint(\"A:\", A)\nprint(\"A\u207b\u00b9:\", A_inv)"
  },
  {
    "input": "Let A = diag([1,2,3]). Compute A^5 using diagonal powers.",
    "output": "import numpy as np\n\nA = np.diag([1,2,3])\nA5 = np.diag([1**5, 2**5, 3**5])\nprint(\"A^5:\", A5)"
  },
  {
    "input": "Determine the matrix representing scaling by 3 in x, -2 in y, and 0.5 in z axes.",
    "output": "import numpy as np\n\nA = np.diag([3, -2, 0.5])\nprint(\"Scaling matrix:\", A)"
  },
  {
    "input": "Let A = [[3,0],[0,2]]. Construct matrix that transforms standard coordinates to eigenbasis.",
    "output": "import numpy as np\n\nA = np.array([[3,0],[0,2]])\nw, v = np.linalg.eig(A)\nP = v\nprint(\"Change of basis matrix:\", P)"
  },
  {
    "input": "Show that similarity transformations preserve eigenvalues of A = [[2,1],[0,2]].",
    "output": "import numpy as np\n\nA = np.array([[2,1],[0,2]])\nP = np.array([[1,1],[0,1]])\nP_inv = np.linalg.inv(P)\nA_sim = P_inv @ A @ P\nprint(\"Eigenvalues of A:\", np.linalg.eigvals(A))\nprint(\"Eigenvalues of A':\", np.linalg.eigvals(A_sim))"
  },
  {
    "input": "Transform A = [[1,1],[0,1]] using a random invertible matrix and compute A'.",
    "output": "import numpy as np\n\nA = np.array([[1,1],[0,1]])\nP = np.array([[2,1],[1,1]])\nP_inv = np.linalg.inv(P)\nA_sim = P_inv @ A @ P\nprint(\"Similarity transform:\", A_sim)"
  },
  {
    "input": "Find transformation matrix for 45\u00b0 rotation in 2D and verify orthogonality.",
    "output": "import numpy as np\n\ntheta = np.pi / 4\nA = np.array([[np.cos(theta), -np.sin(theta)], [np.sin(theta), np.cos(theta)]])\nprint(\"Rotation matrix:\", A)\nprint(\"Orthogonal check:\", np.allclose(A.T @ A, np.eye(2)))"
  },
  {
    "input": "Given A = [[2,0],[0,3]], transform into basis B = [[1,1],[1,-1]] and back to standard.",
    "output": "import numpy as np\n\nA = np.diag([2,3])\nB = np.array([[1,1],[1,-1]])\nP = B\nP_inv = np.linalg.inv(P)\nA_B = P_inv @ A @ P\nA_reconstructed = P @ A_B @ P_inv\nprint(\"A in B:\", A_B)\nprint(\"Reconstructed A:\", A_reconstructed)"
  },
  {
    "input": "Let T be a shear transformation in 2D: T(x, y) = (x + y, y). Write its matrix and change basis.",
    "output": "import numpy as np\n\nA = np.array([[1,1],[0,1]])\nB = np.array([[1,1],[1,-1]])\nP = B\nP_inv = np.linalg.inv(P)\nA_B = P_inv @ A @ P\nprint(\"Shear in new basis:\", A_B)"
  },
  {
    "input": "Diagonalize the symmetric matrix A = [[2,1],[1,2]] using eigendecomposition.",
    "output": "import numpy as np\n\nA = np.array([[2,1],[1,2]])\nw, v = np.linalg.eigh(A)\nD = np.diag(w)\nprint(\"Diagonal matrix:\", D)\nprint(\"Eigenvectors:\", v)"
  },
  {
    "input": "Determine if A = [[0,1,0],[0,0,1],[1,0,0]] is diagonalizable.",
    "output": "import numpy as np\n\nA = np.array([[0,1,0],[0,0,1],[1,0,0]])\nw, v = np.linalg.eig(A)\nprint(\"Eigenvalues:\", w)\nprint(\"Diagonalizable:\", np.linalg.matrix_rank(v) == 3)"
  },
  {
    "input": "Verify that two similar matrices A and B = P\u207b\u00b9AP have same characteristic polynomial.",
    "output": "import numpy as np\n\nA = np.array([[1,2],[3,4]])\nP = np.array([[1,1],[0,1]])\nP_inv = np.linalg.inv(P)\nB = P_inv @ A @ P\nevals_A = np.linalg.eigvals(A)\nevals_B = np.linalg.eigvals(B)\nprint(\"Eigenvalues match:\", np.allclose(sorted(evals_A), sorted(evals_B)))"
  },
  {
    "input": "Construct matrix that projects any 3D vector onto the xz-plane.",
    "output": "import numpy as np\n\nA = np.array([[1,0,0],[0,0,0],[0,0,1]])\nprint(\"Projection matrix onto xz-plane:\", A)"
  },
  {
    "input": "Find eigenvectors and eigenvalues of A = [[4,1],[2,3]].",
    "output": "import numpy as np\n\nA = np.array([[4,1],[2,3]])\nw, v = np.linalg.eig(A)\nprint(\"Eigenvalues:\", w)\nprint(\"Eigenvectors:\", v)"
  },
  {
    "input": "Given A = [[1,1],[0,1]], find generalized eigenvectors.",
    "output": "import numpy as np\n\nA = np.array([[1,1],[0,1]])\nw, v = np.linalg.eig(A)\nprint(\"Eigenvalues:\", w)\nprint(\"Eigenvectors:\", v)\nprint(\"Generalized eigenvectors may be required since algebraic > geometric multiplicity\")"
  },
  {
    "input": "Rotate a vector by 180 degrees using a transformation matrix in 2D.",
    "output": "import numpy as np\n\nA = np.array([[-1,0],[0,-1]])\nv = np.array([3,2])\nresult = A @ v\nprint(\"Rotated vector:\", result)"
  },
  {
    "input": "Let A = [[2,3],[0,1]]. Apply similarity transformation using B = [[1,0],[1,1]].",
    "output": "import numpy as np\n\nA = np.array([[2,3],[0,1]])\nB = np.array([[1,0],[1,1]])\nB_inv = np.linalg.inv(B)\nA_sim = B_inv @ A @ B\nprint(\"A in new basis:\", A_sim)"
  },
  {
    "input": "Given a 3D reflection matrix over the plane x + y + z = 0, write the transformation matrix.",
    "output": "import numpy as np\n\nv = np.array([1,1,1])\nv = v / np.linalg.norm(v)\nI = np.eye(3)\nA = I - 2 * np.outer(v, v)\nprint(\"Reflection matrix:\", A)"
  },
  {
    "input": "Verify if the matrix A = [[1, 2], [0, 1]] is diagonalizable using Python.",
    "output": "import numpy as np\n\nA = np.array([[1, 2], [0, 1]])\nw, v = np.linalg.eig(A)\nrank = np.linalg.matrix_rank(v)\nprint(\"Eigenvalues:\", w)\nprint(\"Eigenvectors:\", v)\nprint(\"Diagonalizable:\", rank == A.shape[0])"
  },
  {
    "input": "Check if the matrix A = [[0, 1], [-1, 0]] is orthogonal.",
    "output": "import numpy as np\n\nA = np.array([[0, 1], [-1, 0]])\nA_T = A.T\nproduct = A_T @ A\nprint(\"A\u1d40A:\", product)\nprint(\"Orthogonal:\", np.allclose(product, np.eye(2)))"
  },
  {
    "input": "Use Python to check whether the matrix A = [[2, 1], [0, 2]] has a complete set of linearly independent eigenvectors.",
    "output": "import numpy as np\n\nA = np.array([[2, 1], [0, 2]])\nw, v = np.linalg.eig(A)\nrank = np.linalg.matrix_rank(v)\nprint(\"Eigenvalues:\", w)\nprint(\"Rank of eigenvector matrix:\", rank)"
  },
  {
    "input": "Verify if a given matrix is symmetric: A = [[2, -1], [-1, 2]].",
    "output": "import numpy as np\n\nA = np.array([[2, -1], [-1, 2]])\nsymmetric = np.allclose(A, A.T)\nprint(\"Symmetric:\", symmetric)"
  },
  {
    "input": "Check if the transformation defined by A = [[1, 2], [3, 4]] preserves the dot product.",
    "output": "import numpy as np\n\nA = np.array([[1, 2], [3, 4]])\nx = np.array([1, 0])\ny = np.array([0, 1])\nleft = np.dot(A @ x, A @ y)\nright = np.dot(x, y)\nprint(\"Preserves dot product:\", np.isclose(left, right))"
  },
  {
    "input": "Determine whether A = [[0, 1], [1, 0]] is both symmetric and orthogonal.",
    "output": "import numpy as np\n\nA = np.array([[0, 1], [1, 0]])\nsymmetric = np.allclose(A, A.T)\northogonal = np.allclose(A @ A.T, np.eye(2))\nprint(\"Symmetric:\", symmetric)\nprint(\"Orthogonal:\", orthogonal)"
  },
  {
    "input": "Check if a matrix is normal: A = [[1, 2], [0, 1]].",
    "output": "import numpy as np\n\nA = np.array([[1, 2], [0, 1]])\nA_star = A.T\nnormal = np.allclose(A @ A_star, A_star @ A)\nprint(\"Normal:\", normal)"
  },
  {
    "input": "Determine if A = [[3, 0], [0, 4]] is an orthogonal matrix.",
    "output": "import numpy as np\n\nA = np.array([[3, 0], [0, 4]])\northogonal = np.allclose(A.T @ A, np.eye(2))\nprint(\"Orthogonal:\", orthogonal)"
  },
  {
    "input": "Check whether eigenvectors of a symmetric matrix A = [[4, 1], [1, 4]] are orthogonal.",
    "output": "import numpy as np\n\nA = np.array([[4, 1], [1, 4]])\n_, v = np.linalg.eigh(A)\northogonality = np.allclose(v.T @ v, np.eye(2))\nprint(\"Eigenvectors orthogonal:\", orthogonality)"
  },
  {
    "input": "Determine whether a matrix A = [[0, -1], [1, 0]] represents a rotation.",
    "output": "import numpy as np\n\nA = np.array([[0, -1], [1, 0]])\nrotation = np.allclose(A.T @ A, np.eye(2)) and np.isclose(np.linalg.det(A), 1)\nprint(\"Is rotation matrix:\", rotation)"
  },
  {
    "input": "Verify if matrix A = [[2, 1], [1, 2]] is diagonalizable and has real eigenvalues.",
    "output": "import numpy as np\n\nA = np.array([[2, 1], [1, 2]])\nevals, evecs = np.linalg.eig(A)\nreal = np.all(np.isreal(evals))\ndiagonalizable = np.linalg.matrix_rank(evecs) == A.shape[0]\nprint(\"Real eigenvalues:\", real)\nprint(\"Diagonalizable:\", diagonalizable)"
  },
  {
    "input": "Check if transformation matrix A = [[1, 1], [0, 1]] is invertible.",
    "output": "import numpy as np\n\nA = np.array([[1, 1], [0, 1]])\ndet = np.linalg.det(A)\nprint(\"Determinant:\", det)\nprint(\"Invertible:\", not np.isclose(det, 0))"
  },
  {
    "input": "Determine if the eigenvectors of A = [[1, 1], [0, 1]] form a basis.",
    "output": "import numpy as np\n\nA = np.array([[1, 1], [0, 1]])\n_, v = np.linalg.eig(A)\nrank = np.linalg.matrix_rank(v)\nprint(\"Eigenvectors form a basis:\", rank == A.shape[0])"
  },
  {
    "input": "Use Python to check whether A = [[1, 2], [3, 4]] has orthogonal eigenvectors.",
    "output": "import numpy as np\n\nA = np.array([[1, 2], [3, 4]])\n_, v = np.linalg.eig(A)\northogonality = np.allclose(v.T @ v, np.eye(2))\nprint(\"Eigenvectors orthogonal:\", orthogonality)"
  },
  {
    "input": "Determine if A = [[0, 1], [-1, 0]] preserves vector norms.",
    "output": "import numpy as np\n\nA = np.array([[0, 1], [-1, 0]])\nv = np.array([2, 3])\nnorm_original = np.linalg.norm(v)\nnorm_transformed = np.linalg.norm(A @ v)\nprint(\"Preserves norms:\", np.isclose(norm_original, norm_transformed))"
  },
  {
    "input": "Use Python to verify that eigenvectors of a symmetric matrix are linearly independent.",
    "output": "import numpy as np\n\nA = np.array([[2, -1], [-1, 2]])\n_, v = np.linalg.eigh(A)\nrank = np.linalg.matrix_rank(v)\nprint(\"Linearly independent eigenvectors:\", rank == A.shape[0])"
  },
  {
    "input": "Determine if A = [[1, 0], [0, -1]] is a reflection matrix.",
    "output": "import numpy as np\n\nA = np.array([[1, 0], [0, -1]])\ndet = np.linalg.det(A)\nsym = np.allclose(A @ A, np.eye(2))\nprint(\"Reflection matrix:\", det == -1 and sym)"
  },
  {
    "input": "Check if A = [[1,2],[3,4]] and B = [[1,2],[3,5]] are similar matrices.",
    "output": "import numpy as np\n\nA = np.array([[1,2],[3,4]])\nB = np.array([[1,2],[3,5]])\ncharpoly_A = np.poly(A)\ncharpoly_B = np.poly(B)\nprint(\"Similar:\", np.allclose(charpoly_A, charpoly_B))"
  },
  {
    "input": "Use Python to confirm that every real symmetric matrix is diagonalizable.",
    "output": "import numpy as np\n\nA = np.array([[3, 2], [2, 3]])\n_, v = np.linalg.eigh(A)\nrank = np.linalg.matrix_rank(v)\nprint(\"Symmetric and diagonalizable:\", rank == A.shape[0])"
  },
  {
    "input": "Check if the matrix A = [[1, 0, 0], [0, 0, -1], [0, 1, 0]] represents a 3D rotation.",
    "output": "import numpy as np\n\nA = np.array([[1, 0, 0], [0, 0, -1], [0, 1, 0]])\nrotation = np.allclose(A.T @ A, np.eye(3)) and np.isclose(np.linalg.det(A), 1)\nprint(\"3D Rotation:\", rotation)"
  },
  {
    "input": "Use Python to test if A = [[2,0],[0,2]] scales all vectors uniformly.",
    "output": "import numpy as np\n\nA = np.array([[2,0],[0,2]])\nv = np.array([1, 1])\nscaled = A @ v\nprint(\"Scaled vector:\", scaled)\nprint(\"Scale factor:\", scaled[0]/v[0])"
  },
  {
    "input": "Determine whether the inverse of an orthogonal matrix is its transpose using A = [[0,1],[1,0]].",
    "output": "import numpy as np\n\nA = np.array([[0,1],[1,0]])\nA_inv = np.linalg.inv(A)\nprint(\"Inverse equals transpose:\", np.allclose(A_inv, A.T))"
  },
  {
    "input": "Use Python to check whether the eigenspaces of A = [[1,0],[0,2]] are orthogonal.",
    "output": "import numpy as np\n\nA = np.array([[1,0],[0,2]])\n_, v = np.linalg.eig(A)\northogonality = np.allclose(v.T @ v, np.eye(2))\nprint(\"Eigenspaces orthogonal:\", orthogonality)"
  },
  {
    "input": "Test if a matrix A = [[4, 0], [3, 4]] is defective (i.e., not diagonalizable).",
    "output": "import numpy as np\n\nA = np.array([[4, 0], [3, 4]])\n_, v = np.linalg.eig(A)\nrank = np.linalg.matrix_rank(v)\nprint(\"Defective:\", rank < A.shape[0])"
  },
  {
    "input": "Check whether Jordan blocks are needed for A = [[5,1],[0,5]].",
    "output": "import numpy as np\n\nA = np.array([[5,1],[0,5]])\nw, v = np.linalg.eig(A)\nrank = np.linalg.matrix_rank(v)\nprint(\"Requires Jordan blocks:\", rank < A.shape[0])"
  },
  {
    "input": "Check if matrix A = [[2, 3], [0, 2]] is diagonalizable. Provide a clear result.",
    "output": "import numpy as np\n\nA = np.array([[2, 3], [0, 2]])\nevals, evecs = np.linalg.eig(A)\nrank = np.linalg.matrix_rank(evecs)\nprint(\"Eigenvalues of A:\", evals)\nprint(\"Diagonalizable:\" , rank == A.shape[0])"
  },
  {
    "input": "Determine whether A = [[0, -1], [1, 0]] is a rotation matrix.",
    "output": "import numpy as np\n\nA = np.array([[0, -1], [1, 0]])\nidentity_check = np.allclose(A.T @ A, np.eye(2))\ndet_check = np.isclose(np.linalg.det(A), 1)\nprint(\"A\u1d40A = I:\", identity_check)\nprint(\"det(A) = 1:\", det_check)\nprint(\"A is a rotation matrix:\", identity_check and det_check)"
  },
  {
    "input": "Verify if matrix A = [[4, -2], [1, 1]] is diagonalizable over the real numbers.",
    "output": "import numpy as np\n\nA = np.array([[4, -2], [1, 1]])\nevals, evecs = np.linalg.eig(A)\nreal_evals = np.all(np.isreal(evals))\nindep_evecs = np.linalg.matrix_rank(evecs) == A.shape[0]\nprint(\"Eigenvalues:\", evals)\nprint(\"Diagonalizable over \u211d:\", real_evals and indep_evecs)"
  },
  {
    "input": "Determine if A = [[1, 0], [0, -1]] reflects vectors across the x-axis.",
    "output": "import numpy as np\n\nA = np.array([[1, 0], [0, -1]])\nreflection = np.allclose(A @ np.array([1, 1]), np.array([1, -1]))\nprint(\"A reflects [1, 1] across x-axis:\", reflection)"
  },
  {
    "input": "Check if a symmetric matrix always has orthogonal eigenvectors: A = [[5, 2], [2, 5]].",
    "output": "import numpy as np\n\nA = np.array([[5, 2], [2, 5]])\n_, evecs = np.linalg.eigh(A)\northogonal = np.allclose(evecs.T @ evecs, np.eye(2))\nprint(\"Eigenvectors are orthogonal:\", orthogonal)"
  },
  {
    "input": "Confirm if the transformation A = [[1, 2], [2, 4]] is a projection.",
    "output": "import numpy as np\n\nA = np.array([[1, 2], [2, 4]])\nprojective = np.allclose(A @ A, A)\nprint(\"A\u00b2 = A:\", projective)\nprint(\"A is a projection:\", projective)"
  },
  {
    "input": "Determine whether the inverse of matrix A = [[0, 1], [-1, 0]] equals its transpose.",
    "output": "import numpy as np\n\nA = np.array([[0, 1], [-1, 0]])\nA_inv = np.linalg.inv(A)\nprint(\"A\u207b\u00b9 = A\u1d40:\", np.allclose(A_inv, A.T))"
  },
  {
    "input": "Use Python to confirm if the matrix A = [[3, 0], [0, 3]] scales all vectors by the same amount.",
    "output": "import numpy as np\n\nA = np.array([[3, 0], [0, 3]])\nv = np.array([2, -1])\nAv = A @ v\nscale = Av[0] / v[0]\nuniform_scaling = np.allclose(Av, scale * v)\nprint(\"Scaled vector:\", Av)\nprint(\"Uniform scaling factor:\", scale)\nprint(\"Uniform scaling confirmed:\", uniform_scaling)"
  },
  {
    "input": "Check if A = [[0, 1], [1, 0]] is symmetric and orthogonal.",
    "output": "import numpy as np\n\nA = np.array([[0, 1], [1, 0]])\nsymmetric = np.allclose(A, A.T)\northogonal = np.allclose(A @ A.T, np.eye(2))\nprint(\"Symmetric:\", symmetric)\nprint(\"Orthogonal:\", orthogonal)"
  },
  {
    "input": "Determine if the matrix A = [[2, 0], [0, 3]] has a complete set of eigenvectors.",
    "output": "import numpy as np\n\nA = np.array([[2, 0], [0, 3]])\n_, v = np.linalg.eig(A)\nfull_basis = np.linalg.matrix_rank(v) == A.shape[0]\nprint(\"Eigenvectors form a basis:\", full_basis)"
  },
  {
    "input": "Is A = [[1, 1], [0, 1]] defective (non-diagonalizable)?",
    "output": "import numpy as np\n\nA = np.array([[1, 1], [0, 1]])\n_, v = np.linalg.eig(A)\nrank = np.linalg.matrix_rank(v)\nprint(\"Matrix is defective:\", rank < A.shape[0])"
  },
  {
    "input": "Check whether A = [[0, 1], [-1, 0]] preserves the norm of any vector.",
    "output": "import numpy as np\n\nA = np.array([[0, 1], [-1, 0]])\nv = np.array([2, 3])\noriginal = np.linalg.norm(v)\ntransformed = np.linalg.norm(A @ v)\nprint(\"Original norm:\", original)\nprint(\"Transformed norm:\", transformed)\nprint(\"Norm preserved:\", np.isclose(original, transformed))"
  },
  {
    "input": "Determine whether eigenvectors of a real symmetric matrix A = [[6, -2], [-2, 3]] are orthonormal.",
    "output": "import numpy as np\n\nA = np.array([[6, -2], [-2, 3]])\n_, evecs = np.linalg.eigh(A)\nprint(\"Orthonormal eigenvectors:\", np.allclose(evecs.T @ evecs, np.eye(2)))"
  },
  {
    "input": "Check if the matrix A = [[0, -1], [1, 0]] represents a 90-degree rotation.",
    "output": "import numpy as np\n\nA = np.array([[0, -1], [1, 0]])\nv = np.array([1, 0])\nrotated = A @ v\nexpected = np.array([0, 1])\nprint(\"Rotation by 90 degrees confirmed:\", np.allclose(rotated, expected))"
  },
  {
    "input": "Determine if A = [[1, 2], [2, 5]] is positive definite.",
    "output": "import numpy as np\n\nA = np.array([[1, 2], [2, 5]])\nevals = np.linalg.eigvals(A)\nprint(\"Eigenvalues:\", evals)\nprint(\"Positive definite:\", np.all(evals > 0))"
  },
  {
    "input": "Check whether eigenvectors of A = [[2, 0], [0, 3]] are aligned with coordinate axes.",
    "output": "import numpy as np\n\nA = np.array([[2, 0], [0, 3]])\n_, v = np.linalg.eig(A)\naligned = np.allclose(v, np.eye(2)) or np.allclose(v, -np.eye(2))\nprint(\"Eigenvectors aligned with axes:\", aligned)"
  },
  {
    "input": "Determine whether the identity matrix is its own inverse.",
    "output": "import numpy as np\n\nI = np.eye(3)\nprint(\"Identity matrix equals its inverse:\", np.allclose(I, np.linalg.inv(I)))"
  },
  {
    "input": "Check if eigenvalues of A = [[1, 4], [0, 1]] are real and repeated.",
    "output": "import numpy as np\n\nA = np.array([[1, 4], [0, 1]])\nevals = np.linalg.eigvals(A)\nprint(\"Eigenvalues:\", evals)\nprint(\"Repeated real eigenvalues:\", np.isreal(evals).all() and np.isclose(evals[0], evals[1]))"
  },
  {
    "input": "Use Python to confirm that eigenvalues of an orthogonal matrix lie on the unit circle.",
    "output": "import numpy as np\n\nA = np.array([[0, -1], [1, 0]])\nevals = np.linalg.eigvals(A)\nmagnitudes = np.abs(evals)\nprint(\"Eigenvalue magnitudes:\", magnitudes)\nprint(\"Lie on unit circle:\", np.allclose(magnitudes, 1))"
  },
  {
    "input": "Check whether A = [[2, -2], [1, 3]] can be diagonalized over complex numbers.",
    "output": "import numpy as np\n\nA = np.array([[2, -2], [1, 3]])\nevals, evecs = np.linalg.eig(A)\nrank = np.linalg.matrix_rank(evecs)\nprint(\"Diagonalizable over \u2102:\", rank == A.shape[0])"
  },
  {
    "input": "Test if the matrix A = [[1, 1], [0, 1]] needs a Jordan form for full classification.",
    "output": "import numpy as np\n\nA = np.array([[1, 1], [0, 1]])\n_, v = np.linalg.eig(A)\nrank = np.linalg.matrix_rank(v)\nprint(\"Jordan form needed:\", rank < A.shape[0])"
  },
  {
    "input": "Verify whether the transpose of an orthogonal matrix is equal to its inverse.",
    "output": "import numpy as np\n\nQ = np.array([[0, 1], [-1, 0]])\nQ_inv = np.linalg.inv(Q)\nprint(\"Q\u1d40 = Q\u207b\u00b9:\", np.allclose(Q.T, Q_inv))"
  },
  {
    "input": "Check if eigenvectors of A = [[3, 4], [0, 3]] are linearly independent.",
    "output": "import numpy as np\n\nA = np.array([[3, 4], [0, 3]])\n_, v = np.linalg.eig(A)\nindependent = np.linalg.matrix_rank(v) == A.shape[0]\nprint(\"Eigenvectors linearly independent:\", independent)"
  },
  {
    "input": "Use Python to verify if a matrix A = [[1, 2], [2, 1]] is normal (A\u1d40A = AA\u1d40).",
    "output": "import numpy as np\n\nA = np.array([[1, 2], [2, 1]])\nnormal = np.allclose(A @ A.T, A.T @ A)\nprint(\"A is normal:\", normal)"
  },
  {
    "input": "Verify that if a matrix is diagonalizable, then there exists a basis of eigenvectors. Use A = [[4, 1], [0, 4]].",
    "output": "import numpy as np\n\nA = np.array([[4, 1], [0, 4]])\n_, evecs = np.linalg.eig(A)\nrank = np.linalg.matrix_rank(evecs)\nprint(\"Matrix A:\", A)\nprint(\"Eigenvectors:\", evecs)\nprint(\"A is diagonalizable (has full set of eigenvectors):\", rank == A.shape[0])"
  },
  {
    "input": "Demonstrate that similar matrices have the same eigenvalues. Use A = [[2, 1], [0, 2]] and P = [[1, 1], [0, 1]].",
    "output": "import numpy as np\n\nA = np.array([[2, 1], [0, 2]])\nP = np.array([[1, 1], [0, 1]])\nP_inv = np.linalg.inv(P)\nB = P_inv @ A @ P\nevals_A = np.linalg.eigvals(A)\nevals_B = np.linalg.eigvals(B)\nprint(\"Eigenvalues of A:\", evals_A)\nprint(\"Eigenvalues of B (similar to A):\", evals_B)\nprint(\"Eigenvalues are the same:\", np.allclose(sorted(evals_A), sorted(evals_B)))"
  },
  {
    "input": "Show that the determinant of a change-of-basis matrix is non-zero. Use P = [[2, 1], [1, 1]].",
    "output": "import numpy as np\n\nP = np.array([[2, 1], [1, 1]])\ndet_P = np.linalg.det(P)\nprint(\"Change of basis matrix P:\", P)\nprint(\"det(P):\", det_P)\nprint(\"Is invertible (non-zero determinant):\", not np.isclose(det_P, 0))"
  },
  {
    "input": "Prove that a matrix and its transpose have the same eigenvalues if the matrix is symmetric. Use A = [[5, 2], [2, 3]].",
    "output": "import numpy as np\n\nA = np.array([[5, 2], [2, 3]])\nevals_A = np.linalg.eigvals(A)\nevals_AT = np.linalg.eigvals(A.T)\nprint(\"Eigenvalues of A:\", evals_A)\nprint(\"Eigenvalues of A\u1d40:\", evals_AT)\nprint(\"Equal eigenvalues:\", np.allclose(sorted(evals_A), sorted(evals_AT)))"
  },
  {
    "input": "Show that orthogonal matrices preserve dot products. Use Q = [[0, 1], [-1, 0]] and vectors u = [1, 2], v = [3, 4].",
    "output": "import numpy as np\n\nQ = np.array([[0, 1], [-1, 0]])\nu = np.array([1, 2])\nv = np.array([3, 4])\nQu = Q @ u\nQv = Q @ v\ndot_original = np.dot(u, v)\ndot_transformed = np.dot(Qu, Qv)\nprint(\"Original dot product:\", dot_original)\nprint(\"Dot product after transformation:\", dot_transformed)\nprint(\"Preserved:\", np.isclose(dot_original, dot_transformed))"
  },
  {
    "input": "Demonstrate that the trace of a matrix is invariant under similarity transformations. Use A = [[1, 2], [3, 4]] and P = [[1, 0], [1, 1]].",
    "output": "import numpy as np\n\nA = np.array([[1, 2], [3, 4]])\nP = np.array([[1, 0], [1, 1]])\nP_inv = np.linalg.inv(P)\nB = P_inv @ A @ P\nprint(\"Trace of A:\", np.trace(A))\nprint(\"Trace of B (similar to A):\", np.trace(B))\nprint(\"Trace preserved:\", np.isclose(np.trace(A), np.trace(B)))"
  },
  {
    "input": "Verify that the inverse of a change-of-basis matrix transforms back to the original basis. Use B = [[1, 2], [0, 1]] and v = [3, 4].",
    "output": "import numpy as np\n\nB = np.array([[1, 2], [0, 1]])\nv = np.array([3, 4])\nv_new = np.linalg.inv(B) @ v\nv_back = B @ v_new\nprint(\"Transformed to new basis:\", v_new)\nprint(\"Back to original basis:\", v_back)\nprint(\"Restored correctly:\", np.allclose(v, v_back))"
  },
  {
    "input": "Prove that an orthonormal basis leads to an orthogonal matrix. Use Q = [[1/np.sqrt(2), 1/np.sqrt(2)], [-1/np.sqrt(2), 1/np.sqrt(2)]].",
    "output": "import numpy as np\n\nQ = np.array([[1/np.sqrt(2), 1/np.sqrt(2)], [-1/np.sqrt(2), 1/np.sqrt(2)]])\nQTQ = Q.T @ Q\nprint(\"Q\u1d40Q = I:\", np.allclose(QTQ, np.eye(2)))\nprint(\"Q is orthogonal:\", np.allclose(Q @ Q.T, np.eye(2)))"
  },
  {
    "input": "Check whether similarity preserves rank. Use A = [[1, 2], [0, 1]] and P = [[1, 0], [1, 1]].",
    "output": "import numpy as np\n\nA = np.array([[1, 2], [0, 1]])\nP = np.array([[1, 0], [1, 1]])\nP_inv = np.linalg.inv(P)\nB = P_inv @ A @ P\nprint(\"Rank of A:\", np.linalg.matrix_rank(A))\nprint(\"Rank of B:\", np.linalg.matrix_rank(B))\nprint(\"Ranks are equal:\", np.linalg.matrix_rank(A) == np.linalg.matrix_rank(B))"
  },
  {
    "input": "Confirm that real symmetric matrices are diagonalizable. Use A = [[3, 1], [1, 3]].",
    "output": "import numpy as np\n\nA = np.array([[3, 1], [1, 3]])\n_, v = np.linalg.eigh(A)\nprint(\"Eigenvectors:\", v)\nprint(\"Orthogonal basis from eigenvectors:\", np.allclose(v.T @ v, np.eye(2)))"
  },
  {
    "input": "Demonstrate that change of basis does not change the dimension of a vector space.",
    "output": "import numpy as np\n\nv = np.array([2, -1, 5])\nP = np.eye(3)\nv_new = P @ v\nprint(\"Original dimension:\", v.shape[0])\nprint(\"Transformed vector:\", v_new)\nprint(\"Dimension unchanged:\", v_new.shape[0] == v.shape[0])"
  },
  {
    "input": "Verify that the eigenvalues of a triangular matrix are its diagonal entries. Use A = [[2, 3], [0, 5]].",
    "output": "import numpy as np\n\nA = np.array([[2, 3], [0, 5]])\nevals = np.linalg.eigvals(A)\nprint(\"Eigenvalues:\", evals)\nprint(\"Match diagonal entries:\", np.allclose(evals, [2, 5]))"
  },
  {
    "input": "Show that orthogonal matrices preserve vector norms. Use Q = [[0, 1], [-1, 0]] and v = [1, 2].",
    "output": "import numpy as np\n\nQ = np.array([[0, 1], [-1, 0]])\nv = np.array([1, 2])\nvQ = Q @ v\nprint(\"Original norm:\", np.linalg.norm(v))\nprint(\"Norm after Q:\", np.linalg.norm(vQ))\nprint(\"Norm preserved:\", np.isclose(np.linalg.norm(v), np.linalg.norm(vQ)))"
  },
  {
    "input": "Prove that an orthogonal matrix has determinant \u00b11. Use Q = [[0, 1], [-1, 0]].",
    "output": "import numpy as np\n\nQ = np.array([[0, 1], [-1, 0]])\ndet_Q = np.linalg.det(Q)\nprint(\"det(Q):\", det_Q)\nprint(\"Is \u00b11:\", np.isclose(np.abs(det_Q), 1))"
  },
  {
    "input": "Show that a projection matrix satisfies P\u00b2 = P. Use P = [[1, 0], [0, 0]].",
    "output": "import numpy as np\n\nP = np.array([[1, 0], [0, 0]])\nprint(\"P\u00b2:\", P @ P)\nprint(\"P\u00b2 = P:\", np.allclose(P @ P, P))"
  },
  {
    "input": "Check if similar matrices have the same determinant. Use A = [[2, 0], [0, 3]] and P = [[1, 1], [0, 1]].",
    "output": "import numpy as np\n\nA = np.array([[2, 0], [0, 3]])\nP = np.array([[1, 1], [0, 1]])\nB = np.linalg.inv(P) @ A @ P\nprint(\"det(A):\", np.linalg.det(A))\nprint(\"det(B):\", np.linalg.det(B))\nprint(\"Determinants match:\", np.isclose(np.linalg.det(A), np.linalg.det(B)))"
  },
  {
    "input": "Demonstrate that any diagonal matrix is symmetric. Use D = [[3, 0], [0, -1]].",
    "output": "import numpy as np\n\nD = np.array([[3, 0], [0, -1]])\nprint(\"D is symmetric:\", np.allclose(D, D.T))"
  },
  {
    "input": "Show that the eigenvectors of a diagonal matrix form the standard basis. Use D = [[7, 0], [0, 4]].",
    "output": "import numpy as np\n\nD = np.array([[7, 0], [0, 4]])\n_, evecs = np.linalg.eig(D)\nprint(\"Eigenvectors of D:\", evecs)\nprint(\"Form standard basis:\", np.allclose(evecs, np.eye(2)) or np.allclose(evecs, -np.eye(2)))"
  },
  {
    "input": "Prove that real matrices may have complex eigenvalues. Use A = [[0, -1], [1, 0]].",
    "output": "import numpy as np\n\nA = np.array([[0, -1], [1, 0]])\nevals = np.linalg.eigvals(A)\nprint(\"Eigenvalues:\", evals)\nprint(\"Are complex:\", not np.all(np.isreal(evals)))"
  },
  {
    "input": "Verify that trace is the sum of eigenvalues. Use A = [[1, 2], [2, 1]].",
    "output": "import numpy as np\n\nA = np.array([[1, 2], [2, 1]])\nevals = np.linalg.eigvals(A)\nprint(\"Trace:\", np.trace(A))\nprint(\"Sum of eigenvalues:\", np.sum(evals))\nprint(\"Match:\", np.isclose(np.trace(A), np.sum(evals)))"
  },
  {
    "input": "Show that any square matrix can be written as A = PDP\u207b\u00b9 if it is diagonalizable. Use A = [[2, 1], [0, 2]].",
    "output": "import numpy as np\n\nA = np.array([[2, 1], [0, 2]])\nevals, evecs = np.linalg.eig(A)\nP = evecs\nD = np.diag(evals)\nP_inv = np.linalg.inv(P)\nA_reconstructed = P @ D @ P_inv\nprint(\"Original A:\", A)\nprint(\"Reconstructed A:\", A_reconstructed)\nprint(\"Equal:\", np.allclose(A, A_reconstructed))"
  },
  {
    "input": "Change the basis of vector v = [1, 2, 3] from standard basis to new basis B = [[1, 0, 1], [0, 1, 1], [0, 0, 1]].",
    "output": "import numpy as np\n\nv = np.array([1, 2, 3])\nB = np.array([[1, 0, 1], [0, 1, 1], [0, 0, 1]])\nB_inv = np.linalg.inv(B)\nv_B = B_inv @ v\nprint(\"Original vector v:\", v)\nprint(\"Basis matrix B:\", B)\nprint(\"Coordinates of v in basis B:\", v_B)"
  },
  {
    "input": "Given a matrix A = [[4, 2], [1, 3]], find its representation in a basis of its eigenvectors.",
    "output": "import numpy as np\n\nA = np.array([[4, 2], [1, 3]])\nevals, evecs = np.linalg.eig(A)\nD = np.diag(evals)\nP = evecs\nP_inv = np.linalg.inv(P)\nA_diag = P_inv @ A @ P\nprint(\"Original matrix A:\", A)\nprint(\"Diagonalized form D:\", A_diag)\nprint(\"Eigenbasis matrix P:\", P)"
  },
  {
    "input": "Rotate a vector v = [2, 1] by 90 degrees using a change of basis.",
    "output": "import numpy as np\n\nv = np.array([2, 1])\ntheta = np.pi / 2\nR = np.array([[np.cos(theta), -np.sin(theta)], [np.sin(theta), np.cos(theta)]])\nv_rot = R @ v\nprint(\"Original vector:\", v)\nprint(\"Rotation matrix (90\u00b0):\", R)\nprint(\"Rotated vector:\", v_rot)"
  },
  {
    "input": "Verify that change of basis using an orthogonal matrix preserves the dot product. Use v = [3, 4], Q = [[0, 1], [1, 0]].",
    "output": "import numpy as np\n\nv = np.array([3, 4])\nw = np.array([1, -1])\nQ = np.array([[0, 1], [1, 0]])\nv_Q = Q @ v\nw_Q = Q @ w\nprint(\"Dot product in standard basis:\", np.dot(v, w))\nprint(\"Dot product in transformed basis:\", np.dot(v_Q, w_Q))\nprint(\"Preserved:\", np.isclose(np.dot(v, w), np.dot(v_Q, w_Q)))"
  },
  {
    "input": "Project vector v = [2, 3, 4] onto a 2D subspace using basis B = [[1, 0], [0, 1], [0, 0]].",
    "output": "import numpy as np\n\nv = np.array([2, 3, 4])\nB = np.array([[1, 0], [0, 1], [0, 0]])\nB_proj = B @ np.linalg.pinv(B.T @ B) @ B.T\nv_proj = B_proj @ v\nprint(\"Original vector v:\", v)\nprint(\"Projection matrix:\", B_proj)\nprint(\"Projected vector in subspace:\", v_proj)"
  },
  {
    "input": "Verify numerically that similarity transformations preserve minimal polynomial. Use A = [[2,1],[0,2]] and B = P\u207b\u00b9AP with P = [[1,1],[0,1]].",
    "output": "import numpy as np\n\nA = np.array([[2, 1], [0, 2]])\nP = np.array([[1, 1], [0, 1]])\nP_inv = np.linalg.inv(P)\nB = P_inv @ A @ P\npoly_A = np.poly(A)\npoly_B = np.poly(B)\nprint(\"Char poly of A:\", poly_A)\nprint(\"Char poly of B:\", poly_B)\nprint(\"Polynomials match:\", np.allclose(poly_A, poly_B))"
  },
  {
    "input": "Use sympy to symbolically verify change of basis of vector v = [x, y] under basis B = [[1,1],[0,1]].",
    "output": "import sympy as sp\n\nx, y = sp.symbols('x y')\nv = sp.Matrix([x, y])\nB = sp.Matrix([[1, 1], [0, 1]])\nB_inv = B.inv()\nv_new = B_inv * v\nprint(\"Symbolic vector v:\", v)\nprint(\"New coordinates in basis B:\", v_new)"
  },
  {
    "input": "Demonstrate how Jordan blocks appear when change of basis fails to diagonalize A = [[2, 1], [0, 2]].",
    "output": "import numpy as np\n\nA = np.array([[2, 1], [0, 2]])\nevals, evecs = np.linalg.eig(A)\nprint(\"Eigenvalues:\", evals)\nprint(\"Eigenvectors:\", evecs)\nprint(\"Matrix is not diagonalizable:\", np.linalg.matrix_rank(evecs) < A.shape[0])"
  },
  {
    "input": "Transform matrix A = [[0,1,0],[0,0,1],[1,0,0]] into new basis B = identity. Confirm it remains unchanged.",
    "output": "import numpy as np\n\nA = np.array([[0, 1, 0], [0, 0, 1], [1, 0, 0]])\nB = np.eye(3)\nB_inv = np.linalg.inv(B)\nA_new = B_inv @ A @ B\nprint(\"A in new basis:\", A_new)\nprint(\"Unchanged:\", np.allclose(A, A_new))"
  },
  {
    "input": "Verify change of basis in symbolic 3D space using sympy. Use basis B = [[1,0,0],[1,1,0],[1,1,1]] and vector v = [a, b, c].",
    "output": "import sympy as sp\n\na, b, c = sp.symbols('a b c')\nv = sp.Matrix([a, b, c])\nB = sp.Matrix([[1, 0, 0], [1, 1, 0], [1, 1, 1]])\nB_inv = B.inv()\nv_new = B_inv * v\nprint(\"Symbolic vector v:\", v)\nprint(\"Coordinates in basis B:\", v_new)"
  },
  {
    "input": "Compute the change of coordinates of vector v = [2, 1, 3] in basis B = [[1,0,1], [0,1,1], [0,0,1]].",
    "output": "import numpy as np\n\nv = np.array([2, 1, 3])\nB = np.array([[1, 0, 1], [0, 1, 1], [0, 0, 1]])\ncoords = np.linalg.inv(B) @ v\nprint(\"Vector v in basis B:\", coords)"
  },
  {
    "input": "Demonstrate the effect of changing from one non-orthogonal basis to another in 2D.",
    "output": "import numpy as np\n\nv = np.array([4, 5])\nB1 = np.array([[1, 2], [1, 1]])\nB2 = np.array([[2, 1], [1, 2]])\nP = np.linalg.inv(B1) @ B2\nv_B1 = np.linalg.inv(B1) @ v\nv_B2 = P @ v_B1\nprint(\"v in basis B1:\", v_B1)\nprint(\"v in basis B2:\", v_B2)"
  },
  {
    "input": "Use a random orthogonal matrix to change the basis of a 3D vector. Verify orthogonality.",
    "output": "import numpy as np\n\nfrom scipy.stats import ortho_group\nQ = ortho_group.rvs(3)\nv = np.array([1, 0, 0])\nv_new = Q @ v\nprint(\"Orthogonal matrix Q:\", Q)\nprint(\"v in new basis:\", v_new)\nprint(\"Q\u1d40Q = I:\", np.allclose(Q.T @ Q, np.eye(3)))"
  },
  {
    "input": "Construct a basis using the Gram-Schmidt process from vectors [[1,1,0],[1,0,1],[0,1,1]].",
    "output": "import numpy as np\n\ndef gram_schmidt(V):\n    U = []\n    for v in V:\n        v = v.astype(float)  # Ensure float dtype\n        for u in U:\n            v = v - (np.dot(u, v) / np.dot(u, u)) * u\n        U.append(v)\n    return np.array(U)\n\nV = [np.array([1,1,0]), np.array([1,0,1]), np.array([0,1,1])]\northonormal = gram_schmidt(V)\nprint(\"Orthonormal basis (not normalized):\\n\", orthonormal)"
  },
  {
    "input": "Convert a basis defined in cylindrical coordinates to Cartesian.",
    "output": "import numpy as np\n\nr, theta, z = 2, np.pi / 4, 3\nx = r * np.cos(theta)\ny = r * np.sin(theta)\nv = np.array([x, y, z])\nprint(\"Cylindrical to Cartesian:\", v)"
  },
  {
    "input": "Prove numerically that if B is invertible, then every vector has a unique coordinate in basis B. Use B = [[1,1],[0,1]].",
    "output": "import numpy as np\n\nB = np.array([[1, 1], [0, 1]])\nv = np.array([3, 2])\nv_coords = np.linalg.inv(B) @ v\nv_back = B @ v_coords\nprint(\"Coordinates in basis B:\", v_coords)\nprint(\"Back to original:\", v_back)\nprint(\"Consistency check:\", np.allclose(v, v_back))"
  },
  {
    "input": "Use symbolic matrices to check change of basis identity: B\u207b\u00b9AB.",
    "output": "import sympy as sp\n\nA = sp.Matrix([[a, b], [0, a]])\nB = sp.Matrix([[1, 1], [0, 1]])\nA_new = B.inv() * A * B\nprint(\"A in new basis:\", A_new)"
  },
  {
    "input": "Find the transformation matrix that rotates a 2D vector by 45 degrees.",
    "output": "import numpy as np\n\ntheta = np.pi / 4\nR = np.array([[np.cos(theta), -np.sin(theta)], [np.sin(theta), np.cos(theta)]])\nprint(\"Rotation matrix (45\u00b0):\", R)"
  },
  {
    "input": "Decompose a vector using a non-standard orthogonal basis. Use Q = [[1,1],[-1,1]] / \u221a2.",
    "output": "import numpy as np\n\nQ = np.array([[1, 1], [-1, 1]]) / np.sqrt(2)\nv = np.array([3, 1])\nv_coords = Q.T @ v\nprint(\"Original vector:\", v)\nprint(\"Orthonormal basis Q:\", Q)\nprint(\"Coordinates in basis Q:\", v_coords)"
  },
  {
    "input": "Transform vector v = [1, 0, 1] to the basis B = [[1, 1, 0], [0, 1, 1], [1, 0, 1]] and back to standard basis.",
    "output": "import numpy as np\n\nv = np.array([1, 0, 1])\nB = np.array([[1, 1, 0], [0, 1, 1], [1, 0, 1]])\nB_inv = np.linalg.inv(B)\nv_coords = B_inv @ v\nv_reconstructed = B @ v_coords\nprint(\"Coordinates of v in basis B:\", v_coords)\nprint(\"Reconstructed vector in standard basis:\", v_reconstructed)"
  },
  {
    "input": "Given basis B = [[2, 0], [1, 3]] and C = [[1, 1], [0, 2]], find the change of basis matrix from B to C.",
    "output": "import numpy as np\n\nB = np.array([[2, 0], [1, 3]])\nC = np.array([[1, 1], [0, 2]])\nB_to_C = np.linalg.inv(C) @ B\nprint(\"Change of basis matrix from B to C:\", B_to_C)"
  },
  {
    "input": "Verify that transforming a matrix A to an orthonormal basis preserves its symmetric property. Use A = [[2, 1], [1, 3]].",
    "output": "import numpy as np\n\nA = np.array([[2, 1], [1, 3]])\nQ = np.array([[1, -1], [1, 1]]) / np.sqrt(2)\nQ_inv = Q.T\nA_new = Q_inv @ A @ Q\nprint(\"Original matrix A:\", A)\nprint(\"Transformed matrix in orthonormal basis:\", A_new)\nprint(\"Is symmetric in new basis:\", np.allclose(A_new, A_new.T))"
  },
  {
    "input": "Given a symbolic matrix A and basis B, express A in basis B using sympy.",
    "output": "import sympy as sp\n\nA = sp.Matrix([[a, b], [c, d]])\nB = sp.Matrix([[1, 1], [0, 1]])\nA_B = B.inv() * A * B\nprint(\"Matrix A in basis B:\")\nsp.pprint(A_B)"
  },
  {
    "input": "Apply change of basis to vector v = [3, 2] using random invertible matrix as basis.",
    "output": "import numpy as np\n\nB = np.random.randint(1, 5, (2, 2))\nwhile np.linalg.matrix_rank(B) < 2:\n    B = np.random.randint(1, 5, (2, 2))\nv = np.array([3, 2])\nv_B = np.linalg.inv(B) @ v\nprint(\"Random basis B:\", B)\nprint(\"Vector in new basis:\", v_B)"
  },
  {
    "input": "Create a symbolic proof that a change of basis matrix is invertible if the basis is linearly independent.",
    "output": "import sympy as sp\n\nx, y, z, w = sp.symbols('x y z w')\nB = sp.Matrix([[x, y], [z, w]])\ndet_B = B.det()\nprint(\"Basis matrix B:\")\nsp.pprint(B)\nprint(\"\\nDeterminant of B:\", det_B)\nprint(\"\\nIf the determinant is nonzero, then B is invertible. This means the basis vectors are linearly independent.\")"
  },
  {
    "input": "Change of basis for 4D vector using block-diagonal matrix. Use v = [1,2,3,4] and B = diag([[1,1],[0,1]]) twice.",
    "output": "import numpy as np\n\nv = np.array([1, 2, 3, 4])\nB1 = np.array([[1, 1], [0, 1]])\nB = np.block([\n    [B1, np.zeros((2, 2))],\n    [np.zeros((2, 2)), B1]\n])\nv_new = np.linalg.inv(B) @ v\nprint(\"Block-diagonal basis B:\", B)\nprint(\"v in new basis:\", v_new)"
  },
  {
    "input": "Given matrix A = [[2,0],[0,3]], and new basis B = [[1,1],[1,-1]], verify that its action changes in B.",
    "output": "import numpy as np\n\nA = np.array([[2, 0], [0, 3]])\nB = np.array([[1, 1], [1, -1]])\nB_inv = np.linalg.inv(B)\nA_new = B_inv @ A @ B\nprint(\"Matrix A in new basis B:\", A_new)"
  },
  {
    "input": "Demonstrate that rotating a basis preserves vector norms. Use Q = 2D rotation, v = [1, 0].",
    "output": "import numpy as np\n\ntheta = np.pi / 3\nQ = np.array([[np.cos(theta), -np.sin(theta)], [np.sin(theta), np.cos(theta)]])\nv = np.array([1, 0])\nv_rot = Q @ v\nprint(\"Rotated vector:\", v_rot)\nprint(\"Original norm:\", np.linalg.norm(v))\nprint(\"Rotated norm:\", np.linalg.norm(v_rot))"
  },
  {
    "input": "Change of basis for function space: represent f(x) = x\u00b2 in terms of basis {1, x, x\u00b2}.",
    "output": "import numpy as np\n\n# Polynomial vector representation\nf = np.array([0, 0, 1])  # x\u00b2\nB = np.eye(3)  # standard polynomial basis\ncoords = np.linalg.inv(B) @ f\nprint(\"f(x) = x\u00b2 coordinates in standard basis:\", coords)"
  },
  {
    "input": "Symbolically change basis for f(x) = x in {1+x, x} using sympy.",
    "output": "import sympy as sp\n\nf = sp.Matrix([0, 1])  # x\nB = sp.Matrix([[1, 0], [1, 1]])\nB_inv = B.inv()\nf_coords = B_inv * f\nprint(\"f(x) in new polynomial basis:\", f_coords)"
  },
  {
    "input": "Verify inverse transformation matrix returns original vector. Use B = [[2,1],[1,2]] and v = [5,3].",
    "output": "import numpy as np\n\nB = np.array([[2, 1], [1, 2]])\nv = np.array([5, 3])\nv_B = np.linalg.inv(B) @ v\nv_back = B @ v_B\nprint(\"v in basis B:\", v_B)\nprint(\"Back to original:\", v_back)"
  },
  {
    "input": "Symbolically verify B\u207b\u00b9 * (B * v) = v for generic 2D basis.",
    "output": "import sympy as sp\n\nx, y = sp.symbols('x y')\nv = sp.Matrix([x, y])\nB = sp.Matrix([[a, b], [c, d]])\nresult = B.inv() * (B * v)\nprint(\"Simplified result:\")\nsp.pprint(result)"
  },
  {
    "input": "Generate random 3D orthonormal basis and transform a vector into it.",
    "output": "import numpy as np\nfrom scipy.stats import ortho_group\n\nQ = ortho_group.rvs(3)\nv = np.array([1, 2, 3])\nv_new = Q.T @ v\nprint(\"Orthonormal basis Q:\", Q)\nprint(\"Vector in orthonormal basis:\", v_new)"
  },
  {
    "input": "Use QR decomposition to produce a new basis for 3D space.",
    "output": "import numpy as np\n\nA = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 10]])\nQ, R = np.linalg.qr(A)\nprint(\"Orthonormal basis from QR (columns of Q):\", Q)"
  },
  {
    "input": "Compute eigenbasis of A = [[0,1],[-2,-3]] and use it as change of basis.",
    "output": "import numpy as np\n\nA = np.array([[0, 1], [-2, -3]])\nevals, evecs = np.linalg.eig(A)\nv = np.array([1, 1])\nv_new = np.linalg.inv(evecs) @ v\nprint(\"Eigenvectors as basis:\", evecs)\nprint(\"v in eigenbasis:\", v_new)"
  },
  {
    "input": "Use matrix exponentials to show that similarity transforms commute. Use A and B = P\u207b\u00b9AP.",
    "output": "import numpy as np\nfrom scipy.linalg import expm\n\nA = np.array([[0, 1], [-1, 0]])\nP = np.array([[1, 1], [0, 1]])\nP_inv = np.linalg.inv(P)\nB = P_inv @ A @ P\nprint(\"exp(A):\", expm(A))\nprint(\"exp(B):\", expm(B))"
  },
  {
    "input": "Symbolically verify coordinate transformation between rotated and standard frame.",
    "output": "import sympy as sp\n\ntheta = sp.symbols('theta')\nvx, vy = sp.symbols('vx vy')\nR = sp.Matrix([[sp.cos(theta), -sp.sin(theta)], [sp.sin(theta), sp.cos(theta)]])\nv = sp.Matrix([vx, vy])\nv_rot = R.T * v\nprint(\"Rotated vector in new frame:\")\nsp.pprint(v_rot)"
  },
  {
    "input": "Diagonalize symmetric matrix A = [[4,1],[1,3]] and interpret the change of basis.",
    "output": "import numpy as np\n\nA = np.array([[4, 1], [1, 3]])\nevals, evecs = np.linalg.eigh(A)\nD = np.diag(evals)\nprint(\"Eigenbasis (orthonormal):\", evecs)\nprint(\"Diagonal form D:\", D)"
  },
  {
    "input": "For B = [[1,2],[3,4]], verify that det(B) \u2260 0 implies valid basis.",
    "output": "import numpy as np\n\nB = np.array([[1, 2], [3, 4]])\ndet_B = np.linalg.det(B)\nprint(\"Determinant of B:\", det_B)\nprint(\"Is B a valid basis (det \u2260 0)?\", det_B != 0)"
  },
  {
    "input": "Decompose a vector in a skewed 2D basis. Use B = [[2,1],[1,1]] and v = [5,4].",
    "output": "import numpy as np\n\nB = np.array([[2, 1], [1, 1]])\nv = np.array([5, 4])\nv_B = np.linalg.inv(B) @ v\nprint(\"Coordinates of v in skewed basis B:\", v_B)"
  },
  {
    "input": "Check that change of basis preserves vector length under orthogonal transformation.",
    "output": "import numpy as np\n\nQ = np.array([[0, 1], [1, 0]])\nv = np.array([3, 4])\nv_Q = Q @ v\nprint(\"Original length:\", np.linalg.norm(v))\nprint(\"Transformed length:\", np.linalg.norm(v_Q))"
  },
  {
    "input": "Convert 4D vector from one random basis to another and back. Confirm round-trip.",
    "output": "import numpy as np\n\nB1 = np.random.rand(4, 4)\nwhile np.linalg.matrix_rank(B1) < 4:\n    B1 = np.random.rand(4, 4)\nB2 = np.random.rand(4, 4)\nwhile np.linalg.matrix_rank(B2) < 4:\n    B2 = np.random.rand(4, 4)\nv = np.random.rand(4)\nv_B1 = np.linalg.inv(B1) @ v\nP = np.linalg.inv(B2) @ B1\nv_B2 = P @ v_B1\nv_back = B2 @ v_B2\nprint(\"Round-trip match:\", np.allclose(v, v_back))"
  },
  {
    "input": "Find the coordinate vector of v = [3, 1, 4] with respect to an orthonormal basis B formed by Gram-Schmidt process.",
    "output": "import numpy as np\nfrom scipy.linalg import orth\n\nv = np.array([3, 1, 4])\nX = np.array([[1, 0, 1], [0, 1, 1], [1, 1, 0]])\nB = orth(X)\nv_coords = B.T @ v\nprint(\"Orthonormal basis B:\", B)\nprint(\"Coordinates of v in basis B:\", v_coords)"
  },
  {
    "input": "Construct a change of basis matrix from standard basis to a custom 3D basis B, then verify its inverse maps back.",
    "output": "import numpy as np\n\nB = np.array([[2, 1, 0], [0, 3, 1], [1, 0, 2]])\nP = B\nP_inv = np.linalg.inv(P)\nv = np.array([5, 2, 3])\nv_B = P_inv @ v\nv_std = P @ v_B\nprint(\"Vector in new basis:\", v_B)\nprint(\"Reconstructed in standard basis:\", v_std)"
  },
  {
    "input": "Symbolically prove that if two bases are related by an invertible matrix P, then P\u207b\u00b9AP represents A in new basis.",
    "output": "import sympy as sp\n\nA = sp.MatrixSymbol('A', 2, 2)\nP = sp.MatrixSymbol('P', 2, 2)\nnew_A = P**-1 * A * P\nprint(\"Matrix A in new basis (symbolically):\")\nsp.pprint(new_A)"
  },
  {
    "input": "Transform a 4D vector to a random orthonormal basis using QR decomposition and convert it back.",
    "output": "import numpy as np\n\nA = np.random.randn(4, 4)\nQ, _ = np.linalg.qr(A)\nv = np.random.randn(4)\nv_coords = Q.T @ v\nv_reconstructed = Q @ v_coords\nprint(\"Coordinates in orthonormal basis:\", v_coords)\nprint(\"Reconstructed vector:\", v_reconstructed)"
  },
  {
    "input": "Define a matrix transformation that rotates vectors in the x-y plane and leaves z unchanged. Show basis transformation.",
    "output": "import numpy as np\n\nangle = np.pi / 4\nR = np.array([\n    [np.cos(angle), -np.sin(angle), 0],\n    [np.sin(angle), np.cos(angle), 0],\n    [0, 0, 1]\n])\nv = np.array([1, 0, 1])\nv_rotated = R @ v\nprint(\"Rotated vector:\", v_rotated)"
  },
  {
    "input": "Prove that determinant is invariant under change of basis for similar matrices.",
    "output": "import numpy as np\n\nA = np.array([[2, 1], [1, 2]])\nP = np.array([[1, 1], [0, 1]])\nA_new = np.linalg.inv(P) @ A @ P\nprint(\"det(A):\", np.linalg.det(A))\nprint(\"det(P\u207b\u00b9AP):\", np.linalg.det(A_new))"
  },
  {
    "input": "Use symbolic computation to check if change of basis preserves matrix rank.",
    "output": "import sympy as sp\n\nA = sp.Matrix([[1, 2], [3, 4]])\nP = sp.Matrix([[1, 1], [0, 1]])\nA_new = P.inv() * A * P\nprint(\"Rank before:\", A.rank())\nprint(\"Rank after:\", A_new.rank())"
  },
  {
    "input": "Find coordinates of v = [1, 2] in a rotated 2D frame rotated by 60 degrees.",
    "output": "import numpy as np\n\ntheta = np.pi / 3\nR = np.array([[np.cos(theta), -np.sin(theta)], [np.sin(theta), np.cos(theta)]])\nv = np.array([1, 2])\nv_rot = R.T @ v\nprint(\"Coordinates of v in rotated basis:\", v_rot)"
  },
  {
    "input": "Check if the basis transformation using a matrix with linearly dependent columns raises an error.",
    "output": "import numpy as np\n\nB = np.array([[1, 2], [2, 4]])\nv = np.array([3, 6])\ntry:\n    coords = np.linalg.inv(B) @ v\n    print(\"Coordinates:\", coords)\nexcept np.linalg.LinAlgError:\n    print(\"Error: Basis is not invertible (linearly dependent vectors).\")"
  },
  {
    "input": "Transform a linear map L(x) = Ax to a different basis and compare original and new outputs.",
    "output": "import numpy as np\n\nA = np.array([[1, 2], [3, 4]])\nB = np.array([[1, 1], [1, -1]])\nB_inv = np.linalg.inv(B)\nA_new = B_inv @ A @ B\nx = np.array([1, 0])\nLx_std = A @ x\nx_new = B_inv @ x\nLx_new = A_new @ x_new\nprint(\"L(x) in standard basis:\", Lx_std)\nprint(\"L(x) in new basis:\", B @ Lx_new)"
  },
  {
    "input": "Construct a new basis for R\u00b3 that includes a given vector v = [1,1,1] and verify orthogonality.",
    "output": "import numpy as np\nfrom scipy.linalg import null_space\n\nv = np.array([1, 1, 1])\nv = v / np.linalg.norm(v)\nnull = null_space(v.reshape(1, -1))\nB = np.column_stack((null, v))\nprint(\"Orthonormal basis including v:\", B)\nprint(\"Check orthogonality:\", np.allclose(B.T @ B, np.eye(3)))"
  },
  {
    "input": "Prove that the trace of a matrix is invariant under basis change using random 3x3 matrix.",
    "output": "import numpy as np\n\nA = np.random.randn(3,3)\nP = np.random.randn(3,3)\nwhile np.linalg.matrix_rank(P) < 3:\n    P = np.random.randn(3,3)\nA_new = np.linalg.inv(P) @ A @ P\nprint(\"Trace of A:\", np.trace(A))\nprint(\"Trace of transformed A:\", np.trace(A_new))"
  },
  {
    "input": "Use symbolic basis and show that transforming vector preserves the space span.",
    "output": "import sympy as sp\n\nB = sp.Matrix([[1, 2], [3, 4]])\nv = sp.Matrix([5, 6])\nv_new = B.inv() * v\nv_back = B * v_new\nprint(\"Original v:\")\nsp.pprint(v)\nprint(\"Reconstructed v:\")\nsp.pprint(v_back)"
  },
  {
    "input": "Visualize the original and transformed coordinate axes after change of basis.",
    "output": "import numpy as np\nimport matplotlib.pyplot as plt\n\nB = np.array([[2, 1], [1, 2]])\norigin = np.array([[0, 0], [0, 0]])\naxes = np.column_stack((B[:,0], B[:,1]))\nplt.quiver(*origin, axes[0], axes[1], color=['r','b'], scale=1, scale_units='xy')\nplt.xlim(-1,3)\nplt.ylim(-1,3)\nplt.grid(True)\nplt.title(\"Transformed Coordinate Axes\")\nplt.gca().set_aspect('equal')\nplt.show()"
  },
  {
    "input": "Decompose a 2D vector into a skewed basis and verify reconstruction.",
    "output": "import numpy as np\n\nB = np.array([[1, 2], [1, 1]])\nv = np.array([3, 4])\nv_coords = np.linalg.inv(B) @ v\nv_reconstructed = B @ v_coords\nprint(\"v in new basis:\", v_coords)\nprint(\"Reconstructed v:\", v_reconstructed)"
  },
  {
    "input": "Symbolically verify (P\u207b\u00b9AP)\u207f = P\u207b\u00b9A\u207fP for n = 2.",
    "output": "import sympy as sp\n\nA = sp.MatrixSymbol('A', 2, 2)\nP = sp.MatrixSymbol('P', 2, 2)\nleft = (P**-1 * A * P)**2\nright = P**-1 * (A**2) * P\nprint(\"Are the expressions equal?:\", sp.simplify(left - right) == 0)"
  },
  {
    "input": "Project a 3D vector onto a plane spanned by a non-orthogonal basis.",
    "output": "import numpy as np\n\nB = np.array([[1, 1], [2, 0], [0, 2]])\nv = np.array([3, 1, 4])\nproj = B @ np.linalg.pinv(B) @ v\nprint(\"Projection of v onto plane spanned by B:\", proj)"
  },
  {
    "input": "Given two bases B and C, compute transformation matrix from B to C and apply to vector.",
    "output": "import numpy as np\n\nB = np.array([[2, 1], [1, 2]])\nC = np.array([[1, 1], [1, -1]])\nv = np.array([3, 4])\nT = np.linalg.inv(C) @ B\nv_in_B = np.linalg.inv(B) @ v\nv_in_C = T @ v_in_B\nprint(\"Transformation matrix B to C:\", T)\nprint(\"v in basis C:\", v_in_C)"
  },
  {
    "input": "Symbolically verify that change of basis is a similarity transformation.",
    "output": "import sympy as sp\n\nA = sp.MatrixSymbol('A', 3, 3)\nP = sp.MatrixSymbol('P', 3, 3)\nsimilar_A = P**-1 * A * P\nprint(\"Similarity transformation representation:\")\nsp.pprint(similar_A)"
  },
  {
    "input": "Demonstrate that applying the identity basis results in no change to vector coordinates.",
    "output": "import numpy as np\n\nI = np.eye(3)\nv = np.array([5, -2, 7])\nv_coords = np.linalg.inv(I) @ v\nprint(\"Vector in identity basis:\", v_coords)"
  },
  {
    "input": "Given matrix A = [[0,1],[-1,0]], verify that eigenvectors form an orthonormal basis.",
    "output": "import numpy as np\n\nA = np.array([[0, 1], [-1, 0]])\nevals, evecs = np.linalg.eig(A)\northonormal = np.allclose(evecs.conj().T @ evecs, np.eye(2))\nprint(\"Eigenvectors:\", evecs)\nprint(\"Are they orthonormal?\", orthonormal)"
  },
  {
    "input": "Transform vector in polynomial basis {1, x, x^2} to new basis {1+x, x+x^2, x^2}.",
    "output": "import numpy as np\n\nB = np.array([[1, 0, 0], [1, 1, 0], [0, 1, 1]])\nv = np.array([0, 0, 1])  # x^2\nv_new = np.linalg.inv(B) @ v\nprint(\"Vector coordinates in new basis:\", v_new)"
  },
  {
    "input": "Fit a line y = mx + c using least squares for the points (1, 2), (2, 3), (3, 5).",
    "output": "import numpy as np\n\nx = np.array([1, 2, 3])\ny = np.array([2, 3, 5])\nA = np.vstack([x, np.ones(len(x))]).T\nm, c = np.linalg.lstsq(A, y, rcond=None)[0]\nprint(f\"Best fit line: y = {m:.2f}x + {c:.2f}\")"
  },
  {
    "input": "Use least squares to find the linear regression line for the data points: (0, 1), (1, 2), (2, 1.3), (3, 3.75).",
    "output": "import numpy as np\n\nx = np.array([0, 1, 2, 3])\ny = np.array([1, 2, 1.3, 3.75])\nA = np.vstack([x, np.ones(len(x))]).T\nm, c = np.linalg.lstsq(A, y, rcond=None)[0]\nprint(f\"Linear regression line: y = {m:.2f}x + {c:.2f}\")"
  },
  {
    "input": "Find the best fit line for the following data: x = [1, 2, 4], y = [2, 3, 6] using least squares method.",
    "output": "import numpy as np\n\nx = np.array([1, 2, 4])\ny = np.array([2, 3, 6])\nA = np.vstack([x, np.ones(len(x))]).T\nm, c = np.linalg.lstsq(A, y, rcond=None)[0]\nprint(f\"Fitted line: y = {m:.2f}x + {c:.2f}\")"
  },
  {
    "input": "Given points (1,1), (2,2), (3,2.5), (4,4), find the best fit line using least squares.",
    "output": "import numpy as np\n\nx = np.array([1, 2, 3, 4])\ny = np.array([1, 2, 2.5, 4])\nA = np.vstack([x, np.ones(len(x))]).T\nm, c = np.linalg.lstsq(A, y, rcond=None)[0]\nprint(f\"Least squares line: y = {m:.2f}x + {c:.2f}\")"
  },
  {
    "input": "Fit a linear regression line using least squares for x = [1, 3, 5], y = [1.2, 2.8, 5.1].",
    "output": "import numpy as np\n\nx = np.array([1, 3, 5])\ny = np.array([1.2, 2.8, 5.1])\nA = np.vstack([x, np.ones(len(x))]).T\nm, c = np.linalg.lstsq(A, y, rcond=None)[0]\nprint(f\"Regression line: y = {m:.2f}x + {c:.2f}\")"
  },
  {
    "input": "Find the best fit line using least squares for points (2,1), (4,3), (6,4).",
    "output": "import numpy as np\n\nx = np.array([2, 4, 6])\ny = np.array([1, 3, 4])\nA = np.vstack([x, np.ones(len(x))]).T\nm, c = np.linalg.lstsq(A, y, rcond=None)[0]\nprint(f\"Fitted line: y = {m:.2f}x + {c:.2f}\")"
  },
  {
    "input": "Given (1,1), (2,2), (3,2.9), use least squares to find y = mx + c.",
    "output": "import numpy as np\n\nx = np.array([1, 2, 3])\ny = np.array([1, 2, 2.9])\nA = np.vstack([x, np.ones(len(x))]).T\nm, c = np.linalg.lstsq(A, y, rcond=None)[0]\nprint(f\"Best fit: y = {m:.2f}x + {c:.2f}\")"
  },
  {
    "input": "Use least squares to fit a line to the data x=[1,2,3,4], y=[1.5,1.7,3.2,4.8].",
    "output": "import numpy as np\n\nx = np.array([1, 2, 3, 4])\ny = np.array([1.5, 1.7, 3.2, 4.8])\nA = np.vstack([x, np.ones(len(x))]).T\nm, c = np.linalg.lstsq(A, y, rcond=None)[0]\nprint(f\"Line of best fit: y = {m:.2f}x + {c:.2f}\")"
  },
  {
    "input": "Apply least squares to fit a line to (1,1.1), (2,2.0), (3,3.1), (4,3.9).",
    "output": "import numpy as np\n\nx = np.array([1, 2, 3, 4])\ny = np.array([1.1, 2.0, 3.1, 3.9])\nA = np.vstack([x, np.ones(len(x))]).T\nm, c = np.linalg.lstsq(A, y, rcond=None)[0]\nprint(f\"Linear model: y = {m:.2f}x + {c:.2f}\")"
  },
  {
    "input": "Fit a straight line using least squares for x=[0,1,2,3], y=[2.1,2.9,3.8,5.2].",
    "output": "import numpy as np\n\nx = np.array([0, 1, 2, 3])\ny = np.array([2.1, 2.9, 3.8, 5.2])\nA = np.vstack([x, np.ones(len(x))]).T\nm, c = np.linalg.lstsq(A, y, rcond=None)[0]\nprint(f\"Equation: y = {m:.2f}x + {c:.2f}\")"
  },
  {
    "input": "Find least squares fit for data x=[1, 2, 3], y=[3, 2, 4].",
    "output": "import numpy as np\n\nx = np.array([1, 2, 3])\ny = np.array([3, 2, 4])\nA = np.vstack([x, np.ones(len(x))]).T\nm, c = np.linalg.lstsq(A, y, rcond=None)[0]\nprint(f\"Least squares line: y = {m:.2f}x + {c:.2f}\")"
  },
  {
    "input": "Estimate y = mx + c for x = [1, 3, 4], y = [2, 5, 7].",
    "output": "import numpy as np\n\nx = np.array([1, 3, 4])\ny = np.array([2, 5, 7])\nA = np.vstack([x, np.ones(len(x))]).T\nm, c = np.linalg.lstsq(A, y, rcond=None)[0]\nprint(f\"Regression result: y = {m:.2f}x + {c:.2f}\")"
  },
  {
    "input": "Fit a line using least squares for x=[5,6,7], y=[7,8,10].",
    "output": "import numpy as np\n\nx = np.array([5, 6, 7])\ny = np.array([7, 8, 10])\nA = np.vstack([x, np.ones(len(x))]).T\nm, c = np.linalg.lstsq(A, y, rcond=None)[0]\nprint(f\"Fitted equation: y = {m:.2f}x + {c:.2f}\")"
  },
  {
    "input": "Find regression line for points (0,0), (1,1), (2,4).",
    "output": "import numpy as np\n\nx = np.array([0, 1, 2])\ny = np.array([0, 1, 4])\nA = np.vstack([x, np.ones(len(x))]).T\nm, c = np.linalg.lstsq(A, y, rcond=None)[0]\nprint(f\"Best fit: y = {m:.2f}x + {c:.2f}\")"
  },
  {
    "input": "Use least squares to find a line fitting (0,0.1), (2,2.2), (4,4.0).",
    "output": "import numpy as np\n\nx = np.array([0, 2, 4])\ny = np.array([0.1, 2.2, 4.0])\nA = np.vstack([x, np.ones(len(x))]).T\nm, c = np.linalg.lstsq(A, y, rcond=None)[0]\nprint(f\"Line: y = {m:.2f}x + {c:.2f}\")"
  },
  {
    "input": "Fit a line to data (1,2), (3,6), (5,10) using least squares.",
    "output": "import numpy as np\n\nx = np.array([1, 3, 5])\ny = np.array([2, 6, 10])\nA = np.vstack([x, np.ones(len(x))]).T\nm, c = np.linalg.lstsq(A, y, rcond=None)[0]\nprint(f\"Linear model: y = {m:.2f}x + {c:.2f}\")"
  },
  {
    "input": "Apply least squares to find best fit line for x=[0,1,2,3], y=[1,2.1,2.9,4.2].",
    "output": "import numpy as np\n\nx = np.array([0, 1, 2, 3])\ny = np.array([1, 2.1, 2.9, 4.2])\nA = np.vstack([x, np.ones(len(x))]).T\nm, c = np.linalg.lstsq(A, y, rcond=None)[0]\nprint(f\"Regression line: y = {m:.2f}x + {c:.2f}\")"
  },
  {
    "input": "Find least squares regression line for points (1,2.1), (2,2.9), (3,3.7).",
    "output": "import numpy as np\n\nx = np.array([1, 2, 3])\ny = np.array([2.1, 2.9, 3.7])\nA = np.vstack([x, np.ones(len(x))]).T\nm, c = np.linalg.lstsq(A, y, rcond=None)[0]\nprint(f\"Estimated line: y = {m:.2f}x + {c:.2f}\")"
  },
  {
    "input": "Estimate the linear regression model using least squares for x=[1,2,3,4], y=[2,4,6,7.5].",
    "output": "import numpy as np\n\nx = np.array([1, 2, 3, 4])\ny = np.array([2, 4, 6, 7.5])\nA = np.vstack([x, np.ones(len(x))]).T\nm, c = np.linalg.lstsq(A, y, rcond=None)[0]\nprint(f\"Model: y = {m:.2f}x + {c:.2f}\")"
  },
  {
    "input": "Fit y = mx + c to data x=[2,3,5], y=[3,5,9].",
    "output": "import numpy as np\n\nx = np.array([2, 3, 5])\ny = np.array([3, 5, 9])\nA = np.vstack([x, np.ones(len(x))]).T\nm, c = np.linalg.lstsq(A, y, rcond=None)[0]\nprint(f\"Line of best fit: y = {m:.2f}x + {c:.2f}\")"
  },
  {
    "input": "Given points (0,0.5), (1,1.8), (2,3.6), find the regression line using least squares.",
    "output": "import numpy as np\n\nx = np.array([0, 1, 2])\ny = np.array([0.5, 1.8, 3.6])\nA = np.vstack([x, np.ones(len(x))]).T\nm, c = np.linalg.lstsq(A, y, rcond=None)[0]\nprint(f\"Regression line: y = {m:.2f}x + {c:.2f}\")"
  },
  {
    "input": "Use least squares to fit a line to data points (2,3), (4,6), (6,7).",
    "output": "import numpy as np\n\nx = np.array([2, 4, 6])\ny = np.array([3, 6, 7])\nA = np.vstack([x, np.ones(len(x))]).T\nm, c = np.linalg.lstsq(A, y, rcond=None)[0]\nprint(f\"Fitted line: y = {m:.2f}x + {c:.2f}\")"
  },
  {
    "input": "Fit a regression line for x = [1, 3, 5], y = [2, 6, 9].",
    "output": "import numpy as np\n\nx = np.array([1, 3, 5])\ny = np.array([2, 6, 9])\nA = np.vstack([x, np.ones(len(x))]).T\nm, c = np.linalg.lstsq(A, y, rcond=None)[0]\nprint(f\"Best fit line: y = {m:.2f}x + {c:.2f}\")"
  },
  {
    "input": "Find least squares line for x=[0,2,4], y=[1,3,5].",
    "output": "import numpy as np\n\nx = np.array([0, 2, 4])\ny = np.array([1, 3, 5])\nA = np.vstack([x, np.ones(len(x))]).T\nm, c = np.linalg.lstsq(A, y, rcond=None)[0]\nprint(f\"Least squares line: y = {m:.2f}x + {c:.2f}\")"
  },
  {
    "input": "Use least squares to fit y = mx + c for data (1, 1), (2, 2.5), (3, 3).",
    "output": "import numpy as np\n\nx = np.array([1, 2, 3])\ny = np.array([1, 2.5, 3])\nA = np.vstack([x, np.ones(len(x))]).T\nm, c = np.linalg.lstsq(A, y, rcond=None)[0]\nprint(f\"Fitted line: y = {m:.2f}x + {c:.2f}\")"
  },
  {
    "input": "Find the best fitting line for x = [2, 4, 6, 8], y = [1, 3, 4, 6].",
    "output": "import numpy as np\n\nx = np.array([2, 4, 6, 8])\ny = np.array([1, 3, 4, 6])\nA = np.vstack([x, np.ones(len(x))]).T\nm, c = np.linalg.lstsq(A, y, rcond=None)[0]\nprint(f\"Regression line: y = {m:.2f}x + {c:.2f}\")"
  },
  {
    "input": "Fit a line using least squares for points (1,2), (2,3), (4,6), (5,8).",
    "output": "import numpy as np\n\nx = np.array([1, 2, 4, 5])\ny = np.array([2, 3, 6, 8])\nA = np.vstack([x, np.ones(len(x))]).T\nm, c = np.linalg.lstsq(A, y, rcond=None)[0]\nprint(f\"Line of best fit: y = {m:.2f}x + {c:.2f}\")"
  },
  {
    "input": "Determine y = mx + c using least squares for (0,0), (1,1), (2,2).",
    "output": "import numpy as np\n\nx = np.array([0, 1, 2])\ny = np.array([0, 1, 2])\nA = np.vstack([x, np.ones(len(x))]).T\nm, c = np.linalg.lstsq(A, y, rcond=None)[0]\nprint(f\"Fitted line: y = {m:.2f}x + {c:.2f}\")"
  },
  {
    "input": "Fit a line to x=[1,2,3], y=[2.2,2.8,3.6] using least squares.",
    "output": "import numpy as np\n\nx = np.array([1, 2, 3])\ny = np.array([2.2, 2.8, 3.6])\nA = np.vstack([x, np.ones(len(x))]).T\nm, c = np.linalg.lstsq(A, y, rcond=None)[0]\nprint(f\"Regression equation: y = {m:.2f}x + {c:.2f}\")"
  },
  {
    "input": "Estimate regression line from x=[2,4,6], y=[3,6,7].",
    "output": "import numpy as np\n\nx = np.array([2, 4, 6])\ny = np.array([3, 6, 7])\nA = np.vstack([x, np.ones(len(x))]).T\nm, c = np.linalg.lstsq(A, y, rcond=None)[0]\nprint(f\"Line: y = {m:.2f}x + {c:.2f}\")"
  },
  {
    "input": "Find best fit line for x=[3,4,5], y=[5,6,8].",
    "output": "import numpy as np\n\nx = np.array([3, 4, 5])\ny = np.array([5, 6, 8])\nA = np.vstack([x, np.ones(len(x))]).T\nm, c = np.linalg.lstsq(A, y, rcond=None)[0]\nprint(f\"Linear fit: y = {m:.2f}x + {c:.2f}\")"
  },
  {
    "input": "Fit a line to (2,1), (3,2.5), (4,3.8).",
    "output": "import numpy as np\n\nx = np.array([2, 3, 4])\ny = np.array([1, 2.5, 3.8])\nA = np.vstack([x, np.ones(len(x))]).T\nm, c = np.linalg.lstsq(A, y, rcond=None)[0]\nprint(f\"Best fit: y = {m:.2f}x + {c:.2f}\")"
  },
  {
    "input": "Use least squares to find best fit line for x = [0,1,2], y = [1,3,2].",
    "output": "import numpy as np\n\nx = np.array([0, 1, 2])\ny = np.array([1, 3, 2])\nA = np.vstack([x, np.ones(len(x))]).T\nm, c = np.linalg.lstsq(A, y, rcond=None)[0]\nprint(f\"Regression result: y = {m:.2f}x + {c:.2f}\")"
  },
  {
    "input": "Find least squares regression for (0,1), (1,1.8), (2,3).",
    "output": "import numpy as np\n\nx = np.array([0, 1, 2])\ny = np.array([1, 1.8, 3])\nA = np.vstack([x, np.ones(len(x))]).T\nm, c = np.linalg.lstsq(A, y, rcond=None)[0]\nprint(f\"Best fit line: y = {m:.2f}x + {c:.2f}\")"
  },
  {
    "input": "Fit y = mx + c to data (2,2), (4,3), (6,5).",
    "output": "import numpy as np\n\nx = np.array([2, 4, 6])\ny = np.array([2, 3, 5])\nA = np.vstack([x, np.ones(len(x))]).T\nm, c = np.linalg.lstsq(A, y, rcond=None)[0]\nprint(f\"Fitted equation: y = {m:.2f}x + {c:.2f}\")"
  },
  {
    "input": "Estimate regression line from x=[1,3,4], y=[2,3.5,5].",
    "output": "import numpy as np\n\nx = np.array([1, 3, 4])\ny = np.array([2, 3.5, 5])\nA = np.vstack([x, np.ones(len(x))]).T\nm, c = np.linalg.lstsq(A, y, rcond=None)[0]\nprint(f\"Regression: y = {m:.2f}x + {c:.2f}\")"
  },
  {
    "input": "Use least squares on x = [1, 2, 3], y = [3, 6, 9].",
    "output": "import numpy as np\n\nx = np.array([1, 2, 3])\ny = np.array([3, 6, 9])\nA = np.vstack([x, np.ones(len(x))]).T\nm, c = np.linalg.lstsq(A, y, rcond=None)[0]\nprint(f\"Line: y = {m:.2f}x + {c:.2f}\")"
  },
  {
    "input": "Find least squares solution for (1,0), (2,1.2), (3,2.8).",
    "output": "import numpy as np\n\nx = np.array([1, 2, 3])\ny = np.array([0, 1.2, 2.8])\nA = np.vstack([x, np.ones(len(x))]).T\nm, c = np.linalg.lstsq(A, y, rcond=None)[0]\nprint(f\"Least squares fit: y = {m:.2f}x + {c:.2f}\")"
  },
  {
    "input": "Fit y = mx + c to data x=[1,3,6], y=[2,4,7].",
    "output": "import numpy as np\n\nx = np.array([1, 3, 6])\ny = np.array([2, 4, 7])\nA = np.vstack([x, np.ones(len(x))]).T\nm, c = np.linalg.lstsq(A, y, rcond=None)[0]\nprint(f\"Fitted line: y = {m:.2f}x + {c:.2f}\")"
  },
  {
    "input": "Use least squares to estimate line from x=[2,3,4], y=[3,3.5,4.8].",
    "output": "import numpy as np\n\nx = np.array([2, 3, 4])\ny = np.array([3, 3.5, 4.8])\nA = np.vstack([x, np.ones(len(x))]).T\nm, c = np.linalg.lstsq(A, y, rcond=None)[0]\nprint(f\"Estimated line: y = {m:.2f}x + {c:.2f}\")"
  },
  {
    "input": "Determine least squares fit for x=[0,2,3], y=[0,1,3].",
    "output": "import numpy as np\n\nx = np.array([0, 2, 3])\ny = np.array([0, 1, 3])\nA = np.vstack([x, np.ones(len(x))]).T\nm, c = np.linalg.lstsq(A, y, rcond=None)[0]\nprint(f\"Best fit line: y = {m:.2f}x + {c:.2f}\")"
  },
  {
    "input": "Fit a linear model to x=[3,5,6], y=[5,8,10].",
    "output": "import numpy as np\n\nx = np.array([3, 5, 6])\ny = np.array([5, 8, 10])\nA = np.vstack([x, np.ones(len(x))]).T\nm, c = np.linalg.lstsq(A, y, rcond=None)[0]\nprint(f\"Linear model: y = {m:.2f}x + {c:.2f}\")"
  },
  {
    "input": "A dataset has x = [1, 2, 3, 4, 5], y = [2.1, 3.9, 6.0, 8.2, 10.1]. Fit a line using least squares.",
    "output": "import numpy as np\n\nx = np.array([1, 2, 3, 4, 5])\ny = np.array([2.1, 3.9, 6.0, 8.2, 10.1])\nA = np.vstack([x, np.ones(len(x))]).T\nm, c = np.linalg.lstsq(A, y, rcond=None)[0]\nprint(f\"Least squares line: y = {m:.2f}x + {c:.2f}\")"
  },
  {
    "input": "Fit a line to noisy data: x = [0, 1, 2, 3, 4], y = [1.2, 2.3, 4.1, 5.9, 7.8].",
    "output": "import numpy as np\n\nx = np.array([0, 1, 2, 3, 4])\ny = np.array([1.2, 2.3, 4.1, 5.9, 7.8])\nA = np.vstack([x, np.ones(len(x))]).T\nm, c = np.linalg.lstsq(A, y, rcond=None)[0]\nprint(f\"Fitted model: y = {m:.2f}x + {c:.2f}\")"
  },
  {
    "input": "Given daily temperatures x = [1, 2, 3, 4, 5, 6], and ice cream sales y = [3, 4.5, 5.2, 6.8, 8.1, 9.7], fit a regression line.",
    "output": "import numpy as np\n\nx = np.array([1, 2, 3, 4, 5, 6])\ny = np.array([3, 4.5, 5.2, 6.8, 8.1, 9.7])\nA = np.vstack([x, np.ones(len(x))]).T\nm, c = np.linalg.lstsq(A, y, rcond=None)[0]\nprint(f\"Regression line: y = {m:.2f}x + {c:.2f}\")"
  },
  {
    "input": "Fit a multiple linear regression model for x1 = [1, 2, 3], x2 = [0, 1, 1], and y = [2, 4, 5].",
    "output": "import numpy as np\n\nX = np.array([[1, 0], [2, 1], [3, 1]])\ny = np.array([2, 4, 5])\nX_aug = np.hstack([X, np.ones((X.shape[0], 1))])\nparams, *_ = np.linalg.lstsq(X_aug, y, rcond=None)\nprint(f\"Model: y = {params[0]:.2f}x1 + {params[1]:.2f}x2 + {params[2]:.2f}\")"
  },
  {
    "input": "You measure speed vs. braking distance: x = [20, 30, 40, 50], y = [10, 20, 33, 47]. Fit a least squares line.",
    "output": "import numpy as np\n\nx = np.array([20, 30, 40, 50])\ny = np.array([10, 20, 33, 47])\nA = np.vstack([x, np.ones(len(x))]).T\nm, c = np.linalg.lstsq(A, y, rcond=None)[0]\nprint(f\"Model: braking_distance = {m:.2f} * speed + {c:.2f}\")"
  },
  {
    "input": "Find the least squares line for x = [-3, -2, -1, 0, 1, 2, 3], y = [-7.8, -4.9, -2.2, 0.1, 1.8, 4.2, 6.9].",
    "output": "import numpy as np\n\nx = np.array([-3, -2, -1, 0, 1, 2, 3])\ny = np.array([-7.8, -4.9, -2.2, 0.1, 1.8, 4.2, 6.9])\nA = np.vstack([x, np.ones(len(x))]).T\nm, c = np.linalg.lstsq(A, y, rcond=None)[0]\nprint(f\"Best fit: y = {m:.2f}x + {c:.2f}\")"
  },
  {
    "input": "You have monthly ad spending x=[10,20,30,40,50] and sales y=[12,24,34,41,55]. Fit a least squares model.",
    "output": "import numpy as np\n\nx = np.array([10, 20, 30, 40, 50])\ny = np.array([12, 24, 34, 41, 55])\nA = np.vstack([x, np.ones(len(x))]).T\nm, c = np.linalg.lstsq(A, y, rcond=None)[0]\nprint(f\"Sales = {m:.2f} * Spending + {c:.2f}\")"
  },
  {
    "input": "Fit a regression line to slightly nonlinear data: x = [1, 2, 3, 4], y = [1.1, 3.8, 9.2, 16.3].",
    "output": "import numpy as np\n\nx = np.array([1, 2, 3, 4])\ny = np.array([1.1, 3.8, 9.2, 16.3])\nA = np.vstack([x, np.ones(len(x))]).T\nm, c = np.linalg.lstsq(A, y, rcond=None)[0]\nprint(f\"Linear approximation: y = {m:.2f}x + {c:.2f}\")"
  },
  {
    "input": "You collect weight vs. calories: weight = [100, 200, 300], cal = [250, 470, 690]. Find the regression line.",
    "output": "import numpy as np\n\nx = np.array([100, 200, 300])\ny = np.array([250, 470, 690])\nA = np.vstack([x, np.ones(len(x))]).T\nm, c = np.linalg.lstsq(A, y, rcond=None)[0]\nprint(f\"Calories = {m:.2f} * Weight + {c:.2f}\")"
  },
  {
    "input": "Fit a model for x = [5, 10, 15, 20, 25], y = [15, 30, 47, 65, 82].",
    "output": "import numpy as np\n\nx = np.array([5, 10, 15, 20, 25])\ny = np.array([15, 30, 47, 65, 82])\nA = np.vstack([x, np.ones(len(x))]).T\nm, c = np.linalg.lstsq(A, y, rcond=None)[0]\nprint(f\"Fitted regression: y = {m:.2f}x + {c:.2f}\")"
  },
  {
    "input": "Given height x = [150, 160, 170, 180], and weight y = [50, 58, 67, 75], fit a linear model.",
    "output": "import numpy as np\n\nx = np.array([150, 160, 170, 180])\ny = np.array([50, 58, 67, 75])\nA = np.vstack([x, np.ones(len(x))]).T\nm, c = np.linalg.lstsq(A, y, rcond=None)[0]\nprint(f\"Weight = {m:.2f} * Height + {c:.2f}\")"
  },
  {
    "input": "Fit least squares to temperature vs. energy use: x=[10,15,20,25], y=[50,45,40,35].",
    "output": "import numpy as np\n\nx = np.array([10, 15, 20, 25])\ny = np.array([50, 45, 40, 35])\nA = np.vstack([x, np.ones(len(x))]).T\nm, c = np.linalg.lstsq(A, y, rcond=None)[0]\nprint(f\"Energy use = {m:.2f} * Temperature + {c:.2f}\")"
  },
  {
    "input": "You observe time vs. battery: x=[1,2,3,4], y=[95,90,84,77]. Fit a regression line.",
    "output": "import numpy as np\n\nx = np.array([1, 2, 3, 4])\ny = np.array([95, 90, 84, 77])\nA = np.vstack([x, np.ones(len(x))]).T\nm, c = np.linalg.lstsq(A, y, rcond=None)[0]\nprint(f\"Battery = {m:.2f} * Time + {c:.2f}\")"
  },
  {
    "input": "Find a line for data with small deviation: x = [0,1,2,3,4], y = [0.1,1.2,2.1,3.3,4.1].",
    "output": "import numpy as np\n\nx = np.array([0,1,2,3,4])\ny = np.array([0.1,1.2,2.1,3.3,4.1])\nA = np.vstack([x,np.ones(len(x))]).T\nm,c = np.linalg.lstsq(A,y,rcond=None)[0]\nprint(f\"Regression: y = {m:.2f}x + {c:.2f}\")"
  },
  {
    "input": "Fit a model for (x1,x2) = (1,2), (2,1), (3,5), with y = [3,4,7].",
    "output": "import numpy as np\n\nX = np.array([[1,2],[2,1],[3,5]])\ny = np.array([3,4,7])\nX_aug = np.hstack([X,np.ones((3,1))])\nparams, *_ = np.linalg.lstsq(X_aug,y,rcond=None)\nprint(f\"y = {params[0]:.2f}x1 + {params[1]:.2f}x2 + {params[2]:.2f}\")"
  },
  {
    "input": "You have hours studied x = [1, 2, 3, 4, 5], scores = [50, 55, 65, 70, 78]. Fit least squares line.",
    "output": "import numpy as np\n\nx = np.array([1, 2, 3, 4, 5])\ny = np.array([50, 55, 65, 70, 78])\nA = np.vstack([x, np.ones_like(x)]).T\nm, c = np.linalg.lstsq(A, y, rcond=None)[0]\nprint(f\"Score = {m:.2f} * Hours + {c:.2f}\")"
  },
  {
    "input": "Fit a linear model for car age vs resale value. x = [1, 2, 3, 4, 5], y = [20, 18, 15.5, 13.2, 11].",
    "output": "import numpy as np\n\nx = np.array([1, 2, 3, 4, 5])\ny = np.array([20, 18, 15.5, 13.2, 11])\nA = np.vstack([x, np.ones_like(x)]).T\nm, c = np.linalg.lstsq(A, y, rcond=None)[0]\nprint(f\"Resale value = {m:.2f} * Age + {c:.2f}\")"
  },
  {
    "input": "Given x = [0, 2, 4, 6, 8], y = [1, 4.5, 7.8, 12.1, 15.9], fit a least squares line.",
    "output": "import numpy as np\n\nx = np.array([0, 2, 4, 6, 8])\ny = np.array([1, 4.5, 7.8, 12.1, 15.9])\nA = np.vstack([x, np.ones_like(x)]).T\nm, c = np.linalg.lstsq(A, y, rcond=None)[0]\nprint(f\"Model: y = {m:.2f}x + {c:.2f}\")"
  },
  {
    "input": "Fit a line to the number of cups of coffee (x) vs productivity score (y): x = [1, 2, 3, 4, 5], y = [50, 55, 59, 61, 60].",
    "output": "import numpy as np\n\nx = np.array([1, 2, 3, 4, 5])\ny = np.array([50, 55, 59, 61, 60])\nA = np.vstack([x, np.ones_like(x)]).T\nm, c = np.linalg.lstsq(A, y, rcond=None)[0]\nprint(f\"Productivity = {m:.2f} * Coffee + {c:.2f}\")"
  },
  {
    "input": "Find the least squares solution for x = [1, 4, 6, 8], y = [3, 9, 14, 19.5].",
    "output": "import numpy as np\n\nx = np.array([1, 4, 6, 8])\ny = np.array([3, 9, 14, 19.5])\nA = np.vstack([x, np.ones_like(x)]).T\nm, c = np.linalg.lstsq(A, y, rcond=None)[0]\nprint(f\"y = {m:.2f}x + {c:.2f}\")"
  },
  {
    "input": "Fit a model for temperature x = [30, 35, 40, 45], and AC usage y = [20, 27, 33, 40].",
    "output": "import numpy as np\n\nx = np.array([30, 35, 40, 45])\ny = np.array([20, 27, 33, 40])\nA = np.vstack([x, np.ones_like(x)]).T\nm, c = np.linalg.lstsq(A, y, rcond=None)[0]\nprint(f\"AC usage = {m:.2f} * Temp + {c:.2f}\")"
  },
  {
    "input": "Fit a model to hours of training x = [0, 1, 2, 3, 4], and skill score y = [5, 7, 9.1, 10.9, 13.2].",
    "output": "import numpy as np\n\nx = np.array([0, 1, 2, 3, 4])\ny = np.array([5, 7, 9.1, 10.9, 13.2])\nA = np.vstack([x, np.ones_like(x)]).T\nm, c = np.linalg.lstsq(A, y, rcond=None)[0]\nprint(f\"Skill = {m:.2f} * Hours + {c:.2f}\")"
  },
  {
    "input": "Using x = [10, 20, 30, 40, 50], and y = [15, 25, 35, 43, 55], fit a linear model.",
    "output": "import numpy as np\n\nx = np.array([10, 20, 30, 40, 50])\ny = np.array([15, 25, 35, 43, 55])\nA = np.vstack([x, np.ones_like(x)]).T\nm, c = np.linalg.lstsq(A, y, rcond=None)[0]\nprint(f\"y = {m:.2f}x + {c:.2f}\")"
  },
  {
    "input": "Fit a multiple regression with x1 = [1,2,3], x2 = [0,1,1], y = [1,2.5,3.8].",
    "output": "import numpy as np\n\nX = np.array([[1,0],[2,1],[3,1]])\ny = np.array([1,2.5,3.8])\nX_aug = np.hstack([X,np.ones((3,1))])\nparams, *_ = np.linalg.lstsq(X_aug,y,rcond=None)\nprint(f\"Model: y = {params[0]:.2f}x1 + {params[1]:.2f}x2 + {params[2]:.2f}\")"
  },
  {
    "input": "Fit a model for x = [1, 2, 3, 4], y = [2.5, 5.0, 6.8, 9.5].",
    "output": "import numpy as np\n\nx = np.array([1, 2, 3, 4])\ny = np.array([2.5, 5.0, 6.8, 9.5])\nA = np.vstack([x, np.ones_like(x)]).T\nm, c = np.linalg.lstsq(A, y, rcond=None)[0]\nprint(f\"Fitted Line: y = {m:.2f}x + {c:.2f}\")"
  },
  {
    "input": "You have sales data: x = [5, 10, 15], y = [50, 100, 145]. Use least squares to model it.",
    "output": "import numpy as np\n\nx = np.array([5, 10, 15])\ny = np.array([50, 100, 145])\nA = np.vstack([x, np.ones_like(x)]).T\nm, c = np.linalg.lstsq(A, y, rcond=None)[0]\nprint(f\"Sales = {m:.2f} * Units + {c:.2f}\")"
  },
  {
    "input": "Fit a model to study hours vs. performance: x = [1, 3, 5, 7], y = [60, 70, 80, 90].",
    "output": "import numpy as np\n\nx = np.array([1, 3, 5, 7])\ny = np.array([60, 70, 80, 90])\nA = np.vstack([x, np.ones_like(x)]).T\nm, c = np.linalg.lstsq(A, y, rcond=None)[0]\nprint(f\"Performance = {m:.2f} * StudyHours + {c:.2f}\")"
  },
  {
    "input": "x = [2, 4, 6, 8], y = [3, 7, 11, 16]. Fit least squares regression.",
    "output": "import numpy as np\n\nx = np.array([2, 4, 6, 8])\ny = np.array([3, 7, 11, 16])\nA = np.vstack([x, np.ones_like(x)]).T\nm, c = np.linalg.lstsq(A, y, rcond=None)[0]\nprint(f\"y = {m:.2f}x + {c:.2f}\")"
  },
  {
    "input": "Fit a linear model to predict salary based on years experience: x = [1,2,3,4,5], y = [35, 42, 50, 57, 65].",
    "output": "import numpy as np\n\nx = np.array([1,2,3,4,5])\ny = np.array([35,42,50,57,65])\nA = np.vstack([x,np.ones_like(x)]).T\nm,c = np.linalg.lstsq(A,y,rcond=None)[0]\nprint(f\"Salary = {m:.2f} * Years + {c:.2f}\")"
  },
  {
    "input": "Fit a regression for x = [1, 2, 4, 5], y = [2, 3.9, 7.9, 10.1].",
    "output": "import numpy as np\n\nx = np.array([1,2,4,5])\ny = np.array([2,3.9,7.9,10.1])\nA = np.vstack([x,np.ones_like(x)]).T\nm,c = np.linalg.lstsq(A,y,rcond=None)[0]\nprint(f\"Regression line: y = {m:.2f}x + {c:.2f}\")"
  },
  {
    "input": "Given x = [0, 2, 3, 4, 5], y = [1.2, 4.2, 6.0, 8.1, 10.3], use least squares to fit a line.",
    "output": "import numpy as np\n\nx = np.array([0,2,3,4,5])\ny = np.array([1.2,4.2,6.0,8.1,10.3])\nA = np.vstack([x,np.ones_like(x)]).T\nm,c = np.linalg.lstsq(A,y,rcond=None)[0]\nprint(f\"Model: y = {m:.2f}x + {c:.2f}\")"
  },
  {
    "input": "Fit a model for income vs. spending: income = [20, 30, 40, 50], spending = [22, 33, 43, 51].",
    "output": "import numpy as np\n\nx = np.array([20,30,40,50])\ny = np.array([22,33,43,51])\nA = np.vstack([x,np.ones_like(x)]).T\nm,c = np.linalg.lstsq(A,y,rcond=None)[0]\nprint(f\"Spending = {m:.2f} * Income + {c:.2f}\")"
  },
  {
    "input": "Fit a line for study time vs grades: x = [1,2,3,4], y = [50,58,67,72].",
    "output": "import numpy as np\n\nx = np.array([1,2,3,4])\ny = np.array([50,58,67,72])\nA = np.vstack([x,np.ones_like(x)]).T\nm,c = np.linalg.lstsq(A,y,rcond=None)[0]\nprint(f\"Grades = {m:.2f} * StudyTime + {c:.2f}\")"
  },
  {
    "input": "Fit a line for x = [0, 1, 2, 3, 4], y = [2, 3.8, 5.9, 8.2, 10].",
    "output": "import numpy as np\n\nx = np.array([0,1,2,3,4])\ny = np.array([2,3.8,5.9,8.2,10])\nA = np.vstack([x,np.ones_like(x)]).T\nm,c = np.linalg.lstsq(A,y,rcond=None)[0]\nprint(f\"y = {m:.2f}x + {c:.2f}\")"
  },
  {
    "input": "Fit a least squares line to predict crop yield (y) from rainfall (x): x = [200, 300, 400, 500], y = [2.5, 3.5, 4.3, 5.1].",
    "output": "import numpy as np\n\nx = np.array([200, 300, 400, 500])\ny = np.array([2.5, 3.5, 4.3, 5.1])\nA = np.vstack([x, np.ones_like(x)]).T\nm, c = np.linalg.lstsq(A, y, rcond=None)[0]\nprint(f\"Yield = {m:.4f} * Rainfall + {c:.4f}\")"
  },
  {
    "input": "Estimate a linear relationship between advertising cost and revenue: x = [10, 20, 30, 40], y = [60, 110, 160, 210].",
    "output": "import numpy as np\n\nx = np.array([10, 20, 30, 40])\ny = np.array([60, 110, 160, 210])\nA = np.vstack([x, np.ones_like(x)]).T\nm, c = np.linalg.lstsq(A, y, rcond=None)[0]\nprint(f\"Revenue = {m:.2f} * AdCost + {c:.2f}\")"
  },
  {
    "input": "Fit a line to estimate calories burned from minutes of exercise: x = [15, 30, 45, 60], y = [100, 210, 310, 420].",
    "output": "import numpy as np\n\nx = np.array([15, 30, 45, 60])\ny = np.array([100, 210, 310, 420])\nA = np.vstack([x, np.ones_like(x)]).T\nm, c = np.linalg.lstsq(A, y, rcond=None)[0]\nprint(f\"Calories = {m:.2f} * Minutes + {c:.2f}\")"
  },
  {
    "input": "Fit a model for temperature (x) vs ice cream sales (y): x = [20, 25, 30, 35], y = [100, 140, 180, 220].",
    "output": "import numpy as np\n\nx = np.array([20, 25, 30, 35])\ny = np.array([100, 140, 180, 220])\nA = np.vstack([x, np.ones_like(x)]).T\nm, c = np.linalg.lstsq(A, y, rcond=None)[0]\nprint(f\"Sales = {m:.2f} * Temp + {c:.2f}\")"
  },
  {
    "input": "Fit a least squares regression to predict blood pressure from age: x = [25, 35, 45, 55], y = [120, 126, 132, 139].",
    "output": "import numpy as np\n\nx = np.array([25, 35, 45, 55])\ny = np.array([120, 126, 132, 139])\nA = np.vstack([x, np.ones_like(x)]).T\nm, c = np.linalg.lstsq(A, y, rcond=None)[0]\nprint(f\"BP = {m:.2f} * Age + {c:.2f}\")"
  },
  {
    "input": "Predict CO2 emissions from engine size: x = [1.2, 1.6, 2.0, 2.4], y = [110, 140, 165, 190].",
    "output": "import numpy as np\n\nx = np.array([1.2, 1.6, 2.0, 2.4])\ny = np.array([110, 140, 165, 190])\nA = np.vstack([x, np.ones_like(x)]).T\nm, c = np.linalg.lstsq(A, y, rcond=None)[0]\nprint(f\"CO2 = {m:.2f} * EngineSize + {c:.2f}\")"
  },
  {
    "input": "Fit a linear model using x1 = hours studied, x2 = attendance, y = grade. x1 = [2,4,6], x2 = [80,85,90], y = [60,75,90].",
    "output": "import numpy as np\n\nX = np.array([[2,80],[4,85],[6,90]])\ny = np.array([60,75,90])\nX_aug = np.hstack([X,np.ones((3,1))])\nparams, *_ = np.linalg.lstsq(X_aug,y,rcond=None)\nprint(f\"Grade = {params[0]:.2f}*Hours + {params[1]:.2f}*Attendance + {params[2]:.2f}\")"
  },
  {
    "input": "Predict sales from number of emails sent: x = [1000, 2000, 3000, 4000], y = [50, 95, 140, 190].",
    "output": "import numpy as np\n\nx = np.array([1000,2000,3000,4000])\ny = np.array([50,95,140,190])\nA = np.vstack([x, np.ones_like(x)]).T\nm,c = np.linalg.lstsq(A,y,rcond=None)[0]\nprint(f\"Sales = {m:.4f} * Emails + {c:.2f}\")"
  },
  {
    "input": "Fit a model to estimate weight based on height: x = [150, 160, 170, 180], y = [50, 56, 63, 70].",
    "output": "import numpy as np\n\nx = np.array([150,160,170,180])\ny = np.array([50,56,63,70])\nA = np.vstack([x,np.ones_like(x)]).T\nm,c = np.linalg.lstsq(A,y,rcond=None)[0]\nprint(f\"Weight = {m:.2f} * Height + {c:.2f}\")"
  },
  {
    "input": "Fit a line for days since launch (x) vs active users (y): x = [1, 2, 3, 4], y = [100, 180, 250, 320].",
    "output": "import numpy as np\n\nx = np.array([1,2,3,4])\ny = np.array([100,180,250,320])\nA = np.vstack([x,np.ones_like(x)]).T\nm,c = np.linalg.lstsq(A,y,rcond=None)[0]\nprint(f\"Users = {m:.2f} * Days + {c:.2f}\")"
  },
  {
    "input": "Use least squares to model house price from size: x = [1000, 1500, 2000, 2500], y = [150, 200, 250, 310].",
    "output": "import numpy as np\n\nx = np.array([1000,1500,2000,2500])\ny = np.array([150,200,250,310])\nA = np.vstack([x,np.ones_like(x)]).T\nm,c = np.linalg.lstsq(A,y,rcond=None)[0]\nprint(f\"Price = {m:.2f} * Size + {c:.2f}\")"
  },
  {
    "input": "Fit a model: x1 = study hrs, x2 = sleep hrs, y = score. x1 = [2,3,4], x2 = [6,7,6], y = [60,70,75].",
    "output": "import numpy as np\n\nX = np.array([[2,6],[3,7],[4,6]])\ny = np.array([60,70,75])\nX_aug = np.hstack([X,np.ones((3,1))])\nparams, *_ = np.linalg.lstsq(X_aug,y,rcond=None)\nprint(f\"Score = {params[0]:.2f}*Study + {params[1]:.2f}*Sleep + {params[2]:.2f}\")"
  },
  {
    "input": "Predict electricity bill from usage: x = [100, 200, 300, 400], y = [25, 45, 70, 90].",
    "output": "import numpy as np\n\nx = np.array([100,200,300,400])\ny = np.array([25,45,70,90])\nA = np.vstack([x,np.ones_like(x)]).T\nm,c = np.linalg.lstsq(A,y,rcond=None)[0]\nprint(f\"Bill = {m:.2f} * Usage + {c:.2f}\")"
  },
  {
    "input": "Estimate taxi fare from distance: x = [2, 5, 8, 10], y = [10, 22, 33, 40].",
    "output": "import numpy as np\n\nx = np.array([2,5,8,10])\ny = np.array([10,22,33,40])\nA = np.vstack([x,np.ones_like(x)]).T\nm,c = np.linalg.lstsq(A,y,rcond=None)[0]\nprint(f\"Fare = {m:.2f} * Distance + {c:.2f}\")"
  },
  {
    "input": "Fit a line: x = [0, 5, 10, 15], y = [1, 5, 8, 12].",
    "output": "import numpy as np\n\nx = np.array([0,5,10,15])\ny = np.array([1,5,8,12])\nA = np.vstack([x,np.ones_like(x)]).T\nm,c = np.linalg.lstsq(A,y,rcond=None)[0]\nprint(f\"y = {m:.2f}x + {c:.2f}\")"
  },
  {
    "input": "Fit a linear model for caffeine intake and alertness: x = [50, 100, 150, 200], y = [2, 4.5, 6.8, 8.9].",
    "output": "import numpy as np\n\nx = np.array([50,100,150,200])\ny = np.array([2,4.5,6.8,8.9])\nA = np.vstack([x,np.ones_like(x)]).T\nm,c = np.linalg.lstsq(A,y,rcond=None)[0]\nprint(f\"Alertness = {m:.3f} * Caffeine + {c:.2f}\")"
  },
  {
    "input": "Fit a model for x = [1,2,3,4], y = [1,4,7,10].",
    "output": "import numpy as np\n\nx = np.array([1,2,3,4])\ny = np.array([1,4,7,10])\nA = np.vstack([x,np.ones_like(x)]).T\nm,c = np.linalg.lstsq(A,y,rcond=None)[0]\nprint(f\"y = {m:.2f}x + {c:.2f}\")"
  },
  {
    "input": "Predict fuel usage from weight of vehicle: x = [1000, 1500, 2000, 2500], y = [4, 5.5, 7.2, 9.1].",
    "output": "import numpy as np\n\nx = np.array([1000,1500,2000,2500])\ny = np.array([4,5.5,7.2,9.1])\nA = np.vstack([x,np.ones_like(x)]).T\nm,c = np.linalg.lstsq(A,y,rcond=None)[0]\nprint(f\"Fuel = {m:.4f} * Weight + {c:.2f}\")"
  },
  {
    "input": "Fit a regression for height vs. vertical jump: x = [160, 170, 180, 190], y = [30, 35, 40, 42].",
    "output": "import numpy as np\n\nx = np.array([160,170,180,190])\ny = np.array([30,35,40,42])\nA = np.vstack([x,np.ones_like(x)]).T\nm,c = np.linalg.lstsq(A,y,rcond=None)[0]\nprint(f\"Jump = {m:.2f} * Height + {c:.2f}\")"
  },
  {
    "input": "Fit least squares model: x = [1, 2, 3, 4, 5], y = [3, 4.9, 6.8, 8.9, 10.2].",
    "output": "import numpy as np\n\nx = np.array([1,2,3,4,5])\ny = np.array([3,4.9,6.8,8.9,10.2])\nA = np.vstack([x,np.ones_like(x)]).T\nm,c = np.linalg.lstsq(A,y,rcond=None)[0]\nprint(f\"y = {m:.2f}x + {c:.2f}\")"
  },
  {
    "input": "Predict time to complete task from number of workers: x = [1,2,3,4], y = [100,55,38,30].",
    "output": "import numpy as np\n\nx = np.array([1,2,3,4])\ny = np.array([100,55,38,30])\nA = np.vstack([x,np.ones_like(x)]).T\nm,c = np.linalg.lstsq(A,y,rcond=None)[0]\nprint(f\"Time = {m:.2f} * Workers + {c:.2f}\")"
  },
  {
    "input": "Use least squares to fit a quadratic model to the data: x = [1, 2, 3, 4, 5], y = [3, 7, 13, 21, 31].",
    "output": "import numpy as np\n\nx = np.array([1, 2, 3, 4, 5])\ny = np.array([3, 7, 13, 21, 31])\nA = np.vstack([x**2, x, np.ones_like(x)]).T\ncoeffs, *_ = np.linalg.lstsq(A, y, rcond=None)\nprint(f\"y = {coeffs[0]:.2f}x\u00b2 + {coeffs[1]:.2f}x + {coeffs[2]:.2f}\")"
  },
  {
    "input": "Fit a multiple regression model with inputs: experience (x1), education level (x2), hours/week (x3) and output salary (y). x1 = [1,2,3,4], x2 = [2,3,4,5], x3 = [40,45,50,55], y = [40,50,65,80].",
    "output": "import numpy as np\n\nX = np.array([[1,2,40], [2,3,45], [3,4,50], [4,5,55]])\ny = np.array([40, 50, 65, 80])\nX_aug = np.hstack([X, np.ones((4,1))])\nparams, *_ = np.linalg.lstsq(X_aug, y, rcond=None)\nprint(f\"Salary = {params[0]:.2f}*Exp + {params[1]:.2f}*Edu + {params[2]:.2f}*Hours + {params[3]:.2f}\")"
  },
  {
    "input": "Given points that approximately lie on a plane, fit the plane z = ax + by + c using least squares: x = [1,2,3], y = [2,4,6], z = [5,8,11].",
    "output": "import numpy as np\n\nx = np.array([1,2,3])\ny = np.array([2,4,6])\nz = np.array([5,8,11])\nA = np.vstack([x, y, np.ones_like(x)]).T\nparams, *_ = np.linalg.lstsq(A, z, rcond=None)\nprint(f\"Plane: z = {params[0]:.2f}x + {params[1]:.2f}y + {params[2]:.2f}\")"
  },
  {
    "input": "You are given noisy data from a physical process: x = [0.1, 0.4, 0.7, 1.0], y = [0.99, 0.76, 0.54, 0.30]. Fit a least squares model assuming exponential decay y = ae^(-bx).",
    "output": "import numpy as np\n\nx = np.array([0.1, 0.4, 0.7, 1.0])\ny = np.array([0.99, 0.76, 0.54, 0.30])\nlog_y = np.log(y)\nA = np.vstack([-x, np.ones_like(x)]).T\nb, log_a = np.linalg.lstsq(A, log_y, rcond=None)[0]\na = np.exp(log_a)\nprint(f\"Model: y = {a:.4f} * exp(-{b:.4f} * x)\")"
  },
  {
    "input": "Fit a linear model to predict sales from 3 features: store size, location score, and advertising spend. X = [[100, 8, 30], [150, 9, 40], [200, 7, 50], [250, 10, 60]], y = [200, 250, 280, 330].",
    "output": "import numpy as np\n\nX = np.array([[100,8,30], [150,9,40], [200,7,50], [250,10,60]])\ny = np.array([200,250,280,330])\nX_aug = np.hstack([X, np.ones((4,1))])\nparams, *_ = np.linalg.lstsq(X_aug, y, rcond=None)\nprint(f\"Sales = {params[0]:.2f}*Size + {params[1]:.2f}*Location + {params[2]:.2f}*Ad + {params[3]:.2f}\")"
  },
  {
    "input": "Use least squares to fit a cubic model to the data: x = [1, 2, 3, 4, 5], y = [1, 8, 27, 64, 125].",
    "output": "import numpy as np\n\nx = np.array([1, 2, 3, 4, 5])\ny = np.array([1, 8, 27, 64, 125])\nA = np.vstack([x**3, x**2, x, np.ones_like(x)]).T\nparams, *_ = np.linalg.lstsq(A, y, rcond=None)\nprint(f\"y = {params[0]:.2f}x\u00b3 + {params[1]:.2f}x\u00b2 + {params[2]:.2f}x + {params[3]:.2f}\")"
  },
  {
    "input": "Given 2D points, fit a line y = mx + c using least squares, then calculate and print the total squared error. x = [1,2,3,4], y = [2.1,4.2,6.3,8.5].",
    "output": "import numpy as np\n\nx = np.array([1,2,3,4])\ny = np.array([2.1,4.2,6.3,8.5])\nA = np.vstack([x,np.ones_like(x)]).T\nm,c = np.linalg.lstsq(A,y,rcond=None)[0]\ny_pred = m*x + c\nsse = np.sum((y - y_pred)**2)\nprint(f\"y = {m:.2f}x + {c:.2f}\")\nprint(f\"Total Squared Error: {sse:.4f}\")"
  },
  {
    "input": "Fit a polynomial of degree 3 to approximate the function f(x) = sin(x) at x = [0, \u03c0/4, \u03c0/2, 3\u03c0/4, \u03c0].",
    "output": "import numpy as np\n\nx = np.array([0, np.pi/4, np.pi/2, 3*np.pi/4, np.pi])\ny = np.sin(x)\nA = np.vstack([x**3, x**2, x, np.ones_like(x)]).T\nparams, *_ = np.linalg.lstsq(A, y, rcond=None)\nprint(f\"Approximation: y = {params[0]:.4f}x\u00b3 + {params[1]:.4f}x\u00b2 + {params[2]:.4f}x + {params[3]:.4f}\")"
  },
  {
    "input": "Fit a multivariable model to predict crop yield from rainfall, fertilizer use, and temperature. X = [[200, 50, 20], [250, 60, 22], [300, 70, 24]], y = [2.5, 3.0, 3.6].",
    "output": "import numpy as np\n\nX = np.array([[200, 50, 20], [250, 60, 22], [300, 70, 24]])\ny = np.array([2.5, 3.0, 3.6])\nX_aug = np.hstack([X, np.ones((3,1))])\nparams, *_ = np.linalg.lstsq(X_aug, y, rcond=None)\nprint(f\"Yield = {params[0]:.4f}*Rain + {params[1]:.4f}*Fert + {params[2]:.4f}*Temp + {params[3]:.4f}\")"
  },
  {
    "input": "Fit a quadratic curve to approximate projectile motion. Given time t = [0, 1, 2, 3, 4], and height h = [0, 5, 8, 9, 8].",
    "output": "import numpy as np\n\nt = np.array([0, 1, 2, 3, 4])\nh = np.array([0, 5, 8, 9, 8])\nA = np.vstack([t**2, t, np.ones_like(t)]).T\nparams, *_ = np.linalg.lstsq(A, h, rcond=None)\nprint(f\"h = {params[0]:.2f}t\u00b2 + {params[1]:.2f}t + {params[2]:.2f}\")"
  },
  {
    "input": "Given 3D data, fit a plane z = ax + by + c for x = [1,2,4], y = [1,3,5], z = [2,6,10].",
    "output": "import numpy as np\n\nx = np.array([1, 2, 4])\ny = np.array([1, 3, 5])\nz = np.array([2, 6, 10])\nA = np.vstack([x, y, np.ones_like(x)]).T\nparams, *_ = np.linalg.lstsq(A, z, rcond=None)\nprint(f\"z = {params[0]:.2f}x + {params[1]:.2f}y + {params[2]:.2f}\")"
  },
  {
    "input": "Fit a linear model to data: temperature (\u00b0C) vs. ice cream sales. x = [20, 22, 25, 27, 30], y = [100, 115, 150, 165, 200].",
    "output": "import numpy as np\n\nx = np.array([20, 22, 25, 27, 30])\ny = np.array([100, 115, 150, 165, 200])\nA = np.vstack([x, np.ones_like(x)]).T\nparams, *_ = np.linalg.lstsq(A, y, rcond=None)\nprint(f\"Sales = {params[0]:.2f}*Temp + {params[1]:.2f}\")"
  },
  {
    "input": "Fit a 3rd-degree polynomial to approximate noisy data: x = [0,1,2,3,4], y = [1.1, 2.9, 7.8, 15.9, 31.2].",
    "output": "import numpy as np\n\nx = np.array([0,1,2,3,4])\ny = np.array([1.1, 2.9, 7.8, 15.9, 31.2])\nA = np.vstack([x**3, x**2, x, np.ones_like(x)]).T\nparams, *_ = np.linalg.lstsq(A, y, rcond=None)\nprint(f\"y = {params[0]:.2f}x\u00b3 + {params[1]:.2f}x\u00b2 + {params[2]:.2f}x + {params[3]:.2f}\")"
  },
  {
    "input": "You have inputs: [1, 2, 3, 4] and corresponding outputs: [2.5, 3.5, 3.0, 5.0]. Fit a line and compute the residual vector.",
    "output": "import numpy as np\n\nx = np.array([1, 2, 3, 4])\ny = np.array([2.5, 3.5, 3.0, 5.0])\nA = np.vstack([x, np.ones_like(x)]).T\nparams, *_ = np.linalg.lstsq(A, y, rcond=None)\ny_pred = A @ params\nresidual = y - y_pred\nprint(f\"Best fit: y = {params[0]:.2f}x + {params[1]:.2f}\")\nprint(\"Residual vector:\", residual)"
  },
  {
    "input": "Fit a least squares model y = ax + b to the data and compute R\u00b2. x = [1, 2, 3, 4, 5], y = [2.2, 4.1, 6.0, 8.2, 10.1].",
    "output": "import numpy as np\n\nx = np.array([1,2,3,4,5])\ny = np.array([2.2,4.1,6.0,8.2,10.1])\nA = np.vstack([x, np.ones_like(x)]).T\nparams, *_ = np.linalg.lstsq(A, y, rcond=None)\ny_pred = A @ params\nss_res = np.sum((y - y_pred)**2)\nss_tot = np.sum((y - np.mean(y))**2)\nr2 = 1 - ss_res/ss_tot\nprint(f\"y = {params[0]:.2f}x + {params[1]:.2f}\")\nprint(f\"R\u00b2 = {r2:.4f}\")"
  },
  {
    "input": "Fit a plane to 3D data and find the point on the plane closest to (x, y) = (3, 3). z = [4, 5, 6] for x = [1, 2, 3], y = [1, 2, 3].",
    "output": "import numpy as np\n\nx = np.array([1,2,3])\ny = np.array([1,2,3])\nz = np.array([4,5,6])\nA = np.vstack([x, y, np.ones_like(x)]).T\nparams, *_ = np.linalg.lstsq(A, z, rcond=None)\nz_pred = params[0]*3 + params[1]*3 + params[2]\nprint(f\"Plane: z = {params[0]:.2f}x + {params[1]:.2f}y + {params[2]:.2f}\")\nprint(f\"Closest point on plane at (3, 3, {z_pred:.2f})\")"
  },
  {
    "input": "Fit a linear regression to house prices based on size (in sqm): x = [60, 80, 100, 120], y = [150, 200, 240, 300].",
    "output": "import numpy as np\n\nx = np.array([60, 80, 100, 120])\ny = np.array([150, 200, 240, 300])\nA = np.vstack([x, np.ones_like(x)]).T\nparams, *_ = np.linalg.lstsq(A, y, rcond=None)\nprint(f\"Price = {params[0]:.2f}*Size + {params[1]:.2f}\")"
  },
  {
    "input": "Fit a least squares model for y = a*log(x) + b using x = [1,2,4,8] and y = [0,1,2,3].",
    "output": "import numpy as np\n\nx = np.array([1,2,4,8])\ny = np.array([0,1,2,3])\nlog_x = np.log(x)\nA = np.vstack([log_x, np.ones_like(log_x)]).T\nparams, *_ = np.linalg.lstsq(A, y, rcond=None)\nprint(f\"Model: y = {params[0]:.4f}*log(x) + {params[1]:.4f}\")"
  },
  {
    "input": "Given height, weight, and age data: X = [[160, 55, 25], [170, 65, 30], [180, 75, 35]], y = [1, 2, 3], fit a model and interpret coefficients.",
    "output": "import numpy as np\n\nX = np.array([[160, 55, 25], [170, 65, 30], [180, 75, 35]])\ny = np.array([1,2,3])\nX_aug = np.hstack([X, np.ones((3,1))])\nparams, *_ = np.linalg.lstsq(X_aug, y, rcond=None)\nprint(f\"y = {params[0]:.4f}*Height + {params[1]:.4f}*Weight + {params[2]:.4f}*Age + {params[3]:.4f}\")"
  },
  {
    "input": "Use least squares to fit a model y = a*x^b to data: x = [1,2,3,4], y = [2, 4.1, 8.2, 16.3].",
    "output": "import numpy as np\n\nx = np.array([1,2,3,4])\ny = np.array([2,4.1,8.2,16.3])\nlog_x = np.log(x)\nlog_y = np.log(y)\nA = np.vstack([log_x, np.ones_like(log_x)]).T\nb, log_a = np.linalg.lstsq(A, log_y, rcond=None)[0]\na = np.exp(log_a)\nprint(f\"Model: y = {a:.4f} * x^{b:.4f}\")"
  },
  {
    "input": "Fit a line to x = [1, 2, 3, 4, 5], y = [5.1, 4.2, 3.2, 2.3, 1.4] and interpret the negative slope.",
    "output": "import numpy as np\n\nx = np.array([1, 2, 3, 4, 5])\ny = np.array([5.1, 4.2, 3.2, 2.3, 1.4])\nA = np.vstack([x, np.ones_like(x)]).T\nm, c = np.linalg.lstsq(A, y, rcond=None)[0]\nprint(f\"y = {m:.2f}x + {c:.2f}\")\nprint(\"The negative slope indicates a decreasing trend between x and y.\")"
  },
  {
    "input": "Given a square matrix A = [[1,2],[3,4]] and vector b = [1,0], solve Ax = b using least squares and verify the residual.",
    "output": "import numpy as np\n\nA = np.array([[1,2],[3,4]])\nb = np.array([1,0])\nx, *_ = np.linalg.lstsq(A, b, rcond=None)\nresidual = b - A @ x\nprint(f\"Solution x: {x}\")\nprint(f\"Residual: {residual}\")"
  },
  {
    "input": "Use least squares to find the best fit for a polynomial of degree 4 for x = [0,1,2,3,4], y = [1,2,1,3,5].",
    "output": "import numpy as np\n\nx = np.array([0,1,2,3,4])\ny = np.array([1,2,1,3,5])\nA = np.vstack([x**4, x**3, x**2, x, np.ones_like(x)]).T\nparams, *_ = np.linalg.lstsq(A, y, rcond=None)\nprint(\"y = {:.4f}x\u2074 + {:.4f}x\u00b3 + {:.4f}x\u00b2 + {:.4f}x + {:.4f}\".format(*params))"
  },
  {
    "input": "Fit a model to predict the efficiency of a machine based on input voltage, current, and load. X = [[220, 10, 50], [230, 12, 55], [240, 14, 60]], y = [85, 88, 90].",
    "output": "import numpy as np\n\nX = np.array([[220, 10, 50], [230, 12, 55], [240, 14, 60]])\ny = np.array([85, 88, 90])\nX_aug = np.hstack([X, np.ones((3,1))])\nparams, *_ = np.linalg.lstsq(X_aug, y, rcond=None)\nprint(f\"Efficiency = {params[0]:.4f}*Volt + {params[1]:.4f}*Curr + {params[2]:.4f}*Load + {params[3]:.4f}\")"
  },
  {
    "input": "Fit a quadratic model to predict car stopping distance from speed. x = [20, 30, 40, 50], y = [15, 25, 40, 60].",
    "output": "import numpy as np\n\nx = np.array([20, 30, 40, 50])\ny = np.array([15, 25, 40, 60])\nA = np.vstack([x**2, x, np.ones_like(x)]).T\nparams, *_ = np.linalg.lstsq(A, y, rcond=None)\nprint(f\"Distance = {params[0]:.2f}x\u00b2 + {params[1]:.2f}x + {params[2]:.2f}\")"
  },
  {
    "input": "Fit a logarithmic model to predict soil moisture from time. x = [1, 2, 4, 8], y = [30, 25, 18, 12].",
    "output": "import numpy as np\n\nx = np.array([1, 2, 4, 8])\ny = np.array([30, 25, 18, 12])\nlog_x = np.log(x)\nA = np.vstack([log_x, np.ones_like(log_x)]).T\nparams, *_ = np.linalg.lstsq(A, y, rcond=None)\nprint(f\"Moisture = {params[0]:.2f}*log(t) + {params[1]:.2f}\")"
  },
  {
    "input": "Fit a cubic model to describe the displacement of a spring over time. x = [0, 1, 2, 3, 4], y = [0, 2, 6, 14, 28].",
    "output": "import numpy as np\n\nx = np.array([0, 1, 2, 3, 4])\ny = np.array([0, 2, 6, 14, 28])\nA = np.vstack([x**3, x**2, x, np.ones_like(x)]).T\nparams, *_ = np.linalg.lstsq(A, y, rcond=None)\nprint(f\"Displacement = {params[0]:.2f}x\u00b3 + {params[1]:.2f}x\u00b2 + {params[2]:.2f}x + {params[3]:.2f}\")"
  },
  {
    "input": "Use least squares to model population growth where x = [2000, 2005, 2010, 2015], y = [2.5, 2.7, 3.1, 3.8].",
    "output": "import numpy as np\n\nx = np.array([2000, 2005, 2010, 2015])\ny = np.array([2.5, 2.7, 3.1, 3.8])\nA = np.vstack([x, np.ones_like(x)]).T\nparams, *_ = np.linalg.lstsq(A, y, rcond=None)\nprint(f\"Population = {params[0]:.4f}*Year + {params[1]:.4f}\")"
  },
  {
    "input": "Fit a plane to 3D data to model elevation based on coordinates: x = [1,2,3], y = [2,4,6], z = [10,15,20].",
    "output": "import numpy as np\n\nx = np.array([1, 2, 3])\ny = np.array([2, 4, 6])\nz = np.array([10, 15, 20])\nA = np.vstack([x, y, np.ones_like(x)]).T\nparams, *_ = np.linalg.lstsq(A, z, rcond=None)\nprint(f\"Elevation = {params[0]:.2f}x + {params[1]:.2f}y + {params[2]:.2f}\")"
  },
  {
    "input": "Given input frequency and power output of a circuit, fit a line: x = [100, 200, 300], y = [5, 9, 13].",
    "output": "import numpy as np\n\nx = np.array([100, 200, 300])\ny = np.array([5, 9, 13])\nA = np.vstack([x, np.ones_like(x)]).T\nparams, *_ = np.linalg.lstsq(A, y, rcond=None)\nprint(f\"Power = {params[0]:.4f}*Freq + {params[1]:.4f}\")"
  },
  {
    "input": "Fit a 2-variable regression model to estimate fuel efficiency: X = [[1000, 50], [1200, 45], [1500, 40]], y = [20, 18, 15].",
    "output": "import numpy as np\n\nX = np.array([[1000, 50], [1200, 45], [1500, 40]])\ny = np.array([20, 18, 15])\nX_aug = np.hstack([X, np.ones((3,1))])\nparams, *_ = np.linalg.lstsq(X_aug, y, rcond=None)\nprint(f\"Efficiency = {params[0]:.4f}*Weight + {params[1]:.4f}*Speed + {params[2]:.4f}\")"
  },
  {
    "input": "Fit a power law model y = ax^b for x = [1, 2, 3, 4], y = [3, 6.1, 12.5, 25.1].",
    "output": "import numpy as np\n\nx = np.array([1, 2, 3, 4])\ny = np.array([3, 6.1, 12.5, 25.1])\nlog_x = np.log(x)\nlog_y = np.log(y)\nA = np.vstack([log_x, np.ones_like(log_x)]).T\nb, log_a = np.linalg.lstsq(A, log_y, rcond=None)[0]\na = np.exp(log_a)\nprint(f\"Model: y = {a:.4f} * x^{b:.4f}\")"
  },
  {
    "input": "Model CPU temperature (y) from usage percentage (x): x = [10, 50, 75, 90], y = [30, 60, 75, 85].",
    "output": "import numpy as np\n\nx = np.array([10, 50, 75, 90])\ny = np.array([30, 60, 75, 85])\nA = np.vstack([x, np.ones_like(x)]).T\nparams, *_ = np.linalg.lstsq(A, y, rcond=None)\nprint(f\"Temp = {params[0]:.2f}*Usage + {params[1]:.2f}\")"
  },
  {
    "input": "Predict concentration of a drug in bloodstream using log-time model: x = [1,2,4,8], y = [50, 30, 15, 7].",
    "output": "import numpy as np\n\nx = np.array([1, 2, 4, 8])\ny = np.array([50, 30, 15, 7])\nlog_x = np.log(x)\nA = np.vstack([log_x, np.ones_like(x)]).T\nparams, *_ = np.linalg.lstsq(A, y, rcond=None)\nprint(f\"Concentration = {params[0]:.2f}*log(t) + {params[1]:.2f}\")"
  },
  {
    "input": "Fit a model using temperature and humidity to predict comfort index: X = [[30, 60], [25, 70], [20, 80]], y = [50, 60, 70].",
    "output": "import numpy as np\n\nX = np.array([[30, 60], [25, 70], [20, 80]])\ny = np.array([50, 60, 70])\nX_aug = np.hstack([X, np.ones((3,1))])\nparams, *_ = np.linalg.lstsq(X_aug, y, rcond=None)\nprint(f\"Comfort = {params[0]:.2f}*Temp + {params[1]:.2f}*Humidity + {params[2]:.2f}\")"
  },
  {
    "input": "Given time (min) and distance (m): x = [0, 1, 2, 3], y = [0, 5, 20, 45], fit a quadratic curve.",
    "output": "import numpy as np\n\nx = np.array([0, 1, 2, 3])\ny = np.array([0, 5, 20, 45])\nA = np.vstack([x**2, x, np.ones_like(x)]).T\nparams, *_ = np.linalg.lstsq(A, y, rcond=None)\nprint(f\"Distance = {params[0]:.2f}t\u00b2 + {params[1]:.2f}t + {params[2]:.2f}\")"
  },
  {
    "input": "Fit an exponential decay model y = ae^(-bx) using x = [1,2,3,4], y = [10, 6, 3.7, 2.2].",
    "output": "import numpy as np\n\nx = np.array([1,2,3,4])\ny = np.array([10,6,3.7,2.2])\nlog_y = np.log(y)\nA = np.vstack([-x, np.ones_like(x)]).T\nb, log_a = np.linalg.lstsq(A, log_y, rcond=None)[0]\na = np.exp(log_a)\nprint(f\"Model: y = {a:.4f} * exp(-{b:.4f}x)\")"
  },
  {
    "input": "Fit a linear model where the feature is a sine transformation of time. x = [0, \u03c0/2, \u03c0, 3\u03c0/2], y = [1, 0.5, 0, -0.5].",
    "output": "import numpy as np\n\nx = np.array([0, np.pi/2, np.pi, 3*np.pi/2])\ny = np.array([1, 0.5, 0, -0.5])\nsin_x = np.sin(x)\nA = np.vstack([sin_x, np.ones_like(sin_x)]).T\nparams, *_ = np.linalg.lstsq(A, y, rcond=None)\nprint(f\"y = {params[0]:.4f}*sin(x) + {params[1]:.4f}\")"
  },
  {
    "input": "Fit a model predicting brightness from RGB color values. X = [[255,0,0], [0,255,0], [0,0,255]], y = [0.3, 0.6, 0.1].",
    "output": "import numpy as np\n\nX = np.array([[255,0,0], [0,255,0], [0,0,255]])\ny = np.array([0.3, 0.6, 0.1])\nX_aug = np.hstack([X, np.ones((3,1))])\nparams, *_ = np.linalg.lstsq(X_aug, y, rcond=None)\nprint(f\"Brightness = {params[0]:.4f}*R + {params[1]:.4f}*G + {params[2]:.4f}*B + {params[3]:.4f}\")"
  },
  {
    "input": "Predict force from mass using the logarithm of mass. x = [1, 2, 4, 8], y = [10, 20, 40, 80].",
    "output": "import numpy as np\n\nx = np.array([1, 2, 4, 8])\ny = np.array([10, 20, 40, 80])\nlog_x = np.log(x)\nA = np.vstack([log_x, np.ones_like(x)]).T\nparams, *_ = np.linalg.lstsq(A, y, rcond=None)\nprint(f\"Force = {params[0]:.2f}*log(mass) + {params[1]:.2f}\")"
  },
  {
    "input": "Fit a linear regression model where all input features are perfectly collinear. X = [[1, 2], [2, 4], [3, 6]], y = [3, 6, 9].",
    "output": "import numpy as np\n\nX = np.array([[1, 2], [2, 4], [3, 6]])\ny = np.array([3, 6, 9])\nX_aug = np.hstack([X, np.ones((3, 1))])\nparams, *_ = np.linalg.lstsq(X_aug, y, rcond=None)\nprint(f\"y = {params[0]:.4f}*x1 + {params[1]:.4f}*x2 + {params[2]:.4f}\")"
  },
  {
    "input": "Fit a model with polynomial features (x\u00b2, x\u00b3) to predict trajectory height. x = [1, 2, 3, 4], y = [3, 8, 27, 64].",
    "output": "import numpy as np\n\nx = np.array([1, 2, 3, 4])\ny = np.array([3, 8, 27, 64])\nX = np.vstack([x**2, x**3, np.ones_like(x)]).T\nparams, *_ = np.linalg.lstsq(X, y, rcond=None)\nprint(f\"Height = {params[0]:.2f}*x\u00b2 + {params[1]:.2f}*x\u00b3 + {params[2]:.2f}\")"
  },
  {
    "input": "Fit a model to predict price from log of square footage. x = [100, 400, 1600, 6400], y = [100, 200, 300, 400].",
    "output": "import numpy as np\n\nx = np.array([100, 400, 1600, 6400])\ny = np.array([100, 200, 300, 400])\nlog_x = np.log(x)\nA = np.vstack([log_x, np.ones_like(log_x)]).T\nparams, *_ = np.linalg.lstsq(A, y, rcond=None)\nprint(f\"Price = {params[0]:.2f}*log(SqFt) + {params[1]:.2f}\")"
  },
  {
    "input": "Fit a model where inputs are probabilities that must sum to 1. X = [[0.6,0.4], [0.2,0.8], [0.9,0.1]], y = [1, 2, 1].",
    "output": "import numpy as np\n\nX = np.array([[0.6,0.4], [0.2,0.8], [0.9,0.1]])\ny = np.array([1, 2, 1])\nX_aug = np.hstack([X, np.ones((3,1))])\nparams, *_ = np.linalg.lstsq(X_aug, y, rcond=None)\nprint(f\"Output = {params[0]:.2f}*p1 + {params[1]:.2f}*p2 + {params[2]:.2f}\")"
  },
  {
    "input": "Fit a model with symbolic transformation where input is x and model is y = a*sin(x) + b*cos(x) + c. x = [0, \u03c0/2, \u03c0], y = [1, 0, -1].",
    "output": "import numpy as np\n\nx = np.array([0, np.pi/2, np.pi])\ny = np.array([1, 0, -1])\nX = np.vstack([np.sin(x), np.cos(x), np.ones_like(x)]).T\nparams, *_ = np.linalg.lstsq(X, y, rcond=None)\nprint(f\"y = {params[0]:.2f}*sin(x) + {params[1]:.2f}*cos(x) + {params[2]:.2f}\")"
  },
  {
    "input": "Fit a model where input is a categorical feature encoded as one-hot. X = [[1,0,0], [0,1,0], [0,0,1]], y = [10, 20, 15].",
    "output": "import numpy as np\n\nX = np.array([[1,0,0], [0,1,0], [0,0,1]])\ny = np.array([10, 20, 15])\nX_aug = np.hstack([X, np.ones((3,1))])\nparams, *_ = np.linalg.lstsq(X_aug, y, rcond=None)\nprint(f\"y = {params[0]:.2f}*C1 + {params[1]:.2f}*C2 + {params[2]:.2f}*C3 + {params[3]:.2f}\")"
  },
  {
    "input": "Model the bending of a metal bar using both the position and square of the position. x = [1,2,3,4], y = [2,5,10,17].",
    "output": "import numpy as np\n\nx = np.array([1,2,3,4])\ny = np.array([2,5,10,17])\nX = np.vstack([x, x**2, np.ones_like(x)]).T\nparams, *_ = np.linalg.lstsq(X, y, rcond=None)\nprint(f\"Bend = {params[0]:.2f}*x + {params[1]:.2f}*x\u00b2 + {params[2]:.2f}\")"
  },
  {
    "input": "Use inverse of input as feature: x = [1, 2, 4], y = [10, 5, 2.5].",
    "output": "import numpy as np\n\nx = np.array([1, 2, 4])\ny = np.array([10, 5, 2.5])\nx_inv = 1/x\nA = np.vstack([x_inv, np.ones_like(x)]).T\nparams, *_ = np.linalg.lstsq(A, y, rcond=None)\nprint(f\"y = {params[0]:.2f}*(1/x) + {params[1]:.2f}\")"
  },
  {
    "input": "Fit a linear model where x = [1, 10, 100, 1000], y = [3, 6, 9, 12].",
    "output": "import numpy as np\n\nx = np.array([1, 10, 100, 1000])\ny = np.array([3, 6, 9, 12])\nA = np.vstack([x, np.ones_like(x)]).T\nparams, *_ = np.linalg.lstsq(A, y, rcond=None)\nprint(f\"y = {params[0]:.5f}*x + {params[1]:.5f}\")"
  },
  {
    "input": "Fit model with heavily imbalanced scale: x = [0.01, 1000, 5000], y = [5, 10, 20].",
    "output": "import numpy as np\n\nx = np.array([0.01, 1000, 5000])\ny = np.array([5, 10, 20])\nA = np.vstack([x, np.ones_like(x)]).T\nparams, *_ = np.linalg.lstsq(A, y, rcond=None)\nprint(f\"y = {params[0]:.6f}*x + {params[1]:.6f}\")"
  },
  {
    "input": "Predict rainfall given pressure and temperature with highly correlated variables. X = [[1000, 20], [1010, 21], [1020, 22]], y = [30, 32, 34].",
    "output": "import numpy as np\n\nX = np.array([[1000, 20], [1010, 21], [1020, 22]])\ny = np.array([30, 32, 34])\nX_aug = np.hstack([X, np.ones((3,1))])\nparams, *_ = np.linalg.lstsq(X_aug, y, rcond=None)\nprint(f\"Rainfall = {params[0]:.4f}*Pressure + {params[1]:.4f}*Temp + {params[2]:.4f}\")"
  },
  {
    "input": "Fit a model where the input feature is the exponential of time. x = [0, 1, 2, 3], y = [1, 2.7, 7.4, 20.1].",
    "output": "import numpy as np\n\nx = np.array([0, 1, 2, 3])\ny = np.array([1, 2.7, 7.4, 20.1])\nexp_x = np.exp(x)\nA = np.vstack([exp_x, np.ones_like(x)]).T\nparams, *_ = np.linalg.lstsq(A, y, rcond=None)\nprint(f\"y = {params[0]:.4f}*exp(x) + {params[1]:.4f}\")"
  },
  {
    "input": "Fit a linear model to approximate the square root function. x = [1, 4, 9, 16], y = [1, 2, 3, 4].",
    "output": "import numpy as np\n\nx = np.array([1, 4, 9, 16])\ny = np.array([1, 2, 3, 4])\nsqrt_x = np.sqrt(x)\nA = np.vstack([sqrt_x, np.ones_like(x)]).T\nparams, *_ = np.linalg.lstsq(A, y, rcond=None)\nprint(f\"y = {params[0]:.4f}*sqrt(x) + {params[1]:.4f}\")"
  },
  {
    "input": "Fit a model where inputs are geographic coordinates: X = [[30.1, -97.7], [34.0, -118.2], [40.7, -74.0]], y = [90, 75, 60].",
    "output": "import numpy as np\n\nX = np.array([[30.1, -97.7], [34.0, -118.2], [40.7, -74.0]])\ny = np.array([90, 75, 60])\nX_aug = np.hstack([X, np.ones((3,1))])\nparams, *_ = np.linalg.lstsq(X_aug, y, rcond=None)\nprint(f\"Value = {params[0]:.2f}*Lat + {params[1]:.2f}*Lon + {params[2]:.2f}\")"
  },
  {
    "input": "Predict crime rate using polynomial features of population size. x = [1000, 2000, 3000, 4000], y = [5, 10, 18, 30].",
    "output": "import numpy as np\n\nx = np.array([1000, 2000, 3000, 4000])\ny = np.array([5, 10, 18, 30])\nX = np.vstack([x, x**2, np.ones_like(x)]).T\nparams, *_ = np.linalg.lstsq(X, y, rcond=None)\nprint(f\"Crime = {params[0]:.6f}*Pop + {params[1]:.8f}*Pop\u00b2 + {params[2]:.2f}\")"
  },
  {
    "input": "Fit a model where inputs include a constant feature. X = [[1, 5], [2, 5], [3, 5]], y = [10, 20, 30].",
    "output": "import numpy as np\n\nX = np.array([[1, 5], [2, 5], [3, 5]])\ny = np.array([10, 20, 30])\nX_aug = np.hstack([X, np.ones((3,1))])\nparams, *_ = np.linalg.lstsq(X_aug, y, rcond=None)\nprint(f\"y = {params[0]:.2f}*x1 + {params[1]:.2f}*const + {params[2]:.2f}\")"
  },
  {
    "input": "Fit a model using distance from origin as the input feature. x = [[3, 4], [6, 8], [9, 12]], y = [5, 10, 15].",
    "output": "import numpy as np\n\nx = np.array([[3, 4], [6, 8], [9, 12]])\ny = np.array([5, 10, 15])\ndistance = np.linalg.norm(x, axis=1)\nA = np.vstack([distance, np.ones_like(distance)]).T\nparams, *_ = np.linalg.lstsq(A, y, rcond=None)\nprint(f\"y = {params[0]:.2f}*distance + {params[1]:.2f}\")"
  },
  {
    "input": "Predict brightness using quadratic RGB values: X = [[255,0,0], [0,255,0], [0,0,255]], y = [76.5, 150.4, 29.9].",
    "output": "import numpy as np\n\nX = np.array([[255,0,0], [0,255,0], [0,0,255]])\ny = np.array([76.5, 150.4, 29.9])\nX_sq = X**2\nX_aug = np.hstack([X_sq, np.ones((3,1))])\nparams, *_ = np.linalg.lstsq(X_aug, y, rcond=None)\nprint(f\"Brightness = {params[0]:.4f}*R\u00b2 + {params[1]:.4f}*G\u00b2 + {params[2]:.4f}*B\u00b2 + {params[3]:.4f}\")"
  },
  {
    "input": "Fit a model where inputs are percentage values summing to 100. X = [[30, 70], [50, 50], [20, 80]], y = [60, 55, 70].",
    "output": "import numpy as np\n\nX = np.array([[30, 70], [50, 50], [20, 80]])\ny = np.array([60, 55, 70])\nX_aug = np.hstack([X, np.ones((3,1))])\nparams, *_ = np.linalg.lstsq(X_aug, y, rcond=None)\nprint(f\"Score = {params[0]:.2f}*Part1 + {params[1]:.2f}*Part2 + {params[2]:.2f}\")"
  },
  {
    "input": "Fit a model where x = [-2, -1, 0, 1, 2], y = [4, 1, 0, 1, 4] using polynomial features.",
    "output": "import numpy as np\n\nx = np.array([-2, -1, 0, 1, 2])\ny = np.array([4, 1, 0, 1, 4])\nX = np.vstack([x**2, np.ones_like(x)]).T\nparams, *_ = np.linalg.lstsq(X, y, rcond=None)\nprint(f\"y = {params[0]:.2f}*x\u00b2 + {params[1]:.2f}\")"
  },
  {
    "input": "Fit a model where output is y = a/x + b. x = [1, 2, 4, 8], y = [10, 5, 2.5, 1.25].",
    "output": "import numpy as np\n\nx = np.array([1, 2, 4, 8])\ny = np.array([10, 5, 2.5, 1.25])\ninv_x = 1 / x\nA = np.vstack([inv_x, np.ones_like(x)]).T\nparams, *_ = np.linalg.lstsq(A, y, rcond=None)\nprint(f\"y = {params[0]:.2f}*(1/x) + {params[1]:.2f}\")"
  },
  {
    "input": "Fit a model using natural log of income to predict happiness. x = [1000, 5000, 10000, 20000], y = [4, 6, 7, 8].",
    "output": "import numpy as np\n\nx = np.array([1000, 5000, 10000, 20000])\ny = np.array([4, 6, 7, 8])\nlog_x = np.log(x)\nA = np.vstack([log_x, np.ones_like(log_x)]).T\nparams, *_ = np.linalg.lstsq(A, y, rcond=None)\nprint(f\"Happiness = {params[0]:.2f}*log(Income) + {params[1]:.2f}\")"
  },
  {
    "input": "Fit a model using both sine and cosine of an angle. x = [0, \u03c0/2, \u03c0], y = [1, 0, -1].",
    "output": "import numpy as np\n\nx = np.array([0, np.pi/2, np.pi])\ny = np.array([1, 0, -1])\nX = np.vstack([np.sin(x), np.cos(x), np.ones_like(x)]).T\nparams, *_ = np.linalg.lstsq(X, y, rcond=None)\nprint(f\"y = {params[0]:.2f}*sin(x) + {params[1]:.2f}*cos(x) + {params[2]:.2f}\")"
  },
  {
    "input": "Fit a model where one input is always zero: X = [[1,0], [2,0], [3,0]], y = [5,10,15].",
    "output": "import numpy as np\n\nX = np.array([[1,0], [2,0], [3,0]])\ny = np.array([5,10,15])\nX_aug = np.hstack([X, np.ones((3,1))])\nparams, *_ = np.linalg.lstsq(X_aug, y, rcond=None)\nprint(f\"y = {params[0]:.2f}*x1 + {params[1]:.2f}*x2 + {params[2]:.2f}\")"
  },
  {
    "input": "Fit a linear model using time of day in radians: x = [0, \u03c0/2, \u03c0, 3\u03c0/2], y = [1, 2, 1, 0.5].",
    "output": "import numpy as np\n\nx = np.array([0, np.pi/2, np.pi, 3*np.pi/2])\ny = np.array([1, 2, 1, 0.5])\nX = np.vstack([np.sin(x), np.cos(x), np.ones_like(x)]).T\nparams, *_ = np.linalg.lstsq(X, y, rcond=None)\nprint(f\"y = {params[0]:.4f}*sin(t) + {params[1]:.4f}*cos(t) + {params[2]:.4f}\")"
  },
  {
    "input": "Model altitude based on barometric pressure: x = [1013, 1000, 980], y = [0, 111, 222].",
    "output": "import numpy as np\n\nx = np.array([1013, 1000, 980])\ny = np.array([0, 111, 222])\ninv_x = 1 / x\nX = np.vstack([inv_x, np.ones_like(x)]).T\nparams, *_ = np.linalg.lstsq(X, y, rcond=None)\nprint(f\"Altitude = {params[0]:.2f}*(1/Pressure) + {params[1]:.2f}\")"
  },
  {
    "input": "Use sin(x^2) as the transformed input: x = [1, 2, 3, 4], y = [0.84, 0.91, 0.14, -0.76].",
    "output": "import numpy as np\n\nx = np.array([1, 2, 3, 4])\ny = np.array([0.84, 0.91, 0.14, -0.76])\nsin_sq = np.sin(x**2)\nX = np.vstack([sin_sq, np.ones_like(x)]).T\nparams, *_ = np.linalg.lstsq(X, y, rcond=None)\nprint(f\"y = {params[0]:.3f}*sin(x\u00b2) + {params[1]:.3f}\")"
  },
  {
    "input": "Fit a linear model with one-hot encoded categories: X = [[1,0,0], [0,1,0], [0,0,1]], y = [10, 20, 30].",
    "output": "import numpy as np\n\nX = np.array([[1,0,0], [0,1,0], [0,0,1]])\ny = np.array([10, 20, 30])\nX_aug = np.hstack([X, np.ones((3,1))])\nparams, *_ = np.linalg.lstsq(X_aug, y, rcond=None)\nprint(f\"y = {params[0]:.2f}*Cat1 + {params[1]:.2f}*Cat2 + {params[2]:.2f}*Cat3 + {params[3]:.2f}\")"
  },
  {
    "input": "Use logarithm and square of inputs: x = [1, 2, 4, 8], y = [0.1, 0.4, 1.2, 3.2].",
    "output": "import numpy as np\n\nx = np.array([1, 2, 4, 8])\ny = np.array([0.1, 0.4, 1.2, 3.2])\nlog_x = np.log(x)\nx_sq = x**2\nX = np.vstack([log_x, x_sq, np.ones_like(x)]).T\nparams, *_ = np.linalg.lstsq(X, y, rcond=None)\nprint(f\"y = {params[0]:.4f}*log(x) + {params[1]:.4f}*x\u00b2 + {params[2]:.4f}\")"
  },
  {
    "input": "Fit a model with interaction terms: x1 = [1,2,3], x2 = [4,5,6], y = [5,10,18].",
    "output": "import numpy as np\n\nx1 = np.array([1,2,3])\nx2 = np.array([4,5,6])\ny = np.array([5,10,18])\nX = np.vstack([x1, x2, x1*x2, np.ones_like(x1)]).T\nparams, *_ = np.linalg.lstsq(X, y, rcond=None)\nprint(f\"y = {params[0]:.2f}*x1 + {params[1]:.2f}*x2 + {params[2]:.2f}*x1*x2 + {params[3]:.2f}\")"
  },
  {
    "input": "Use cubic polynomial regression: x = [0, 1, 2, 3], y = [1, 2, 7, 20].",
    "output": "import numpy as np\n\nx = np.array([0, 1, 2, 3])\ny = np.array([1, 2, 7, 20])\nX = np.vstack([x**3, x**2, x, np.ones_like(x)]).T\nparams, *_ = np.linalg.lstsq(X, y, rcond=None)\nprint(f\"y = {params[0]:.2f}*x\u00b3 + {params[1]:.2f}*x\u00b2 + {params[2]:.2f}*x + {params[3]:.2f}\")"
  },
  {
    "input": "Model y using both x and exp(-x): x = [0,1,2,3], y = [1, 1.5, 1.3, 1.1].",
    "output": "import numpy as np\n\nx = np.array([0,1,2,3])\ny = np.array([1, 1.5, 1.3, 1.1])\nX = np.vstack([x, np.exp(-x), np.ones_like(x)]).T\nparams, *_ = np.linalg.lstsq(X, y, rcond=None)\nprint(f\"y = {params[0]:.4f}*x + {params[1]:.4f}*exp(-x) + {params[2]:.4f}\")"
  },
  {
    "input": "Fit a model with high collinearity: X = [[1,2], [2,4.01], [3,6.02]], y = [3,6,9].",
    "output": "import numpy as np\n\nX = np.array([[1,2], [2,4.01], [3,6.02]])\ny = np.array([3,6,9])\nX_aug = np.hstack([X, np.ones((3,1))])\nparams, *_ = np.linalg.lstsq(X_aug, y, rcond=None)\nprint(f\"y = {params[0]:.3f}*x1 + {params[1]:.3f}*x2 + {params[2]:.3f}\")"
  },
  {
    "input": "Fit a model to noisy quadratic data: x = [1,2,3,4,5], y = [2, 5.1, 10, 17.2, 26].",
    "output": "import numpy as np\n\nx = np.array([1,2,3,4,5])\ny = np.array([2, 5.1, 10, 17.2, 26])\nX = np.vstack([x**2, x, np.ones_like(x)]).T\nparams, *_ = np.linalg.lstsq(X, y, rcond=None)\nprint(f\"y = {params[0]:.3f}*x\u00b2 + {params[1]:.3f}*x + {params[2]:.3f}\")"
  },
  {
    "input": "A company tracks its advertising spend in thousands of dollars and resulting sales in millions. Given: ad_spend = [2, 3, 5, 7], sales = [1.2, 1.8, 3.0, 4.1]. Use least squares to predict sales from ad spend.",
    "output": "import numpy as np\n\nad_spend = np.array([2, 3, 5, 7])\nsales = np.array([1.2, 1.8, 3.0, 4.1])\nX = np.vstack([ad_spend, np.ones_like(ad_spend)]).T\nparams, *_ = np.linalg.lstsq(X, sales, rcond=None)\nprint(f\"Sales = {params[0]:.4f}*AdSpend + {params[1]:.4f}\")"
  },
  {
    "input": "An engineer records machine temperature (in \u00b0C) and the number of units produced per hour: temp = [60, 65, 70, 75], units = [200, 210, 240, 250]. Build a linear model.",
    "output": "import numpy as np\n\ntemp = np.array([60, 65, 70, 75])\nunits = np.array([200, 210, 240, 250])\nX = np.vstack([temp, np.ones_like(temp)]).T\nparams, *_ = np.linalg.lstsq(X, units, rcond=None)\nprint(f\"Units = {params[0]:.2f}*Temp + {params[1]:.2f}\")"
  },
  {
    "input": "A bakery measures the number of loaves sold based on outside temperature (\u00b0C): temp = [10, 15, 20, 25], loaves = [100, 95, 85, 80]. Fit a least squares model.",
    "output": "import numpy as np\n\ntemp = np.array([10, 15, 20, 25])\nloaves = np.array([100, 95, 85, 80])\nX = np.vstack([temp, np.ones_like(temp)]).T\nparams, *_ = np.linalg.lstsq(X, loaves, rcond=None)\nprint(f\"Loaves = {params[0]:.2f}*Temp + {params[1]:.2f}\")"
  },
  {
    "input": "A farmer notes that for each increase in irrigation hours, crop yield (tons) changes: hours = [1, 2, 3, 4], yield = [1.5, 1.9, 2.7, 3.2]. Build a linear model.",
    "output": "import numpy as np\n\nhours = np.array([1, 2, 3, 4])\nyield_ = np.array([1.5, 1.9, 2.7, 3.2])\nX = np.vstack([hours, np.ones_like(hours)]).T\nparams, *_ = np.linalg.lstsq(X, yield_, rcond=None)\nprint(f\"Yield = {params[0]:.2f}*Hours + {params[1]:.2f}\")"
  },
  {
    "input": "A runner records distance run (km) and calories burned: distance = [2, 4, 6, 8], calories = [150, 300, 450, 600]. Fit a linear model using least squares.",
    "output": "import numpy as np\n\ndistance = np.array([2, 4, 6, 8])\ncalories = np.array([150, 300, 450, 600])\nX = np.vstack([distance, np.ones_like(distance)]).T\nparams, *_ = np.linalg.lstsq(X, calories, rcond=None)\nprint(f\"Calories = {params[0]:.2f}*Distance + {params[1]:.2f}\")"
  },
  {
    "input": "A student observes how many hours of sleep affect test scores: sleep = [4, 5, 6, 7, 8], scores = [60, 65, 70, 75, 80]. Create a least squares model.",
    "output": "import numpy as np\n\nsleep = np.array([4, 5, 6, 7, 8])\nscores = np.array([60, 65, 70, 75, 80])\nX = np.vstack([sleep, np.ones_like(sleep)]).T\nparams, *_ = np.linalg.lstsq(X, scores, rcond=None)\nprint(f\"Score = {params[0]:.2f}*Sleep + {params[1]:.2f}\")"
  },
  {
    "input": "An app measures usage time (hours) and number of interactions: usage = [1, 2, 3, 4], interactions = [20, 35, 55, 75]. Fit a linear model.",
    "output": "import numpy as np\n\nusage = np.array([1, 2, 3, 4])\ninteractions = np.array([20, 35, 55, 75])\nX = np.vstack([usage, np.ones_like(usage)]).T\nparams, *_ = np.linalg.lstsq(X, interactions, rcond=None)\nprint(f\"Interactions = {params[0]:.2f}*Usage + {params[1]:.2f}\")"
  },
  {
    "input": "A teacher observes students\u2019 study time (hrs) and corresponding grades: study = [2, 4, 6, 8], grades = [55, 65, 75, 85]. Build a linear model.",
    "output": "import numpy as np\n\nstudy = np.array([2, 4, 6, 8])\ngrades = np.array([55, 65, 75, 85])\nX = np.vstack([study, np.ones_like(study)]).T\nparams, *_ = np.linalg.lstsq(X, grades, rcond=None)\nprint(f\"Grade = {params[0]:.2f}*Study + {params[1]:.2f}\")"
  },
  {
    "input": "A startup tracks server load and number of requests handled: load = [1, 2, 3, 4], requests = [100, 200, 300, 400]. Fit a linear model using least squares.",
    "output": "import numpy as np\n\nload = np.array([1, 2, 3, 4])\nrequests = np.array([100, 200, 300, 400])\nX = np.vstack([load, np.ones_like(load)]).T\nparams, *_ = np.linalg.lstsq(X, requests, rcond=None)\nprint(f\"Requests = {params[0]:.2f}*Load + {params[1]:.2f}\")"
  },
  {
    "input": "An experiment records time and bacteria count: time = [0, 1, 2, 3], count = [100, 180, 260, 340]. Use least squares to model growth.",
    "output": "import numpy as np\n\ntime = np.array([0, 1, 2, 3])\ncount = np.array([100, 180, 260, 340])\nX = np.vstack([time, np.ones_like(time)]).T\nparams, *_ = np.linalg.lstsq(X, count, rcond=None)\nprint(f\"Count = {params[0]:.2f}*Time + {params[1]:.2f}\")"
  },
  {
    "input": "A business tracks website visits and product purchases: visits = [100, 200, 300, 400], purchases = [5, 10, 15, 21]. Build a linear model.",
    "output": "import numpy as np\n\nvisits = np.array([100, 200, 300, 400])\npurchases = np.array([5, 10, 15, 21])\nX = np.vstack([visits, np.ones_like(visits)]).T\nparams, *_ = np.linalg.lstsq(X, purchases, rcond=None)\nprint(f\"Purchases = {params[0]:.4f}*Visits + {params[1]:.2f}\")"
  },
  {
    "input": "An architect studies room area (sq meters) vs. cooling cost (USD): area = [20, 30, 40, 50], cost = [100, 140, 180, 220]. Fit a model.",
    "output": "import numpy as np\n\narea = np.array([20, 30, 40, 50])\ncost = np.array([100, 140, 180, 220])\nX = np.vstack([area, np.ones_like(area)]).T\nparams, *_ = np.linalg.lstsq(X, cost, rcond=None)\nprint(f\"Cost = {params[0]:.2f}*Area + {params[1]:.2f}\")"
  },
  {
    "input": "A meteorologist tracks temperature vs. ice cream sales: temp = [15, 20, 25, 30], sales = [200, 300, 400, 500]. Build a linear model.",
    "output": "import numpy as np\n\ntemp = np.array([15, 20, 25, 30])\nsales = np.array([200, 300, 400, 500])\nX = np.vstack([temp, np.ones_like(temp)]).T\nparams, *_ = np.linalg.lstsq(X, sales, rcond=None)\nprint(f\"Sales = {params[0]:.2f}*Temp + {params[1]:.2f}\")"
  },
  {
    "input": "A gym records hours spent on treadmill and calories lost: hours = [0.5, 1.0, 1.5, 2.0], calories = [100, 200, 290, 390]. Fit a least squares model.",
    "output": "import numpy as np\n\nhours = np.array([0.5, 1.0, 1.5, 2.0])\ncalories = np.array([100, 200, 290, 390])\nX = np.vstack([hours, np.ones_like(hours)]).T\nparams, *_ = np.linalg.lstsq(X, calories, rcond=None)\nprint(f\"Calories = {params[0]:.2f}*Hours + {params[1]:.2f}\")"
  },
  {
    "input": "A delivery service tracks the number of packages delivered based on the distance traveled (in km): distance = [5, 10, 15, 20], packages = [50, 70, 85, 100]. Build a least squares model.",
    "output": "import numpy as np\n\ndistance = np.array([5, 10, 15, 20])\npackages = np.array([50, 70, 85, 100])\nX = np.vstack([distance, np.ones_like(distance)]).T\nparams, *_ = np.linalg.lstsq(X, packages, rcond=None)\nprint(f\"Packages = {params[0]:.2f}*Distance + {params[1]:.2f}\")"
  },
  {
    "input": "A chef logs the amount of flour used (in cups) and the number of cookies baked: flour = [1, 2, 3, 4], cookies = [24, 48, 68, 85]. Fit a linear model.",
    "output": "import numpy as np\n\nflour = np.array([1, 2, 3, 4])\ncookies = np.array([24, 48, 68, 85])\nX = np.vstack([flour, np.ones_like(flour)]).T\nparams, *_ = np.linalg.lstsq(X, cookies, rcond=None)\nprint(f\"Cookies = {params[0]:.2f}*Flour + {params[1]:.2f}\")"
  },
  {
    "input": "A school tracks students\u2019 reading hours per week and their vocabulary test scores: hours = [1, 2, 3, 4], scores = [60, 70, 78, 85]. Fit a least squares model.",
    "output": "import numpy as np\n\nhours = np.array([1, 2, 3, 4])\nscores = np.array([60, 70, 78, 85])\nX = np.vstack([hours, np.ones_like(hours)]).T\nparams, *_ = np.linalg.lstsq(X, scores, rcond=None)\nprint(f\"Score = {params[0]:.2f}*Hours + {params[1]:.2f}\")"
  },
  {
    "input": "A freelance writer records number of articles written and total earnings: articles = [5, 10, 15, 20], earnings = [100, 190, 280, 370]. Fit a linear model.",
    "output": "import numpy as np\n\narticles = np.array([5, 10, 15, 20])\nearnings = np.array([100, 190, 280, 370])\nX = np.vstack([articles, np.ones_like(articles)]).T\nparams, *_ = np.linalg.lstsq(X, earnings, rcond=None)\nprint(f\"Earnings = {params[0]:.2f}*Articles + {params[1]:.2f}\")"
  },
  {
    "input": "An artist measures time spent painting and the size of canvas completed: time = [1, 2, 3, 4], canvas_size = [10, 22, 32, 42]. Build a linear model.",
    "output": "import numpy as np\n\ntime = np.array([1, 2, 3, 4])\ncanvas_size = np.array([10, 22, 32, 42])\nX = np.vstack([time, np.ones_like(time)]).T\nparams, *_ = np.linalg.lstsq(X, canvas_size, rcond=None)\nprint(f\"CanvasSize = {params[0]:.2f}*Time + {params[1]:.2f}\")"
  },
  {
    "input": "A business monitors working hours vs productivity index: hours = [6, 7, 8, 9], productivity = [65, 70, 78, 85]. Fit a model using least squares.",
    "output": "import numpy as np\n\nhours = np.array([6, 7, 8, 9])\nproductivity = np.array([65, 70, 78, 85])\nX = np.vstack([hours, np.ones_like(hours)]).T\nparams, *_ = np.linalg.lstsq(X, productivity, rcond=None)\nprint(f\"Productivity = {params[0]:.2f}*Hours + {params[1]:.2f}\")"
  },
  {
    "input": "A coffee shop tracks number of customers and profit (in $): customers = [50, 100, 150, 200], profit = [200, 400, 610, 820]. Build a least squares model.",
    "output": "import numpy as np\n\ncustomers = np.array([50, 100, 150, 200])\nprofit = np.array([200, 400, 610, 820])\nX = np.vstack([customers, np.ones_like(customers)]).T\nparams, *_ = np.linalg.lstsq(X, profit, rcond=None)\nprint(f\"Profit = {params[0]:.2f}*Customers + {params[1]:.2f}\")"
  },
  {
    "input": "A developer tracks time spent on debugging and lines of code fixed: time = [1, 2, 3, 4], fixes = [10, 20, 35, 50]. Fit a least squares model.",
    "output": "import numpy as np\n\ntime = np.array([1, 2, 3, 4])\nfixes = np.array([10, 20, 35, 50])\nX = np.vstack([time, np.ones_like(time)]).T\nparams, *_ = np.linalg.lstsq(X, fixes, rcond=None)\nprint(f\"Fixes = {params[0]:.2f}*Time + {params[1]:.2f}\")"
  },
  {
    "input": "A teacher tracks time spent revising and exam scores: time = [1, 2, 4, 6], scores = [50, 60, 75, 90]. Fit a linear model using least squares.",
    "output": "import numpy as np\n\ntime = np.array([1, 2, 4, 6])\nscores = np.array([50, 60, 75, 90])\nX = np.vstack([time, np.ones_like(time)]).T\nparams, *_ = np.linalg.lstsq(X, scores, rcond=None)\nprint(f\"Score = {params[0]:.2f}*Time + {params[1]:.2f}\")"
  },
  {
    "input": "A florist notes number of flowers sold based on weather temperature: temp = [10, 15, 20, 25], flowers = [30, 45, 60, 75]. Build a least squares model.",
    "output": "import numpy as np\n\ntemp = np.array([10, 15, 20, 25])\nflowers = np.array([30, 45, 60, 75])\nX = np.vstack([temp, np.ones_like(temp)]).T\nparams, *_ = np.linalg.lstsq(X, flowers, rcond=None)\nprint(f\"Flowers = {params[0]:.2f}*Temp + {params[1]:.2f}\")"
  },
  {
    "input": "A social media influencer tracks number of posts vs. new followers: posts = [1, 2, 3, 4], followers = [10, 25, 40, 55]. Fit a least squares model.",
    "output": "import numpy as np\n\nposts = np.array([1, 2, 3, 4])\nfollowers = np.array([10, 25, 40, 55])\nX = np.vstack([posts, np.ones_like(posts)]).T\nparams, *_ = np.linalg.lstsq(X, followers, rcond=None)\nprint(f\"Followers = {params[0]:.2f}*Posts + {params[1]:.2f}\")"
  },
  {
    "input": "A taxi service records time driven (hrs) and distance covered (km): time = [1, 2, 3, 4], distance = [20, 45, 70, 90]. Build a model using least squares.",
    "output": "import numpy as np\n\ntime = np.array([1, 2, 3, 4])\ndistance = np.array([20, 45, 70, 90])\nX = np.vstack([time, np.ones_like(time)]).T\nparams, *_ = np.linalg.lstsq(X, distance, rcond=None)\nprint(f\"Distance = {params[0]:.2f}*Time + {params[1]:.2f}\")"
  },
  {
    "input": "A nurse monitors medicine dose and patient response score: dose = [10, 20, 30, 40], response = [3, 5, 8, 10]. Build a linear model.",
    "output": "import numpy as np\n\ndose = np.array([10, 20, 30, 40])\nresponse = np.array([3, 5, 8, 10])\nX = np.vstack([dose, np.ones_like(dose)]).T\nparams, *_ = np.linalg.lstsq(X, response, rcond=None)\nprint(f\"Response = {params[0]:.2f}*Dose + {params[1]:.2f}\")"
  },
  {
    "input": "A painter observes time spent mixing colors vs. color quality score: time = [5, 10, 15, 20], score = [55, 60, 70, 80]. Fit a least squares model.",
    "output": "import numpy as np\n\ntime = np.array([5, 10, 15, 20])\nscore = np.array([55, 60, 70, 80])\nX = np.vstack([time, np.ones_like(time)]).T\nparams, *_ = np.linalg.lstsq(X, score, rcond=None)\nprint(f\"Score = {params[0]:.2f}*Time + {params[1]:.2f}\")"
  },
  {
    "input": "An ice cream vendor tracks hours of sunshine vs. cones sold: sun = [1, 2, 3, 4], cones = [20, 40, 65, 90]. Build a linear model.",
    "output": "import numpy as np\n\nsun = np.array([1, 2, 3, 4])\ncones = np.array([20, 40, 65, 90])\nX = np.vstack([sun, np.ones_like(sun)]).T\nparams, *_ = np.linalg.lstsq(X, cones, rcond=None)\nprint(f\"Cones = {params[0]:.2f}*Sunshine + {params[1]:.2f}\")"
  },
  {
    "input": "A bookstore records number of hours open per day and number of books sold: hours = [6, 7, 8, 9, 10], books = [60, 68, 74, 83, 95]. Fit a linear model.",
    "output": "import numpy as np\n\nhours = np.array([6, 7, 8, 9, 10])\nbooks = np.array([60, 68, 74, 83, 95])\nX = np.vstack([hours, np.ones_like(hours)]).T\nparams, *_ = np.linalg.lstsq(X, books, rcond=None)\nprint(f\"Books = {params[0]:.2f}*Hours + {params[1]:.2f}\")"
  },
  {
    "input": "A farm records temperature and humidity to predict milk yield. X = [[20, 70], [22, 65], [25, 60], [28, 55]], y = [18, 20, 22, 24]. Build a multivariable model.",
    "output": "import numpy as np\n\nX = np.array([[20, 70], [22, 65], [25, 60], [28, 55]])\ny = np.array([18, 20, 22, 24])\nX_aug = np.hstack([X, np.ones((X.shape[0], 1))])\nparams, *_ = np.linalg.lstsq(X_aug, y, rcond=None)\nprint(f\"Milk Yield = {params[0]:.2f}*Temp + {params[1]:.2f}*Humidity + {params[2]:.2f}\")"
  },
  {
    "input": "An athlete records calories burned per session and duration (minutes): duration = [30, 45, 60, 75], calories = [200, 290, 380, 470]. Fit a linear model.",
    "output": "import numpy as np\n\nduration = np.array([30, 45, 60, 75])\ncalories = np.array([200, 290, 380, 470])\nX = np.vstack([duration, np.ones_like(duration)]).T\nparams, *_ = np.linalg.lstsq(X, calories, rcond=None)\nprint(f\"Calories = {params[0]:.2f}*Duration + {params[1]:.2f}\")"
  },
  {
    "input": "A freelancer logs hours worked and income from different weeks: hours = [10, 15, 20, 25], income = [300, 450, 600, 750]. Fit a linear regression model.",
    "output": "import numpy as np\n\nhours = np.array([10, 15, 20, 25])\nincome = np.array([300, 450, 600, 750])\nX = np.vstack([hours, np.ones_like(hours)]).T\nparams, *_ = np.linalg.lstsq(X, income, rcond=None)\nprint(f\"Income = {params[0]:.2f}*Hours + {params[1]:.2f}\")"
  },
  {
    "input": "A company tracks number of ads run and resulting sales (in $1000): ads = [1, 2, 3, 4, 5], sales = [10, 20, 28, 40, 48]. Fit a linear model.",
    "output": "import numpy as np\n\nads = np.array([1, 2, 3, 4, 5])\nsales = np.array([10, 20, 28, 40, 48])\nX = np.vstack([ads, np.ones_like(ads)]).T\nparams, *_ = np.linalg.lstsq(X, sales, rcond=None)\nprint(f\"Sales = {params[0]:.2f}*Ads + {params[1]:.2f}\")"
  },
  {
    "input": "Predict vehicle mileage (MPG) based on engine size and weight: X = [[1.5, 1200], [2.0, 1400], [2.5, 1600], [3.0, 1800]], y = [35, 30, 26, 22].",
    "output": "import numpy as np\n\nX = np.array([[1.5, 1200], [2.0, 1400], [2.5, 1600], [3.0, 1800]])\ny = np.array([35, 30, 26, 22])\nX_aug = np.hstack([X, np.ones((4,1))])\nparams, *_ = np.linalg.lstsq(X_aug, y, rcond=None)\nprint(f\"MPG = {params[0]:.2f}*EngineSize + {params[1]:.2f}*Weight + {params[2]:.2f}\")"
  },
  {
    "input": "A bakery tracks loaves baked vs. flour used (kg): loaves = [100, 200, 300, 400], flour = [25, 48, 73, 98]. Fit a regression model.",
    "output": "import numpy as np\n\nloaves = np.array([100, 200, 300, 400])\nflour = np.array([25, 48, 73, 98])\nX = np.vstack([loaves, np.ones_like(loaves)]).T\nparams, *_ = np.linalg.lstsq(X, flour, rcond=None)\nprint(f\"Flour = {params[0]:.2f}*Loaves + {params[1]:.2f}\")"
  },
  {
    "input": "A caf\u00e9 tracks time of day and number of customers. Time (in hours from 8 AM): [1, 2, 3, 4], customers = [10, 20, 30, 40]. Fit a model.",
    "output": "import numpy as np\n\ntime = np.array([1, 2, 3, 4])\ncustomers = np.array([10, 20, 30, 40])\nX = np.vstack([time, np.ones_like(time)]).T\nparams, *_ = np.linalg.lstsq(X, customers, rcond=None)\nprint(f\"Customers = {params[0]:.2f}*Time + {params[1]:.2f}\")"
  },
  {
    "input": "A gym records exercise time and calories burned: time = [15, 30, 45, 60], calories = [120, 230, 340, 450]. Use least squares method.",
    "output": "import numpy as np\n\ntime = np.array([15, 30, 45, 60])\ncalories = np.array([120, 230, 340, 450])\nX = np.vstack([time, np.ones_like(time)]).T\nparams, *_ = np.linalg.lstsq(X, calories, rcond=None)\nprint(f\"Calories = {params[0]:.2f}*Time + {params[1]:.2f}\")"
  },
  {
    "input": "Predict car price based on age and mileage: X = [[1, 10000], [2, 20000], [3, 30000], [4, 40000]], y = [20000, 18000, 16000, 14000].",
    "output": "import numpy as np\n\nX = np.array([[1, 10000], [2, 20000], [3, 30000], [4, 40000]])\ny = np.array([20000, 18000, 16000, 14000])\nX_aug = np.hstack([X, np.ones((4,1))])\nparams, *_ = np.linalg.lstsq(X_aug, y, rcond=None)\nprint(f\"Price = {params[0]:.2f}*Age + {params[1]:.4f}*Mileage + {params[2]:.2f}\")"
  },
  {
    "input": "Estimate electricity bill based on AC hours used: hours = [2, 4, 6, 8], bill = [20, 35, 50, 65]. Fit a linear model.",
    "output": "import numpy as np\n\nhours = np.array([2, 4, 6, 8])\nbill = np.array([20, 35, 50, 65])\nX = np.vstack([hours, np.ones_like(hours)]).T\nparams, *_ = np.linalg.lstsq(X, bill, rcond=None)\nprint(f\"Bill = {params[0]:.2f}*Hours + {params[1]:.2f}\")"
  },
  {
    "input": "Predict study score from hours studied and sleep hours: X = [[1, 8], [2, 7], [3, 6], [4, 5]], y = [60, 65, 70, 75].",
    "output": "import numpy as np\n\nX = np.array([[1, 8], [2, 7], [3, 6], [4, 5]])\ny = np.array([60, 65, 70, 75])\nX_aug = np.hstack([X, np.ones((4,1))])\nparams, *_ = np.linalg.lstsq(X_aug, y, rcond=None)\nprint(f\"Score = {params[0]:.2f}*StudyHours + {params[1]:.2f}*Sleep + {params[2]:.2f}\")"
  },
  {
    "input": "Model rent cost based on apartment size (sqft): size = [500, 750, 1000, 1250], rent = [800, 1100, 1400, 1700]. Fit least squares.",
    "output": "import numpy as np\n\nsize = np.array([500, 750, 1000, 1250])\nrent = np.array([800, 1100, 1400, 1700])\nX = np.vstack([size, np.ones_like(size)]).T\nparams, *_ = np.linalg.lstsq(X, rent, rcond=None)\nprint(f\"Rent = {params[0]:.2f}*Size + {params[1]:.2f}\")"
  },
  {
    "input": "A dog trainer records time spent per session vs. behavior score: time = [1, 2, 3, 4], score = [10, 25, 40, 55]. Fit a linear model.",
    "output": "import numpy as np\n\ntime = np.array([1, 2, 3, 4])\nscore = np.array([10, 25, 40, 55])\nX = np.vstack([time, np.ones_like(time)]).T\nparams, *_ = np.linalg.lstsq(X, score, rcond=None)\nprint(f\"Score = {params[0]:.2f}*Time + {params[1]:.2f}\")"
  },
  {
    "input": "A school's test scores over years are [78, 80, 83, 87] for years [2019, 2020, 2021, 2022]. Predict the score for 2025.",
    "output": "import numpy as np\n\nyears = np.array([2019, 2020, 2021, 2022])\nscores = np.array([78, 80, 83, 87])\nX = np.vstack([years, np.ones_like(years)]).T\nparams, *_ = np.linalg.lstsq(X, scores, rcond=None)\npred = params[0]*2025 + params[1]\nprint(f\"Predicted score in 2025: {pred:.2f}\")"
  },
  {
    "input": "Sales for the past years are: [100, 120, 135, 160] for years [2018, 2019, 2020, 2021]. Estimate 2023 sales.",
    "output": "import numpy as np\n\nyears = np.array([2018, 2019, 2020, 2021])\nsales = np.array([100, 120, 135, 160])\nX = np.vstack([years, np.ones_like(years)]).T\nparams, *_ = np.linalg.lstsq(X, sales, rcond=None)\npred = params[0]*2023 + params[1]\nprint(f\"Estimated sales in 2023: {pred:.2f}\")"
  },
  {
    "input": "Temperature recorded at 8 AM for the last 5 days: [15, 16, 17, 19, 20]. Days: [1, 2, 3, 4, 5]. Predict day 6 temperature.",
    "output": "import numpy as np\n\ndays = np.array([1, 2, 3, 4, 5])\ntemps = np.array([15, 16, 17, 19, 20])\nX = np.vstack([days, np.ones_like(days)]).T\nparams, *_ = np.linalg.lstsq(X, temps, rcond=None)\npred = params[0]*6 + params[1]\nprint(f\"Predicted temperature on day 6: {pred:.2f}\u00b0C\")"
  },
  {
    "input": "Predict monthly subscribers in month 8 if months 1\u20135 had subscribers: [1000, 1200, 1500, 1800, 2100].",
    "output": "import numpy as np\n\nmonths = np.array([1, 2, 3, 4, 5])\nsubs = np.array([1000, 1200, 1500, 1800, 2100])\nX = np.vstack([months, np.ones_like(months)]).T\nparams, *_ = np.linalg.lstsq(X, subs, rcond=None)\npred = params[0]*8 + params[1]\nprint(f\"Predicted subscribers in month 8: {pred:.0f}\")"
  },
  {
    "input": "Company revenue in millions over 4 years: [1.5, 2.0, 2.8, 3.5]. Years: [1, 2, 3, 4]. Estimate year 6 revenue.",
    "output": "import numpy as np\n\nyears = np.array([1, 2, 3, 4])\nrevenue = np.array([1.5, 2.0, 2.8, 3.5])\nX = np.vstack([years, np.ones_like(years)]).T\nparams, *_ = np.linalg.lstsq(X, revenue, rcond=None)\npred = params[0]*6 + params[1]\nprint(f\"Estimated revenue in year 6: {pred:.2f} million\")"
  },
  {
    "input": "Fit a model to predict fuel efficiency from year: years = [2010, 2012, 2014, 2016], mpg = [28, 29, 30.5, 32.2]. Predict for 2020.",
    "output": "import numpy as np\n\nyears = np.array([2010, 2012, 2014, 2016])\nmpg = np.array([28, 29, 30.5, 32.2])\nX = np.vstack([years, np.ones_like(years)]).T\nparams, *_ = np.linalg.lstsq(X, mpg, rcond=None)\npred = params[0]*2020 + params[1]\nprint(f\"Predicted MPG in 2020: {pred:.2f}\")"
  },
  {
    "input": "An influencer gained followers monthly: [500, 800, 1200, 1600]. Predict the number of followers in month 6.",
    "output": "import numpy as np\n\nmonths = np.array([1, 2, 3, 4])\nfollowers = np.array([500, 800, 1200, 1600])\nX = np.vstack([months, np.ones_like(months)]).T\nparams, *_ = np.linalg.lstsq(X, followers, rcond=None)\npred = params[0]*6 + params[1]\nprint(f\"Predicted followers in month 6: {pred:.0f}\")"
  },
  {
    "input": "Predict house price in 2025 based on past years: prices = [200, 220, 250, 270] (in $1000s), years = [2018, 2019, 2020, 2021].",
    "output": "import numpy as np\n\nyears = np.array([2018, 2019, 2020, 2021])\nprices = np.array([200, 220, 250, 270])\nX = np.vstack([years, np.ones_like(years)]).T\nparams, *_ = np.linalg.lstsq(X, prices, rcond=None)\npred = params[0]*2025 + params[1]\nprint(f\"Predicted house price in 2025: ${pred:.2f}k\")"
  },
  {
    "input": "A podcast tracks weekly listeners: [100, 250, 390, 530]. Estimate number of listeners in week 7.",
    "output": "import numpy as np\n\nweeks = np.array([1, 2, 3, 4])\nlisteners = np.array([100, 250, 390, 530])\nX = np.vstack([weeks, np.ones_like(weeks)]).T\nparams, *_ = np.linalg.lstsq(X, listeners, rcond=None)\npred = params[0]*7 + params[1]\nprint(f\"Estimated listeners in week 7: {pred:.0f}\")"
  },
  {
    "input": "A stock\u2019s closing prices: [150, 155, 160, 162] over days [1, 2, 3, 4]. Predict day 6 price.",
    "output": "import numpy as np\n\ndays = np.array([1, 2, 3, 4])\nprices = np.array([150, 155, 160, 162])\nX = np.vstack([days, np.ones_like(days)]).T\nparams, *_ = np.linalg.lstsq(X, prices, rcond=None)\npred = params[0]*6 + params[1]\nprint(f\"Predicted price on day 6: ${pred:.2f}\")"
  },
  {
    "input": "Train delays in minutes across days: [5, 7, 6, 8], days = [1, 2, 3, 4]. Estimate day 6 delay.",
    "output": "import numpy as np\n\ndays = np.array([1, 2, 3, 4])\ndelays = np.array([5, 7, 6, 8])\nX = np.vstack([days, np.ones_like(days)]).T\nparams, *_ = np.linalg.lstsq(X, delays, rcond=None)\npred = params[0]*6 + params[1]\nprint(f\"Estimated delay on day 6: {pred:.2f} minutes\")"
  },
  {
    "input": "Monthly rainfall (in mm): [70, 90, 110, 130]. Predict value for month 6.",
    "output": "import numpy as np\n\nmonths = np.array([1, 2, 3, 4])\nrainfall = np.array([70, 90, 110, 130])\nX = np.vstack([months, np.ones_like(months)]).T\nparams, *_ = np.linalg.lstsq(X, rainfall, rcond=None)\npred = params[0]*6 + params[1]\nprint(f\"Predicted rainfall in month 6: {pred:.2f} mm\")"
  },
  {
    "input": "Fit a least squares line to x = [1, 2, 3], y = [2, 3, 5], and compute the residuals.",
    "output": "import numpy as np\n\nx = np.array([1, 2, 3])\ny = np.array([2, 3, 5])\nX = np.vstack([x, np.ones_like(x)]).T\nparams, *_ = np.linalg.lstsq(X, y, rcond=None)\ny_pred = X @ params\nresiduals = y - y_pred\nprint(\"Residuals:\", residuals)"
  },
  {
    "input": "Given x = [1, 2, 3, 4], y = [1.2, 1.9, 3.0, 4.1], fit a model and compute the Mean Squared Error.",
    "output": "import numpy as np\n\nx = np.array([1, 2, 3, 4])\ny = np.array([1.2, 1.9, 3.0, 4.1])\nX = np.vstack([x, np.ones_like(x)]).T\nparams, *_ = np.linalg.lstsq(X, y, rcond=None)\ny_pred = X @ params\nmse = np.mean((y - y_pred)**2)\nprint(f\"Mean Squared Error: {mse:.4f}\")"
  },
  {
    "input": "Compute R-squared for the model fit to x = [0, 1, 2, 3], y = [1, 2, 1.3, 3.75].",
    "output": "import numpy as np\n\nx = np.array([0, 1, 2, 3])\ny = np.array([1, 2, 1.3, 3.75])\nX = np.vstack([x, np.ones_like(x)]).T\nparams, *_ = np.linalg.lstsq(X, y, rcond=None)\ny_pred = X @ params\nss_res = np.sum((y - y_pred)**2)\nss_tot = np.sum((y - np.mean(y))**2)\nr2 = 1 - ss_res/ss_tot\nprint(f\"R-squared: {r2:.4f}\")"
  },
  {
    "input": "Find residuals of the model fit to x = [1, 2, 3], y = [3, 6, 7].",
    "output": "import numpy as np\n\nx = np.array([1, 2, 3])\ny = np.array([3, 6, 7])\nX = np.vstack([x, np.ones_like(x)]).T\nparams, *_ = np.linalg.lstsq(X, y, rcond=None)\ny_pred = X @ params\nresiduals = y - y_pred\nprint(\"Residuals:\", residuals)"
  },
  {
    "input": "Use x = [0, 1, 2, 3], y = [1, 2, 2, 3] to fit a model. Report slope, intercept, and MSE.",
    "output": "import numpy as np\n\nx = np.array([0, 1, 2, 3])\ny = np.array([1, 2, 2, 3])\nX = np.vstack([x, np.ones_like(x)]).T\nparams, *_ = np.linalg.lstsq(X, y, rcond=None)\ny_pred = X @ params\nmse = np.mean((y - y_pred)**2)\nprint(f\"Slope: {params[0]:.2f}, Intercept: {params[1]:.2f}, MSE: {mse:.4f}\")"
  },
  {
    "input": "Fit a model to x = [10, 20, 30], y = [15, 30, 45] and check if residuals are all zero.",
    "output": "import numpy as np\n\nx = np.array([10, 20, 30])\ny = np.array([15, 30, 45])\nX = np.vstack([x, np.ones_like(x)]).T\nparams, *_ = np.linalg.lstsq(X, y, rcond=None)\ny_pred = X @ params\nresiduals = y - y_pred\nprint(\"Residuals:\", residuals)\nprint(\"All zero residuals?\", np.allclose(residuals, 0))"
  },
  {
    "input": "Use least squares to model y = [2, 4, 6, 8] from x = [1, 2, 3, 4]. Compute the residual sum of squares.",
    "output": "import numpy as np\n\nx = np.array([1, 2, 3, 4])\ny = np.array([2, 4, 6, 8])\nX = np.vstack([x, np.ones_like(x)]).T\nparams, *_ = np.linalg.lstsq(X, y, rcond=None)\ny_pred = X @ params\nrss = np.sum((y - y_pred)**2)\nprint(f\"Residual Sum of Squares: {rss:.4f}\")"
  },
  {
    "input": "Evaluate the fit of y = [5, 7, 9, 11] from x = [1, 2, 3, 4] using R\u00b2.",
    "output": "import numpy as np\n\nx = np.array([1, 2, 3, 4])\ny = np.array([5, 7, 9, 11])\nX = np.vstack([x, np.ones_like(x)]).T\nparams, *_ = np.linalg.lstsq(X, y, rcond=None)\ny_pred = X @ params\nss_res = np.sum((y - y_pred)**2)\nss_tot = np.sum((y - np.mean(y))**2)\nr2 = 1 - ss_res/ss_tot\nprint(f\"R-squared: {r2:.4f}\")"
  },
  {
    "input": "Given a model fit to 5 points, calculate residual variance.",
    "output": "import numpy as np\n\nx = np.array([1, 2, 3, 4, 5])\ny = np.array([2.1, 4.1, 6.2, 8.3, 10.5])\nX = np.vstack([x, np.ones_like(x)]).T\nparams, *_ = np.linalg.lstsq(X, y, rcond=None)\ny_pred = X @ params\nresiduals = y - y_pred\nvar_res = np.var(residuals)\nprint(f\"Residual Variance: {var_res:.4f}\")"
  },
  {
    "input": "For x = [0, 1, 2], y = [1, 2.2, 3.8], calculate R\u00b2 and residuals.",
    "output": "import numpy as np\n\nx = np.array([0, 1, 2])\ny = np.array([1, 2.2, 3.8])\nX = np.vstack([x, np.ones_like(x)]).T\nparams, *_ = np.linalg.lstsq(X, y, rcond=None)\ny_pred = X @ params\nresiduals = y - y_pred\nss_res = np.sum(residuals**2)\nss_tot = np.sum((y - np.mean(y))**2)\nr2 = 1 - ss_res/ss_tot\nprint(\"Residuals:\", residuals)\nprint(f\"R-squared: {r2:.4f}\")"
  },
  {
    "input": "Fit a model to x = [1, 2, 3], y = [2, 4, 5] and calculate residuals.",
    "output": "import numpy as np\n\nx = np.array([1, 2, 3])\ny = np.array([2, 4, 5])\nX = np.vstack([x, np.ones_like(x)]).T\nparams, *_ = np.linalg.lstsq(X, y, rcond=None)\ny_pred = X @ params\nresiduals = y - y_pred\nprint(\"Residuals:\", residuals)"
  },
  {
    "input": "Compute Mean Squared Error for x = [1, 2, 3, 4], y = [2, 2.9, 4.1, 5].",
    "output": "import numpy as np\n\nx = np.array([1, 2, 3, 4])\ny = np.array([2, 2.9, 4.1, 5])\nX = np.vstack([x, np.ones_like(x)]).T\nparams, *_ = np.linalg.lstsq(X, y, rcond=None)\ny_pred = X @ params\nmse = np.mean((y - y_pred)**2)\nprint(f\"Mean Squared Error: {mse:.4f}\")"
  },
  {
    "input": "Given x = [1, 3, 5], y = [2, 4.5, 6.1], compute R\u00b2 for the model.",
    "output": "import numpy as np\n\nx = np.array([1, 3, 5])\ny = np.array([2, 4.5, 6.1])\nX = np.vstack([x, np.ones_like(x)]).T\nparams, *_ = np.linalg.lstsq(X, y, rcond=None)\ny_pred = X @ params\nss_res = np.sum((y - y_pred)**2)\nss_tot = np.sum((y - np.mean(y))**2)\nr2 = 1 - ss_res / ss_tot\nprint(f\"R-squared: {r2:.4f}\")"
  },
  {
    "input": "Fit a linear model and print RSS using x = [2, 4, 6], y = [3, 7, 10].",
    "output": "import numpy as np\n\nx = np.array([2, 4, 6])\ny = np.array([3, 7, 10])\nX = np.vstack([x, np.ones_like(x)]).T\nparams, *_ = np.linalg.lstsq(X, y, rcond=None)\ny_pred = X @ params\nrss = np.sum((y - y_pred)**2)\nprint(f\"Residual Sum of Squares: {rss:.4f}\")"
  },
  {
    "input": "Use x = [0, 1, 2, 3], y = [1, 1.8, 3.1, 4.2] to calculate residuals and R\u00b2.",
    "output": "import numpy as np\n\nx = np.array([0, 1, 2, 3])\ny = np.array([1, 1.8, 3.1, 4.2])\nX = np.vstack([x, np.ones_like(x)]).T\nparams, *_ = np.linalg.lstsq(X, y, rcond=None)\ny_pred = X @ params\nresiduals = y - y_pred\nr2 = 1 - np.sum(residuals**2) / np.sum((y - np.mean(y))**2)\nprint(\"Residuals:\", residuals)\nprint(f\"R-squared: {r2:.4f}\")"
  },
  {
    "input": "Fit a line to x = [5, 10, 15, 20], y = [10, 20, 30, 40] and confirm if residuals are zero.",
    "output": "import numpy as np\n\nx = np.array([5, 10, 15, 20])\ny = np.array([10, 20, 30, 40])\nX = np.vstack([x, np.ones_like(x)]).T\nparams, *_ = np.linalg.lstsq(X, y, rcond=None)\ny_pred = X @ params\nresiduals = y - y_pred\nprint(\"Residuals:\", residuals)\nprint(\"All residuals zero?\", np.allclose(residuals, 0))"
  },
  {
    "input": "Fit a model to x = [1, 2, 3, 4, 5], y = [2.2, 3.9, 6.1, 8, 10.1] and print slope and R\u00b2.",
    "output": "import numpy as np\n\nx = np.array([1, 2, 3, 4, 5])\ny = np.array([2.2, 3.9, 6.1, 8, 10.1])\nX = np.vstack([x, np.ones_like(x)]).T\nparams, *_ = np.linalg.lstsq(X, y, rcond=None)\ny_pred = X @ params\nss_res = np.sum((y - y_pred)**2)\nss_tot = np.sum((y - np.mean(y))**2)\nr2 = 1 - ss_res / ss_tot\nprint(f\"Slope: {params[0]:.4f}, Intercept: {params[1]:.4f}, R\u00b2: {r2:.4f}\")"
  },
  {
    "input": "Check residual variance for x = [1, 2, 3], y = [2.5, 5.1, 7.4].",
    "output": "import numpy as np\n\nx = np.array([1, 2, 3])\ny = np.array([2.5, 5.1, 7.4])\nX = np.vstack([x, np.ones_like(x)]).T\nparams, *_ = np.linalg.lstsq(X, y, rcond=None)\ny_pred = X @ params\nvar_res = np.var(y - y_pred)\nprint(f\"Residual Variance: {var_res:.4f}\")"
  },
  {
    "input": "Evaluate model fit with x = [0, 1, 2, 3, 4], y = [1.2, 2.1, 3.8, 3.9, 5.1] using MSE and R\u00b2.",
    "output": "import numpy as np\n\nx = np.array([0, 1, 2, 3, 4])\ny = np.array([1.2, 2.1, 3.8, 3.9, 5.1])\nX = np.vstack([x, np.ones_like(x)]).T\nparams, *_ = np.linalg.lstsq(X, y, rcond=None)\ny_pred = X @ params\nmse = np.mean((y - y_pred)**2)\nr2 = 1 - np.sum((y - y_pred)**2) / np.sum((y - np.mean(y))**2)\nprint(f\"MSE: {mse:.4f}, R\u00b2: {r2:.4f}\")"
  },
  {
    "input": "Using x = [1, 2, 3, 4, 5], y = [3, 6, 9, 12, 15], fit model and confirm perfect fit.",
    "output": "import numpy as np\n\nx = np.array([1, 2, 3, 4, 5])\ny = np.array([3, 6, 9, 12, 15])\nX = np.vstack([x, np.ones_like(x)]).T\nparams, *_ = np.linalg.lstsq(X, y, rcond=None)\ny_pred = X @ params\nr2 = 1 - np.sum((y - y_pred)**2) / np.sum((y - np.mean(y))**2)\nprint(\"Perfect fit?\", np.allclose(y, y_pred))\nprint(f\"R\u00b2: {r2:.4f}\")"
  },
  {
    "input": "Fit a least squares model and report all residuals for x = [10, 20, 30], y = [15, 28, 41].",
    "output": "import numpy as np\n\nx = np.array([10, 20, 30])\ny = np.array([15, 28, 41])\nX = np.vstack([x, np.ones_like(x)]).T\nparams, *_ = np.linalg.lstsq(X, y, rcond=None)\ny_pred = X @ params\nresiduals = y - y_pred\nprint(\"Residuals:\", residuals)"
  },
  {
    "input": "Fit a linear model and calculate residuals for x = [2, 4, 6, 8], y = [3, 7, 10, 15].",
    "output": "import numpy as np\n\nx = np.array([2, 4, 6, 8])\ny = np.array([3, 7, 10, 15])\nX = np.vstack([x, np.ones_like(x)]).T\nparams, *_ = np.linalg.lstsq(X, y, rcond=None)\ny_pred = X @ params\nresiduals = y - y_pred\nprint(\"Residuals:\", residuals)"
  },
  {
    "input": "Compute RSS for the model: x = [1, 2, 3], y = [2.5, 4.5, 6.8].",
    "output": "import numpy as np\n\nx = np.array([1, 2, 3])\ny = np.array([2.5, 4.5, 6.8])\nX = np.vstack([x, np.ones_like(x)]).T\nparams, *_ = np.linalg.lstsq(X, y, rcond=None)\ny_pred = X @ params\nrss = np.sum((y - y_pred) ** 2)\nprint(f\"RSS: {rss:.4f}\")"
  },
  {
    "input": "Fit model to x = [0, 1, 2, 3], y = [0.1, 1.1, 1.9, 3.2] and check if residuals are small.",
    "output": "import numpy as np\n\nx = np.array([0, 1, 2, 3])\ny = np.array([0.1, 1.1, 1.9, 3.2])\nX = np.vstack([x, np.ones_like(x)]).T\nparams, *_ = np.linalg.lstsq(X, y, rcond=None)\ny_pred = X @ params\nresiduals = y - y_pred\nprint(\"Residuals:\", residuals)\nprint(\"Small residuals?\", np.all(np.abs(residuals) < 0.2))"
  },
  {
    "input": "Using x = [2, 4, 6], y = [5, 9, 13], calculate the model's R\u00b2.",
    "output": "import numpy as np\n\nx = np.array([2, 4, 6])\ny = np.array([5, 9, 13])\nX = np.vstack([x, np.ones_like(x)]).T\nparams, *_ = np.linalg.lstsq(X, y, rcond=None)\ny_pred = X @ params\nss_res = np.sum((y - y_pred)**2)\nss_tot = np.sum((y - np.mean(y))**2)\nr2 = 1 - ss_res / ss_tot\nprint(f\"R\u00b2: {r2:.4f}\")"
  },
  {
    "input": "Given noisy data x = [1, 2, 3], y = [2.1, 4.2, 5.8], assess MSE.",
    "output": "import numpy as np\n\nx = np.array([1, 2, 3])\ny = np.array([2.1, 4.2, 5.8])\nX = np.vstack([x, np.ones_like(x)]).T\nparams, *_ = np.linalg.lstsq(X, y, rcond=None)\ny_pred = X @ params\nmse = np.mean((y - y_pred)**2)\nprint(f\"MSE: {mse:.4f}\")"
  },
  {
    "input": "Check if model x = [1, 3, 5], y = [2, 6, 9] fits perfectly by verifying zero residuals.",
    "output": "import numpy as np\n\nx = np.array([1, 3, 5])\ny = np.array([2, 6, 9])\nX = np.vstack([x, np.ones_like(x)]).T\nparams, *_ = np.linalg.lstsq(X, y, rcond=None)\ny_pred = X @ params\nprint(\"All residuals zero?\", np.allclose(y, y_pred))"
  },
  {
    "input": "Evaluate how well the model fits x = [1, 2, 3, 4], y = [2, 3.8, 6.2, 8.1]. Use RSS and R\u00b2.",
    "output": "import numpy as np\n\nx = np.array([1, 2, 3, 4])\ny = np.array([2, 3.8, 6.2, 8.1])\nX = np.vstack([x, np.ones_like(x)]).T\nparams, *_ = np.linalg.lstsq(X, y, rcond=None)\ny_pred = X @ params\nrss = np.sum((y - y_pred) ** 2)\nss_tot = np.sum((y - np.mean(y)) ** 2)\nr2 = 1 - rss / ss_tot\nprint(f\"RSS: {rss:.4f}, R\u00b2: {r2:.4f}\")"
  },
  {
    "input": "Check residual spread using x = [5, 10, 15], y = [10, 21, 29].",
    "output": "import numpy as np\n\nx = np.array([5, 10, 15])\ny = np.array([10, 21, 29])\nX = np.vstack([x, np.ones_like(x)]).T\nparams, *_ = np.linalg.lstsq(X, y, rcond=None)\ny_pred = X @ params\nresiduals = y - y_pred\nprint(\"Residual Spread:\", residuals)\nprint(\"Standard deviation:\", np.std(residuals))"
  },
  {
    "input": "Using x = [0, 1, 2, 3, 4], y = [1, 2.1, 4.3, 6.1, 8], evaluate MSE and model accuracy.",
    "output": "import numpy as np\n\nx = np.array([0, 1, 2, 3, 4])\ny = np.array([1, 2.1, 4.3, 6.1, 8])\nX = np.vstack([x, np.ones_like(x)]).T\nparams, *_ = np.linalg.lstsq(X, y, rcond=None)\ny_pred = X @ params\nmse = np.mean((y - y_pred)**2)\nprint(f\"MSE: {mse:.4f}\")"
  },
  {
    "input": "Determine R\u00b2 of linear fit for x = [3, 6, 9], y = [2.5, 6, 9.2].",
    "output": "import numpy as np\n\nx = np.array([3, 6, 9])\ny = np.array([2.5, 6, 9.2])\nX = np.vstack([x, np.ones_like(x)]).T\nparams, *_ = np.linalg.lstsq(X, y, rcond=None)\ny_pred = X @ params\nss_res = np.sum((y - y_pred)**2)\nss_tot = np.sum((y - np.mean(y))**2)\nr2 = 1 - ss_res / ss_tot\nprint(f\"R\u00b2: {r2:.4f}\")"
  },
  {
    "input": "Using x = [1, 4, 6], y = [2, 6.1, 9.9], print both MSE and RSS.",
    "output": "import numpy as np\n\nx = np.array([1, 4, 6])\ny = np.array([2, 6.1, 9.9])\nX = np.vstack([x, np.ones_like(x)]).T\nparams, *_ = np.linalg.lstsq(X, y, rcond=None)\ny_pred = X @ params\nresiduals = y - y_pred\nrss = np.sum(residuals**2)\nmse = np.mean(residuals**2)\nprint(f\"RSS: {rss:.4f}, MSE: {mse:.4f}\")"
  },
  {
    "input": "Check if model x = [10, 20, 30], y = [15, 28, 45] overfits using only 3 points.",
    "output": "import numpy as np\n\nx = np.array([10, 20, 30])\ny = np.array([15, 28, 45])\nX = np.vstack([x, np.ones_like(x)]).T\nparams, *_ = np.linalg.lstsq(X, y, rcond=None)\ny_pred = X @ params\nresiduals = y - y_pred\nprint(\"Residuals:\", residuals)\nprint(\"Possible overfit?\", len(x) <= len(params))"
  },
  {
    "input": "Using x = [1, 2, 3], y = [3, 6.2, 9.1], check if R\u00b2 is close to 1.",
    "output": "import numpy as np\n\nx = np.array([1, 2, 3])\ny = np.array([3, 6.2, 9.1])\nX = np.vstack([x, np.ones_like(x)]).T\nparams, *_ = np.linalg.lstsq(X, y, rcond=None)\ny_pred = X @ params\nss_res = np.sum((y - y_pred) ** 2)\nss_tot = np.sum((y - np.mean(y)) ** 2)\nr2 = 1 - ss_res / ss_tot\nprint(f\"R\u00b2: {r2:.4f}\")"
  },
  {
    "input": "Model x = [0, 2, 4, 6], y = [0.1, 4.2, 8.1, 12] and calculate residuals and their mean.",
    "output": "import numpy as np\n\nx = np.array([0, 2, 4, 6])\ny = np.array([0.1, 4.2, 8.1, 12])\nX = np.vstack([x, np.ones_like(x)]).T\nparams, *_ = np.linalg.lstsq(X, y, rcond=None)\ny_pred = X @ params\nresiduals = y - y_pred\nprint(\"Residuals:\", residuals)\nprint(\"Mean of residuals:\", np.mean(residuals))"
  },
  {
    "input": "Fit a line to x = [1, 2, 3], y = [2, 4, 6] and check if it's a perfect fit.",
    "output": "import numpy as np\n\nx = np.array([1, 2, 3])\ny = np.array([2, 4, 6])\nX = np.vstack([x, np.ones_like(x)]).T\nparams, *_ = np.linalg.lstsq(X, y, rcond=None)\ny_pred = X @ params\nprint(\"Perfect fit:\", np.allclose(y, y_pred))"
  },
  {
    "input": "Given X = [[1, 2], [2, 3], [3, 5]], y = [1, 2, 2], find the least squares solution.",
    "output": "import numpy as np\n\nX = np.array([[1, 2], [2, 3], [3, 5]])\ny = np.array([1, 2, 2])\nX_aug = np.hstack([X, np.ones((X.shape[0], 1))])\nparams, *_ = np.linalg.lstsq(X_aug, y, rcond=None)\nprint(\"Parameters:\", params)"
  },
  {
    "input": "Check if a system X = [[1, 1], [2, 2], [3, 3]], y = [2, 4, 5] has a unique least squares solution.",
    "output": "import numpy as np\n\nX = np.array([[1, 1], [2, 2], [3, 3]])\ny = np.array([2, 4, 5])\nU, s, Vt = np.linalg.svd(X, full_matrices=False)\nrank = np.sum(s > 1e-10)\nprint(\"Rank of X:\", rank)\nprint(\"Full rank?\", rank == X.shape[1])"
  },
  {
    "input": "Given symbolic matrix and target vector, solve least squares using sympy.",
    "output": "import sympy as sp\n\nx1, x2 = sp.symbols('x1 x2')\nA = sp.Matrix([[1, 2], [2, 3], [3, 5]])\nb = sp.Matrix([1, 2, 2])\nparams = (A.T * A).inv() * A.T * b\nprint(\"Symbolic least squares solution:\", params)"
  },
  {
    "input": "Fit a polynomial of degree 2 to x = [0, 1, 2], y = [1, 2, 5] using least squares.",
    "output": "import numpy as np\n\nx = np.array([0, 1, 2])\ny = np.array([1, 2, 5])\nX = np.vstack([x**2, x, np.ones_like(x)]).T\nparams, *_ = np.linalg.lstsq(X, y, rcond=None)\nprint(\"Quadratic coefficients:\", params)"
  },
  {
    "input": "Given x = [1, 2, 3, 4], y = [2.1, 3.9, 6.2, 8.1], compute RSS.",
    "output": "import numpy as np\n\nx = np.array([1, 2, 3, 4])\ny = np.array([2.1, 3.9, 6.2, 8.1])\nX = np.vstack([x, np.ones_like(x)]).T\nparams, *_ = np.linalg.lstsq(X, y, rcond=None)\ny_pred = X @ params\nrss = np.sum((y - y_pred) ** 2)\nprint(\"RSS:\", rss)"
  },
  {
    "input": "Fit model and compute mean residual for x = [0, 1, 2], y = [1, 2, 3.1].",
    "output": "import numpy as np\n\nx = np.array([0, 1, 2])\ny = np.array([1, 2, 3.1])\nX = np.vstack([x, np.ones_like(x)]).T\nparams, *_ = np.linalg.lstsq(X, y, rcond=None)\nresiduals = y - (X @ params)\nprint(\"Mean Residual:\", np.mean(residuals))"
  },
  {
    "input": "Use SVD to solve the least squares problem for X = [[1, 2], [2, 3], [3, 5]], y = [1, 2, 2].",
    "output": "import numpy as np\n\nX = np.array([[1, 2], [2, 3], [3, 5]])\ny = np.array([1, 2, 2])\nU, s, Vt = np.linalg.svd(X, full_matrices=False)\nparams = Vt.T @ np.diag(1/s) @ U.T @ y\nprint(\"Solution using SVD:\", params)"
  },
  {
    "input": "Compute projection of y onto col space of X = [[1], [1], [1]], y = [2, 3, 5].",
    "output": "import numpy as np\n\nX = np.ones((3, 1))\ny = np.array([2, 3, 5])\nproj = X @ np.linalg.pinv(X) @ y\nprint(\"Projection of y:\", proj)"
  },
  {
    "input": "Check if fitting y = [1, 2, 4] to x = [1, 2, 3] with a constant model makes sense.",
    "output": "import numpy as np\n\nx = np.array([1, 2, 3])\ny = np.array([1, 2, 4])\nX = np.ones((3,1))  # constant model\nparams, *_ = np.linalg.lstsq(X, y, rcond=None)\ny_pred = X @ params\nprint(\"Fit with constant model:\", y_pred)"
  },
  {
    "input": "Given X = [[1, 2], [1, 2], [1, 2]], y = [5, 5, 5], show the rank deficiency.",
    "output": "import numpy as np\n\nX = np.array([[1, 2], [1, 2], [1, 2]])\nrank = np.linalg.matrix_rank(X)\nprint(\"Rank of X:\", rank)"
  },
  {
    "input": "Use np.polyfit to fit a line to x = [1, 2, 3], y = [2, 4, 6] and compare with lstsq.",
    "output": "import numpy as np\n\nx = np.array([1, 2, 3])\ny = np.array([2, 4, 6])\ncoef_polyfit = np.polyfit(x, y, 1)\nX = np.vstack([x, np.ones_like(x)]).T\ncoef_lstsq, *_ = np.linalg.lstsq(X, y, rcond=None)\nprint(\"Polyfit:\", coef_polyfit)\nprint(\"Lstsq:\", coef_lstsq)"
  },
  {
    "input": "Explain geometrically why residual is orthogonal to column space of X.",
    "output": "import numpy as np\n\nX = np.array([[1], [2], [3]])\ny = np.array([1, 2, 2.5])\nX_aug = np.hstack([X, np.ones((3,1))])\nparams, *_ = np.linalg.lstsq(X_aug, y, rcond=None)\ny_pred = X_aug @ params\nresidual = y - y_pred\nproj = X_aug.T @ residual\nprint(\"X.T @ residual:\", proj)"
  },
  {
    "input": "Compare residual norms of two models: fit y = [2, 4, 6] to x = [1, 2, 3] and x\u00b2.",
    "output": "import numpy as np\n\nx = np.array([1, 2, 3])\ny = np.array([2, 4, 6])\nX1 = np.vstack([x, np.ones_like(x)]).T\nX2 = np.vstack([x**2, np.ones_like(x)]).T\nparams1, *_ = np.linalg.lstsq(X1, y, rcond=None)\nparams2, *_ = np.linalg.lstsq(X2, y, rcond=None)\nres1 = y - X1 @ params1\nres2 = y - X2 @ params2\nprint(\"Norm Linear:\", np.linalg.norm(res1))\nprint(\"Norm Quad:\", np.linalg.norm(res2))"
  },
  {
    "input": "Fit x = [0, 1, 2, 3], y = [1, 3, 7, 13] to a quadratic model and show coefficients.",
    "output": "import numpy as np\n\nx = np.array([0, 1, 2, 3])\ny = np.array([1, 3, 7, 13])\nX = np.vstack([x**2, x, np.ones_like(x)]).T\nparams, *_ = np.linalg.lstsq(X, y, rcond=None)\nprint(\"Coefficients a, b, c:\", params)"
  },
  {
    "input": "Explain how least squares helps when system is overdetermined using x = [1, 2, 3], y = [2, 3, 4].",
    "output": "import numpy as np\n\nx = np.array([1, 2, 3])\ny = np.array([2, 3, 4])\nX = np.vstack([x, np.ones_like(x)]).T\nparams, *_ = np.linalg.lstsq(X, y, rcond=None)\nprint(\"Best fit line:\", params)"
  },
  {
    "input": "Simulate noisy data and fit a model: x = [1, 2, 3, 4], y = [2.1, 4.2, 6.1, 8.2].",
    "output": "import numpy as np\n\nx = np.array([1, 2, 3, 4])\ny = np.array([2.1, 4.2, 6.1, 8.2])\nX = np.vstack([x, np.ones_like(x)]).T\nparams, *_ = np.linalg.lstsq(X, y, rcond=None)\nprint(\"Fitted model:\", params)"
  },
  {
    "input": "Estimate regression line for random integers between 1 and 10.",
    "output": "import numpy as np\n\nnp.random.seed(0)\nx = np.random.randint(1, 10, size=10)\ny = 2 * x + 3 + np.random.randn(10)\nX = np.vstack([x, np.ones_like(x)]).T\nparams, *_ = np.linalg.lstsq(X, y, rcond=None)\nprint(\"Estimated model:\", params)"
  },
  {
    "input": "Check if matrix X = [[1, 0], [0, 1], [1, 1]] is full rank.",
    "output": "import numpy as np\n\nX = np.array([[1, 0], [0, 1], [1, 1]])\nrank = np.linalg.matrix_rank(X)\nprint(\"Rank of X:\", rank)"
  },
  {
    "input": "Use normal equations to solve X = [[1,2],[2,1],[3,3]], y = [5,6,7].",
    "output": "import numpy as np\n\nX = np.array([[1,2],[2,1],[3,3]])\ny = np.array([5,6,7])\nparams = np.linalg.inv(X.T @ X) @ X.T @ y\nprint(\"Normal eq solution:\", params)"
  },
  {
    "input": "Given X = [[1,1],[2,2],[3,3]], y = [3,6,9], confirm solution lies in column space.",
    "output": "import numpy as np\n\nX = np.array([[1,1],[2,2],[3,3]])\ny = np.array([3,6,9])\nparams, *_ = np.linalg.lstsq(X, y, rcond=None)\ny_proj = X @ params\nprint(\"y_proj in colspace of X:\", np.allclose(y, y_proj))"
  },
  {
    "input": "Compute R\u00b2 and RSS for noisy fit: x = [1, 2, 3], y = [2.1, 4.1, 6.1].",
    "output": "import numpy as np\n\nx = np.array([1, 2, 3])\ny = np.array([2.1, 4.1, 6.1])\nX = np.vstack([x, np.ones_like(x)]).T\nparams, *_ = np.linalg.lstsq(X, y, rcond=None)\ny_pred = X @ params\nrss = np.sum((y - y_pred)**2)\nr2 = 1 - rss / np.sum((y - np.mean(y))**2)\nprint(f\"RSS: {rss:.4f}, R\u00b2: {r2:.4f}\")"
  },
  {
    "input": "Perform ridge regression to fit y = X\u03b2 with \u03bb = 0.1. X = [[1, 2], [2, 3], [3, 4]], y = [6, 8, 10].",
    "output": "import numpy as np\n\nX = np.array([[1, 2], [2, 3], [3, 4]])\ny = np.array([6, 8, 10])\nlmbda = 0.1\nX_aug = np.hstack([X, np.ones((X.shape[0], 1))])\nI = np.eye(X_aug.shape[1])\nI[-1, -1] = 0  # don't regularize bias\nparams = np.linalg.inv(X_aug.T @ X_aug + lmbda * I) @ X_aug.T @ y\nprint(f\"Ridge Regression Coefficients: {params}\")"
  },
  {
    "input": "Apply ridge regression on data: X = [[1], [2], [3], [4]], y = [2.1, 4.1, 6.2, 8.2] with \u03bb=1.",
    "output": "import numpy as np\n\nX = np.array([[1], [2], [3], [4]])\ny = np.array([2.1, 4.1, 6.2, 8.2])\nlmbda = 1\nX_aug = np.hstack([X, np.ones((X.shape[0], 1))])\nI = np.eye(X_aug.shape[1])\nI[-1, -1] = 0\nparams = np.linalg.inv(X_aug.T @ X_aug + lmbda * I) @ X_aug.T @ y\nprint(f\"Coefficients with Ridge: {params}\")"
  },
  {
    "input": "Estimate parameters using regularized least squares with \u03bb=0.5. X = [[1,0],[0,1],[1,1]], y = [1,1,2].",
    "output": "import numpy as np\n\nX = np.array([[1,0],[0,1],[1,1]])\ny = np.array([1,1,2])\nlmbda = 0.5\nX_aug = np.hstack([X, np.ones((X.shape[0], 1))])\nI = np.eye(X_aug.shape[1])\nI[-1, -1] = 0\nparams = np.linalg.inv(X_aug.T @ X_aug + lmbda * I) @ X_aug.T @ y\nprint(f\"Regularized Coefficients: {params}\")"
  },
  {
    "input": "Use ridge regression on noisy linear data: X = [[1],[2],[3],[4]], y = [2.05, 4.02, 6.1, 7.95], \u03bb=0.2.",
    "output": "import numpy as np\n\nX = np.array([[1],[2],[3],[4]])\ny = np.array([2.05, 4.02, 6.1, 7.95])\nlmbda = 0.2\nX_aug = np.hstack([X, np.ones((X.shape[0], 1))])\nI = np.eye(X_aug.shape[1])\nI[-1, -1] = 0\nparams = np.linalg.inv(X_aug.T @ X_aug + lmbda * I) @ X_aug.T @ y\nprint(f\"Ridge Fit Parameters: {params}\")"
  },
  {
    "input": "Fit a ridge regression line through X = [[5],[10],[15],[20]], y = [2, 4, 6, 8] with \u03bb=0.3.",
    "output": "import numpy as np\n\nX = np.array([[5],[10],[15],[20]])\ny = np.array([2, 4, 6, 8])\nlmbda = 0.3\nX_aug = np.hstack([X, np.ones((4,1))])\nI = np.eye(X_aug.shape[1])\nI[-1,-1] = 0\nparams = np.linalg.inv(X_aug.T @ X_aug + lmbda * I) @ X_aug.T @ y\nprint(f\"Ridge Parameters: {params}\")"
  },
  {
    "input": "Fit a ridge regression model where X = [[1, 2], [3, 4], [5, 6]] and y = [5, 11, 17] with \u03bb=0.4.",
    "output": "import numpy as np\n\nX = np.array([[1, 2], [3, 4], [5, 6]])\ny = np.array([5, 11, 17])\nlmbda = 0.4\nX_aug = np.hstack([X, np.ones((3, 1))])\nI = np.eye(3)\nI[-1, -1] = 0\nparams = np.linalg.inv(X_aug.T @ X_aug + lmbda * I) @ X_aug.T @ y\nprint(f\"Ridge Regression Coefficients: {params}\")"
  },
  {
    "input": "Apply regularization to a multivariate regression problem. X = [[1, 0], [0, 1], [1, 1]], y = [3, 3, 6], \u03bb=0.2.",
    "output": "import numpy as np\n\nX = np.array([[1, 0], [0, 1], [1, 1]])\ny = np.array([3, 3, 6])\nlmbda = 0.2\nX_aug = np.hstack([X, np.ones((3, 1))])\nI = np.eye(3)\nI[-1, -1] = 0\nparams = np.linalg.inv(X_aug.T @ X_aug + lmbda * I) @ X_aug.T @ y\nprint(f\"Regularized Parameters: {params}\")"
  },
  {
    "input": "Use ridge regression with \u03bb=1 on X = [[2],[4],[6]], y = [3, 7, 11].",
    "output": "import numpy as np\n\nX = np.array([[2],[4],[6]])\ny = np.array([3, 7, 11])\nlmbda = 1\nX_aug = np.hstack([X, np.ones((3,1))])\nI = np.eye(2)\nI[-1,-1] = 0\nparams = np.linalg.inv(X_aug.T @ X_aug + lmbda * I) @ X_aug.T @ y\nprint(f\"Ridge Fit Coefficients: {params}\")"
  },
  {
    "input": "Fit ridge regression on high-dimensional data: X = [[1,2,3,4], [2,3,4,5], [3,4,5,6]], y = [10, 14, 18], \u03bb=0.3.",
    "output": "import numpy as np\n\nX = np.array([[1,2,3,4], [2,3,4,5], [3,4,5,6]])\ny = np.array([10, 14, 18])\nlmbda = 0.3\nX_aug = np.hstack([X, np.ones((3,1))])\nI = np.eye(X_aug.shape[1])\nI[-1,-1] = 0\nparams = np.linalg.inv(X_aug.T @ X_aug + lmbda * I) @ X_aug.T @ y\nprint(f\"Coefficients with Regularization: {params}\")"
  },
  {
    "input": "Implement ridge regression with bias term excluded from regularization. X = [[1],[2],[3]], y = [1,2,3], \u03bb=5.",
    "output": "import numpy as np\n\nX = np.array([[1],[2],[3]])\ny = np.array([1,2,3])\nlmbda = 5\nX_aug = np.hstack([X, np.ones((3,1))])\nI = np.eye(2)\nI[-1,-1] = 0\nparams = np.linalg.inv(X_aug.T @ X_aug + lmbda*I) @ X_aug.T @ y\nprint(f\"Ridge Coefficients: {params}\")"
  },
  {
    "input": "Perform ridge regression on data with slight multicollinearity. X = [[1, 2], [2, 4.1], [3, 6.2]], y = [1, 2, 3], \u03bb=0.5.",
    "output": "import numpy as np\n\nX = np.array([[1, 2], [2, 4.1], [3, 6.2]])\ny = np.array([1, 2, 3])\nlmbda = 0.5\nX_aug = np.hstack([X, np.ones((3,1))])\nI = np.eye(3)\nI[-1,-1] = 0\nparams = np.linalg.inv(X_aug.T @ X_aug + lmbda*I) @ X_aug.T @ y\nprint(f\"Ridge Regression Weights: {params}\")"
  },
  {
    "input": "Use ridge regression to prevent overfitting on X = [[1,1],[2,4],[3,9]], y = [2, 3, 6], \u03bb=1.5.",
    "output": "import numpy as np\n\nX = np.array([[1,1],[2,4],[3,9]])\ny = np.array([2,3,6])\nlmbda = 1.5\nX_aug = np.hstack([X, np.ones((3,1))])\nI = np.eye(3)\nI[-1,-1] = 0\nparams = np.linalg.inv(X_aug.T @ X_aug + lmbda*I) @ X_aug.T @ y\nprint(f\"Regularized Coefficients: {params}\")"
  },
  {
    "input": "Fit a ridge regression model on polynomial features. X = [[1,1], [2,4], [3,9]], y = [3,6,9], \u03bb=0.7.",
    "output": "import numpy as np\n\nX = np.array([[1,1], [2,4], [3,9]])\ny = np.array([3,6,9])\nlmbda = 0.7\nX_aug = np.hstack([X, np.ones((3,1))])\nI = np.eye(3)\nI[-1,-1] = 0\nparams = np.linalg.inv(X_aug.T @ X_aug + lmbda*I) @ X_aug.T @ y\nprint(f\"Ridge Fit Output: {params}\")"
  },
  {
    "input": "Train a regularized linear model with \u03bb=2. X = [[0,1],[1,0],[1,1]], y = [1,2,3].",
    "output": "import numpy as np\n\nX = np.array([[0,1],[1,0],[1,1]])\ny = np.array([1,2,3])\nlmbda = 2\nX_aug = np.hstack([X, np.ones((3,1))])\nI = np.eye(3)\nI[-1,-1] = 0\nparams = np.linalg.inv(X_aug.T @ X_aug + lmbda*I) @ X_aug.T @ y\nprint(f\"Ridge Regression Solution: {params}\")"
  },
  {
    "input": "Use ridge regression for stability in high-dimensional model. X = [[1,2,3], [4,5,6], [7,8,9]], y = [6,15,24], \u03bb=0.6.",
    "output": "import numpy as np\n\nX = np.array([[1,2,3], [4,5,6], [7,8,9]])\ny = np.array([6,15,24])\nlmbda = 0.6\nX_aug = np.hstack([X, np.ones((3,1))])\nI = np.eye(4)\nI[-1,-1] = 0\nparams = np.linalg.inv(X_aug.T @ X_aug + lmbda*I) @ X_aug.T @ y\nprint(f\"Ridge Coefficients: {params}\")"
  },
  {
    "input": "Apply ridge regression to a small dataset. X = [[1], [2], [3]], y = [2, 4, 6], \u03bb=0.1.",
    "output": "import numpy as np\n\nX = np.array([[1], [2], [3]])\ny = np.array([2, 4, 6])\nlmbda = 0.1\nX_aug = np.hstack([X, np.ones((3, 1))])\nI = np.eye(2)\nI[-1, -1] = 0\nparams = np.linalg.inv(X_aug.T @ X_aug + lmbda * I) @ X_aug.T @ y\nprint(f\"Ridge Regression Parameters: {params}\")"
  },
  {
    "input": "Perform ridge regression where X = [[0, 1], [1, 0], [1, 1]], y = [1, 2, 3], \u03bb=0.2.",
    "output": "import numpy as np\n\nX = np.array([[0, 1], [1, 0], [1, 1]])\ny = np.array([1, 2, 3])\nlmbda = 0.2\nX_aug = np.hstack([X, np.ones((3, 1))])\nI = np.eye(3)\nI[-1, -1] = 0\nparams = np.linalg.inv(X_aug.T @ X_aug + lmbda * I) @ X_aug.T @ y\nprint(f\"Ridge Regression Output: {params}\")"
  },
  {
    "input": "Fit a regularized linear model. X = [[1, 2], [2, 4], [3, 6]], y = [5, 10, 15], \u03bb=1.0.",
    "output": "import numpy as np\n\nX = np.array([[1, 2], [2, 4], [3, 6]])\ny = np.array([5, 10, 15])\nlmbda = 1.0\nX_aug = np.hstack([X, np.ones((3, 1))])\nI = np.eye(3)\nI[-1, -1] = 0\nparams = np.linalg.inv(X_aug.T @ X_aug + lmbda * I) @ X_aug.T @ y\nprint(f\"Regularized Coefficients: {params}\")"
  },
  {
    "input": "Use ridge regression on polynomial features. X = [[1, 1], [2, 4], [3, 9]], y = [2, 4, 6], \u03bb=0.5.",
    "output": "import numpy as np\n\nX = np.array([[1, 1], [2, 4], [3, 9]])\ny = np.array([2, 4, 6])\nlmbda = 0.5\nX_aug = np.hstack([X, np.ones((3, 1))])\nI = np.eye(3)\nI[-1, -1] = 0\nparams = np.linalg.inv(X_aug.T @ X_aug + lmbda * I) @ X_aug.T @ y\nprint(f\"Ridge Regression Fit: {params}\")"
  },
  {
    "input": "Train a ridge model with X = [[1, 3], [2, 5], [3, 7]], y = [4, 9, 14], \u03bb=0.3.",
    "output": "import numpy as np\n\nX = np.array([[1, 3], [2, 5], [3, 7]])\ny = np.array([4, 9, 14])\nlmbda = 0.3\nX_aug = np.hstack([X, np.ones((3, 1))])\nI = np.eye(3)\nI[-1, -1] = 0\nparams = np.linalg.inv(X_aug.T @ X_aug + lmbda * I) @ X_aug.T @ y\nprint(f\"Fitted Ridge Model: {params}\")"
  },
  {
    "input": "Perform ridge regression with X = [[5, 1], [6, 2], [7, 3]], y = [12, 14, 16], \u03bb=0.7.",
    "output": "import numpy as np\n\nX = np.array([[5, 1], [6, 2], [7, 3]])\ny = np.array([12, 14, 16])\nlmbda = 0.7\nX_aug = np.hstack([X, np.ones((3, 1))])\nI = np.eye(3)\nI[-1, -1] = 0\nparams = np.linalg.inv(X_aug.T @ X_aug + lmbda * I) @ X_aug.T @ y\nprint(f\"Ridge Output Parameters: {params}\")"
  },
  {
    "input": "Regularize the fit to X = [[1], [2], [3], [4]], y = [3, 5, 7, 9], \u03bb=0.2.",
    "output": "import numpy as np\n\nX = np.array([[1], [2], [3], [4]])\ny = np.array([3, 5, 7, 9])\nlmbda = 0.2\nX_aug = np.hstack([X, np.ones((4, 1))])\nI = np.eye(2)\nI[-1, -1] = 0\nparams = np.linalg.inv(X_aug.T @ X_aug + lmbda * I) @ X_aug.T @ y\nprint(f\"Regularized Fit Coefficients: {params}\")"
  },
  {
    "input": "Use ridge regression with X = [[1, 4], [2, 5], [3, 6]], y = [7, 8, 9], \u03bb=0.05.",
    "output": "import numpy as np\n\nX = np.array([[1, 4], [2, 5], [3, 6]])\ny = np.array([7, 8, 9])\nlmbda = 0.05\nX_aug = np.hstack([X, np.ones((3, 1))])\nI = np.eye(3)\nI[-1, -1] = 0\nparams = np.linalg.inv(X_aug.T @ X_aug + lmbda * I) @ X_aug.T @ y\nprint(f\"Ridge Regression Coefficients: {params}\")"
  },
  {
    "input": "Apply ridge regression on X = [[1, 0], [2, 1], [3, 2], [4, 3]], y = [2, 4, 6, 8], \u03bb=0.4.",
    "output": "import numpy as np\n\nX = np.array([[1, 0], [2, 1], [3, 2], [4, 3]])\ny = np.array([2, 4, 6, 8])\nlmbda = 0.4\nX_aug = np.hstack([X, np.ones((4, 1))])\nI = np.eye(3)\nI[-1, -1] = 0\nparams = np.linalg.inv(X_aug.T @ X_aug + lmbda * I) @ X_aug.T @ y\nprint(f\"Fitted Ridge Parameters: {params}\")"
  },
  {
    "input": "Use ridge regression with moderate regularization. X = [[2, 3], [3, 5], [4, 7]], y = [10, 15, 20], \u03bb=0.9.",
    "output": "import numpy as np\n\nX = np.array([[2, 3], [3, 5], [4, 7]])\ny = np.array([10, 15, 20])\nlmbda = 0.9\nX_aug = np.hstack([X, np.ones((3, 1))])\nI = np.eye(3)\nI[-1, -1] = 0\nparams = np.linalg.inv(X_aug.T @ X_aug + lmbda * I) @ X_aug.T @ y\nprint(f\"Regularized Linear Fit: {params}\")"
  },
  {
    "input": "Fit a quadratic polynomial to X = [0, 1, 2], y = [1, 2, 5].",
    "output": "import numpy as np\n\nX = np.array([0, 1, 2])\ny = np.array([1, 2, 5])\nX_poly = np.vstack([X**2, X, np.ones_like(X)]).T\nparams, *_ = np.linalg.lstsq(X_poly, y, rcond=None)\nprint(f\"Fitted Quadratic: y = {params[0]:.4f}x^2 + {params[1]:.4f}x + {params[2]:.4f}\")"
  },
  {
    "input": "Fit a cubic polynomial through X = [-1, 0, 1, 2], y = [2, 0, 2, 10].",
    "output": "import numpy as np\n\nX = np.array([-1, 0, 1, 2])\ny = np.array([2, 0, 2, 10])\nX_poly = np.vstack([X**3, X**2, X, np.ones_like(X)]).T\nparams, *_ = np.linalg.lstsq(X_poly, y, rcond=None)\nprint(f\"Fitted Cubic: y = {params[0]:.4f}x^3 + {params[1]:.4f}x^2 + {params[2]:.4f}x + {params[3]:.4f}\")"
  },
  {
    "input": "Fit a degree-2 polynomial to noisy quadratic data X = [1, 2, 3, 4], y = [2.1, 3.9, 9.2, 15.8].",
    "output": "import numpy as np\n\nX = np.array([1, 2, 3, 4])\ny = np.array([2.1, 3.9, 9.2, 15.8])\nX_poly = np.vstack([X**2, X, np.ones_like(X)]).T\nparams, *_ = np.linalg.lstsq(X_poly, y, rcond=None)\nprint(f\"Quadratic Fit: y = {params[0]:.4f}x^2 + {params[1]:.4f}x + {params[2]:.4f}\")"
  },
  {
    "input": "Fit a degree-1 polynomial to linearly increasing data X = [2, 4, 6], y = [5, 9, 13].",
    "output": "import numpy as np\n\nX = np.array([2, 4, 6])\ny = np.array([5, 9, 13])\nX_poly = np.vstack([X, np.ones_like(X)]).T\nparams, *_ = np.linalg.lstsq(X_poly, y, rcond=None)\nprint(f\"Linear Fit: y = {params[0]:.4f}x + {params[1]:.4f}\")"
  },
  {
    "input": "Use degree-3 polynomial on X = [0, 1, 2, 3], y = [1, 8, 27, 64].",
    "output": "import numpy as np\n\nX = np.array([0, 1, 2, 3])\ny = np.array([1, 8, 27, 64])\nX_poly = np.vstack([X**3, X**2, X, np.ones_like(X)]).T\nparams, *_ = np.linalg.lstsq(X_poly, y, rcond=None)\nprint(f\"Cubic Polynomial Fit: y = {params[0]:.4f}x^3 + {params[1]:.4f}x^2 + {params[2]:.4f}x + {params[3]:.4f}\")"
  },
  {
    "input": "Fit a degree-4 polynomial to X = [-2, -1, 0, 1, 2], y = [16, 1, 0, 1, 16].",
    "output": "import numpy as np\n\nX = np.array([-2, -1, 0, 1, 2])\ny = np.array([16, 1, 0, 1, 16])\nX_poly = np.vstack([X**4, X**3, X**2, X, np.ones_like(X)]).T\nparams, *_ = np.linalg.lstsq(X_poly, y, rcond=None)\nprint(f\"Degree-4 Polynomial: y = {params[0]:.4f}x^4 + {params[1]:.4f}x^3 + {params[2]:.4f}x^2 + {params[3]:.4f}x + {params[4]:.4f}\")"
  },
  {
    "input": "Fit quadratic curve through X = [1, 2, 3, 4], y = [3, 7, 13, 21].",
    "output": "import numpy as np\n\nX = np.array([1, 2, 3, 4])\ny = np.array([3, 7, 13, 21])\nX_poly = np.vstack([X**2, X, np.ones_like(X)]).T\nparams, *_ = np.linalg.lstsq(X_poly, y, rcond=None)\nprint(f\"Fitted Quadratic Curve: y = {params[0]:.4f}x^2 + {params[1]:.4f}x + {params[2]:.4f}\")"
  },
  {
    "input": "Fit a degree-2 polynomial on X = [0, 2, 4], y = [1, 3, 9].",
    "output": "import numpy as np\n\nX = np.array([0, 2, 4])\ny = np.array([1, 3, 9])\nX_poly = np.vstack([X**2, X, np.ones_like(X)]).T\nparams, *_ = np.linalg.lstsq(X_poly, y, rcond=None)\nprint(f\"Quadratic Fit: y = {params[0]:.4f}x^2 + {params[1]:.4f}x + {params[2]:.4f}\")"
  },
  {
    "input": "Use degree-3 fit for sinusoidal-like data. X = [0, 1, 2, 3], y = [0, 1, 0, -1].",
    "output": "import numpy as np\n\nX = np.array([0, 1, 2, 3])\ny = np.array([0, 1, 0, -1])\nX_poly = np.vstack([X**3, X**2, X, np.ones_like(X)]).T\nparams, *_ = np.linalg.lstsq(X_poly, y, rcond=None)\nprint(f\"Cubic Polynomial Approximation: y = {params[0]:.4f}x^3 + {params[1]:.4f}x^2 + {params[2]:.4f}x + {params[3]:.4f}\")"
  },
  {
    "input": "Fit a quadratic polynomial to approximate exponential-like data X = [1, 2, 3], y = [2.7, 7.4, 20.1].",
    "output": "import numpy as np\n\nX = np.array([1, 2, 3])\ny = np.array([2.7, 7.4, 20.1])\nX_poly = np.vstack([X**2, X, np.ones_like(X)]).T\nparams, *_ = np.linalg.lstsq(X_poly, y, rcond=None)\nprint(f\"Quadratic Approximation: y = {params[0]:.4f}x^2 + {params[1]:.4f}x + {params[2]:.4f}\")"
  },
  {
    "input": "Fit linear and quadratic models and compare. X = [0, 1, 2, 3], y = [1, 2, 5, 10].",
    "output": "import numpy as np\n\nX = np.array([0, 1, 2, 3])\ny = np.array([1, 2, 5, 10])\nX_lin = np.vstack([X, np.ones_like(X)]).T\nX_quad = np.vstack([X**2, X, np.ones_like(X)]).T\nparams_lin, *_ = np.linalg.lstsq(X_lin, y, rcond=None)\nparams_quad, *_ = np.linalg.lstsq(X_quad, y, rcond=None)\nprint(f\"Linear: y = {params_lin[0]:.4f}x + {params_lin[1]:.4f}\")\nprint(f\"Quadratic: y = {params_quad[0]:.4f}x^2 + {params_quad[1]:.4f}x + {params_quad[2]:.4f}\")"
  },
  {
    "input": "Fit polynomial of degree 3 to X = [1, 2, 3, 4], y = [2, 6, 14, 30].",
    "output": "import numpy as np\n\nX = np.array([1, 2, 3, 4])\ny = np.array([2, 6, 14, 30])\nX_poly = np.vstack([X**3, X**2, X, np.ones_like(X)]).T\nparams, *_ = np.linalg.lstsq(X_poly, y, rcond=None)\nprint(f\"Cubic Fit: y = {params[0]:.4f}x^3 + {params[1]:.4f}x^2 + {params[2]:.4f}x + {params[3]:.4f}\")"
  },
  {
    "input": "Fit a degree-3 polynomial to estimate a sequence X = [1, 2, 3, 4], y = [3, 7, 13, 21].",
    "output": "import numpy as np\n\nX = np.array([1, 2, 3, 4])\ny = np.array([3, 7, 13, 21])\nX_poly = np.vstack([X**3, X**2, X, np.ones_like(X)]).T\nparams, *_ = np.linalg.lstsq(X_poly, y, rcond=None)\nprint(f\"Fitted Cubic Model: y = {params[0]:.4f}x^3 + {params[1]:.4f}x^2 + {params[2]:.4f}x + {params[3]:.4f}\")"
  },
  {
    "input": "Fit a degree-2 polynomial to X = [-2, -1, 0, 1, 2], y = [7, 2, 1, 2, 7].",
    "output": "import numpy as np\n\nX = np.array([-2, -1, 0, 1, 2])\ny = np.array([7, 2, 1, 2, 7])\nX_poly = np.vstack([X**2, X, np.ones_like(X)]).T\nparams, *_ = np.linalg.lstsq(X_poly, y, rcond=None)\nprint(f\"Fitted Quadratic: y = {params[0]:.4f}x^2 + {params[1]:.4f}x + {params[2]:.4f}\")"
  },
  {
    "input": "Fit a polynomial of degree 4 to X = [0, 1, 2, 3, 4], y = [1, 2, 1, 2, 1].",
    "output": "import numpy as np\n\nX = np.array([0, 1, 2, 3, 4])\ny = np.array([1, 2, 1, 2, 1])\nX_poly = np.vstack([X**4, X**3, X**2, X, np.ones_like(X)]).T\nparams, *_ = np.linalg.lstsq(X_poly, y, rcond=None)\nprint(f\"Degree-4 Fit: y = {params[0]:.4f}x^4 + {params[1]:.4f}x^3 + {params[2]:.4f}x^2 + {params[3]:.4f}x + {params[4]:.4f}\")"
  },
  {
    "input": "Fit linear and quadratic models to noisy data. X = [1, 2, 3, 4], y = [3.1, 5.9, 9.0, 13.2].",
    "output": "import numpy as np\n\nX = np.array([1, 2, 3, 4])\ny = np.array([3.1, 5.9, 9.0, 13.2])\nX_lin = np.vstack([X, np.ones_like(X)]).T\nX_quad = np.vstack([X**2, X, np.ones_like(X)]).T\nparams_lin, *_ = np.linalg.lstsq(X_lin, y, rcond=None)\nparams_quad, *_ = np.linalg.lstsq(X_quad, y, rcond=None)\nprint(f\"Linear: y = {params_lin[0]:.4f}x + {params_lin[1]:.4f}\")\nprint(f\"Quadratic: y = {params_quad[0]:.4f}x^2 + {params_quad[1]:.4f}x + {params_quad[2]:.4f}\")"
  },
  {
    "input": "Fit a cubic model to oscillating data: X = [0, 1, 2, 3, 4], y = [1, 0, 1, 0, 1].",
    "output": "import numpy as np\n\nX = np.array([0, 1, 2, 3, 4])\ny = np.array([1, 0, 1, 0, 1])\nX_poly = np.vstack([X**3, X**2, X, np.ones_like(X)]).T\nparams, *_ = np.linalg.lstsq(X_poly, y, rcond=None)\nprint(f\"Cubic Approximation: y = {params[0]:.4f}x^3 + {params[1]:.4f}x^2 + {params[2]:.4f}x + {params[3]:.4f}\")"
  },
  {
    "input": "Estimate curve using polynomial of degree 2: X = [2, 4, 6, 8], y = [1, 2, 1, 2].",
    "output": "import numpy as np\n\nX = np.array([2, 4, 6, 8])\ny = np.array([1, 2, 1, 2])\nX_poly = np.vstack([X**2, X, np.ones_like(X)]).T\nparams, *_ = np.linalg.lstsq(X_poly, y, rcond=None)\nprint(f\"Quadratic Estimate: y = {params[0]:.4f}x^2 + {params[1]:.4f}x + {params[2]:.4f}\")"
  },
  {
    "input": "Fit a degree-5 polynomial to noisy periodic pattern X = [0, 1, 2, 3, 4, 5], y = [0, 1, 0, -1, 0, 1].",
    "output": "import numpy as np\n\nX = np.array([0, 1, 2, 3, 4, 5])\ny = np.array([0, 1, 0, -1, 0, 1])\nX_poly = np.vstack([X**5, X**4, X**3, X**2, X, np.ones_like(X)]).T\nparams, *_ = np.linalg.lstsq(X_poly, y, rcond=None)\nprint(f\"Degree-5 Fit: y = {params[0]:.4f}x^5 + {params[1]:.4f}x^4 + {params[2]:.4f}x^3 + {params[3]:.4f}x^2 + {params[4]:.4f}x + {params[5]:.4f}\")"
  },
  {
    "input": "Fit a polynomial of degree 2 to X = [1, 3, 5, 7], y = [1, 4, 9, 16].",
    "output": "import numpy as np\n\nX = np.array([1, 3, 5, 7])\ny = np.array([1, 4, 9, 16])\nX_poly = np.vstack([X**2, X, np.ones_like(X)]).T\nparams, *_ = np.linalg.lstsq(X_poly, y, rcond=None)\nprint(f\"Quadratic Approximation: y = {params[0]:.4f}x^2 + {params[1]:.4f}x + {params[2]:.4f}\")"
  },
  {
    "input": "Fit cubic polynomial for curve interpolation: X = [-1, 0, 1, 2], y = [4, 1, 0, 1].",
    "output": "import numpy as np\n\nX = np.array([-1, 0, 1, 2])\ny = np.array([4, 1, 0, 1])\nX_poly = np.vstack([X**3, X**2, X, np.ones_like(X)]).T\nparams, *_ = np.linalg.lstsq(X_poly, y, rcond=None)\nprint(f\"Fitted Cubic Curve: y = {params[0]:.4f}x^3 + {params[1]:.4f}x^2 + {params[2]:.4f}x + {params[3]:.4f}\")"
  },
  {
    "input": "Estimate data trend using degree-3 polynomial: X = [1, 2, 3, 4, 5], y = [2, 6, 14, 30, 62].",
    "output": "import numpy as np\n\nX = np.array([1, 2, 3, 4, 5])\ny = np.array([2, 6, 14, 30, 62])\nX_poly = np.vstack([X**3, X**2, X, np.ones_like(X)]).T\nparams, *_ = np.linalg.lstsq(X_poly, y, rcond=None)\nprint(f\"Degree-3 Polynomial: y = {params[0]:.4f}x^3 + {params[1]:.4f}x^2 + {params[2]:.4f}x + {params[3]:.4f}\")"
  },
  {
    "input": "Fit a linear model to almost-linear data: X = [0, 1, 2, 3], y = [1.1, 2.0, 2.9, 4.1].",
    "output": "import numpy as np\n\nX = np.array([0, 1, 2, 3])\ny = np.array([1.1, 2.0, 2.9, 4.1])\nX_poly = np.vstack([X, np.ones_like(X)]).T\nparams, *_ = np.linalg.lstsq(X_poly, y, rcond=None)\nprint(f\"Linear Approximation: y = {params[0]:.4f}x + {params[1]:.4f}\")"
  },
  {
    "input": "Use degree-3 polynomial to fit descending values. X = [1, 2, 3, 4], y = [8, 3, 0, -1].",
    "output": "import numpy as np\n\nX = np.array([1, 2, 3, 4])\ny = np.array([8, 3, 0, -1])\nX_poly = np.vstack([X**3, X**2, X, np.ones_like(X)]).T\nparams, *_ = np.linalg.lstsq(X_poly, y, rcond=None)\nprint(f\"Cubic Fit: y = {params[0]:.4f}x^3 + {params[1]:.4f}x^2 + {params[2]:.4f}x + {params[3]:.4f}\")"
  },
  {
    "input": "Fit a degree-2 polynomial to approximate y = 2x\u00b2 - 3x + 1 using X = [1, 2, 3, 4], y = [0, 3, 10, 21].",
    "output": "import numpy as np\n\nX = np.array([1, 2, 3, 4])\ny = np.array([0, 3, 10, 21])\nX_poly = np.vstack([X**2, X, np.ones_like(X)]).T\nparams, *_ = np.linalg.lstsq(X_poly, y, rcond=None)\nprint(f\"Fitted Quadratic: y = {params[0]:.4f}x\u00b2 + {params[1]:.4f}x + {params[2]:.4f}\")"
  },
  {
    "input": "Fit a degree-3 polynomial to noisy cube-like data: X = [0, 1, 2, 3], y = [0.1, 1.1, 7.8, 26.9].",
    "output": "import numpy as np\n\nX = np.array([0, 1, 2, 3])\ny = np.array([0.1, 1.1, 7.8, 26.9])\nX_poly = np.vstack([X**3, X**2, X, np.ones_like(X)]).T\nparams, *_ = np.linalg.lstsq(X_poly, y, rcond=None)\nprint(f\"Cubic Fit: y = {params[0]:.4f}x\u00b3 + {params[1]:.4f}x\u00b2 + {params[2]:.4f}x + {params[3]:.4f}\")"
  },
  {
    "input": "Fit a degree-4 polynomial to alternating pattern: X = [0, 1, 2, 3, 4], y = [1, -1, 1, -1, 1].",
    "output": "import numpy as np\n\nX = np.array([0, 1, 2, 3, 4])\ny = np.array([1, -1, 1, -1, 1])\nX_poly = np.vstack([X**4, X**3, X**2, X, np.ones_like(X)]).T\nparams, *_ = np.linalg.lstsq(X_poly, y, rcond=None)\nprint(f\"Degree-4 Fit: y = {params[0]:.4f}x\u2074 + {params[1]:.4f}x\u00b3 + {params[2]:.4f}x\u00b2 + {params[3]:.4f}x + {params[4]:.4f}\")"
  },
  {
    "input": "Fit a polynomial of degree 2 to simulate parabola: X = [-2, -1, 0, 1, 2], y = [4, 1, 0, 1, 4].",
    "output": "import numpy as np\n\nX = np.array([-2, -1, 0, 1, 2])\ny = np.array([4, 1, 0, 1, 4])\nX_poly = np.vstack([X**2, X, np.ones_like(X)]).T\nparams, *_ = np.linalg.lstsq(X_poly, y, rcond=None)\nprint(f\"Parabolic Fit: y = {params[0]:.4f}x\u00b2 + {params[1]:.4f}x + {params[2]:.4f}\")"
  },
  {
    "input": "Fit linear and quadratic models to X = [1, 2, 3, 4], y = [2, 5, 10, 17]. Compare them.",
    "output": "import numpy as np\n\nX = np.array([1, 2, 3, 4])\ny = np.array([2, 5, 10, 17])\nX_lin = np.vstack([X, np.ones_like(X)]).T\nX_quad = np.vstack([X**2, X, np.ones_like(X)]).T\nparams_lin, *_ = np.linalg.lstsq(X_lin, y, rcond=None)\nparams_quad, *_ = np.linalg.lstsq(X_quad, y, rcond=None)\nprint(f\"Linear: y = {params_lin[0]:.4f}x + {params_lin[1]:.4f}\")\nprint(f\"Quadratic: y = {params_quad[0]:.4f}x\u00b2 + {params_quad[1]:.4f}x + {params_quad[2]:.4f}\")"
  },
  {
    "input": "Fit a cubic polynomial to symmetric pattern X = [-2, -1, 0, 1, 2], y = [-8, -1, 0, 1, 8].",
    "output": "import numpy as np\n\nX = np.array([-2, -1, 0, 1, 2])\ny = np.array([-8, -1, 0, 1, 8])\nX_poly = np.vstack([X**3, X**2, X, np.ones_like(X)]).T\nparams, *_ = np.linalg.lstsq(X_poly, y, rcond=None)\nprint(f\"Cubic Fit: y = {params[0]:.4f}x\u00b3 + {params[1]:.4f}x\u00b2 + {params[2]:.4f}x + {params[3]:.4f}\")"
  },
  {
    "input": "Estimate curve using degree-3 polynomial: X = [0, 2, 4, 6], y = [1, 4, 15, 40].",
    "output": "import numpy as np\n\nX = np.array([0, 2, 4, 6])\ny = np.array([1, 4, 15, 40])\nX_poly = np.vstack([X**3, X**2, X, np.ones_like(X)]).T\nparams, *_ = np.linalg.lstsq(X_poly, y, rcond=None)\nprint(f\"Polynomial Fit: y = {params[0]:.4f}x\u00b3 + {params[1]:.4f}x\u00b2 + {params[2]:.4f}x + {params[3]:.4f}\")"
  },
  {
    "input": "Fit a degree-5 polynomial to X = [0, 1, 2, 3, 4, 5], y = [1, 2, 3, 4, 3, 2].",
    "output": "import numpy as np\n\nX = np.array([0, 1, 2, 3, 4, 5])\ny = np.array([1, 2, 3, 4, 3, 2])\nX_poly = np.vstack([X**5, X**4, X**3, X**2, X, np.ones_like(X)]).T\nparams, *_ = np.linalg.lstsq(X_poly, y, rcond=None)\nprint(f\"Degree-5 Polynomial: y = {params[0]:.4f}x\u2075 + {params[1]:.4f}x\u2074 + {params[2]:.4f}x\u00b3 + {params[3]:.4f}x\u00b2 + {params[4]:.4f}x + {params[5]:.4f}\")"
  },
  {
    "input": "Fit a degree-2 polynomial to simulate noisy square growth: X = [0, 1, 2, 3], y = [0.1, 1.0, 4.2, 8.9].",
    "output": "import numpy as np\n\nX = np.array([0, 1, 2, 3])\ny = np.array([0.1, 1.0, 4.2, 8.9])\nX_poly = np.vstack([X**2, X, np.ones_like(X)]).T\nparams, *_ = np.linalg.lstsq(X_poly, y, rcond=None)\nprint(f\"Noisy Quadratic Fit: y = {params[0]:.4f}x\u00b2 + {params[1]:.4f}x + {params[2]:.4f}\")"
  },
  {
    "input": "Fit a degree-4 polynomial to model bumpy trend: X = [1, 2, 3, 4, 5], y = [2, 5, 3, 6, 4].",
    "output": "import numpy as np\n\nX = np.array([1, 2, 3, 4, 5])\ny = np.array([2, 5, 3, 6, 4])\nX_poly = np.vstack([X**4, X**3, X**2, X, np.ones_like(X)]).T\nparams, *_ = np.linalg.lstsq(X_poly, y, rcond=None)\nprint(f\"Bumpy Fit: y = {params[0]:.4f}x\u2074 + {params[1]:.4f}x\u00b3 + {params[2]:.4f}x\u00b2 + {params[3]:.4f}x + {params[4]:.4f}\")"
  },
  {
    "input": "Fit a degree-2 polynomial to model data: X = [-1, 0, 1, 2], y = [2, 1, 2, 5].",
    "output": "import numpy as np\n\nX = np.array([-1, 0, 1, 2])\ny = np.array([2, 1, 2, 5])\nX_poly = np.vstack([X**2, X, np.ones_like(X)]).T\nparams, *_ = np.linalg.lstsq(X_poly, y, rcond=None)\nprint(f\"Degree-2 Fit: y = {params[0]:.4f}x\u00b2 + {params[1]:.4f}x + {params[2]:.4f}\")"
  },
  {
    "input": "Approximate y = sin(x) over [0, \u03c0] using a degree-3 polynomial fit on X = [0, \u03c0/4, \u03c0/2, 3\u03c0/4, \u03c0].",
    "output": "import numpy as np\n\nX = np.array([0, np.pi/4, np.pi/2, 3*np.pi/4, np.pi])\ny = np.sin(X)\nX_poly = np.vstack([X**3, X**2, X, np.ones_like(X)]).T\nparams, *_ = np.linalg.lstsq(X_poly, y, rcond=None)\nprint(f\"Sine Approximation: y = {params[0]:.4f}x\u00b3 + {params[1]:.4f}x\u00b2 + {params[2]:.4f}x + {params[3]:.4f}\")"
  },
  {
    "input": "Fit a polynomial of degree 2 to data: X = [0, 1, 2, 3, 4], y = [1, 2.9, 7.8, 14.9, 24.2].",
    "output": "import numpy as np\n\nX = np.array([0, 1, 2, 3, 4])\ny = np.array([1, 2.9, 7.8, 14.9, 24.2])\nX_poly = np.vstack([X**2, X, np.ones_like(X)]).T\nparams, *_ = np.linalg.lstsq(X_poly, y, rcond=None)\nprint(f\"Quadratic Fit: y = {params[0]:.4f}x\u00b2 + {params[1]:.4f}x + {params[2]:.4f}\")"
  },
  {
    "input": "Fit a 4th-degree polynomial to data with fluctuations: X = [0, 1, 2, 3, 4, 5], y = [1, 3, 2, 4, 3, 5].",
    "output": "import numpy as np\n\nX = np.array([0, 1, 2, 3, 4, 5])\ny = np.array([1, 3, 2, 4, 3, 5])\nX_poly = np.vstack([X**4, X**3, X**2, X, np.ones_like(X)]).T\nparams, *_ = np.linalg.lstsq(X_poly, y, rcond=None)\nprint(f\"Fluctuating Fit: y = {params[0]:.4f}x\u2074 + {params[1]:.4f}x\u00b3 + {params[2]:.4f}x\u00b2 + {params[3]:.4f}x + {params[4]:.4f}\")"
  },
  {
    "input": "Fit a degree-3 polynomial to model trend: X = [-3, -2, -1, 0, 1, 2, 3], y = [-27, -8, -1, 0, 1, 8, 27].",
    "output": "import numpy as np\n\nX = np.array([-3, -2, -1, 0, 1, 2, 3])\ny = np.array([-27, -8, -1, 0, 1, 8, 27])\nX_poly = np.vstack([X**3, X**2, X, np.ones_like(X)]).T\nparams, *_ = np.linalg.lstsq(X_poly, y, rcond=None)\nprint(f\"Cubic Trend Fit: y = {params[0]:.4f}x\u00b3 + {params[1]:.4f}x\u00b2 + {params[2]:.4f}x + {params[3]:.4f}\")"
  },
  {
    "input": "Model exponential-like growth with a polynomial fit: X = [0, 1, 2, 3], y = [1, 3, 9, 27].",
    "output": "import numpy as np\n\nX = np.array([0, 1, 2, 3])\ny = np.array([1, 3, 9, 27])\nX_poly = np.vstack([X**3, X**2, X, np.ones_like(X)]).T\nparams, *_ = np.linalg.lstsq(X_poly, y, rcond=None)\nprint(f\"Approx. Exponential: y = {params[0]:.4f}x\u00b3 + {params[1]:.4f}x\u00b2 + {params[2]:.4f}x + {params[3]:.4f}\")"
  },
  {
    "input": "Fit a polynomial to model the bounce of a ball: X = [0, 1, 2, 3], y = [10, 5, 2.5, 1.25].",
    "output": "import numpy as np\n\nX = np.array([0, 1, 2, 3])\ny = np.array([10, 5, 2.5, 1.25])\nX_poly = np.vstack([X**3, X**2, X, np.ones_like(X)]).T\nparams, *_ = np.linalg.lstsq(X_poly, y, rcond=None)\nprint(f\"Bounce Approximation: y = {params[0]:.4f}x\u00b3 + {params[1]:.4f}x\u00b2 + {params[2]:.4f}x + {params[3]:.4f}\")"
  },
  {
    "input": "Fit a degree-3 polynomial to X = [0, 1, 2, 3], y = [1, 0, -1, 0].",
    "output": "import numpy as np\n\nX = np.array([0, 1, 2, 3])\ny = np.array([1, 0, -1, 0])\nX_poly = np.vstack([X**3, X**2, X, np.ones_like(X)]).T\nparams, *_ = np.linalg.lstsq(X_poly, y, rcond=None)\nprint(f\"Degree-3 Fit: y = {params[0]:.4f}x\u00b3 + {params[1]:.4f}x\u00b2 + {params[2]:.4f}x + {params[3]:.4f}\")"
  },
  {
    "input": "Fit a polynomial to model sensor drift: X = [0, 1, 2, 3, 4], y = [0.2, 1.1, 2.9, 4.2, 5.9].",
    "output": "import numpy as np\n\nX = np.array([0, 1, 2, 3, 4])\ny = np.array([0.2, 1.1, 2.9, 4.2, 5.9])\nX_poly = np.vstack([X**2, X, np.ones_like(X)]).T\nparams, *_ = np.linalg.lstsq(X_poly, y, rcond=None)\nprint(f\"Sensor Drift Model: y = {params[0]:.4f}x\u00b2 + {params[1]:.4f}x + {params[2]:.4f}\")"
  },
  {
    "input": "Fit a cubic polynomial to noisy cube: X = [0, 1, 2, 3, 4], y = [0, 1.2, 8.1, 27.5, 65].",
    "output": "import numpy as np\n\nX = np.array([0, 1, 2, 3, 4])\ny = np.array([0, 1.2, 8.1, 27.5, 65])\nX_poly = np.vstack([X**3, X**2, X, np.ones_like(X)]).T\nparams, *_ = np.linalg.lstsq(X_poly, y, rcond=None)\nprint(f\"Cubic Noise Fit: y = {params[0]:.4f}x\u00b3 + {params[1]:.4f}x\u00b2 + {params[2]:.4f}x + {params[3]:.4f}\")"
  },
  {
    "input": "Use Ridge Regression to fit X = [[1], [2], [3]], y = [1, 2, 3] with \u03bb=1.",
    "output": "import numpy as np\n\nX = np.array([[1], [2], [3]])\ny = np.array([1, 2, 3])\nlamb = 1\nX_aug = np.hstack([X, np.ones((3,1))])\nI = np.eye(X_aug.shape[1])\nparams = np.linalg.inv(X_aug.T @ X_aug + lamb * I) @ X_aug.T @ y\nprint(f\"Ridge Regression Model: y = {params[0]:.4f}x + {params[1]:.4f}\")"
  },
  {
    "input": "Fit regularized linear model to noisy linear data: X = [[1], [2], [3], [4]], y = [2.1, 4.2, 6.3, 8.1], \u03bb=0.5.",
    "output": "import numpy as np\n\nX = np.array([[1], [2], [3], [4]])\ny = np.array([2.1, 4.2, 6.3, 8.1])\nlamb = 0.5\nX_aug = np.hstack([X, np.ones((4,1))])\nI = np.eye(X_aug.shape[1])\nparams = np.linalg.inv(X_aug.T @ X_aug + lamb * I) @ X_aug.T @ y\nprint(f\"Ridge Fit: y = {params[0]:.4f}x + {params[1]:.4f}\")"
  },
  {
    "input": "Model X = [[1,2], [2,3], [3,4]], y = [6, 9, 12] using Ridge regression, \u03bb=2.",
    "output": "import numpy as np\n\nX = np.array([[1,2], [2,3], [3,4]])\ny = np.array([6, 9, 12])\nlamb = 2\nX_aug = np.hstack([X, np.ones((3,1))])\nI = np.eye(X_aug.shape[1])\nparams = np.linalg.inv(X_aug.T @ X_aug + lamb * I) @ X_aug.T @ y\nprint(f\"Ridge Model: y = {params[0]:.4f}x1 + {params[1]:.4f}x2 + {params[2]:.4f}\")"
  },
  {
    "input": "Fit Ridge Regression for high-dimensional case: X has shape (5, 10), y = [5, 10, 15, 20, 25], \u03bb=0.1.",
    "output": "import numpy as np\n\nnp.random.seed(0)\nX = np.random.rand(5, 10)\ny = np.array([5, 10, 15, 20, 25])\nlamb = 0.1\nX_aug = np.hstack([X, np.ones((5,1))])\nI = np.eye(X_aug.shape[1])\nparams = np.linalg.inv(X_aug.T @ X_aug + lamb * I) @ X_aug.T @ y\nprint(\"Ridge Coefficients:\")\nprint(params)"
  },
  {
    "input": "Test how increasing \u03bb affects the fit: X = [[1], [2], [3]], y = [1, 2, 3], \u03bb = 0.01 and 100.",
    "output": "import numpy as np\n\nX = np.array([[1], [2], [3]])\ny = np.array([1, 2, 3])\nX_aug = np.hstack([X, np.ones((3,1))])\nI = np.eye(X_aug.shape[1])\nfor lamb in [0.01, 100]:\n    params = np.linalg.inv(X_aug.T @ X_aug + lamb * I) @ X_aug.T @ y\n    print(f\"\u03bb={lamb}: y = {params[0]:.4f}x + {params[1]:.4f}\")"
  },
  {
    "input": "Apply Ridge to X = [[1, 0], [0, 1]], y = [1, 1] with a high \u03bb=1000.",
    "output": "import numpy as np\n\nX = np.array([[1, 0], [0, 1]])\ny = np.array([1, 1])\nlamb = 1000\nX_aug = np.hstack([X, np.ones((2,1))])\nI = np.eye(X_aug.shape[1])\nparams = np.linalg.inv(X_aug.T @ X_aug + lamb * I) @ X_aug.T @ y\nprint(\"With high \u03bb, coefficients shrink:\")\nprint(params)"
  },
  {
    "input": "Use Ridge with X = [[1, 1], [2, 2], [3, 3]], y = [2, 4, 6], \u03bb=0.1.",
    "output": "import numpy as np\n\nX = np.array([[1, 1], [2, 2], [3, 3]])\ny = np.array([2, 4, 6])\nlamb = 0.1\nX_aug = np.hstack([X, np.ones((3,1))])\nI = np.eye(X_aug.shape[1])\nparams = np.linalg.inv(X_aug.T @ X_aug + lamb * I) @ X_aug.T @ y\nprint(f\"Ridge output: y = {params[0]:.4f}x1 + {params[1]:.4f}x2 + {params[2]:.4f}\")"
  },
  {
    "input": "Ridge fit for polynomial features: x = [1, 2, 3], y = [1, 4, 9], \u03bb=1.",
    "output": "import numpy as np\n\nx = np.array([1, 2, 3])\nX = np.vstack([x**2, x, np.ones_like(x)]).T\ny = np.array([1, 4, 9])\nlamb = 1\nI = np.eye(X.shape[1])\nparams = np.linalg.inv(X.T @ X + lamb * I) @ X.T @ y\nprint(f\"Ridge poly fit: y = {params[0]:.4f}x^2 + {params[1]:.4f}x + {params[2]:.4f}\")"
  },
  {
    "input": "Ridge on symbolic matrix X = [[x1, x2], [x3, x4]] not supported; give numerical example.",
    "output": "import numpy as np\n\nX = np.array([[1, 2], [3, 4]])\ny = np.array([5, 11])\nlamb = 0.5\nX_aug = np.hstack([X, np.ones((2,1))])\nI = np.eye(X_aug.shape[1])\nparams = np.linalg.inv(X_aug.T @ X_aug + lamb * I) @ X_aug.T @ y\nprint(\"Ridge with dummy values:\")\nprint(params)"
  },
  {
    "input": "Apply Ridge Regression on random (100, 5) dataset, \u03bb=0.01.",
    "output": "import numpy as np\n\nnp.random.seed(42)\nX = np.random.randn(100, 5)\ny = X @ np.array([2, -1, 0.5, 3, 1]) + np.random.randn(100)\nlamb = 0.01\nX_aug = np.hstack([X, np.ones((100,1))])\nI = np.eye(X_aug.shape[1])\nparams = np.linalg.inv(X_aug.T @ X_aug + lamb * I) @ X_aug.T @ y\nprint(\"Trained Ridge Parameters:\")\nprint(params)"
  },
  {
    "input": "Fit Ridge model for dataset with multicollinearity: X = [[1, 2], [2, 4], [3, 6]], y = [3, 6, 9], \u03bb=1.",
    "output": "import numpy as np\n\nX = np.array([[1, 2], [2, 4], [3, 6]])\ny = np.array([3, 6, 9])\nlamb = 1\nX_aug = np.hstack([X, np.ones((3, 1))])\nI = np.eye(X_aug.shape[1])\nparams = np.linalg.inv(X_aug.T @ X_aug + lamb * I) @ X_aug.T @ y\nprint(f\"Ridge with multicollinearity: y = {params[0]:.4f}x1 + {params[1]:.4f}x2 + {params[2]:.4f}\")"
  },
  {
    "input": "Check ridge coefficients shrinkage: X = [[1, 1], [2, 2], [3, 3]], y = [2, 4, 6], \u03bb=10.",
    "output": "import numpy as np\n\nX = np.array([[1, 1], [2, 2], [3, 3]])\ny = np.array([2, 4, 6])\nlamb = 10\nX_aug = np.hstack([X, np.ones((3, 1))])\nI = np.eye(X_aug.shape[1])\nparams = np.linalg.inv(X_aug.T @ X_aug + lamb * I) @ X_aug.T @ y\nprint(\"Shrinked Ridge Coefficients:\")\nprint(params)"
  },
  {
    "input": "Use ridge regression for underdetermined system: X = [[1,2,3],[4,5,6]], y = [1,2], \u03bb=0.5.",
    "output": "import numpy as np\n\nX = np.array([[1, 2, 3], [4, 5, 6]])\ny = np.array([1, 2])\nlamb = 0.5\nX_aug = np.hstack([X, np.ones((2, 1))])\nI = np.eye(X_aug.shape[1])\nparams = np.linalg.inv(X_aug.T @ X_aug + lamb * I) @ X_aug.T @ y\nprint(\"Underdetermined Ridge Fit:\")\nprint(params)"
  },
  {
    "input": "Use Ridge Regression on noisy linear relation: y = 3x + noise, x in range(1,6), \u03bb=0.1.",
    "output": "import numpy as np\n\nx = np.arange(1, 6)\ny = 3 * x + np.random.normal(0, 1, size=5)\nX = np.vstack([x]).T\nX_aug = np.hstack([X, np.ones((5, 1))])\nlamb = 0.1\nI = np.eye(X_aug.shape[1])\nparams = np.linalg.inv(X_aug.T @ X_aug + lamb * I) @ X_aug.T @ y\nprint(f\"Ridge with noise: y = {params[0]:.4f}x + {params[1]:.4f}\")"
  },
  {
    "input": "Ridge regression with polynomial features x^3, x^2, x, and constant: x = [1,2,3,4], y = [3,6,11,18], \u03bb=0.5.",
    "output": "import numpy as np\n\nx = np.array([1, 2, 3, 4])\ny = np.array([3, 6, 11, 18])\nX = np.vstack([x**3, x**2, x, np.ones_like(x)]).T\nlamb = 0.5\nI = np.eye(X.shape[1])\nparams = np.linalg.inv(X.T @ X + lamb * I) @ X.T @ y\nprint(f\"y = {params[0]:.4f}x^3 + {params[1]:.4f}x^2 + {params[2]:.4f}x + {params[3]:.4f}\")"
  },
  {
    "input": "Create a ridge model with categorical one-hot data: X = [[1,0], [0,1], [1,0]], y = [5, 3, 6], \u03bb=1.",
    "output": "import numpy as np\n\nX = np.array([[1,0], [0,1], [1,0]])\ny = np.array([5, 3, 6])\nlamb = 1\nX_aug = np.hstack([X, np.ones((3, 1))])\nI = np.eye(X_aug.shape[1])\nparams = np.linalg.inv(X_aug.T @ X_aug + lamb * I) @ X_aug.T @ y\nprint(\"Ridge with one-hot categorical data:\")\nprint(params)"
  },
  {
    "input": "Use ridge regression with correlated features: X = [[1,1], [2,2], [3,3]], y = [2,4,6], \u03bb=100.",
    "output": "import numpy as np\n\nX = np.array([[1,1], [2,2], [3,3]])\ny = np.array([2,4,6])\nlamb = 100\nX_aug = np.hstack([X, np.ones((3,1))])\nI = np.eye(X_aug.shape[1])\nparams = np.linalg.inv(X_aug.T @ X_aug + lamb * I) @ X_aug.T @ y\nprint(f\"High \u03bb Ridge Fit: y = {params[0]:.4f}x1 + {params[1]:.4f}x2 + {params[2]:.4f}\")"
  },
  {
    "input": "Compare unregularized vs ridge: X = [[1], [2], [3]], y = [2, 4, 6], \u03bb=0 and \u03bb=10.",
    "output": "import numpy as np\n\nX = np.array([[1], [2], [3]])\ny = np.array([2, 4, 6])\nX_aug = np.hstack([X, np.ones((3,1))])\nI = np.eye(X_aug.shape[1])\nfor lamb in [0, 10]:\n    params = np.linalg.inv(X_aug.T @ X_aug + lamb * I) @ X_aug.T @ y\n    print(f\"\u03bb={lamb}: y = {params[0]:.4f}x + {params[1]:.4f}\")"
  },
  {
    "input": "Apply ridge regression on data with outlier: X = [[1], [2], [3], [10]], y = [2, 4, 6, 30], \u03bb=1.",
    "output": "import numpy as np\n\nX = np.array([[1], [2], [3], [10]])\ny = np.array([2, 4, 6, 30])\nlamb = 1\nX_aug = np.hstack([X, np.ones((4,1))])\nI = np.eye(X_aug.shape[1])\nparams = np.linalg.inv(X_aug.T @ X_aug + lamb * I) @ X_aug.T @ y\nprint(f\"Ridge fit with outlier: y = {params[0]:.4f}x + {params[1]:.4f}\")"
  },
  {
    "input": "Use Ridge for a flat data scenario: X = [[0], [0], [0]], y = [1, 1, 1], \u03bb=1.",
    "output": "import numpy as np\n\nX = np.array([[0], [0], [0]])\ny = np.array([1, 1, 1])\nlamb = 1\nX_aug = np.hstack([X, np.ones((3,1))])\nI = np.eye(X_aug.shape[1])\nparams = np.linalg.inv(X_aug.T @ X_aug + lamb * I) @ X_aug.T @ y\nprint(\"Flat data Ridge model:\")\nprint(params)"
  },
  {
    "input": "Use Lasso on a dataset with one irrelevant feature: X = [[1, 100], [2, 200], [3, 300]], y = [2, 4, 6], \u03b1=0.5.",
    "output": "from sklearn.linear_model import Lasso\nimport numpy as np\n\nX = np.array([[1, 100], [2, 200], [3, 300]])\ny = np.array([2, 4, 6])\nmodel = Lasso(alpha=0.5)\nmodel.fit(X, y)\nprint(f\"Coefficients: {model.coef_}, Intercept: {model.intercept_:.4f}\")"
  },
  {
    "input": "Perform Lasso regression on sparse data: X = [[0, 0], [1, 0], [0, 1]], y = [0, 1, 1], \u03b1=0.1.",
    "output": "from sklearn.linear_model import Lasso\nimport numpy as np\n\nX = np.array([[0, 0], [1, 0], [0, 1]])\ny = np.array([0, 1, 1])\nmodel = Lasso(alpha=0.1)\nmodel.fit(X, y)\nprint(f\"Coefficients: {model.coef_}, Intercept: {model.intercept_:.4f}\")"
  },
  {
    "input": "Apply Lasso to eliminate redundant predictors: X = [[1, 1, 1], [2, 2, 2], [3, 3, 3]], y = [1, 2, 3], \u03b1=5.",
    "output": "from sklearn.linear_model import Lasso\nimport numpy as np\n\nX = np.array([[1, 1, 1], [2, 2, 2], [3, 3, 3]])\ny = np.array([1, 2, 3])\nmodel = Lasso(alpha=5)\nmodel.fit(X, y)\nprint(\"Coefficients:\", model.coef_)\nprint(\"Intercept:\", model.intercept_)"
  },
  {
    "input": "Test Lasso with polynomial features: x = [1,2,3], y = [1,4,9], \u03b1=0.01.",
    "output": "from sklearn.linear_model import Lasso\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.pipeline import make_pipeline\nimport numpy as np\n\nx = np.array([1,2,3]).reshape(-1,1)\ny = np.array([1,4,9])\nmodel = make_pipeline(PolynomialFeatures(2), Lasso(alpha=0.01))\nmodel.fit(x, y)\nprint(f\"Coefficients: {model.named_steps['lasso'].coef_}\")"
  },
  {
    "input": "Use Lasso on standardized data: X = [[1, 10], [2, 20], [3, 30]], y = [1, 2, 3], \u03b1=0.2.",
    "output": "from sklearn.linear_model import Lasso\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import make_pipeline\nimport numpy as np\n\nX = np.array([[1,10],[2,20],[3,30]])\ny = np.array([1,2,3])\nmodel = make_pipeline(StandardScaler(), Lasso(alpha=0.2))\nmodel.fit(X, y)\nprint(f\"Coefficients: {model.named_steps['lasso'].coef_}\")"
  },
  {
    "input": "Demonstrate sparse solution from Lasso: X = [[1,2,3], [4,5,6], [7,8,9]], y = [1,2,3], \u03b1=100.",
    "output": "from sklearn.linear_model import Lasso\nimport numpy as np\n\nX = np.array([[1,2,3], [4,5,6], [7,8,9]])\ny = np.array([1,2,3])\nmodel = Lasso(alpha=100)\nmodel.fit(X, y)\nprint(\"Lasso Coefficients:\", model.coef_)\nprint(\"Intercept:\", model.intercept_)"
  },
  {
    "input": "Compare Lasso and OLS: X = [[1], [2], [3]], y = [1.1, 2.1, 3.1], \u03b1=0.01.",
    "output": "from sklearn.linear_model import Lasso, LinearRegression\nimport numpy as np\n\nX = np.array([[1],[2],[3]])\ny = np.array([1.1, 2.1, 3.1])\nlasso = Lasso(alpha=0.01)\nols = LinearRegression()\nlasso.fit(X, y)\nols.fit(X, y)\nprint(f\"Lasso Coef: {lasso.coef_[0]:.4f}, OLS Coef: {ols.coef_[0]:.4f}\")"
  },
  {
    "input": "Apply Lasso with redundant and irrelevant features. X = [[1, 1, 100], [2, 2, 200], [3, 3, 300]], y = [2, 4, 6], \u03b1=0.3.",
    "output": "from sklearn.linear_model import Lasso\nimport numpy as np\n\nX = np.array([[1,1,100],[2,2,200],[3,3,300]])\ny = np.array([2,4,6])\nmodel = Lasso(alpha=0.3)\nmodel.fit(X, y)\nprint(\"Lasso Coefficients:\", model.coef_)\nprint(\"Intercept:\", model.intercept_)"
  },
  {
    "input": "Use Lasso on categorical encoded data: X = [[1,0], [0,1], [1,0]], y = [5, 7, 6], \u03b1=0.05.",
    "output": "from sklearn.linear_model import Lasso\nimport numpy as np\n\nX = np.array([[1,0], [0,1], [1,0]])\ny = np.array([5,7,6])\nmodel = Lasso(alpha=0.05)\nmodel.fit(X, y)\nprint(\"Coefficients:\", model.coef_)\nprint(\"Intercept:\", model.intercept_)"
  },
  {
    "input": "Perform Lasso on small dataset with more features than samples: X = [[1,2,3],[4,5,6]], y = [1,2], \u03b1=0.1.",
    "output": "from sklearn.linear_model import Lasso\nimport numpy as np\n\nX = np.array([[1,2,3],[4,5,6]])\ny = np.array([1,2])\nmodel = Lasso(alpha=0.1, max_iter=10000)\nmodel.fit(X, y)\nprint(\"Coefficients:\", model.coef_)\nprint(\"Intercept:\", model.intercept_)"
  },
  {
    "input": "Lasso regression on dataset with outliers: X = [[1], [2], [3], [100]], y = [1, 2, 3, 100], \u03b1=0.1.",
    "output": "from sklearn.linear_model import Lasso\nimport numpy as np\n\nX = np.array([[1],[2],[3],[100]])\ny = np.array([1,2,3,100])\nmodel = Lasso(alpha=0.1)\nmodel.fit(X, y)\nprint(\"Coefficient:\", model.coef_[0])\nprint(\"Intercept:\", model.intercept_)"
  },
  {
    "input": "Show Lasso shrinkage: X = [[1,0], [2,0], [3,0]], y = [1,2,3], \u03b1=0.5.",
    "output": "from sklearn.linear_model import Lasso\nimport numpy as np\n\nX = np.array([[1,0],[2,0],[3,0]])\ny = np.array([1,2,3])\nmodel = Lasso(alpha=0.5)\nmodel.fit(X, y)\nprint(\"Coefficients:\", model.coef_)\nprint(\"Intercept:\", model.intercept_)"
  },
  {
    "input": "Lasso regression with sklearn's built-in LassoCV for \u03b1 selection. X = [[1,2],[2,3],[3,4]], y = [3,5,7].",
    "output": "from sklearn.linear_model import LassoCV\nimport numpy as np\n\nX = np.array([[1,2],[2,3],[3,4]])\ny = np.array([3,5,7])\nmodel = LassoCV(cv=3).fit(X, y)\nprint(f\"Best \u03b1: {model.alpha_:.4f}, Coefficients: {model.coef_}\")"
  },
  {
    "input": "Use Lasso on multicollinear data: X = [[1,2], [2,4], [3,6]], y = [2, 4, 6], \u03b1=0.3.",
    "output": "from sklearn.linear_model import Lasso\nimport numpy as np\n\nX = np.array([[1,2],[2,4],[3,6]])\ny = np.array([2,4,6])\nmodel = Lasso(alpha=0.3)\nmodel.fit(X, y)\nprint(\"Coefficients:\", model.coef_)\nprint(\"Intercept:\", model.intercept_)"
  },
  {
    "input": "Apply Lasso to a dataset where one feature is strongly correlated with the target. X = [[1, 0], [2, 0], [3, 0]], y = [2, 4, 6], \u03b1=0.1.",
    "output": "from sklearn.linear_model import Lasso\nimport numpy as np\n\nX = np.array([[1, 0], [2, 0], [3, 0]])\ny = np.array([2, 4, 6])\nmodel = Lasso(alpha=0.1)\nmodel.fit(X, y)\nprint(\"Coefficients:\", model.coef_)\nprint(\"Intercept:\", model.intercept_)"
  },
  {
    "input": "Run Lasso on a feature matrix with a constant column: X = [[1, 5], [2, 5], [3, 5]], y = [3, 5, 7], \u03b1=0.2.",
    "output": "from sklearn.linear_model import Lasso\nimport numpy as np\n\nX = np.array([[1, 5], [2, 5], [3, 5]])\ny = np.array([3, 5, 7])\nmodel = Lasso(alpha=0.2)\nmodel.fit(X, y)\nprint(\"Lasso Coefficients:\", model.coef_)\nprint(\"Intercept:\", model.intercept_)"
  },
  {
    "input": "Evaluate Lasso on noisy linear data: X = [[1], [2], [3], [4]], y = [2.1, 3.9, 6.2, 8.1], \u03b1=0.05.",
    "output": "from sklearn.linear_model import Lasso\nimport numpy as np\n\nX = np.array([[1], [2], [3], [4]])\ny = np.array([2.1, 3.9, 6.2, 8.1])\nmodel = Lasso(alpha=0.05)\nmodel.fit(X, y)\nprint(\"Coefficient:\", model.coef_[0])\nprint(\"Intercept:\", model.intercept_)"
  },
  {
    "input": "Use Lasso with feature selection in high-dimensional setting: X = [[1,2,0],[3,4,0],[5,6,0]], y = [1,3,5], \u03b1=0.5.",
    "output": "from sklearn.linear_model import Lasso\nimport numpy as np\n\nX = np.array([[1,2,0],[3,4,0],[5,6,0]])\ny = np.array([1,3,5])\nmodel = Lasso(alpha=0.5)\nmodel.fit(X, y)\nprint(\"Selected features:\", model.coef_)\nprint(\"Intercept:\", model.intercept_)"
  },
  {
    "input": "Show effect of high regularization with Lasso: X = [[1, 2], [2, 4], [3, 6]], y = [1, 2, 3], \u03b1=10.",
    "output": "from sklearn.linear_model import Lasso\nimport numpy as np\n\nX = np.array([[1, 2], [2, 4], [3, 6]])\ny = np.array([1, 2, 3])\nmodel = Lasso(alpha=10)\nmodel.fit(X, y)\nprint(\"Lasso Coefficients:\", model.coef_)\nprint(\"Intercept:\", model.intercept_)"
  },
  {
    "input": "Lasso regression on scaled polynomial features. X = [[1], [2], [3]], y = [1, 4, 9], \u03b1=0.1.",
    "output": "from sklearn.linear_model import Lasso\nfrom sklearn.preprocessing import PolynomialFeatures, StandardScaler\nfrom sklearn.pipeline import make_pipeline\nimport numpy as np\n\nX = np.array([[1], [2], [3]])\ny = np.array([1, 4, 9])\nmodel = make_pipeline(PolynomialFeatures(2), StandardScaler(), Lasso(alpha=0.1))\nmodel.fit(X, y)\nprint(\"Coefficients:\", model.named_steps['lasso'].coef_)"
  },
  {
    "input": "Predict with Lasso after training: X_train = [[1,2],[3,4]], y_train = [5,6], X_test = [[2,3]].",
    "output": "from sklearn.linear_model import Lasso\nimport numpy as np\n\nX_train = np.array([[1,2],[3,4]])\ny_train = np.array([5,6])\nX_test = np.array([[2,3]])\nmodel = Lasso(alpha=0.1)\nmodel.fit(X_train, y_train)\npred = model.predict(X_test)\nprint(\"Prediction:\", pred[0])"
  },
  {
    "input": "Use Lasso on highly correlated features: X = [[1,2],[2,4],[3,6]], y = [1,2,3], \u03b1=0.4.",
    "output": "from sklearn.linear_model import Lasso\nimport numpy as np\n\nX = np.array([[1,2],[2,4],[3,6]])\ny = np.array([1,2,3])\nmodel = Lasso(alpha=0.4)\nmodel.fit(X, y)\nprint(\"Coefficients:\", model.coef_)\nprint(\"Intercept:\", model.intercept_)"
  },
  {
    "input": "Fit Lasso with sklearn pipeline: include standardization. X = [[1,10], [2,20], [3,30]], y = [3,5,7].",
    "output": "from sklearn.linear_model import Lasso\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import StandardScaler\nimport numpy as np\n\nX = np.array([[1,10],[2,20],[3,30]])\ny = np.array([3,5,7])\nmodel = make_pipeline(StandardScaler(), Lasso(alpha=0.1))\nmodel.fit(X, y)\nprint(\"Coefficients:\", model.named_steps['lasso'].coef_)"
  },
  {
    "input": "Apply Lasso with high alpha to force zero coefficients: X = [[1,2], [2,3], [3,4]], y = [3,4,5], \u03b1=100.",
    "output": "from sklearn.linear_model import Lasso\nimport numpy as np\n\nX = np.array([[1,2], [2,3], [3,4]])\ny = np.array([3,4,5])\nmodel = Lasso(alpha=100)\nmodel.fit(X, y)\nprint(\"Coefficients after shrinkage:\", model.coef_)\nprint(\"Intercept:\", model.intercept_)"
  },
  {
    "input": "Use Lasso on binary feature matrix: X = [[1,0,0],[0,1,0],[0,0,1]], y = [1,2,3], \u03b1=0.2.",
    "output": "from sklearn.linear_model import Lasso\nimport numpy as np\n\nX = np.array([[1,0,0],[0,1,0],[0,0,1]])\ny = np.array([1,2,3])\nmodel = Lasso(alpha=0.2)\nmodel.fit(X, y)\nprint(\"Lasso Coefficients:\", model.coef_)\nprint(\"Intercept:\", model.intercept_)"
  },
  {
    "input": "Perform Lasso with PolynomialFeatures and interpret output. X = [[1], [2], [3]], y = [2, 5, 10], \u03b1=0.01.",
    "output": "from sklearn.pipeline import make_pipeline\nfrom sklearn.linear_model import Lasso\nfrom sklearn.preprocessing import PolynomialFeatures\nimport numpy as np\n\nX = np.array([[1], [2], [3]])\ny = np.array([2, 5, 10])\nmodel = make_pipeline(PolynomialFeatures(2), Lasso(alpha=0.01))\nmodel.fit(X, y)\nprint(\"Polynomial Coefficients:\", model.named_steps['lasso'].coef_)"
  },
  {
    "input": "Use Lasso on dataset with small magnitude targets: X = [[1,2], [3,4], [5,6]], y = [0.01, 0.02, 0.03], \u03b1=0.001.",
    "output": "from sklearn.linear_model import Lasso\nimport numpy as np\n\nX = np.array([[1,2],[3,4],[5,6]])\ny = np.array([0.01, 0.02, 0.03])\nmodel = Lasso(alpha=0.001)\nmodel.fit(X, y)\nprint(\"Coefficients:\", model.coef_)\nprint(\"Intercept:\", model.intercept_)"
  },
  {
    "input": "Use Lasso to estimate relationship in overfit situation. X = [[1,1,1],[2,2,2],[3,3,3]], y = [3,6,9], \u03b1=1.",
    "output": "from sklearn.linear_model import Lasso\nimport numpy as np\n\nX = np.array([[1,1,1],[2,2,2],[3,3,3]])\ny = np.array([3,6,9])\nmodel = Lasso(alpha=1)\nmodel.fit(X, y)\nprint(\"Lasso Coefficients:\", model.coef_)\nprint(\"Intercept:\", model.intercept_)"
  },
  {
    "input": "Apply Ridge regression to a simple dataset: X = [[1], [2], [3]], y = [1, 2, 3], \u03b1=0.1.",
    "output": "from sklearn.linear_model import Ridge\nimport numpy as np\n\nX = np.array([[1], [2], [3]])\ny = np.array([1, 2, 3])\nmodel = Ridge(alpha=0.1)\nmodel.fit(X, y)\nprint(\"Coefficients:\", model.coef_)\nprint(\"Intercept:\", model.intercept_)"
  },
  {
    "input": "Use Ridge regression with multiple features: X = [[1,2], [3,4], [5,6]], y = [1,2,3], \u03b1=0.5.",
    "output": "from sklearn.linear_model import Ridge\nimport numpy as np\n\nX = np.array([[1,2], [3,4], [5,6]])\ny = np.array([1,2,3])\nmodel = Ridge(alpha=0.5)\nmodel.fit(X, y)\nprint(\"Coefficients:\", model.coef_)\nprint(\"Intercept:\", model.intercept_)"
  },
  {
    "input": "Fit Ridge regression on noisy data: X = [[1], [2], [3], [4]], y = [2.1, 4.2, 6.3, 8.4], \u03b1=0.05.",
    "output": "from sklearn.linear_model import Ridge\nimport numpy as np\n\nX = np.array([[1], [2], [3], [4]])\ny = np.array([2.1, 4.2, 6.3, 8.4])\nmodel = Ridge(alpha=0.05)\nmodel.fit(X, y)\nprint(\"Coefficient:\", model.coef_[0])\nprint(\"Intercept:\", model.intercept_)"
  },
  {
    "input": "Use Ridge to prevent overfitting in high-dimensional data: X = [[1,2,3], [4,5,6], [7,8,9]], y = [3,6,9], \u03b1=1.",
    "output": "from sklearn.linear_model import Ridge\nimport numpy as np\n\nX = np.array([[1,2,3], [4,5,6], [7,8,9]])\ny = np.array([3,6,9])\nmodel = Ridge(alpha=1)\nmodel.fit(X, y)\nprint(\"Ridge Coefficients:\", model.coef_)\nprint(\"Intercept:\", model.intercept_)"
  },
  {
    "input": "Perform Ridge regression with a polynomial feature matrix: X = [[1], [2], [3]], y = [1, 2, 4], \u03b1=0.2.",
    "output": "from sklearn.linear_model import Ridge\nfrom sklearn.preprocessing import PolynomialFeatures\nimport numpy as np\n\nX = np.array([[1], [2], [3]])\ny = np.array([1, 2, 4])\npoly = PolynomialFeatures(degree=2)\nX_poly = poly.fit_transform(X)\nmodel = Ridge(alpha=0.2)\nmodel.fit(X_poly, y)\nprint(\"Coefficients:\", model.coef_)\nprint(\"Intercept:\", model.intercept_)"
  },
  {
    "input": "Use Ridge with cross-validation for model selection. X = [[1, 2], [2, 3], [3, 4]], y = [1, 3, 5], \u03b1=0.3.",
    "output": "from sklearn.linear_model import RidgeCV\nimport numpy as np\n\nX = np.array([[1,2], [2,3], [3,4]])\ny = np.array([1,3,5])\nmodel = RidgeCV(alphas=[0.1, 0.3, 1.0], store_cv_values=True)\nmodel.fit(X, y)\nprint(\"Best Alpha:\", model.alpha_)\nprint(\"Coefficients:\", model.coef_)\nprint(\"Intercept:\", model.intercept_)"
  },
  {
    "input": "Fit Ridge regression on scaled features: X = [[1], [2], [3]], y = [1, 2, 3], \u03b1=0.5.",
    "output": "from sklearn.linear_model import Ridge\nfrom sklearn.preprocessing import StandardScaler\nimport numpy as np\n\nX = np.array([[1], [2], [3]])\ny = np.array([1, 2, 3])\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\nmodel = Ridge(alpha=0.5)\nmodel.fit(X_scaled, y)\nprint(\"Coefficients:\", model.coef_)\nprint(\"Intercept:\", model.intercept_)"
  },
  {
    "input": "Apply Ridge regression with high regularization: X = [[1, 2], [3, 4], [5, 6]], y = [10, 20, 30], \u03b1=100.",
    "output": "from sklearn.linear_model import Ridge\nimport numpy as np\n\nX = np.array([[1, 2], [3, 4], [5, 6]])\ny = np.array([10, 20, 30])\nmodel = Ridge(alpha=100)\nmodel.fit(X, y)\nprint(\"Ridge Coefficients:\", model.coef_)\nprint(\"Intercept:\", model.intercept_)"
  },
  {
    "input": "Perform Ridge regression for high-dimensional feature matrix: X = [[1, 2, 3], [4, 5, 6], [7, 8, 9]], y = [1, 2, 3], \u03b1=0.7.",
    "output": "from sklearn.linear_model import Ridge\nimport numpy as np\n\nX = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\ny = np.array([1, 2, 3])\nmodel = Ridge(alpha=0.7)\nmodel.fit(X, y)\nprint(\"Ridge Coefficients:\", model.coef_)\nprint(\"Intercept:\", model.intercept_)"
  },
  {
    "input": "Fit Ridge regression on noisy data with outliers: X = [[1, 1], [2, 2], [100, 100]], y = [2, 4, 100], \u03b1=0.1.",
    "output": "from sklearn.linear_model import Ridge\nimport numpy as np\n\nX = np.array([[1,1], [2,2], [100,100]])\ny = np.array([2,4,100])\nmodel = Ridge(alpha=0.1)\nmodel.fit(X, y)\nprint(\"Ridge Coefficients:\", model.coef_)\nprint(\"Intercept:\", model.intercept_)"
  },
  {
    "input": "Evaluate Ridge regression performance with different alphas: X = [[1, 2], [2, 3], [3, 4]], y = [5, 7, 9], \u03b1=0.2.",
    "output": "from sklearn.linear_model import RidgeCV\nimport numpy as np\n\nX = np.array([[1,2], [2,3], [3,4]])\ny = np.array([5,7,9])\nmodel = RidgeCV(alphas=[0.1, 0.2, 0.5], store_cv_values=True)\nmodel.fit(X, y)\nprint(\"Best Alpha:\", model.alpha_)\nprint(\"Ridge Coefficients:\", model.coef_)\nprint(\"Intercept:\", model.intercept_)"
  }
]
